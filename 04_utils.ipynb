{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Provides utility functions and classes\n",
    "output-file: utils.html\n",
    "title: Utils module\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from collections.abc import Iterable\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "from redis import Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generateComplementDict(seqType='DNA',isDict=True):\n",
    "    '''\n",
    "    The function `generateComplementDict` generates a dictionary\n",
    "    for complementing the DNA sequence. It can be applied to RNA to identify inverted sequences.\n",
    "\n",
    "    `seqType`: str, Can be either 'DNA' or 'RNA' at the moment. If 'DNA', then the complement\n",
    "    to four known nucleotide (A, C, G, T) will be provided. All other letters (B, D, H, U, N and\n",
    "    all others) will be translated to N.\n",
    "    '''\n",
    "    fromstr = 'ACGTURYKMSWBDHVN-'\n",
    "    tostr = 'TGCAAYRMKSWVHDBN-'\n",
    "    if seqType.upper()=='DNA':\n",
    "        fromLetters = list(fromstr)\n",
    "        toLetters = list(tostr)\n",
    "    elif seqType.upper()=='RNA':\n",
    "        fromLetters = list(fromstr.lower())\n",
    "        toLetters = list(tostr.lower())\n",
    "    else:\n",
    "        raise ValueError(f\"`seqType can be either 'DNA' or 'RNA', but '{seqType}' was given\")\n",
    "\n",
    "\n",
    "    if isDict:\n",
    "        res = {}\n",
    "\n",
    "        for fl,tl in zip(fromLetters,toLetters):\n",
    "            res[fl] = tl\n",
    "    else:\n",
    "        res = str.maketrans(fromLetters,toLetters)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def complementSequence(seq,complementDict='DNA'):\n",
    "    if isinstance(complementDict,str):\n",
    "        compDict = generateComplementDict(seqType=complementDict)\n",
    "    elif isinstance(complementDict,dict):\n",
    "        compDict = complementDict\n",
    "    else:\n",
    "        raise ValueError(f'`complementDict` can be either string \"DNA\" or \"RNA\" or dict, but {type(complementDict)} is given.')\n",
    "    return seq.translate(str.maketrans(compDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def reverseSequence(seq):\n",
    "    return seq[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def inverseSequence(seq,complementDict='DNA'):\n",
    "    return complementSequence(reverseSequence(seq),complementDict=complementDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other file operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkNodeLengthsFile(GFAPath):\n",
    "    directory = os.path.dirname(GFAPath)\n",
    "    filebase = os.path.splitext(os.path.basename(GFAPath))[0]\n",
    "    nodeLenPath = f'{directory}{os.path.sep}nodeLengths_{filebase}.dat'\n",
    "    \n",
    "    if os.path.exists(nodeLenPath):\n",
    "        return joblib.load(nodeLenPath)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path files operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sortAccessions(sort,_paths):\n",
    "    paths = {}\n",
    "    if isinstance(sort,bool):\n",
    "        for accession in sorted(list(_paths.keys())):\n",
    "            paths[accession] = _paths[accession]\n",
    "    elif isinstance(sort,str):\n",
    "        pathNamesList = list(_paths.keys())\n",
    "        try:\n",
    "            paths[sort] = _paths[sort]\n",
    "            pathNamesList.remove(sort)\n",
    "        except KeyError:\n",
    "            Warning(f'Path name {sort} was not found in path file. All paths are sorted in lexicographic order')\n",
    "        for accession in sorted(pathNamesList):\n",
    "            paths[accession] = _paths[accession]\n",
    "    elif isinstance(sort,Iterable):\n",
    "        pathNamesList = list(_paths.keys())\n",
    "        for pathInd in sort:\n",
    "            accession = pathNamesList[pathInd]\n",
    "            paths[accession] = _path[accession]\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pathFileToPathDict(filePath,directional=True,sort=True,v2=True):\n",
    "    '''\n",
    "    Reads path file (ASCII file) and translates it to path dictionary for `GenGraph` class constructor.\n",
    "    \n",
    "    Path file has a path on each line in the following format:\n",
    "    <path name>: <nodeID[+|-]>[,<nodeID[+,-]>]\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    `filePath`: str. Absolute path to the path file.\n",
    "    `directional`: boolean (default: True). Whether the path file contains \n",
    "                   directionality (whether nodeID has `+` or `-` at the end). \n",
    "                   If False (the file does not contain directionality marks), \n",
    "                   then all nodes in all paths are treated as positive (not inverted).\n",
    "    `sort`: boolean, str or iterable (e.g. list). If Boolean, true means that the paths should be sorted\n",
    "            in lexicographic order (by names) and appear in the path dict in sorted order. If False,\n",
    "            then no sorting is done and paths will appear as they are in the file. If iterable with \n",
    "            indexes of the paths (from 0 to n-1 for n paths), then this particular order will be used\n",
    "            in the paths dictionary. If str, then it should provide a single path name that should appear \n",
    "            first with the rest being sorted in lexicographic order.\n",
    "            \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    `paths`: a dictionary with path names as keys and lists of nodeID (str) with directionality markers (`+` or `-`) \n",
    "             at the end as values.\n",
    "    \n",
    "    '''\n",
    "    _paths = {}\n",
    "    with open(filePath) as f:\n",
    "        for line in f:\n",
    "            pathNameChr,pathNodeList = line.strip(' \\n\\t').split(':')\n",
    "            if v2:\n",
    "                pathName,seqID = [name.strip() for name in pathNameChr.split('-')]\n",
    "            else:\n",
    "                pathName = pathNameChr.strip()\n",
    "                seqID = None\n",
    "            if directional:\n",
    "                chainList = [nodedir.strip() for nodedir in pathNodeList.strip().split(',')]\n",
    "            else:\n",
    "                chainList = [f'{node.strip()}+' for node in pathNodeList.strip().split(',')]\n",
    "            \n",
    "            if v2:\n",
    "                _paths.setdefault(seqID,{})[pathName] = chainList\n",
    "            else:\n",
    "                _paths[pathName] = chainList\n",
    "            \n",
    "    if isinstance(sort,bool):\n",
    "        if sort:\n",
    "            if v2:\n",
    "                paths = {}\n",
    "                for seqID in _paths.keys():\n",
    "                    paths[seqID] = sortAccessions(sort,_paths[seqID])\n",
    "            else:\n",
    "                paths = sortAccessions(sort,_paths)\n",
    "            del _paths\n",
    "        else:\n",
    "            paths = _paths\n",
    "    elif isinstance(sort,str):\n",
    "        if v2:\n",
    "            paths = {}\n",
    "            for seqID in _paths.keys():\n",
    "                paths[seqID] = sortAccessions(sort,_paths[seqID])\n",
    "        else:\n",
    "            paths = sortAccessions(sort,_paths)\n",
    "        del _paths\n",
    "    elif isinstance(sort,Iterable):\n",
    "        if v2:\n",
    "            paths = {}\n",
    "            for seqID in _paths.keys():\n",
    "                paths[seqID] = sortAccessions(sort,_paths[seqID])\n",
    "        else:\n",
    "            paths = sortAccessions(sort,_paths)\n",
    "        del _paths\n",
    "    else:\n",
    "        paths = _paths\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export parameters processing and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pathConvert(inputPath, suffix=''):\n",
    "    outputPath = os.path.dirname(inputPath)\n",
    "    outputName = '.'.join(os.path.splitext(os.path.basename(inputPath))[:-1])+suffix\n",
    "    return outputPath,outputName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkZoomLevels(zoomLevels):\n",
    "    '''\n",
    "    Check that each previous zoom level is factor of next one\n",
    "    '''\n",
    "    _zoomLevels = np.array(zoomLevels)\n",
    "    div = _zoomLevels[1:]/_zoomLevels[:-1]\n",
    "    return not np.any(div - div.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def adjustZoomLevels(zoomLevels):\n",
    "    '''\n",
    "    If there is no zoom level 1, adds it to the list.\n",
    "    '''\n",
    "    if not checkZoomLevels(zoomLevels):\n",
    "        raise ValueError('Zoom level list is incorrect. Each next level \\\n",
    "                          should have previous one as factor.')\n",
    "    if min(zoomLevels) > 1:\n",
    "        zoomLevels = [1] + zoomLevels\n",
    "    return zoomLevels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy to JSON encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# https://stackoverflow.com/questions/50916422/python-typeerror-object-of-type-int64-is-not-json-serializable\n",
    "# Class for encoding np types to JSON\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional dict structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class bidict(dict):\n",
    "    '''\n",
    "    Here is a class for a bidirectional dict, inspired by Finding key from\n",
    "    value in Python dictionary and modified to allow the following 2) and 3).\n",
    "\n",
    "    Note that :\n",
    "\n",
    "    1) The inverse directory bd.inverse auto-updates itself when the standard\n",
    "        dict bd is modified.\n",
    "    2) The inverse directory bd.inverse[value] is always a list of keys such\n",
    "        that value in bd[key] for each key.\n",
    "    3) Unlike the bidict module from https://pypi.python.org/pypi/bidict,\n",
    "        here we can have 2 keys having same value, this is very important.\n",
    "    4) After modification, values in the \"forward\" (not inversed) dict\n",
    "        can be lists (or any iterables theoretically,\n",
    "        but only list was tested).\n",
    "\n",
    "    For implementing 4), new method `add` was introduced.\n",
    "    If d[key].append(value) attempted, the link between main and inversed dict\n",
    "    will be broken. Method `add` can accept both\n",
    "\n",
    "    Credit:\n",
    "    Implemented as an answer to\n",
    "    https://stackoverflow.com/questions/3318625/how-to-implement-an-efficient-bidirectional-hash-table\n",
    "    by Basj (https://stackoverflow.com/users/1422096/basj).\n",
    "    '''\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.inverse = {}\n",
    "        for key, value in self.items():\n",
    "            if isinstance(value, Iterable):\n",
    "                for v in value:\n",
    "                    self.inverse.setdefault(v, []).append(key)\n",
    "            else:\n",
    "                self.inverse.setdefault(value, []).append(key)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key in self:\n",
    "            keyV = self[key]\n",
    "            if isinstance(keyV, Iterable):\n",
    "                for v in keyV:\n",
    "                    self.inverse[v].remove(key)\n",
    "            else:\n",
    "                self.inverse[keyV].remove(key)\n",
    "        super(bidict, self).__setitem__(key, value)\n",
    "        if isinstance(value, Iterable):\n",
    "            for v in value:\n",
    "                self.inverse.setdefault(v, []).append(key)\n",
    "        else:\n",
    "            self.inverse.setdefault(value, []).append(key)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        value = self[key]\n",
    "        if isinstance(value, Iterable):\n",
    "            for v in value:\n",
    "                self.inverse.setdefault(v, []).remove(key)\n",
    "                if v in self.inverse and not self.inverse[v]:\n",
    "                    del self.inverse[v]\n",
    "        else:\n",
    "            self.inverse.setdefault(value, []).remove(key)\n",
    "            if value in self.inverse and not self.inverse[value]:\n",
    "                del self.inverse[value]\n",
    "        super(bidict, self).__delitem__(key)\n",
    "\n",
    "    def add(self, key, value):\n",
    "        valKey = self.setdefault(key, [])\n",
    "        if isinstance(valKey,Iterable):\n",
    "            valKey = set(valKey)\n",
    "        else:\n",
    "            valKey = set([valKey])\n",
    "\n",
    "        if isinstance(value, Iterable):\n",
    "            valKey = valKey.union(value)\n",
    "        else:\n",
    "            valKey.add(value)\n",
    "\n",
    "        self[key] = list(valKey)\n",
    "    \n",
    "    def remove(self,key,value):\n",
    "        valKey = set(self.setdefault(key,[]))\n",
    "        \n",
    "        if isinstance(value,Iterable):\n",
    "            valKey.difference_update(value)\n",
    "        else:\n",
    "            valKey.remove(value)\n",
    "        \n",
    "        self[key] = list(valKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redis utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB cleaning and maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def resetDB(redisServer='redis',port=6379):\n",
    "    '''\n",
    "    Reset the whole database. Be careful, it is impossible re restore DB once it was flushed.\n",
    "    '''\n",
    "    conn = Redis(host=redisServer,port=port,db=0)\n",
    "    conn.flushall()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions implementing secondary interval set in Redis database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def iset_add(r,name,intervalMapping):\n",
    "    '''\n",
    "        Add members with intervals to interval set. If interval set does not exist, it will be created. \n",
    "        In reality, it will create two Redis Sorted Sets for starts and ends of the intervals.\n",
    "        The rest of the functions ``iset_`` will know what to do with them.\n",
    "        \n",
    "        ``r``: Redis object. Redis client.\n",
    "        ``name``: string. Name of the interval set.\n",
    "        ``intervalMapping``: dict. Dictionary with names of intervals as keys and \n",
    "                tuples with start and end of intervals.\n",
    "                \n",
    "        \n",
    "        Return number of added intervals. In reality, it adds equal number of elements \n",
    "        to two sorted sets, if number of added elements are not equal, DataError is raised.\n",
    "        \n",
    "    '''\n",
    "    starts = {f'{n}_{seqnum}':int(interval[0]) for n,inv in intervalMapping.items() for seqnum,interval in enumerate(inv)}\n",
    "    ends = {f'{n}_{seqnum}':int(interval[1]) for n,inv in intervalMapping.items() for seqnum,interval in enumerate(inv)}\n",
    "    numAddedStarts = r.zadd(f'{name}Start',mapping=starts)\n",
    "    numAddedEnds = r.zadd(f'{name}End',mapping=ends)\n",
    "    if numAddedStarts!=numAddedEnds:\n",
    "        raise DataError(f'Not equal number of starts and ends were added to DB. For consistency, the sorted sets {name}Start and {name}End should be checked and/or recreated')\n",
    "    return numAddedStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def iset_get(r,name,member=None):\n",
    "    '''\n",
    "        Return either the whole interval set or specific name(s) with its interval.\n",
    "        \n",
    "        ``r``: Redis object. Redis client.\n",
    "        ``name``: string. Name of the interval set.\n",
    "        ``member``: string, list, tuple or None. If None, function return all members with their respective intervals.\n",
    "            If string, returns a single member with its interval,\n",
    "            if list or tuple, returns all requested members with their respecitve intervals.\n",
    "\n",
    "        Return a dictionary with member names as keys and tuples with interval starts and ends as values.\n",
    "        For member names not found in interval set, the value for the given key will be a tuple (None,None).\n",
    "    '''\n",
    "    if member is None:\n",
    "        starts = {k.decode():v for k,v in r.zrange(f'{name}Start',0,-1,withscores=True)}\n",
    "        ends = {k.decode():v for k,v in r.zrange(f'{name}End',0,-1,withscores=True)}\n",
    "        return {k:(starts[k],ends[k])for k in starts.keys()}\n",
    "    elif isinstance(member,str):\n",
    "        intStart = r.zscore(f'{name}Start',member)\n",
    "        intEnd = r.zscore(f'{name}End',member)\n",
    "        return {member: (intStart, intEnd)}\n",
    "    else:\n",
    "        res = {}\n",
    "        for mm in member:\n",
    "            intStart = r.zscore(f'{name}Start',mm)\n",
    "            intEnd = r.zscore(f'{name}End',mm)\n",
    "            res[mm] = (intStart, intEnd)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def iset_score(r,name,start,end=None):\n",
    "    '''\n",
    "        Returns all member names whose interval contains a given value or intersects with the given interval\n",
    "        \n",
    "        ``r``: Redis object. Redis client.\n",
    "        ``name``: string. Name of the interval set\n",
    "        ``start``: int. Query value or the start of query interval.\n",
    "        ``end``: int or None. If None, ``start`` is treated as a single query value. \n",
    "                If int, then ``start`` is the start of the query interval, \n",
    "                ``end`` is the end of the query interval.\n",
    "                \n",
    "        Returns a list of members whose intervals either contain query value or intersects with query interval.\n",
    "    '''\n",
    "    if end:\n",
    "        _endPos = end\n",
    "    else:\n",
    "        _endPos = start\n",
    "    if _endPos<start:\n",
    "        raise ValueError('``start`` should be less or equal to ``end``.')\n",
    "    tid = random.randint(1e8,1e9-1)\n",
    "#     r.execute_command('ZRANGESTORE',*['startSetTemp','geneStart','-inf',_endPos,'BYSCORE'])\n",
    "#     r.execute_command('ZRANGESTORE',*['endSetTemp','geneEnd',start,'inf','BYSCORE'])\n",
    "    r.zrangestore(f'startSetTemp_{tid}',f'{name}Start','-inf',_endPos,byscore=True)\n",
    "    r.zrangestore(f'endSetTemp_{tid}',f'{name}End',start,'inf',byscore=True)\n",
    "    res = ['_'.join(el.decode().split('_')[:-1]) for el in r.zinter([f'startSetTemp_{tid}',f'endSetTemp_{tid}'])]\n",
    "    r.delete(f'startSetTemp_{tid}',f'endSetTemp_{tid}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def iset_not_score(r,name,start,end=None):\n",
    "    '''\n",
    "        Returns all intervals (member names only) where query value is not contained or query interval is not intersecting.\n",
    "        Inverison of ``iset_score()`` function\n",
    "        \n",
    "        ``r``: Redis object. Redis client.\n",
    "        ``name``: string. Name of the interval set\n",
    "        ``start``: int. Query value or the start of query interval.\n",
    "        ``end``: int or None. If None, ``start`` is treated as a single query value. \n",
    "                If int, then ``start`` is the start of the query interval, \n",
    "                ``end`` is the end of the query interval.\n",
    "                \n",
    "        Returns a list of members whose intervals either does not contain query value or does not intersect with query interval.\n",
    "    \n",
    "    '''\n",
    "    if end:\n",
    "        _endPos = end\n",
    "    else:\n",
    "        _endPos = start\n",
    "    if _endPos<start:\n",
    "        raise ValueError('``start`` should be less or equal to ``end``.')\n",
    "    tid = random.randint(1e8,1e9-1)\n",
    "\n",
    "    r.zrangestore(f'startSetTemp_{tid}',f'{name}Start','-inf',_endPos,byscore=True)\n",
    "    r.zrangestore(f'endSetTemp_{tid}',f'{name}End',start,'inf',byscore=True)\n",
    "    r.zinterstore(f'foundSetTemp_{tid}',[f'startSetTemp_{tid}',f'endSetTemp_{tid}'])\n",
    "    r.zrangestore(f'allSetTemp_{tid}',f'{name}Start','-inf','inf',byscore=True)\n",
    "    res = [el.decode() for el in (r.zdiff([f'allSetTemp_{tid}',f'foundSetTemp_{tid}']))]\n",
    "    r.delete(f'startSetTemp_{tid}',f'endSetTemp_{tid}',f'allSetTemp_{tid}',f'foundSetTemp_{tid}')\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def iset_del(r,name,member=None):\n",
    "    '''\n",
    "        Return either the whole interval set or specific name(s) with its interval.\n",
    "        \n",
    "        ``r``: Redis object. Redis client.\n",
    "        ``name``: string. Name of the interval set.\n",
    "        ``member``: string, list, tuple or None. If None, function return all members with their respective intervals.\n",
    "            If string, returns a single member with its interval,\n",
    "            if list or tuple, returns all requested members with their respecitve intervals.\n",
    "\n",
    "        Return number of removed intervals. In reality, it removes equal number of elements \n",
    "        from two sorted sets, if number of added elements are not equal, DataError is raised.\n",
    "    '''\n",
    "    if member is None:\n",
    "        keyRemovedStart = r.delete(f'{name}Start')\n",
    "        keyRemovedEnd = r.delete(f'{name}End')\n",
    "        if keyRemovedStart==1 and keyRemovedEnd==1:\n",
    "            return 1\n",
    "        else:\n",
    "            raise DataError('Less than two sorted sets were deleted. Something is wrong with the Redis DB.')\n",
    "    elif isinstance(member,str):\n",
    "        removedStartCount = r.zrem(f'{name}Start',member)\n",
    "        removedEndCount = r.zrem(f'{name}End',member)\n",
    "    else:\n",
    "        removedStartCount = r.zrem(f'{name}Start',*member)\n",
    "        removedEndCount = r.zrem(f'{name}End',*member)\n",
    "    \n",
    "    if removedStartCount==removedEndCount:\n",
    "        return removedStartCount\n",
    "    else:\n",
    "        raise DataError(f'Not equal number of starts and ends were deleted from DB. \\\n",
    "        For consistency, the sorted sets {name}Start and {name}End should be checked and/or recreated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

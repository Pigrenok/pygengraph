{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: This package provides all functionality from graph construction (currently,\n",
    "  from annotation, in the future, from raw assembled sequences) to graph processing\n",
    "  (sorting, grouping, adjusting).\n",
    "output-file: index.html\n",
    "title: pygengraph\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the directory of the library and enter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and for development use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -e .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "\n",
    "from pygengraph.graph import GenomeGraph\n",
    "from pygengraph.utils import pathFileToPathDict\n",
    "from pygengraph.export import exportProject"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If redis database needs to be cleaned.\n",
    "\n",
    "from redis import Redis\n",
    "\n",
    "redisConn = Redis(host='redis',port=6379)\n",
    "\n",
    "redisConn.flushall()\n",
    "\n",
    "redisConn.close()\n",
    "\n",
    "del redisConn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('always',category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating from annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "refdir = '/path/to/reference/'\n",
    "annotationdir = '/path/to/annotation'\n",
    "gfadir = '/path/to/graphs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "annotationFiles = sorted(glob.glob(f'{annotationdir}{os.path.sep}*.gff'))\n",
    "pangenomeFiles = sorted(glob.glob(f'{annotationdir}{os.path.sep}*pangen.gff'))\n",
    "# If you want to include sequences instead of simple notion of genes.\n",
    "# It should also be converted to sequenceFileDict, see details in documentation for GenomeGraph Class constructor.\n",
    "# sequenceFiles = sorted(glob.glob(f'{annotationdir}{os.path.sep}sequences{os.path.sep}*.fasta'))\n",
    "refAnnotationFile = f'{refdir}{os.path.sep}reference.gff'\n",
    "# If you want to include sequences instead of simple notion of genes\n",
    "# refSequenceFile = f'{refdir}{os.path.sep}reference.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "refdir = '../../1001G/annotations/freeze2.1/outgroups'\n",
    "annotationdir = '../../1001G/annotations/freeze2.1'\n",
    "gfadir = '../../1001G/annotations/graphs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "annotationFiles = sorted(glob.glob(f'{annotationdir}{os.path.sep}*.gff'))\n",
    "# pangenomeFiles = sorted(glob.glob(f'{annotationdir}{os.path.sep}*pangen.gff'))\n",
    "# If you want to include sequences instead of simple notion of genes.\n",
    "# It should also be converted to sequenceFileDict, see details in documentation for GenomeGraph Class constructor.\n",
    "# sequenceFiles = sorted(glob.glob(f'{annotationdir}{os.path.sep}sequences{os.path.sep}*.fasta'))\n",
    "refAnnotationFile = f'{refdir}{os.path.sep}araport.gff'\n",
    "# If you want to include sequences instead of simple notion of genes\n",
    "# refSequenceFile = f'{refdir}{os.path.sep}reference.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../1001G/annotations/freeze2.1/10002.gff',\n",
       " '../../1001G/annotations/freeze2.1/10015.gff',\n",
       " '../../1001G/annotations/freeze2.1/10024.gff',\n",
       " '../../1001G/annotations/freeze2.1/1741.gff',\n",
       " '../../1001G/annotations/freeze2.1/22001.gff',\n",
       " '../../1001G/annotations/freeze2.1/22002.gff',\n",
       " '../../1001G/annotations/freeze2.1/22003.gff',\n",
       " '../../1001G/annotations/freeze2.1/22004.gff',\n",
       " '../../1001G/annotations/freeze2.1/22005.gff',\n",
       " '../../1001G/annotations/freeze2.1/22006.gff',\n",
       " '../../1001G/annotations/freeze2.1/22007.gff',\n",
       " '../../1001G/annotations/freeze2.1/6024.gff',\n",
       " '../../1001G/annotations/freeze2.1/6069.gff',\n",
       " '../../1001G/annotations/freeze2.1/6124.gff',\n",
       " '../../1001G/annotations/freeze2.1/6244.gff',\n",
       " '../../1001G/annotations/freeze2.1/6909.gff',\n",
       " '../../1001G/annotations/freeze2.1/6966.gff',\n",
       " '../../1001G/annotations/freeze2.1/8236.gff',\n",
       " '../../1001G/annotations/freeze2.1/9075.gff',\n",
       " '../../1001G/annotations/freeze2.1/9537.gff',\n",
       " '../../1001G/annotations/freeze2.1/9543.gff',\n",
       " '../../1001G/annotations/freeze2.1/9638.gff',\n",
       " '../../1001G/annotations/freeze2.1/9728.gff',\n",
       " '../../1001G/annotations/freeze2.1/9764.gff',\n",
       " '../../1001G/annotations/freeze2.1/9888.gff',\n",
       " '../../1001G/annotations/freeze2.1/9905.gff',\n",
       " '../../1001G/annotations/freeze2.1/9981.gff']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotationFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../1001G/annotations/freeze2.1/outgroups/araport.gff',\n",
       " '../../1001G/annotations/freeze2.1/outgroups/araport.gff')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refAnnotationFile,'../../1001G/annotations/freeze2.1/outgroups/araport.gff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generaton of gene graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Chr1\n",
      "============\n",
      "Processing file ../../1001G/annotations/freeze2.1/10002.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/10002.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/10002.gff finished in 28.673924207687378 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/10015.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/10015.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/10015.gff finished in 24.959019660949707 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/10024.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/10024.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/10024.gff finished in 23.587310552597046 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/1741.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/1741.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/1741.gff finished in 24.746922492980957 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22001.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/22001.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22001.gff finished in 30.712225437164307 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22002.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/22002.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22002.gff finished in 27.338926076889038 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22003.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/22003.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22003.gff finished in 26.056288242340088 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22004.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/22004.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22004.gff finished in 26.142362594604492 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22005.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/22005.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22005.gff finished in 25.327133655548096 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22006.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/22006.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22006.gff finished in 27.31480574607849 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22007.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/22007.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/22007.gff finished in 29.14346981048584 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6024.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/6024.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6024.gff finished in 23.878724813461304 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6069.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/6069.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6069.gff finished in 27.885523557662964 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6124.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/6124.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6124.gff finished in 29.288628578186035 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6244.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/6244.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6244.gff finished in 24.656330585479736 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6909.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/6909.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6909.gff finished in 28.404035329818726 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6966.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/6966.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/6966.gff finished in 26.316243648529053 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/8236.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/8236.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/8236.gff finished in 26.969415426254272 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9075.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9075.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9075.gff finished in 30.04488444328308 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9537.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9537.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9537.gff finished in 24.44810676574707 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9543.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9543.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9543.gff finished in 27.33419370651245 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9638.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9638.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9638.gff finished in 28.21004581451416 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9728.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9728.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9728.gff finished in 27.377279043197632 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9764.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9764.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9764.gff finished in 27.37028455734253 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9888.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9888.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9888.gff finished in 31.27537989616394 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9905.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9905.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9905.gff finished in 26.91718864440918 seconds.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9981.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/9981.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/9981.gff finished in 25.28101348876953 seconds.\n",
      "Converting gene tables into pandas DataFrames.\n",
      "Reading annotation files finished in 732.4830706119537 seconds\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005310535430908203\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005102634429931641\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005021810531616211\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005028963088989258\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005017280578613281\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005041599273681641\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005007743835449219\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005049943923950195\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005000114440917969\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.004920244216918945\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005032062530517578\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.004972219467163086\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.004975318908691406\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.004948854446411133\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.004979610443115234\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.0050182342529296875\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.0049571990966796875\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.0049898624420166016\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.004945516586303711\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.00493621826171875\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005014896392822266\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.00494074821472168\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005017518997192383\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.004950284957885742\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.0049762725830078125\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005274534225463867\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.005564212799072266\n",
      "Processing file ../../1001G/annotations/freeze2.1/outgroups/araport.gff...\n",
      "Annotation file ../../1001G/annotations/freeze2.1/outgroups/araport.gff read.\n",
      "Processing file ../../1001G/annotations/freeze2.1/outgroups/araport.gff finished in 61.855565547943115 seconds.\n",
      "Converting gene tables into pandas DataFrames.\n",
      "Reading annotation files finished in 61.98409605026245 seconds\n",
      "Converting gene table into graph...\n",
      "\n",
      "Processing gene table finished in 0.006478786468505859\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m============\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m curtst \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 11\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mGenomeGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotationFiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mannotationFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mpangenomeFiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msequenceFilesDict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdoUS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdoUS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mchromosome\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchromosome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mrefAnnotationFile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefAnnotationFile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mrefAccession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTAIR10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerating graph for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mcurtst\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m curtst \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/data/YandexDisk/Kew/src/graphConstruction/pangraph_constructor/graph.py:506\u001b[0m, in \u001b[0;36mGenomeGraph.__init__\u001b[0;34m(self, gfaPath, doOverlapCleaning, paths, nodes, nodesData, links, pathsDict, sequenceFilesDict, annotationFiles, pangenomeFiles, doBack, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphFromPaths(pathsDict,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;66;03m# sequenceFiles can be None\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m annotationFiles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graphFromAnnotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotationFiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpangenomeFiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43msequenceFilesDict\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpureForwardlinks \u001b[38;5;241m=\u001b[39m LinkGetter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforwardLinks)\n",
      "File \u001b[0;32m/data/YandexDisk/Kew/src/graphConstruction/pangraph_constructor/graph.py:968\u001b[0m, in \u001b[0;36m_graphFromAnnotation\u001b[0;34m(self, annotationFiles, pangenomeFiles, sequenceFilesDict, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefAnnotationFile\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    962\u001b[0m     links \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processRefAnnotation(kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefAnnotationFile\u001b[39m\u001b[38;5;124m'\u001b[39m], links,\n\u001b[1;32m    963\u001b[0m                                     ATmap\u001b[38;5;241m=\u001b[39mATmap,pangenomeDict\u001b[38;5;241m=\u001b[39mpangenomeDict,\n\u001b[1;32m    964\u001b[0m                                     seqFile \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefSequenceFile\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m), \n\u001b[1;32m    965\u001b[0m                                     chromosome \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchromosome\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), doUS \u001b[38;5;241m=\u001b[39m doUS,\n\u001b[1;32m    966\u001b[0m                                     accID \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefAccession\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforwardLinks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_linksSetToDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/YandexDisk/Kew/src/graphConstruction/pangraph_constructor/graph.py:1850\u001b[0m, in \u001b[0;36m_linksSetToDict\u001b[0;34m(self, setLinks)\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[38;5;129m@patch_to\u001b[39m(GenomeGraph)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_linksSetToDict\u001b[39m(\u001b[38;5;28mself\u001b[39m,setLinks):\n\u001b[1;32m   1849\u001b[0m     dictLinks \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fromNodeStrand,links \u001b[38;5;129;01min\u001b[39;00m \u001b[43msetLinks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m   1851\u001b[0m         fromNode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(fromNodeStrand[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m   1852\u001b[0m         fromStrand \u001b[38;5;241m=\u001b[39m fromNodeStrand[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "doUS = False\n",
    "n = 1\n",
    "for chrnum in range(1,n+1): # here n is number of chromosomes.\n",
    "    chromosome = f'Chr{chrnum}'\n",
    "\n",
    "    print(f'\\nProcessing {chromosome}\\n============')\n",
    "\n",
    "    curtst = time.time()\n",
    "    \n",
    "    graph = GenomeGraph(annotationFiles = annotationFiles,\n",
    "                        pangenomeFiles = None,\n",
    "                        sequenceFilesDict = None,\n",
    "                        doUS = doUS,\n",
    "                        chromosome = chromosome,\n",
    "                        refAnnotationFile=refAnnotationFile,\n",
    "                        refAccession='TAIR10')\n",
    "    \n",
    "    print(f'Generating graph for {chromosome} took {time.time() - curtst} seconds')\n",
    "    \n",
    "    curtst = time.time()\n",
    "    graph.treeSort()\n",
    "    print(f'Sorting graph for {chromosome} took {time.time() - curtst} seconds')\n",
    "    if len(graph.nodes)!=len(graph.order):\n",
    "            print('Sorting failed and not all nodes were sorted. Saving unsorted graph')\n",
    "            gfaFilename = f'Gene_{chromosome}_simOnly_unordered.gfa'\n",
    "            graph.order = list(range(1,len(graph.nodes)+1))\n",
    "    else:\n",
    "        gfaFilename = f'Gene_{chromosome}_simOnly.gfa'\n",
    "    \n",
    "    graph.toGFA(f'{gfadir}{os.path.sep}{gfaFilename}',doSeq=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pathfile to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For path file v1\n",
    "pathfileDir = 'examples/gene_graph'\n",
    "\n",
    "pathsfile = 'paths_genegraph.txt'\n",
    "\n",
    "paths = pathFileToPathDict(f'{pathfileDir}{os.path.sep}{pathsfile}', True, True)\n",
    "\n",
    "graph = GenomeGraph(pathsDict=paths)\n",
    "\n",
    "graph.treeSort()\n",
    "\n",
    "if len(graph.nodes)!=len(graph.order):\n",
    "    print('Sorting failed and not all nodes were sorted. Saving unsorted graph')\n",
    "    output = 'paths_genegraph_unordered.gfa'\n",
    "    graph.order = list(range(1,len(graph.nodes)+1))\n",
    "    graph.toGFA(output,doSeq=False)\n",
    "else:\n",
    "    coreGFApath = f'paths_genegraph.gfa'\n",
    "    coregraph.toGFA(coreGFApath,doSeq=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# For v2\n",
    "# This is example, no v2 file currently available for demonstration.\n",
    "pathfileDir = '/path/to/file'\n",
    "\n",
    "pathsfile = f'paths.txt'\n",
    "\n",
    "paths = pathFileToPathDict(f'{pathfileDir}{os.path.sep}{pathsfile}',True,'reference',True)\n",
    "\n",
    "for seqNum in paths.keys():\n",
    "\n",
    "    graph = GenomeGraph(pathsDict=paths[seqNum])\n",
    "\n",
    "    # On undirected coregraph sorting is not optimal! Check sorting!!!\n",
    "\n",
    "    graph.treeSort()\n",
    "\n",
    "    if len(graph.nodes)!=len(graph.order):\n",
    "        print('Sorting failed and not all nodes were sorted. Saving unsorted graph')\n",
    "        output = f'{pathfileDir}{os.path.sep}graph_Chr{seqNum}_unordered.gfa'\n",
    "        graph.order = list(range(1,len(graph.nodes)+1))\n",
    "        graph.toGFA(output,doSeq=False)\n",
    "    else:\n",
    "        coreGFApath = f'{pathfileDir}{os.path.sep}graph_Chr{seqNum}.gfa'\n",
    "        graph.toGFA(coreGFApath,doSeq=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading graph from GFA and sorting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfadir = 'examples/nucleotide_graph'\n",
    "\n",
    "# It is nucleotide graph. If it is not nucleotide graph, then `isSeq` variable should be changed to False.\n",
    "gfafilename = 'paths_presentation.gfa'\n",
    "isSeq = True\n",
    "\n",
    "graph = GenomeGraph(gfaPath=f'{gfadir}{os.path.sep}{gfafilename}',isGFASeq=isSeq)\n",
    "\n",
    "graph_new.treeSort()\n",
    "\n",
    "assert len(graph_new.nodes)==len(graph_new.order)\n",
    "\n",
    "basename,ext = os.path.splitext(gfafilename)\n",
    "\n",
    "graph_new.toGFA(f'{gfadir}{os.path.sep}{basename}_ordered.{ext}',doSeq=isSeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting presentation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfileDir = '../../Meetings/1001G+_20220518/'\n",
    "coreGFApath = f'{pathfileDir}{os.path.sep}paths_presentation.gfa'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# changing annotation\n",
    "genome = GenomeGraph(coreGFApath,isGFASeq=True)\n",
    "\n",
    "for nodeID,node in enumerate(genome.nodesAnnotation):\n",
    "    for seqName,seqDict in node.items():\n",
    "        for annText in seqDict.keys():\n",
    "            genome.nodesAnnotation[nodeID][seqName][annText] = [(0,len(genome.nodesData[nodeID])-1)]\n",
    "\n",
    "genome.toGFA(coreGFApath,doSeq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 6\n",
    "inversionThreshold = 0.5\n",
    "isSeq = True\n",
    "zoomLevels = [1,2,4,8,16]#,8,16,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../Meetings/1001G+_20220518', 'paths_presentation_new', [1, 2, 4, 8, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoomLevels = adjustZoomLevels(zoomLevels)\n",
    "outputPath,outputName = pathConvert(coreGFApath,suffix='_new')\n",
    "outputPath,outputName,zoomLevels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "print(f'Opening Redis connection for db {dbid}')\n",
    "redisConn = Redis(host='redis',port = 6379,db=dbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redisConn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Genome\n",
      "Loading graph from ../../Meetings/1001G+_20220518//paths_presentation.gfa\n",
      "Found nodeNames file ../../Meetings/1001G+_20220518/nodeNames_paths_presentation.json, loading names.\n",
      "Found node annotation file ../../Meetings/1001G+_20220518/annotation_paths_presentation.dat, loading associations.\n",
      "Loading segment 7/7\n",
      "Loading segments finished.\n",
      "Loading link 12/12\n",
      "Loading links finished\n",
      "Loading path 5/5\n",
      "Loading paths finished. 5 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 7/7\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 5/5\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../Meetings/1001G+_20220518/paths_presentation_new\n",
      "Calculating nodes length...\n",
      "Processing node 7/7\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 5/5\n",
      "Finished preprocessing paths\n",
      "Processing path breaks...\n",
      "Postprocessing interconnected links 2/2\n",
      "Preprocessing interconnected links finished.\n",
      "\n",
      "Processing path breaks finished.\n",
      "Converting blocks to block lengths 5/5\n",
      "Conversion finished.\n",
      "Reformating links to block lengths associations 5/5\n",
      "Reformating finished.\n",
      "Identifying rearrangement blocks\n",
      "Processing node 7/7\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 7/7\n",
      "Processing component links 6/6\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "Recording component 6/6\n",
      "Recording zoom level 1 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <2 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 2\n",
      "===========================\n",
      "Processing component 6/6\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 6/6\n",
      "Recording zoom level 2 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <4 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 4\n",
      "===========================\n",
      "Processing component 6/6\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 6/6\n",
      "Recording zoom level 4 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <8 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 8\n",
      "===========================\n",
      "Processing component 6/6\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 6/6\n",
      "Recording zoom level 8 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <16 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 16\n",
      "===========================\n",
      "Processing component 6/6\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 6/6\n",
      "Recording zoom level 16 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <32 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 32\n",
      "===========================\n",
      "Processing component 6/6\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 6/6\n",
      "Recording zoom level 32 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <64 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 64\n",
      "===========================\n",
      "Processing component 6/6\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 6/6\n",
      "Recording zoom level 64 finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%%capture output\n",
    "startTime = time.time()\n",
    "# [zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,toComponentLinks,fromComponentLinks,graph] = \\\n",
    "# [zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,zoomAccStarts,zoomAccEnds, \n",
    "#                 invertedStarts,invertedEnds,toComponentLinks,fromComponentLinks,collapsibleBlocks,fromLinks,toLinks,graph,rootStruct] = \\\n",
    "exportToPantograph(inputPath=coreGFApath, GenomeGraphParams={}, \n",
    "                                outputPath=outputPath, outputName=outputName,\n",
    "                                isSeq=isSeq,\n",
    "                                redisConn=redisConn,\n",
    "                                zoomLevels=zoomLevels,\n",
    "                                fillZoomLevels = True,\n",
    "                                maxLengthComponent=maxLengthComponent, \n",
    "                                maxLengthChunk=maxLengthChunk, \n",
    "                                inversionThreshold=inversionThreshold)\n",
    "#                                 returnDebugData=True)\n",
    "runTime = time.time() - startTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting tutorial gene graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfileDir = '../../1001G/pantograph'\n",
    "coreGFApath = f'{pathfileDir}{os.path.sep}genegraph_tutorial.gfa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from ../../1001G/pantograph/genegraph_tutorial.gfa\n",
      "Found node annotation file ../../1001G/pantograph/annotation_genegraph_tutorial.dat, loading associations.\n",
      "Loading segment 7/7\n",
      "Loading segments finished.\n",
      "Loading link 13/13\n",
      "Loading links finished\n",
      "Loading path 5/5\n",
      "Loading paths finished. 5 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 7/7\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 5/5\n",
      "Finished preprocessing paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = GenomeGraph(gfaPath=coreGFApath,isGFASeq=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1+', '2+', '3+', '4+'],\n",
       " ['1+', '5+', '6+', '7+', '1+'],\n",
       " ['4+', '1+', '2+', '3+'],\n",
       " ['2+', '3+', '4+', '1+', '5-', '4+', '7+'],\n",
       " ['6+', '7-', '1+', '2+', '3+']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.paths"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# changing annotation\n",
    "genome = GenomeGraph(coreGFApath,isGFASeq=True)\n",
    "\n",
    "for nodeID,node in enumerate(genome.nodesAnnotation):\n",
    "    for seqName,seqDict in node.items():\n",
    "        for annText in seqDict.keys():\n",
    "            genome.nodesAnnotation[nodeID][seqName][annText] = [(0,len(genome.nodesData[nodeID])-1)]\n",
    "\n",
    "genome.toGFA(coreGFApath,doSeq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 6\n",
    "inversionThreshold = 0.5\n",
    "isSeq = False\n",
    "zoomLevels = [1]#,8,16,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../1001G/pantograph', 'genegraph_tutorial', [1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoomLevels = adjustZoomLevels(zoomLevels)\n",
    "outputPath,outputName = pathConvert(coreGFApath,suffix='')\n",
    "outputPath,outputName,zoomLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "# print(f'Opening Redis connection for db {dbid}')\n",
    "redisConn = Redis(host = 'redis',port = 6379, db = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "redisConn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/genegraph_tutorial.gfa\n",
      "Found node annotation file ../../1001G/pantograph/annotation_genegraph_tutorial.dat, loading associations.\n",
      "Loading segment 7/7\n",
      "Loading segments finished.\n",
      "Loading link 13/13\n",
      "Loading links finished\n",
      "Loading path 5/5\n",
      "Loading paths finished. 5 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 7/7\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 5/5\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/genegraph_tutorial\n",
      "Calculating nodes length...\n",
      "Processing node 7/7\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 5/5\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 7/7\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 7/7\n",
      "Processing component links 6/6\n",
      "Recording component 6/6\n",
      "Recording zoom level 1 finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%%capture output\n",
    "startTime = time.time()\n",
    "# [zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,toComponentLinks,fromComponentLinks,graph] = \\\n",
    "# [zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,zoomAccStarts,zoomAccEnds, \n",
    "#                 invertedStarts,invertedEnds,toComponentLinks,fromComponentLinks,collapsibleBlocks,fromLinks,toLinks,graph,rootStruct] = \\\n",
    "exportToPantograph(inputPath=coreGFApath, GenomeGraphParams={}, \n",
    "                                outputPath=outputPath, outputName=outputName,\n",
    "                                isSeq=isSeq,\n",
    "                                redisConn=redisConn,\n",
    "                                zoomLevels=zoomLevels,\n",
    "                                fillZoomLevels = False,\n",
    "                                maxLengthComponent=maxLengthComponent, \n",
    "                                maxLengthChunk=maxLengthChunk, \n",
    "                                inversionThreshold=inversionThreshold)\n",
    "#                                 returnDebugData=True)\n",
    "runTime = time.time() - startTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing removable elements identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangraph_constructor.exportDev import getRemovableStructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./tests/breakIdentify.dat'):\n",
    "    correctResults = joblib.load('./tests/breakIdentify.dat')\n",
    "else:\n",
    "    correctResults = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../1001G/GraphCollapsing/TestGraphs'\n",
    "filePrefix = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "for filename,resDict in correctResults.items():\n",
    "    print(f'\\n####### Testing on case {filename} ########')\n",
    "    graph = GenomeGraph(f'{path}/{filename}',isGFASeq=False)\n",
    "    linksLengths, pairedLinks, blockEdges, _ = getRemovableStructures(graph=graph)\n",
    "    assert linksLengths==resDict['linksLengths']\n",
    "    assert pairedLinks==resDict['pairedLinks']\n",
    "    assert blockEdges==resDict['blockEdges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseNum = 17\n",
    "filename = f'{filePrefix}{caseNum:02d}.gfa'\n",
    "\n",
    "\n",
    "print('############')\n",
    "print(f'Graph from file {filename}')\n",
    "coreGFApath = f'{path}/{filename}'\n",
    "graph = GenomeGraph(coreGFApath,isGFASeq=False)\n",
    "print('Graph Paths:')\n",
    "ipd.display(graph.paths)\n",
    "linkLengths, pairedLinks, blockEdges, _ = getRemovableStructures(graph=graph)\n",
    "\n",
    "print('Link-Lengths associations:')\n",
    "ipd.display(linkLengths)\n",
    "\n",
    "print('PairedLinks:')\n",
    "ipd.display(pairedLinks)\n",
    "\n",
    "print('Rearrangemenet block edges:')\n",
    "ipd.display(blockEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctResults[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctResults[filename] = {'linksLengths':linkLengths,'pairedLinks':pairedLinks,'blockEdges':blockEdges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(correctResults,'./tests/breakIdentify.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting test collapse graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfileDir = '../../1001G/pantograph/data'\n",
    "coreGFApath = f'{pathfileDir}{os.path.sep}testCollapse.gfa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 6\n",
    "inversionThreshold = 0.5\n",
    "isSeq = False\n",
    "zoomLevels = [1,2,4]#,8,16,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomLevels = adjustZoomLevels(zoomLevels)\n",
    "outputPath,outputName = pathConvert(coreGFApath,suffix='_new')\n",
    "outputPath,outputName,zoomLevels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "print(f'Opening Redis connection for db {dbid}')\n",
    "redisConn = Redis(host='redis',port = 6379,db=dbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redisConn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture output\n",
    "startTime = time.time()\n",
    "# [zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,toComponentLinks,fromComponentLinks,graph] = \\\n",
    "[zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,zoomAccStarts,zoomAccEnds, \n",
    "                invertedStarts,invertedEnds,toComponentLinks,fromComponentLinks,collapsibleBlocks,fromLinks,toLinks,graph,rootStruct] = \\\n",
    "exportToPantograph(inputPath=coreGFApath, GenomeGraphParams={}, \n",
    "                                outputPath=outputPath, outputName=outputName,\n",
    "                                isSeq=isSeq,\n",
    "                                redisConn=redisConn,\n",
    "                                zoomLevels=zoomLevels,\n",
    "                                fillZoomLevels = True,\n",
    "                                maxLengthComponent=maxLengthComponent, \n",
    "                                maxLengthChunk=maxLengthChunk, \n",
    "                                inversionThreshold=inversionThreshold,\n",
    "                                returnDebugData=True)\n",
    "runTime = time.time() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Executed in {runTime} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ntfy send \"Exporting test collapse graph finished. Overall time = {runTime} seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting coregraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfileDir = '../../1001G/coreGraph'\n",
    "coreGFApath = f'{pathfileDir}{os.path.sep}coregraph_Chr1.gfa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 6\n",
    "inversionThreshold = 0.5\n",
    "isSeq = False\n",
    "zoomLevels = [1,2,4,8,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../1001G/coreGraph', 'coregraph_Chr1_new', [1, 2, 4, 8, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoomLevels = adjustZoomLevels(zoomLevels)\n",
    "outputPath,outputName = pathConvert(coreGFApath,suffix='_new')\n",
    "outputPath,outputName,zoomLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "# print(f'Opening Redis connection for db {dbid}')\n",
    "redisConn = Redis(host='redis',port = 6379,db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_init.ipynb.\n",
      "Converted 01_graph.ipynb.\n",
      "Converted 02_tree.ipynb.\n",
      "Converted 03_synteny.ipynb.\n",
      "Converted 04_utils.ipynb.\n",
      "Converted 05_export.ipynb.\n",
      "Converted 05_exportDev.ipynb.\n",
      "Converted deBruijnGraphProcessing.ipynb.\n",
      "Converted dev.ipynb.\n",
      "Converted graphTesting.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Genome\n",
      "Loading graph from ../../1001G/coreGraph/coregraph_Chr1.gfa\n",
      "Found node annotation file ../../1001G/coreGraph/annotation_coregraph_Chr1.dat, loading associations.\n",
      "Loading segment 35/35\n",
      "Loading segments finished.\n",
      "Loading link 72/72\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 35/35\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/coreGraph/coregraph_Chr1_new\n",
      "Calculating nodes length...\n",
      "Processing node 35/35\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Processing path breaks...\n",
      "Postprocessing interconnected links 16/16\n",
      "Preprocessing interconnected links finished.\n",
      "\n",
      "Processing path breaks finished.\n",
      "Converting blocks to block lengths 34/34\n",
      "Conversion finished.\n",
      "Reformating links to block lengths associations 34/34\n",
      "Reformating finished.\n",
      "Identifying rearrangement blocks\n",
      "Processing node 35/35\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 35/35\n",
      "Processing component links 35/35\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "Recording component 35/35\n",
      "Recording zoom level 1 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <2 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 2\n",
      "===========================\n",
      "Processing component 35/35\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 8/8\n",
      "Recording zoom level 2 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <4 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 4\n",
      "===========================\n",
      "Processing component 8/8\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 5/5\n",
      "Recording zoom level 4 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <8 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 8\n",
      "===========================\n",
      "Processing component 5/5\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 1/1\n",
      "Recording zoom level 8 finished.\n",
      "Removing links according to collapsible blocks\n",
      "All links associated with collapsibleComponents <16 were removed.     0 components were deleted as isolated.\n",
      "\n",
      "===========================\n",
      "Zoom level 16\n",
      "===========================\n",
      "Processing component 1/1\n",
      "Processing component finished.\n",
      "Converting link to block lengths associations\n",
      "Converting paired links\n",
      "Converting interconnected links\n",
      "Converting rearrangement blocks\n",
      "\n",
      "Recording component 1/1\n",
      "Recording zoom level 16 finished.\n",
      "27.11550521850586\n"
     ]
    }
   ],
   "source": [
    "#%%capture output\n",
    "startTime = time.time()\n",
    "# [zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,toComponentLinks,fromComponentLinks,graph] = \\\n",
    "exportToPantograph(inputPath=coreGFApath, GenomeGraphParams={}, \n",
    "                                outputPath=outputPath, outputName=outputName,\n",
    "                                isSeq=isSeq,\n",
    "                                redisConn=redisConn,\n",
    "                                zoomLevels=zoomLevels, \n",
    "                                maxLengthComponent=maxLengthComponent, \n",
    "                                maxLengthChunk=maxLengthChunk, \n",
    "                                inversionThreshold=inversionThreshold)\n",
    "#                                 returnDebugata=True)\n",
    "runTime = time.time() - startTime\n",
    "print(runTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "!ntfy send \"Exporting coregraph finished. Overall time = {runTime} seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️❗️❗️ TODO: Next test API. WHen works, change front end to get jsons without annotation and then to load annotation from API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from ../../1001G/coreGraph/coregraph_Chr1.gfa\n",
      "Found node annotation file ../../1001G/coreGraph/annotation_coregraph_Chr1.dat, loading associations.\n",
      "Loading segment 35/35\n",
      "Loading segments finished.\n",
      "Loading link 72/72\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 35/35\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = GenomeGraph(coreGFApath,isGFASeq=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pangraph_constructor.utils import iset_get,iset_score,iset_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redisConn = Redis(host='redis',port=6379,db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_0': (1.0, 3.0), 'b_0': (1.0, 5.0)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iset_get(redisConn,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iset_score(redisConn,'coregraph_Chr1_new.1.10024.Pos',22)\n",
    "# coregraph_Chr1_new/10024/1/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3370',\n",
       " 'AT1G15940',\n",
       " 'AT1G15950',\n",
       " 'AT1G16000',\n",
       " 'AT1G16010',\n",
       " 'AT1G16022',\n",
       " 'AT1G62830',\n",
       " 'AT1G62840',\n",
       " 'OG0001502',\n",
       " 'OG0004404',\n",
       " 'OG0007340',\n",
       " 'OG0007341',\n",
       " 'OG0007343',\n",
       " 'OG0008435',\n",
       " 'OG0015400',\n",
       " 'OG0017985',\n",
       " 'OG0022841',\n",
       " 'OG0024046',\n",
       " 'OG0024055',\n",
       " 'OG0025924',\n",
       " 'OG0027925',\n",
       " 'OG0030893']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iset_score(redisConn,'coregraph_Chr1_new.9543.Gene',50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3370_0': (48.0, 51.0)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iset_get(redisConn,'coregraph_Chr1_new.9543.Gene','3370_0')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "redisConn=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting coregraph with genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfileDir = '../../1001G/coreGraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 6\n",
    "inversionThreshold = 0.5\n",
    "isSeq = True\n",
    "zoomLevels = [1,3,9]# + [9*2**i for i in range(9)]\n",
    "# zoomLevels = [2**i for i in range(12)]#  [1,2,4,8,16,32,9*16,9*32,9*128,9*256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomLevels = adjustZoomLevels(zoomLevels)\n",
    "# outputPath,outputName = pathConvert(coreGFApath,suffix='_new')\n",
    "# outputPath,outputName,zoomLevels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "print(f'Opening Redis connection for db {dbid}')\n",
    "redisConn = Redis(host='redis',port = 6379,db=dbid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "redisConn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture output\n",
    "for chrNum in range(1,6):\n",
    "    coreGFApath = f'{pathfileDir}{os.path.sep}coregraph_genes_Chr{chrNum}.gfa'\n",
    "    \n",
    "    outputPath,outputName = pathConvert(coreGFApath,suffix='_new')\n",
    "    \n",
    "    dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "    print(f'Opening Redis connection for db {dbid}')\n",
    "    redisConn = Redis(host='redis',port = 6379,db=dbid)\n",
    "    \n",
    "    startTime = time.time()\n",
    "    # [zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,toComponentLinks,fromComponentLinks,graph] = \\\n",
    "    exportToPantograph(inputPath=coreGFApath, GenomeGraphParams={}, \n",
    "                                    outputPath=outputPath, outputName=outputName,\n",
    "                                    isSeq=isSeq,\n",
    "                                    redisConn=redisConn,\n",
    "                                    zoomLevels=zoomLevels,\n",
    "                                    fillZoomLevels = True,\n",
    "                                    maxLengthComponent=maxLengthComponent, \n",
    "                                    maxLengthChunk=maxLengthChunk, \n",
    "                                    inversionThreshold=inversionThreshold)\n",
    "    #                                 returnDebugata=True)\n",
    "    runTime = time.time() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curT = time.localtime(time.time()+3600)\n",
    "message = f\"Exporting core graph with genes for all chromosomes finished at \\\n",
    "            {curT.tm_hour:02d}:{curT.tm_min:02d} on {curT.tm_mday:02d}/{curT.tm_mon:02d}!\\n\"\n",
    "!ntfy send \"{message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomLevels = [1,2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomLevels = adjustZoomLevels(zoomLevels)\n",
    "# outputPath,outputName = pathConvert(coreGFApath,suffix='_new')\n",
    "# outputPath,outputName,zoomLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture output2\n",
    "for chrNum in range(1,6):\n",
    "    coreGFApath = f'{pathfileDir}{os.path.sep}coregraph_Chr{chrNum}.gfa'\n",
    "    \n",
    "    outputPath,outputName = pathConvert(coreGFApath,suffix='_new')\n",
    "    \n",
    "    dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "    print(f'Opening Redis connection for db {dbid}')\n",
    "    redisConn = Redis(host='redis',port = 6379,db=dbid)\n",
    "    \n",
    "    startTime = time.time()\n",
    "    # [zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,toComponentLinks,fromComponentLinks,graph] = \\\n",
    "    exportToPantograph(inputPath=coreGFApath, GenomeGraphParams={}, \n",
    "                                    outputPath=outputPath, outputName=outputName,\n",
    "                                    isSeq=isSeq,\n",
    "                                    redisConn=redisConn,\n",
    "                                    zoomLevels=zoomLevels,\n",
    "                                    fillZoomLevels = True,\n",
    "                                    maxLengthComponent=maxLengthComponent, \n",
    "                                    maxLengthChunk=maxLengthChunk, \n",
    "                                    inversionThreshold=inversionThreshold)\n",
    "    #                                 returnDebugata=True)\n",
    "    runTime = time.time() - startTime\n",
    "    \n",
    "    print(f'Exporting core graph for Chr{chrNum} took {runTime} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curT = time.localtime(time.time()+3600)\n",
    "message = f\"Exporting core graph with genes for all chromosomes finished at \\\n",
    " {curT.tm_hour:02d}:{curT.tm_min:02d} on {curT.tm_mday:02d}/{curT.tm_mon:02d}!\\n\"\n",
    "!ntfy send \"{message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ntfy send \"Exporting coregraph with genes finished. Overall time = {runTime} seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting gene graphs for all chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfileDir = '../../1001G/pantograph/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 6\n",
    "inversionThreshold = 0.5\n",
    "isSeq = False\n",
    "zoomLevels = [1]#,2,4]# + [9*2**i for i in range(12)]\n",
    "fillZoomLevel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chr1': 'AT_Chr1_OGOnly_2.1.gfa',\n",
       " 'Chr2': 'AT_Chr2_OGOnly_2.1.gfa',\n",
       " 'Chr3': 'AT_Chr3_OGOnly_2.1.gfa',\n",
       " 'Chr4': 'AT_Chr4_OGOnly_2.1.gfa',\n",
       " 'Chr5': 'AT_Chr5_OGOnly_2.1.gfa'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caseDict = {}\n",
    "for i in range(1,6):\n",
    "    GFA = f'AT_Chr{i}_OGOnly_2.1.gfa'\n",
    "    caseDict[f'Chr{i}'] = GFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing case AT_OGOnly_2.1_Chr1pr\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr1_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr1_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 7455/7455\n",
      "Loading segments finished.\n",
      "Loading link 14001/14001\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 7455/7455\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_OGOnly_2.1/AT_OGOnly_2.1_Chr1pr\n",
      "Calculating nodes length...\n",
      "Processing node 7455/7455\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 7455/7455\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 7455/7455\n",
      "Processing component links 3869/3869\n",
      "Recording component 3869/3869\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr1 took 465.6470103263855 seconds\n",
      "\n",
      "Processing case AT_OGOnly_2.1_Chr2pr\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr2_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr2_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 4877/4877\n",
      "Loading segments finished.\n",
      "Loading link 10302/10302\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 4877/4877\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_OGOnly_2.1/AT_OGOnly_2.1_Chr2pr\n",
      "Calculating nodes length...\n",
      "Processing node 4877/4877\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 4877/4877\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 4877/4877\n",
      "Processing component links 2534/2534\n",
      "Recording component 2534/2534\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr2 took 214.97250485420227 seconds\n",
      "\n",
      "Processing case AT_OGOnly_2.1_Chr3pr\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr3_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr3_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 8442/8442\n",
      "Loading segments finished.\n",
      "Loading link 15985/15985\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 8442/8442\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_OGOnly_2.1/AT_OGOnly_2.1_Chr3pr\n",
      "Calculating nodes length...\n",
      "Processing node 8442/8442\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 8442/8442\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 8442/8442\n",
      "Processing component links 3383/3383\n",
      "Recording component 3383/3383\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr3 took 430.0764102935791 seconds\n",
      "\n",
      "Processing case AT_OGOnly_2.1_Chr4pr\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr4_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr4_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 4620/4620\n",
      "Loading segments finished.\n",
      "Loading link 9980/9980\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 4620/4620\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_OGOnly_2.1/AT_OGOnly_2.1_Chr4pr\n",
      "Calculating nodes length...\n",
      "Processing node 4620/4620\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 4620/4620\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 4620/4620\n",
      "Processing component links 2526/2526\n",
      "Recording component 2526/2526\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr4 took 199.40259623527527 seconds\n",
      "\n",
      "Processing case AT_OGOnly_2.1_Chr5pr\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr5_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr5_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 7052/7052\n",
      "Loading segments finished.\n",
      "Loading link 12737/12737\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 7052/7052\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_OGOnly_2.1/AT_OGOnly_2.1_Chr5pr\n",
      "Calculating nodes length...\n",
      "Processing node 7052/7052\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 7052/7052\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 7052/7052\n",
      "Processing component links 3274/3274\n",
      "Recording component 3274/3274\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr5 took 348.297509431839 seconds\n"
     ]
    }
   ],
   "source": [
    "exportProject(projectID = 'AT_OGOnly_2.1', projectName = 'A. thaliana 27 genomes + TAIR10 gene graph 2.1', \n",
    "              caseDict = caseDict, pathToIndex = pathfileDir, pathToGraphs = pathfileDir,\n",
    "              redisHost='redis', redisPort = 6379, redisDB = 0,\n",
    "              suffix = 'pr',\n",
    "              maxLengthComponent = maxLengthComponent, maxLengthChunk = maxLengthChunk,\n",
    "              inversionThreshold = inversionThreshold,\n",
    "              isSeq = isSeq, zoomLevels = zoomLevels, fillZoomLevel = fillZoomLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing case AT_Chr1_OGOnly_2.1_viscol\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr1_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr1_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 7455/7455\n",
      "Loading segments finished.\n",
      "Loading link 14001/14001\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 7455/7455\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_Chr1_OGOnly_2.1_viscol\n",
      "Calculating nodes length...\n",
      "Processing node 7455/7455\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 7455/7455\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 7455/7455\n",
      "Processing component links 3869/3869\n",
      "Recording component 3869/3869\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr1 took 445.7378799915314 seconds\n",
      "\n",
      "Processing case AT_Chr2_OGOnly_2.1_viscol\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr2_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr2_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 4877/4877\n",
      "Loading segments finished.\n",
      "Loading link 10302/10302\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 4877/4877\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_Chr2_OGOnly_2.1_viscol\n",
      "Calculating nodes length...\n",
      "Processing node 4877/4877\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 4877/4877\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 4877/4877\n",
      "Processing component links 2534/2534\n",
      "Recording component 2534/2534\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr2 took 193.71776700019836 seconds\n",
      "\n",
      "Processing case AT_Chr3_OGOnly_2.1_viscol\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr3_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr3_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 8442/8442\n",
      "Loading segments finished.\n",
      "Loading link 15985/15985\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 8442/8442\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_Chr3_OGOnly_2.1_viscol\n",
      "Calculating nodes length...\n",
      "Processing node 8442/8442\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 8442/8442\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 8442/8442\n",
      "Processing component links 3383/3383\n",
      "Recording component 3383/3383\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr3 took 411.77689695358276 seconds\n",
      "\n",
      "Processing case AT_Chr4_OGOnly_2.1_viscol\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr4_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr4_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 4620/4620\n",
      "Loading segments finished.\n",
      "Loading link 9980/9980\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 4620/4620\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_Chr4_OGOnly_2.1_viscol\n",
      "Calculating nodes length...\n",
      "Processing node 4620/4620\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 4620/4620\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 4620/4620\n",
      "Processing component links 2526/2526\n",
      "Recording component 2526/2526\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr4 took 180.36719918251038 seconds\n",
      "\n",
      "Processing case AT_Chr5_OGOnly_2.1_viscol\n",
      "Loading Genome\n",
      "Loading graph from ../../1001G/pantograph/data/AT_Chr5_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr5_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 7052/7052\n",
      "Loading segments finished.\n",
      "Loading link 12737/12737\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 7052/7052\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n",
      "Recording Pantograph data to ../../1001G/pantograph/data/AT_Chr5_OGOnly_2.1_viscol\n",
      "Calculating nodes length...\n",
      "Processing node 7052/7052\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "Identifying rearrangement blocks\n",
      "Processing node 7052/7052\n",
      "Identifying rearrangement blocks finished.\n",
      "\n",
      "===========================\n",
      "Zoom level 1\n",
      "===========================\n",
      "Processing node 7052/7052\n",
      "Processing component links 3274/3274\n",
      "Recording component 3274/3274\n",
      "Recording zoom level 1 finished.\n",
      "Exporting gene graph for Chr5 took 338.8390169143677 seconds\n"
     ]
    }
   ],
   "source": [
    "for seqID in ['Chr1','Chr2','Chr3','Chr4','Chr5']:#'Chr1','Chr2',\n",
    "\n",
    "    coreGFApath = f'{pathfileDir}{os.path.sep}AT_{seqID}_OGOnly_2.1.gfa'\n",
    "\n",
    "    outputPath,outputName = pathConvert(coreGFApath,suffix='_viscol')\n",
    "    \n",
    "    print()\n",
    "    print(f'Processing case {outputName}')\n",
    "    # dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "    # print(f'Opening Redis connection for db {dbid}')\n",
    "    redisConn = Redis(host='redis',port = 6379,db=0)\n",
    "\n",
    "    #%%capture output\n",
    "    startTime = time.time()\n",
    "    # initialLinkLengths, initialPairedLinks, initialInterconnectedLinks, initialBlockEdges, \\\n",
    "    # zoomNodeToComponent,zoomComponentToNodes,zoomComponents,\\\n",
    "    # zoomFromComponentLinks, zoomToComponentLinks, zoomLinkLengths, zoomPairedLinks, zoomInterconnectedLinks, \\\n",
    "    # zoomOldToNewRemoval, zoomNewToOldRemoval, \\\n",
    "    # zoomLinkLengthsRemoval, zoomPairedLinksRemoval, zoomInterconnectedLinksRemoval, zoomBlockEdgesRemoval, \\\n",
    "    # zoomFromComponentLinksRemoval, zoomToComponentLinksRemoval, \\\n",
    "    # graph = \\\n",
    "    exportToPantograph(inputPath=coreGFApath, GenomeGraphParams={}, \n",
    "                                    outputPath=outputPath, outputName=outputName,\n",
    "                                    isSeq=isSeq,\n",
    "                                    redisConn=redisConn,\n",
    "                                    zoomLevels=zoomLevels, \n",
    "                                    fillZoomLevels = False,\n",
    "                                    maxLengthComponent=maxLengthComponent, \n",
    "                                    maxLengthChunk=maxLengthChunk, \n",
    "                                    inversionThreshold=inversionThreshold)#,\n",
    "                                    # returnDebugData=True)\n",
    "    runTime = time.time() - startTime\n",
    "    \n",
    "    print(f'Exporting gene graph for {seqID} took {runTime} seconds')\n",
    "    \n",
    "    redisConn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curT = time.localtime()\n",
    "message = f\"Exporting gene graph for all chromosomes finished at \\\n",
    "            {curT.tm_hour:02d}:{curT.tm_min:02d} on {curT.tm_mday:02d}/{curT.tm_mon:02d}!\"\n",
    "!ntfy send \"{message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from ../../1001G/pantograph/data/AT_Chr1_OGOnly_2.1.gfa\n",
      "Found node annotation file ../../1001G/pantograph/data/annotation_AT_Chr1_OGOnly_2.1.dat, loading associations.\n",
      "Loading segment 7455/7455\n",
      "Loading segments finished.\n",
      "Loading link 14001/14001\n",
      "Loading links finished\n",
      "Loading path 28/28\n",
      "Loading paths finished. 28 paths added, 0 paths ignored.\n",
      "Calculating nodes length...\n",
      "Processing node 7455/7455\n",
      "Finished calculating nodes lengths\n",
      "Preprocessing paths...\n",
      "Processing path 28/28\n",
      "Finished preprocessing paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coreGFApath = f'{pathfileDir}{os.path.sep}AT_Chr1_OGOnly_2.1.gfa'\n",
    "graph = GenomeGraph(gfaPath=coreGFApath, isGFASeq=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genPos': [{'chr': 'Chr1', 'genomePosition': [19020282, 19020893]},\n",
       "  {'chr': 'Chr1', 'genomePosition': [19022280, 19023284]}],\n",
       " 'annotation': {'OG0001585': [(0, 0)],\n",
       "  'AT1G55230': [(0, 0)],\n",
       "  'AT1G55240': [(0, 0)]}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodesMetadata[1361]['22006']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "joblib.dump(initialLinkLengths,'dumps/initialLinkLengths.dump')\n",
    "joblib.dump(initialPairedLinks,'dumps/initialPairedLinks.dump')\n",
    "joblib.dump(initialInterconnectedLinks,'dumps/initialInterconnectedLinks.dump')\n",
    "joblib.dump(initialBlockEdges,'dumps/initialBlockEdges.dump')\n",
    "joblib.dump(zoomNodeToComponent,'dumps/zoomNodeToComponent.dump')\n",
    "joblib.dump(zoomComponentToNodes,'dumps/zoomComponentToNodes.dump')\n",
    "joblib.dump(zoomComponents,'dumps/zoomComponents.dump')\n",
    "joblib.dump(zoomFromComponentLinks,'dumps/zoomFromComponentLinks.dump')\n",
    "joblib.dump(zoomToComponentLinks,'dumps/zoomToComponentLinks.dump')\n",
    "joblib.dump(zoomLinkLengths,'dumps/zoomLinkLengths.dump')\n",
    "joblib.dump(zoomPairedLinks,'dumps/zoomPairedLinks.dump')\n",
    "joblib.dump(zoomInterconnectedLinks,'dumps/zoomInterconnectedLinks.dump')\n",
    "joblib.dump(zoomOldToNewRemoval,'dumps/zoomOldToNewRemoval.dump')\n",
    "joblib.dump(zoomNewToOldRemoval,'dumps/zoomNewToOldRemoval.dump')\n",
    "joblib.dump(zoomLinkLengthsRemoval,'dumps/zoomLinkLengthsRemoval.dump')\n",
    "joblib.dump(zoomPairedLinksRemoval,'dumps/zoomPairedLinksRemoval.dump')\n",
    "joblib.dump(zoomInterconnectedLinksRemoval,'dumps/zoomInterconnectedLinksRemoval.dump')\n",
    "joblib.dump(zoomBlockEdgesRemoval,'dumps/zoomBlockEdgesRemoval.dump')\n",
    "joblib.dump(zoomFromComponentLinksRemoval,'dumps/zoomFromComponentLinksRemoval.dump')\n",
    "joblib.dump(zoomToComponentLinksRemoval,'dumps/zoomToComponentLinksRemoval.dump')\n",
    "joblib.dump(graph,'dumps/graph.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "initialLinkLengths = joblib.load('dumps/initialLinkLengths.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "initialPairedLinks = joblib.load('dumps/initialPairedLinks.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "initialInterconnectedLinks = joblib.load('dumps/initialInterconnectedLinks.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "initialBlockEdges = joblib.load('dumps/initialBlockEdges.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomNodeToComponent = joblib.load('dumps/zoomNodeToComponent.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomComponentToNodes = joblib.load('dumps/zoomComponentToNodes.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomComponents = joblib.load('dumps/zoomComponents.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomFromComponentLinks = joblib.load('dumps/zoomFromComponentLinks.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomToComponentLinks = joblib.load('dumps/zoomToComponentLinks.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomLinkLengths = joblib.load('dumps/zoomLinkLengths.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomPairedLinks = joblib.load('dumps/zoomPairedLinks.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomInterconnectedLinks = joblib.load('dumps/zoomInterconnectedLinks.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomOldToNewRemoval = joblib.load('dumps/zoomOldToNewRemoval.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomNewToOldRemoval = joblib.load('dumps/zoomNewToOldRemoval.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomLinkLengthsRemoval = joblib.load('dumps/zoomLinkLengthsRemoval.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomPairedLinksRemoval = joblib.load('dumps/zoomPairedLinksRemoval.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomInterconnectedLinksRemoval = joblib.load('dumps/zoomInterconnectedLinksRemoval.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomBlockEdgesRemoval = joblib.load('dumps/zoomBlockEdgesRemoval.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomFromComponentLinksRemoval = joblib.load('dumps/zoomFromComponentLinksRemoval.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoomToComponentLinksRemoval = joblib.load('dumps/zoomToComponentLinksRemoval.dump')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "graph = joblib.load('dumps/graph.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node processing time increase significantly with overall number of nodes. This is wrong and should be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfileDir = '../../1001G/coreGraph'\n",
    "coreGFApath = f'{pathfileDir}{os.path.sep}coreGraph_f2.1_Ref_v04.gfa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coregraph = GenomeGraph(gfaPath=coreGFApath,isGFASeq=False)\n",
    "coregraph_genes = deepcopy(coregraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullGraphPath = '../../1001G/pantograph/data/AT_Chr1_OGOnly_2.1.gfa'\n",
    "fullgraph = GenomeGraph(gfaPath=fullGraphPath,isGFASeq=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainToGenesFile = 'chain2gene_f2.1_Ref_v04.txt'\n",
    "maxChainLength = len(coregraph.nodes[0])\n",
    "chainToListDict = {}\n",
    "with open(f'{pathfileDir}{os.path.sep}{chainToGenesFile}') as f:\n",
    "    for line in f:\n",
    "        chainName, geneList = line.split(':')\n",
    "        geneList = geneList.lstrip().rstrip().split(',')\n",
    "        chainToListDict[chainName.zfill(maxChainLength)] = geneList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nodeIdx,nodeName in enumerate(coregraph.nodes):\n",
    "    print(f'\\nNode {nodeIdx+1}/{len(coregraph.nodes)}',end='')\n",
    "    geneList = chainToListDict.get(nodeName.zfill(maxChainLength), [f'ch{nodeName.zfill(7)}'])\n",
    "    geneIds = []\n",
    "    if geneList[0][:2]!='ch':\n",
    "        geneIds = [int(gene.rstrip('+'))-1 for gene in geneList]\n",
    "        geneList = [fullgraph.nodes[geneid] for geneid in geneIds]\n",
    "    coregraph_genes.nodesData[nodeIdx] = ''.join(geneList)\n",
    "    \n",
    "    for accession, chainDict in coregraph.nodesAnnotation[nodeIdx].items():\n",
    "        interval = chainDict[nodeName]\n",
    "        geneCumLengths = np.hstack((0, np.cumsum([len(gene) for gene in geneList])))\n",
    "        \n",
    "        coregraph.nodesAnnotation[nodeIdx][accession].\\\n",
    "            update({geneAnnotation:interval \\\n",
    "                    for geneid in geneIds \\\n",
    "                        for geneAnnotation in fullgraph.nodesAnnotation[geneid].get(accession,{fullgraph.nodes[geneid]:None}).keys()})\n",
    "\n",
    "        coregraph_genes.nodesAnnotation[nodeIdx][accession].\\\n",
    "            update({geneAnnotation:[(geneCumLengths[i], geneCumLengths[i+1]-1)] \\\n",
    "                            for i,geneid in enumerate(geneIds) \\\n",
    "                                for geneAnnotation in fullgraph.nodesAnnotation[geneid].get(accession,{fullgraph.nodes[geneid]:None}).keys()})\n",
    "\n",
    "        coregraph_genes.nodesAnnotation[nodeIdx][accession].\\\n",
    "            update({nodeName:[(geneCumLengths[0], geneCumLengths[-1]-1)]})\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coregraph.toGFA(f'{pathfileDir}{os.path.sep}coregraph_f2.1_Ref_v04.gfa',doSeq=False)\n",
    "coregraph_genes.toGFA(f'{pathfileDir}{os.path.sep}coregraph_genes_f2.1_Ref_v04.gfa',doSeq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfileDir = '../../1001G/coreGraph'\n",
    "coreGFApath = f'{pathfileDir}{os.path.sep}coregraph_genes_f2.1_Ref_v04.gfa'\n",
    "# coreGFApath = f'{pathfileDir}{os.path.sep}coreGraph.gfa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoomLevels = [1,10,20,100,500,1000,5000,10000,50000,100000,500000,1000000]\n",
    "zoomLevels = [1,3,9,45,90,450,900,4500,9000]\n",
    "# zoomLevels = [1,3,9,18]\n",
    "# zoomLevels = [4,8,16]\n",
    "\n",
    "isSeq = True\n",
    "\n",
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 16\n",
    "invertionThreshold = 0.5\n",
    "# inputPath = '../../1001G/pantograph/data/shorttest2.gfa'\n",
    "# inputPath = '../../1001G/pantograph/data/AT_Chr1_OGOnly.gfa'\n",
    "# inputPath = '../../1001G/chrisGraph/chr1.wfmash.n20.a90.s10000.p1,19,39,3,81,1.seqwish.sort.smooth.sort.gfa'\n",
    "# inputPath = '../../1001G/pantograph/data/shorttest_seq.gfa'\n",
    "inputPath = coreGFApath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomLevels = adjustZoomLevels(zoomLevels)\n",
    "outputPath,outputName = pathConvert(inputPath,suffix='_new')\n",
    "outputPath,outputName,zoomLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "print(f'Opening Redis connection for db {dbid}')\n",
    "redisConn = Redis(host='redis',port = 6379,db=dbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides = \\\n",
    "exportToPantograph(inputPath=inputPath,\n",
    "                   outputName=outputName,\n",
    "                   outputPath=outputPath,\n",
    "                   isSeq=isSeq,\n",
    "                   redisConn=redisConn,\n",
    "                   GenomeGraphParams={'accessionsToRemove':['Consensus']},\n",
    "                   zoomLevels=zoomLevels,\n",
    "                   maxLengthChunk=maxLengthChunk,\n",
    "                   maxLengthComponent=maxLengthComponent,\n",
    "                   invertionThreshold=invertionThreshold,)\n",
    "#                                              debug=True,returnDebugData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ntfy send \"Pantograph data generation for coregraph finished.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting to Pantograph visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectID = 'paths_genegraph'\n",
    "projectName = 'Example gene graph'\n",
    "pathToGraphs = 'examples/gene_graph'\n",
    "caseDict = {'Main': 'paths_genegraph.gfa'}\n",
    "pathToIndex = 'examples/Visdata'\n",
    "\n",
    "# This is if you run it in Docker compose together with active Redis image, which is named \"redis\".\n",
    "# If you have separate redis server, enter full address here.\n",
    "# If you do not want to add any annotation, `redisHost` should be None.\n",
    "redisHost = 'redis'\n",
    "redisPort = 6379\n",
    "redisDB = 0\n",
    "\n",
    "suffix = ''\n",
    "\n",
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 6\n",
    "inversionThreshold = 0.5\n",
    "isSeq = False\n",
    "zoomLevels = [1]\n",
    "fillZoomLevel = True\n",
    "\n",
    "exportProject(projectID, projectName, caseDict, pathToIndex, pathToGraphs,\n",
    "              redisHost = redisHost, redisPort = redisPort, redisDB = redisDB,\n",
    "              suffix = suffix,\n",
    "              maxLengthComponent = maxLengthComponent, maxLengthChunk = maxLengthChunk,\n",
    "              inversionThreshold = inversionThreshold,\n",
    "              isSeq = isSeq,\n",
    "              zoomLevels = zoomLevels, fillZoomLevel = fillZoomLevel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectID = 'tutorial_graph'\n",
    "projectName = 'Example nucleotide graph'\n",
    "pathToGraphs = 'examples/nucleotide_graph'\n",
    "caseDict = {'Main': 'paths_presentation.gfa'}\n",
    "pathToIndex = 'examples/Visdata'\n",
    "\n",
    "# This is if you run it in Docker compose together with active Redis image, which is named \"redis\".\n",
    "# If you have separate redis server, enter full address here.\n",
    "# If you do not want to add any annotation, `redisHost` should be None.\n",
    "redisHost = 'redis'\n",
    "redisPort = 6379\n",
    "redisDB = 0\n",
    "\n",
    "suffix = ''\n",
    "\n",
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 6\n",
    "inversionThreshold = 0.5\n",
    "isSeq = \n",
    "zoomLevels = [1]\n",
    "fillZoomLevel = True\n",
    "\n",
    "exportProject(projectID, projectName, caseDict, pathToIndex, pathToGraphs,\n",
    "              redisHost = redisHost, redisPort = redisPort, redisDB = redisDB,\n",
    "              suffix = suffix,\n",
    "              maxLengthComponent = maxLengthComponent, maxLengthChunk = maxLengthChunk,\n",
    "              inversionThreshold = inversionThreshold,\n",
    "              isSeq = isSeq,\n",
    "              zoomLevels = zoomLevels, fillZoomLevel = fillZoomLevel):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "# Adding gene data mass processing several chromosomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "\n",
    "This is old version of adding subunits to graph containing units (e.g. graph of conserved gene blocks and adding information about individual genes to it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "\n",
    "from pangraph_constructor.utils import checkNodeLengthsFile, pathConvert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "doCreateCoreGenes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pathfileDir = '../../1001G/coreGraph/new_Nov2022'\n",
    "maxLengthComponent = 100\n",
    "maxLengthChunk = 16\n",
    "invertionThreshold = 0.5\n",
    "zoomLevels = [1,3,9]\n",
    "zoomLevels = adjustZoomLevels(zoomLevels)\n",
    "\n",
    "for seqNum in range(1,6):\n",
    "    if doCreateCoreGenes:\n",
    "        coreGFApath = f'{pathfileDir}{os.path.sep}coregraph_v2_Chr{seqNum:d}.gfa'\n",
    "\n",
    "        coregraph = GenomeGraph(gfaPath=coreGFApath,isGFASeq=False)\n",
    "        coregraph_genes = deepcopy(coregraph)\n",
    "\n",
    "        fullGraphPath = f'../../1001G/pantograph/data/AT_Chr{seqNum:d}_OGOnly_2.1.gfa'\n",
    "        fullgraph = GenomeGraph(gfaPath=fullGraphPath,isGFASeq=False)\n",
    "\n",
    "        chainToGenesFile = f'chain2gene.txt'\n",
    "        # maxChainLength = len(coregraph.nodes[0])\n",
    "        chainToListDict = {}\n",
    "        nodeLengths = []\n",
    "        with open(f'{pathfileDir}{os.path.sep}{chainToGenesFile}') as f:\n",
    "            for line in f:\n",
    "                chainName, geneList = line.split(':')\n",
    "                geneList = geneList.lstrip().rstrip().split(',')\n",
    "                chainToListDict[chainName] = geneList\n",
    "\n",
    "        for nodeIdx,nodeName in enumerate(coregraph.nodes):\n",
    "            print(f'\\rNode {nodeIdx+1}/{len(coregraph.nodes)}',end='')\n",
    "            geneList = chainToListDict.get(nodeName, [])\n",
    "            # geneIds = []\n",
    "            # if geneList[0][:2]!='ch':\n",
    "            geneList = [gene.rstrip('+') for gene in geneList]\n",
    "            geneIds = [fullgraph.nodes.index(genename) for genename in geneList]\n",
    "            # coregraph_genes.nodesData[nodeIdx] = ''.join(geneList)\n",
    "            geneNum = max(1,len(geneList))\n",
    "            nodeLengths.append(geneNum)\n",
    "\n",
    "            for accession, chainDict in coregraph.nodesAnnotation[nodeIdx].items():\n",
    "                interval = chainDict[nodeName]\n",
    "                # geneCumLengths = np.hstack((0, np.cumsum([len(gene) for gene in geneList])))\n",
    "                \n",
    "                coregraph.nodesAnnotation[nodeIdx][accession].pop(nodeName,None)\n",
    "                \n",
    "                coregraph.nodesAnnotation[nodeIdx][accession].\\\n",
    "                    update({geneAnnotation:interval \\\n",
    "                            for i,geneid in enumerate(geneIds) \\\n",
    "                                for geneAnnotation in fullgraph.nodesAnnotation[geneid].get(accession,{fullgraph.nodes[geneid]:None}).keys()})\n",
    "\n",
    "                coregraph_genes.nodesAnnotation[nodeIdx][accession].\\\n",
    "                    update({geneAnnotation:[(i,i)] \\\n",
    "                                    for i,geneid in enumerate(geneIds) \\\n",
    "                                        for geneAnnotation in fullgraph.nodesAnnotation[geneid].get(accession,{fullgraph.nodes[geneid]:None}).keys()})\n",
    "\n",
    "                # coregraph_genes.nodesAnnotation[nodeIdx][accession].\\\n",
    "                #     update({nodeName:[(0, geneNum-1)]})\n",
    "        print('')\n",
    "\n",
    "    coreGFApath = f'{pathfileDir}{os.path.sep}coregraph_v2_Chr{seqNum:d}.gfa'\n",
    "    coreGeneGFApath = f'{pathfileDir}{os.path.sep}coregraph_v2_genes_Chr{seqNum:d}.gfa'\n",
    "    \n",
    "    if doCreateCoreGenes:\n",
    "        coreGeneNodeLengthsPath = f'{pathfileDir}{os.path.sep}nodeLengths_coregraph_v2_genes_Chr{seqNum:d}.dat'\n",
    "\n",
    "        coregraph.toGFA(coreGFApath,doSeq=False)\n",
    "        coregraph_genes.toGFA(coreGeneGFApath,doSeq=True)\n",
    "        joblib.dump(nodeLengths,coreGeneNodeLengthsPath)\n",
    "\n",
    "    #Exporting chain graph with annotation only\n",
    "    isSeq = False\n",
    "    inputPath = coreGFApath\n",
    "    \n",
    "    outputPath,outputName = pathConvert(inputPath,suffix='_new')\n",
    "\n",
    "    # dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "    # print(f'Opening Redis connection for db {dbid}')\n",
    "    redisConn = Redis(host='redis',port = 6379,db=0)\n",
    "\n",
    "    exportToPantograph(inputPath=inputPath,\n",
    "                       outputName=outputName,\n",
    "                       outputPath=outputPath,\n",
    "                       isSeq=isSeq,\n",
    "                       redisConn=redisConn,\n",
    "                       GenomeGraphParams={'accessionsToRemove':['Consensus']},\n",
    "                       zoomLevels=zoomLevels,\n",
    "                       fillZoomLevels=True,\n",
    "                       maxLengthChunk=maxLengthChunk,\n",
    "                       maxLengthComponent=maxLengthComponent,\n",
    "                       inversionThreshold=inversionThreshold,)\n",
    "\n",
    "    #Exporting chain graph with genes\n",
    "    isSeq = False\n",
    "    inputPath = coreGeneGFApath\n",
    "    \n",
    "    outputPath,outputName = pathConvert(inputPath,suffix='_new')\n",
    "\n",
    "    # dbid = getDBID('../pantograph_API/data/caseToDBID.dict',outputName)\n",
    "    # print(f'Opening Redis connection for db {dbid}')\n",
    "    redisConn = Redis(host='redis',port = 6379,db=0)\n",
    "\n",
    "    exportToPantograph(inputPath=inputPath,\n",
    "                       outputName=outputName,\n",
    "                       outputPath=outputPath,\n",
    "                       isSeq=isSeq,\n",
    "                       nodeLengths=checkNodeLengthsFile(inputPath),\n",
    "                       redisConn=redisConn,\n",
    "                       GenomeGraphParams={'accessionsToRemove':['Consensus']},\n",
    "                       zoomLevels=zoomLevels,\n",
    "                       fillZoomLevels=True,\n",
    "                       maxLengthChunk=maxLengthChunk,\n",
    "                       maxLengthComponent=maxLengthComponent,\n",
    "                       inversionThreshold=inversionThreshold,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7b547a9d",
   "metadata": {},
   "source": [
    "---\n",
    "description: Provides functionality to export graph to Pantograph data storage.\n",
    "output-file: exportdev.html\n",
    "title: Export module\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp exportDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3abd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfa6934",
   "metadata": {},
   "source": [
    "## Imports and templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e486e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "import traceback\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import pdb\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from sortedcontainers import SortedSet\n",
    "from multiprocessing import Pool,Process, Manager, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "from redis import ResponseError\n",
    "\n",
    "from pangraph_constructor.utils import pathConvert,NpEncoder,adjustZoomLevels\n",
    "from pangraph_constructor.utils import iset_add,resetDB\n",
    "from pangraph_constructor.graph import GenomeGraph\n",
    "from pangraph_constructor.graph import initialPathAnalysis,calcNodeLengths\n",
    "from pangraph_constructor.graph import getNodesStructurePathNodeInversionRate,pathNodeDirToCombinedArray,getNextNodePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01cb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc714621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "componentTemplate = {\n",
    "    \"first_bin\": 1,\n",
    "    \"last_bin\": 1,\n",
    "    \"firstCol\": 1,\n",
    "    \"lastCol\": 1,\n",
    "    \"occupants\": [],\n",
    "    \"matrix\": [],\n",
    "    \"larrivals\": [],\n",
    "    \"rarrivals\": [],\n",
    "    \"ldepartures\": [],\n",
    "    \"rdepartures\": [],\n",
    "    \"x\": 0\n",
    "}\n",
    "\n",
    "chunkTemplate = {\n",
    "    \"json_version\":19,\n",
    "    \"first_bin\": 1,\n",
    "    \"first_col\": 1,\n",
    "    \"last_bin\": 1,\n",
    "    \"last_col\": 1,\n",
    "    \"includes_connectors\": True,\n",
    "    \"components\": []\n",
    "}\n",
    "\n",
    "rootStructTemplate = {\n",
    "    \"json_version\": 19,\n",
    "    \"pangenome_length\": 0,#pangenomeLength, #total number of bp in pangenome\n",
    "    \"includes_connectors\": True,\n",
    "    \"zoom_levels\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba18c2",
   "metadata": {},
   "source": [
    "## Functions intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf3007",
   "metadata": {},
   "source": [
    "**Notation and terminology**\n",
    "\n",
    "In documentation, we refer to graph nucleotides, columns and components. Components contain columns and columns contain nucleotides.\n",
    "\n",
    "In the code variable names and comments use slightly different notation. Columns in documentation are bins in code and comments, whereas graph nucleotides in documentation are called columns in the code and comments. This happened for the legacy reasons, i.e. originally there was no nucleotide numbers (columns) in the visualised graph structure and components were split into bins (literally, equal sized bins). It is not true anymore, but old terminology left here.\n",
    "\n",
    "Ideally all variable names and comments should be changes in line with documentation notation, but I have no idea when this can happen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95390ac7",
   "metadata": {},
   "source": [
    "components: keys: 0-based, values: occupants: 0-based, binNumbers: 0-based  \n",
    "componentToNode: keys: 0-based, values: 1-based  \n",
    "nodeToComponent: keys: 0-based, values: 1-based  \n",
    "newToOldInd and oldToNewInd: both index and values are 0-based numbers of components in previous and current zoomlayer.  \n",
    "fromLinks: top level keys (from nodes): 1-based, bottom level keys (to nodes): 1-based, values (list of participants): 0-based  \n",
    "toLinks: top level keys (to nodes): 1-based, bottom level keys (from nodes): 1-based, values (list of participants): 0-based  \n",
    "fromComponentLinks: top level keys (from components): 1-based, bottom level keys (to components): 1-based, values (set of participants): 0-based  \n",
    "toComponentLinks: top level keys (to components): 1-based, bottom level keys (from components): 1-based, values (set of participants): 0-based  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1a0f8",
   "metadata": {},
   "source": [
    "To be updated!!!\n",
    "![title](images/exportFunctionRelations.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0161a0",
   "metadata": {},
   "source": [
    "## Generating base layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e5f62-c237-4e39-8ca3-a23c5e8867c1",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154886e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def outLeftRight(nodeInversionInPath,leftFarLink,rightFarLink,reason,debug=False,inversionThreshold=0.5):\n",
    "    \n",
    "    if (nodeInversionInPath<=inversionThreshold):\n",
    "#         if debug:\n",
    "#             print(f'Node {nodeIdx}: Component will be broken after node {nodeIdx} due to {reason} to node {nextNode}.')\n",
    "        rightFarLink = True\n",
    "    else:\n",
    "#         if debug:\n",
    "#             print(f'Node {nodeIdx}: Component will be broken before node {nodeIdx} due to {reason} to node {nextNode}.')\n",
    "        leftFarLink = True\n",
    "        \n",
    "    return leftFarLink,rightFarLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def recordLinks(nodeIdx,nextNode,pathID,step,nodeInversionInPath,nonLinearCond,pathNodeArray,fromLinks,toLinks,debug=False,inversionThreshold=0.5):\n",
    "    leftFarLink = False\n",
    "    rightFarLink = False\n",
    "    if nonLinearCond:\n",
    "        if debug:\n",
    "            print(f'Non-linear link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "        fromLinks.setdefault(nodeIdx,{}).setdefault(nextNode,[]).append(pathID)\n",
    "        toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "        leftFarLink,rightFarLink = outLeftRight(nodeInversionInPath,leftFarLink,rightFarLink,'backward link',debug=debug,inversionThreshold=0.5)\n",
    "            \n",
    "    else:\n",
    "        if np.any([node in pathNodeArray[pathID,:] for node in range(nodeIdx+1*step,nextNode,step)]):\n",
    "            if debug:\n",
    "                print(f'Jump link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "            fromLinks.setdefault(nodeIdx,{}).setdefault(nextNode,[]).append(pathID)\n",
    "            toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "            \n",
    "            leftFarLink,rightFarLink = outLeftRight(nodeInversionInPath,leftFarLink,rightFarLink,'forward jumping link',debug=debug,inversionThreshold=0.5)\n",
    "        else:\n",
    "            startNode = None\n",
    "            endNode = None\n",
    "\n",
    "            if step==-1:\n",
    "                startNode = nodeIdx\n",
    "                endNode = nextNode\n",
    "                if debug:\n",
    "                    print(f'Intermediate nodes for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "            elif step==1:\n",
    "                startNode = nodeIdx\n",
    "                endNode = nextNode\n",
    "                if debug:\n",
    "                    print(f'Intermediate nodes for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f'Jump link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "                fromLinks.setdefault(nodeIdx,{}).setdefault(nextNode,[]).append(pathID)\n",
    "                toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "                leftFarLink,rightFarLink = outLeftRight(nodeInversionInPath,leftFarLink,rightFarLink,'forward jumping link',debug=debug,inversionThreshold=0.5)\n",
    "\n",
    "            if startNode is not None and endNode is not None and step is not None:\n",
    "                for intermediateNodeIdx in range(startNode,endNode,step):\n",
    "                    if debug:\n",
    "                        print(f'Adding link from node {intermediateNodeIdx} to node {intermediateNodeIdx+1*step} for path {pathID}')\n",
    "                    fromLinks.setdefault(intermediateNodeIdx,{}).setdefault(intermediateNodeIdx+1*step,[]).append(pathID)\n",
    "                    toLinks.setdefault(intermediateNodeIdx+1*step,{}).setdefault(intermediateNodeIdx,[]).append(pathID)\n",
    "    return leftFarLink,rightFarLink,fromLinks,toLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214452b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkForBreak(nodeIdx,nodeLen,\n",
    "                  nodePathsIdx,nodeSeqInPath,\n",
    "                  uniqueNodePathsIDs,pathNodeCount,\n",
    "                  pathLengths,\n",
    "                  pathNodeArray,pathDirArray,\n",
    "                  occupancy,inversion,\n",
    "                  fromLinks,toLinks,\n",
    "                  nBins,maxLengthComponent,\n",
    "                  blockEdges,\n",
    "                  inversionThreshold=0.5,\n",
    "                  debug=False):\n",
    "    '''\n",
    "    Function to check whether the component should be broken before (left) and/or after (right) it.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    `nodeIdx`: int. Numerical (1 based) node ID within the graph (consecutive number of the node)\n",
    "               in the graph order.\n",
    "    \n",
    "    #######\n",
    "    The following 5 parameters are calculated in `nodeStat` function externally and passed here:\n",
    "    `nodeLen`: int. Length of the node in nucleotides\n",
    "    `nodePathsIdx`: numpy.array. A 1D numpy.array which contain ids of the paths \n",
    "                    for each appearance of the node ID in each path.\n",
    "    `nodeSeqInPath`: numpy.array. A 1D numpy.array with positions of given node in every path. \n",
    "                     The path to which this position is related to can be found from `nodePathsIdx`, \n",
    "                     e.g. if `nodeSeqInPath[i]` is `k`, then node with node ID `nodeIdx`\n",
    "                     appear in path `nodePathsIdx[i]` at position `k`.\n",
    "    `uniqueNodePathsIDs`: Iterable[int]. Usually a list or 1D numpy.array holding unique IDs of paths \n",
    "                          which pass this node at least once.\n",
    "    `pathNodeCount`: numpy.array.: A 1D array (the same length as `uniqueNodePathsIDs`) which \n",
    "                     contains number of times the node appear in each path from `uniqueNodePathsIDs`,\n",
    "                     e.g. if `pathNodeCount[i]` is `k` then node with ID nodeIdx appears in path\n",
    "                     `uniqueNodePathsIds[i]` `k` times.\n",
    "    #######\n",
    "    \n",
    "    `occupancy`: dict. A dictionary containing occupancy (number of times given path passed the given \n",
    "                 node) of the previous node (in terms of graph order) for each path than passed \n",
    "                 through previous node. The dictionary has path IDs as keys.\n",
    "    `inversion`: dict. A dictionary containing inversion (fraction of copies of the node in the path \n",
    "                 that are inverted) of the previous node (in terms of graph order) for each path than \n",
    "                 passed through previous node. The dictionary has path IDs as keys.\n",
    "    `fromLinks`: dict[dict[list]]. Dictionary which holds links from each processed node.\n",
    "    `toLinks`: dict[dict[list]]. Dictionary which holds links to each processed node.\n",
    "    `nBins`: int. Number of bins recorded in the current component.\n",
    "    `maxLengthComponent`: int. Maximum number of bins allowed in a component. Used to break too \n",
    "                          long components into smaller more manageable blocks.\n",
    "    `pathDirArray`: 2D numpy.array. Each row (corresponding to specific path in graph) contains directionality\n",
    "                    of each node in the path. See `initialPathAnalysis` for details.\n",
    "    `inversionThreshold`: float (default: 0.5). A threshold after which the node is considered inverted.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    `leftFarLink`: bool. Shows whether there is a far link on the left that will require component break.\n",
    "    `rightFarLink`: bool. Shows whether there is a far link on the right that will require component break.\n",
    "    `leftPathStartEnd`: bool. Shows whether there is a start or end of the path on the left of the node.\n",
    "    `rightPathStartEnd`: bool. Shows whether there is a start or end of the path on the right of the node.\n",
    "    `isChangedOccupancy`: bool. Shows whether the occupancy of at least one path significantly changed \n",
    "                          from previous node. If previous node was missing, and current node has any \n",
    "                          occupancy, it will be False as it does not constitute a component break.\n",
    "    `isChangeInversion`: bool. Shows whether the inversion of at least one path significantly changed \n",
    "                          from previous node.\n",
    "    `isNotFitIntoComponent`: bool. Shows whether this node won't fit into the currently forming component\n",
    "                             and it should be broken before the current node.\n",
    "    `pathStarts`: list. Contains list of path IDs which start from this node.\n",
    "    `pathEnds`: list. Contains list of path IDs which end on this node.\n",
    "    `fromLinks`: dict[dict[list]]\n",
    "    `toLinks`: \n",
    "    `occupancy`: dict. A dictionary containing occupancy (number of times given path passed the given \n",
    "                 node) of the current node (in terms of graph order) for each path than passed \n",
    "                 through previous node. The dictionary has path IDs as keys.\n",
    "    `inversion`: dict. A dictionary containing inversion (fraction of copies of the node in the path \n",
    "                 that are inverted) of the current node (in terms of graph order) for each path than \n",
    "                 passed through previous node. The dictionary has path IDs as keys.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Boolean indicator of far incoming link on the left and right\n",
    "    leftFarLink = False\n",
    "    rightFarLink = False\n",
    "\n",
    "    # Boolean if at least one path starts from this node and start is on the left or right\n",
    "    leftPathStart = False\n",
    "    rightPathStart = False\n",
    "    # Boolean if at least one path ends on this node and end is on the left or right\n",
    "    leftPathEnd = False\n",
    "    rightPathEnd = False\n",
    "\n",
    "    # Indicator whether occupancy changed from one node to the next\n",
    "    # isChangedOccupancy = False\n",
    "    \n",
    "    # Indicator whether inversion is changed from one side of\n",
    "    # `inversionThreshold` to the other.\n",
    "    # isChangeInversion = False\n",
    "    \n",
    "    # Indicator whether structure (inversion and occupancy combination over all paths) changed from previous node\n",
    "    isChangedStructure = nodeIdx-1 in blockEdges\n",
    "    \n",
    "    # Indicator whether this node does not fit into current component.\n",
    "    isNotFitIntoComponent = False\n",
    "\n",
    "    pathEnds = np.sort(np.unique([pathIdx for pathIdx,nodeInSeq in zip(nodePathsIdx,nodeSeqInPath) if nodeInSeq==pathLengths[pathIdx]-1]))\n",
    "    pathStarts = np.sort(np.unique([pathIdx for pathIdx,nodeInSeq in zip(nodePathsIdx,nodeSeqInPath) if nodeInSeq==0]))\n",
    "    \n",
    "    invertedEnds = set()\n",
    "    invertedStarts = set()\n",
    "    \n",
    "    # Check whether adding this node to the current component will violate the limitation\n",
    "    # for maximum component length. Is it still needed with proper treatment of partially\n",
    "    # visible components in the front-end???\n",
    "    if nBins+nodeLen>maxLengthComponent:\n",
    "        isNotFitIntoComponent = True\n",
    "    \n",
    "    # Check whether component should be broken before current node.\n",
    "    for j, pathID in enumerate(uniqueNodePathsIDs):\n",
    "        \n",
    "        # Check whether occupancy changed from previous node.\n",
    "        # That will require breaking component before current node.\n",
    "        # if nodeIdx>1:\n",
    "        #     if np.abs(pathNodeCount[j]-occupancy.get(pathID,0))>0 and occupancy.get(pathID,0)>0:\n",
    "        #         isChangedOccupancy = True\n",
    "        \n",
    "        # Calculate occupancy of current node for path\n",
    "        # It is simply how many times this node is passed by current path.\n",
    "        occupancy[pathID] = pathNodeCount[j]\n",
    "        \n",
    "        # Calculate inversion rate of current node for path\n",
    "        # It is ratio of how many times the node is passed in reversed direction\n",
    "        # by the path to overall occupancy of the node by the path.\n",
    "        nodePositions = np.where(nodePathsIdx==pathID)[0]\n",
    "        \n",
    "        nodeInversionInPath = np.sum([int(pathDirArray[pathID,nodeNumInPath]) \\\n",
    "                          for nodeNumInPath in nodeSeqInPath[nodePositions]])\\\n",
    "                          /occupancy[pathID]\n",
    "        \n",
    "        # Check whether inversion is switched from one side of `inversionThreshold` to the other side.\n",
    "        # if nodeIdx>1 and (nodeInversionInPath-inversionThreshold)*(inversion.get(pathID, nodeInversionInPath)-inversionThreshold)<0:\n",
    "        #     isChangeInversion = True\n",
    "        # Record current inversion for current pathID for bins generation.\n",
    "        inversion[pathID] = nodeInversionInPath\n",
    "\n",
    "        # Get indexes of positions of the node in the path\n",
    "        \n",
    "        \n",
    "        # Check whether the node \n",
    "        if nodeInversionInPath<=inversionThreshold:\n",
    "            # not inverted node\n",
    "            leftPathStart = leftPathStart or (pathID in pathStarts)\n",
    "            rightPathEnd = rightPathEnd or (pathID in pathEnds)\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f'Node {nodeIdx}, accession {graph.accessions[pathID]}, inversion {nodeInversionInPath}')\n",
    "            # inverted node\n",
    "            rightPathStart = rightPathStart or (pathID in pathStarts)\n",
    "            \n",
    "            if pathID in pathStarts:\n",
    "                invertedStarts.add(pathID)\n",
    "            \n",
    "            leftPathEnd = leftPathEnd or (pathID in pathEnds)\n",
    "            \n",
    "            if pathID in pathEnds:\n",
    "                invertedEnds.add(pathID)\n",
    "        \n",
    "        for nodePos in nodePositions:\n",
    "            # Boolean flags to whether check and record incoming and outgoing links\n",
    "            checkIn = False\n",
    "            checkOut = False\n",
    "            # Get the sequencial number of node in the path (for current passing), can be several for duplicated nodes\n",
    "            nodePositionInPath = nodeSeqInPath[nodePos]\n",
    "            \n",
    "            if nodePositionInPath<(pathLengths[pathID]-1):\n",
    "                # if not last node in the path\n",
    "                checkOut = True\n",
    "                nextNode = pathNodeArray[pathID,nodePositionInPath+1]\n",
    "                nextNodePositions = np.where(pathNodeArray[pathID,:]==nextNode)[0]\n",
    "                nextNodeInversionInPath = np.sum([int(pathDirArray[pathID,nodeInPathPos]) for nodeInPathPos in nextNodePositions])/len(nextNodePositions)\n",
    "                if debug:\n",
    "                    print(f'Node {nodeIdx}, next node {nextNode}, path {pathID}, number in path {nodePositionInPath}, length of path {pathLengths[pathID]}')\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(\"Last node in path\")\n",
    "            \n",
    "            if nodePositionInPath>0:\n",
    "                checkIn = True\n",
    "                prevNode = pathNodeArray[pathID,nodePositionInPath-1]\n",
    "                prevNodePositions = np.where(pathNodeArray[pathID,:]==prevNode)[0]\n",
    "                prevNodeInversionInPath = np.sum([int(pathDirArray[pathID,nodeInPathPos]) for nodeInPathPos in prevNodePositions])/len(prevNodePositions)\n",
    "                if debug:\n",
    "                    print(f'Node {nodeIdx}, previous node {nextNode}, path {pathID}, number in path {nodePositionInPath}, length of path {pathLengths[pathID]}')\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(\"First node in path\")\n",
    "            \n",
    "            \n",
    "            if nodeInversionInPath<=inversionThreshold:\n",
    "            # Not inverted node\n",
    "            # For the node find the links going to the left of the node\n",
    "                if checkIn:\n",
    "                    # node is not the first\n",
    "                    if debug:\n",
    "                        print(f\"IncomingLinks: {prevNode} -> {nodeIdx}\")\n",
    "                        print(f'Existing known links: {fromLinks.get(prevNode,{})}')\n",
    "\n",
    "                    if prevNode+1!=nodeIdx:\n",
    "                        # Link in the path does not go between consecutive nodes (from previous to current)\n",
    "                        # This means that there is a links coming to the left of the node\n",
    "                        if (prevNode<nodeIdx and nodeIdx in fromLinks.get(prevNode,{})) or (prevNode>=nodeIdx):\n",
    "                            # If we are not picking up passing through empty blocks as far link\n",
    "                            # Tandem duplicates are included as they cause an arrow to the left of the node.\n",
    "                            leftFarLink = True\n",
    "                if checkOut:\n",
    "                    # node is not the last\n",
    "                    \n",
    "                    # Find out whether it is a non-linear (e.g. reversed link or link from inversed to non-inversed node).\n",
    "                    if nextNodeInversionInPath<=inversionThreshold:\n",
    "                        # The inversion is the same for two consecutive (in path) nodes\n",
    "                        # Link will be non-linear if previous node is staying further in linearised graph\n",
    "                        nonLinearCond = (nodeIdx>=nextNode)\n",
    "                        # Step for checking for jumping over link\n",
    "                        step = 1\n",
    "                    else:\n",
    "                        # The inversion is not the same for two consecutive nodes.\n",
    "                        nonLinearCond = True\n",
    "                        # Step is not used and assigned for consistency\n",
    "                        step =0\n",
    "                        \n",
    "                    # Process links from (!) this node.\n",
    "                    _leftFarLink,_rightFarLink,fromLinks,toLinks = \\\n",
    "                    recordLinks(nodeIdx,nextNode,pathID,\n",
    "                                step,nodeInversionInPath,\n",
    "                                nonLinearCond,\n",
    "                                pathNodeArray,\n",
    "                                fromLinks,toLinks,\n",
    "                                debug=debug,\n",
    "                                inversionThreshold=inversionThreshold)\n",
    "                    \n",
    "                    leftFarLink = leftFarLink or _leftFarLink\n",
    "                    rightFarLink = rightFarLink or _rightFarLink\n",
    "                            \n",
    "            else:\n",
    "                #Inverted node\n",
    "                # For the node find the links goint from the left of the node\n",
    "                if checkOut:\n",
    "                    # node is not the last\n",
    "                    # Find out whether it is a non-linear (e.g. reversed link or link from inversed to non-inversed node).\n",
    "                    if nextNodeInversionInPath>inversionThreshold:\n",
    "                        # The inversion is the same for two consecutive (in path) nodes\n",
    "\n",
    "                        # Link will be non-linear if previous node is staying further in linearised graph\n",
    "                        nonLinearCond  = (nodeIdx<=nextNode)\n",
    "                        # Step for checking for jumping over link\n",
    "                        step = -1\n",
    "                    else:\n",
    "                        # The inversion is not the same for two consecutive nodes.\n",
    "                        nonLinearCond = True\n",
    "                        # Step is not used and assigned for consistency\n",
    "                        step = 0\n",
    "                        \n",
    "                    _leftFarLink,_rightFarLink,fromLinks,toLinks = \\\n",
    "                    recordLinks(nodeIdx,nextNode,pathID,\n",
    "                                step,nodeInversionInPath,\n",
    "                                nonLinearCond,\n",
    "                                pathNodeArray,\n",
    "                                fromLinks,toLinks,\n",
    "                                debug=debug,\n",
    "                                inversionThreshold=inversionThreshold)\n",
    "                    \n",
    "                    leftFarLink = leftFarLink or _leftFarLink\n",
    "                    rightFarLink = rightFarLink or _rightFarLink\n",
    "                \n",
    "                if checkIn:\n",
    "                    # The node is not the first\n",
    "                    if debug:\n",
    "                        print(f\"IncomingLinks: {nodeIdx} -> {nextNode}\")\n",
    "                        print(f'Existing known links: {toLinks.get(nextNode,{})}')\n",
    "\n",
    "                    if nodeIdx-1!=nextNode:\n",
    "                        # Link does not go between consecutive blocks (from this to previous one)\n",
    "                        if (nodeIdx>nextNode and nodeIdx in toLinks.get(nextNode,{})) or (nodeIdx<=nextNode):\n",
    "                            # If we are not picking up passing through empty blocks as far link\n",
    "                            # Tandems duplicates are included as they also cause an arrow from the left of the node.\n",
    "                            rightFarLink = True\n",
    "        \n",
    "    return (leftFarLink,rightFarLink,\n",
    "            leftPathStart or leftPathEnd,\n",
    "            rightPathStart or rightPathEnd,\n",
    "            isChangedStructure,\n",
    "            isNotFitIntoComponent,\n",
    "            pathStarts,pathEnds,\n",
    "            fromLinks,toLinks,\n",
    "            occupancy,inversion,\n",
    "            invertedStarts,invertedEnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bead44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nodeStat(nodeIdx,pathNodeArray,nodeLengths):\n",
    "    '''\n",
    "    Function calculate information about node as part of the overall graph.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    `nodeIdx`: int. Number of the node in the graph (1 based).\n",
    "    `pathNodeArray`: numpy.array. A 2D array (<number of paths> x <max lengths of path>), \n",
    "                     where each line present sequence of node IDs in a particular path.\n",
    "                     Path ordered as they are present in the graph.\n",
    "    `nodeLengths`: list or numpy.array. An 1D subscribable structure \n",
    "                   (normally, list or 1D numpy.array is expected) where each element i\n",
    "                   is the length of the node ID (1 based) i+1.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    `nodePathsIdx`: numpy.array. A 1D numpy.array which contain ids of the paths \n",
    "                    for each appearance of the node ID in each path.\n",
    "    `nodeSeqInPath`: numpy.array. A 1D numpy.array with positions of given node in every path. \n",
    "                     The path to which this position is related to can be found from `nodePathsIdx`, \n",
    "                     e.g. if `nodeSeqInPath[i]` is `k`, then node with node ID `nodeIdx`\n",
    "                     appear in path `nodePathsIdx[i]` at position `k`.\n",
    "    `nodeLen`: int. Length of the node (in terms of nucleotides, real or simulated).\n",
    "    `uniqueNodePathsIDs`: numpy.array. A 1D array containing all path IDs (0 based, non-repeated) \n",
    "                          that contains the node.\n",
    "    `pathNodeCount`: numpy.array.: A 1D array (the same length as `uniqueNodePathsIDs`) which \n",
    "                     contains number of times the node appear in each path from `uniqueNodePathsIDs`,\n",
    "                     e.g. if `pathNodeCount[i]` is `k` then node with ID nodeIdx appears in path\n",
    "                     `uniqueNodePathsIds[i]` `k` times.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Find positions of the node in each path\n",
    "    nodePathsIdx, nodeSeqInPath = np.where(pathNodeArray == nodeIdx)\n",
    "    # Find node length\n",
    "    nodeLen = nodeLengths[nodeIdx-1]\n",
    "\n",
    "    # Find unique path IDs (numerical) and cound of given node in each path.\n",
    "    uniqueNodePathsIDs,pathNodeCount = np.unique(nodePathsIdx,return_counts=True)\n",
    "    \n",
    "    return nodePathsIdx,nodeSeqInPath,nodeLen,uniqueNodePathsIDs,pathNodeCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca34b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def finaliseComponentBase(component,\n",
    "                      components,componentNucleotides,\n",
    "                      matrix,occupants,nBins,componentLengths,nucleotides,zoomLevel,accessions,inversionThreshold=0.5):\n",
    "        \n",
    "    componentLengths.append(nBins)\n",
    "    component[\"matrix\"].extend([[pathID,\n",
    "                                 int(matrixPathArray[1][0][1]>inversionThreshold),\n",
    "                                 matrixPathArray] \\\n",
    "                                for pathID,matrixPathArray in matrix.items()])\n",
    "    component['binsToCols'] = [1]*nBins\n",
    "    \n",
    "    component[\"occupants\"] = sorted(list(occupants))\n",
    "    component['last_bin'] = component['first_bin'] + nBins - 1\n",
    "    component['lastCol'] = component['firstCol'] + nBins - 1\n",
    "    component['binColStarts'] = list(range(component['firstCol'],component['lastCol']+1))\n",
    "    component['binColEnds'] = list(range(component['firstCol'],component['lastCol']+1))\n",
    "    if nucleotides!='':\n",
    "        componentNucleotides.append(nucleotides)\n",
    "    \n",
    "    firstBin = component['last_bin'] + 1\n",
    "    firstCol = component['lastCol'] + 1\n",
    "    components.append(component)\n",
    "    component = deepcopy(componentTemplate)\n",
    "    component['first_bin'] = firstBin\n",
    "    component['firstCol'] = firstCol\n",
    "    return component,components,componentNucleotides,{},set(),0,''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def processAnnotationInterval(posStart,posEnd,annotation,res):\n",
    "    for pos in range(posStart,posEnd):\n",
    "        r = []\n",
    "        for name,intervals in annotation.items():\n",
    "            for interval in intervals:\n",
    "                if pos<=interval[1] and pos>=interval[0]:\n",
    "                    r.append(name)\n",
    "        res[pos] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d564e0c-de5f-419e-af78-58bc76a41ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def combineAnnotation(combAnnotation):\n",
    "    for accAnn in combAnnotation.values():\n",
    "        for annString,intList in accAnn.items():\n",
    "            accAnn[annString] = combineIntervals(intList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65287cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def updateEdges(accEdge,edgeAccessions,compNum):\n",
    "    '''\n",
    "    Function fills up either accStarts or accEnds (on which component each accession starts and \n",
    "    on which ends). `compNum` is assumed to be 1-based.\n",
    "    '''\n",
    "    \n",
    "    for accID in edgeAccessions:\n",
    "        accEdge[accID] = compNum\n",
    "        \n",
    "    return accEdge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363a007-2f21-4243-a779-bfe7749a2cd1",
   "metadata": {},
   "source": [
    "### Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def baseLayerZoom(graph,\n",
    "                  outputPath,outputName,\n",
    "                  pathNodeArray,pathDirArray,\n",
    "                  pathLengths,nodeLengths,\n",
    "                  pathNodeLengthsCum,\n",
    "                  maxLengthComponent,\n",
    "                  blockEdges,\n",
    "                  CPUS = cpu_count(),\n",
    "                  inversionThreshold=0.5,\n",
    "                  isSeq=True,\n",
    "                  debug=False,\n",
    "                  debugTime=False):\n",
    "\n",
    "    zoomLevel = 1\n",
    "    \n",
    "    #Create the directory to hold zoomLevel chunks and fasta files (if available)\n",
    "#     createZoomLevelDir(outputPath,outputName,zoomLevel)\n",
    "    \n",
    "\n",
    "    print('\\n===========================')\n",
    "    print(f'Zoom level {zoomLevel}')\n",
    "    print('===========================')\n",
    "    zoom_level_struct = {}\n",
    "    zoom_level_struct[\"files\"] = []\n",
    "    \n",
    "    accStarts = {}\n",
    "    accEnds = {}\n",
    "    \n",
    "    invertedStarts = set()\n",
    "    invertedEnds = set()\n",
    "    \n",
    "    nodeToComponent = []\n",
    "    componentToNode = []\n",
    "    componentLengths = []\n",
    "    components = []\n",
    "    componentNucleotides = []\n",
    "\n",
    "    component = deepcopy(componentTemplate)\n",
    "    \n",
    "    numNodes = len(graph.nodes)\n",
    "    numNodesDigits = np.int(np.ceil(np.log10(numNodes)))\n",
    "    \n",
    "    fromLinks = {}\n",
    "    toLinks = {}\n",
    "    \n",
    "    fromComponentLinks = {}\n",
    "    toComponentLinks = {}\n",
    "    \n",
    "    occupants = set()\n",
    "    nucleotides = ''\n",
    "    matrix = {}\n",
    "\n",
    "    nodeLinks = []\n",
    "\n",
    "    nBins = 0\n",
    "#     previousInv = {}\n",
    "    binLength = 0\n",
    "    occupancy = {}\n",
    "    inversion = {}\n",
    "    pos = {} #???\n",
    "    nodesInComp = set()\n",
    "    annotationNames = {}\n",
    "    \n",
    "    combAnnotation = {}\n",
    "    combGenPos = {}\n",
    "    combGenPosSearch = {}\n",
    "    combAltChrGenPos = {}\n",
    "    annFirstBin = 0\n",
    "#     breakComponentWhenBinEnds = False\n",
    "#         breakCompBeforeBin = False\n",
    "#     binOpen = False\n",
    "#     breakComponent = False\n",
    "#     forceBreak = False\n",
    "    \n",
    "    for nodeIdx in range(1,numNodes+1):\n",
    "        if debug or debugTime:\n",
    "            print(f'Processing node {nodeIdx:0{numNodesDigits}}/{numNodes:0{numNodesDigits}}')\n",
    "        else:\n",
    "            print(f'\\rProcessing node {nodeIdx:0{numNodesDigits}}/{numNodes:0{numNodesDigits}}',end='')\n",
    "        \n",
    "        if debugTime:\n",
    "            startNodeTime = time.time()\n",
    "        ######################\n",
    "        # Node preprocessing #\n",
    "        ######################\n",
    "        # Get some onfo about the node\n",
    "        nodePathsIdx,nodeSeqInPath,nodeLen,uniqueNodePathsIDs,pathNodeCount = \\\n",
    "        nodeStat(nodeIdx,pathNodeArray,nodeLengths)\n",
    "        \n",
    "        # Combining annotations\n",
    "        for accID,accNodeAnn in graph.nodesMetadata[nodeIdx-1].items():    \n",
    "            for annString,intervals in accNodeAnn['annotation'].items():\n",
    "                for interval in intervals:\n",
    "                    combAnnotation.setdefault(accID,{}).\\\n",
    "                    setdefault(annString,[]).\\\n",
    "                    append((interval[0]+annFirstBin,interval[1]+annFirstBin))\n",
    "            for genPos in accNodeAnn.get('genPos',[]):\n",
    "                combGenPos.setdefault(accID,{})[f'{genPos[\"chr\"]}:{\"..\".join(map(str,genPos[\"genomePosition\"]))}']=[(annFirstBin,annFirstBin+nodeLengths[nodeIdx-1]-1)]\n",
    "                combGenPosSearch.setdefault(accID,{})[annFirstBin] = [genPos[\"genomePosition\"]]\n",
    "            for altGenPos in accNodeAnn.get('altChrGenPos',[]):\n",
    "                combAltChrGenPos.setdefault(accID,{})[f'{altGenPos[\"chr\"]}:{\"..\".join(map(str,altGenPos[\"genomePosition\"]))}']=[(annFirstBin,annFirstBin+nodeLengths[nodeIdx-1]-1)]\n",
    "        annFirstBin +=nodeLengths[nodeIdx-1]\n",
    "        \n",
    "        # Check whether the component should be broken before and/or after current node\n",
    "        (leftFarLink,rightFarLink,\n",
    "        leftPathStartEnd,\n",
    "        rightPathStartEnd,\n",
    "        isChangedStructure,\n",
    "        isNotFitIntoComponent,\n",
    "        pathStarts,pathEnds,\n",
    "        fromLinks,toLinks,\n",
    "        occupancy,inversion,\n",
    "        invertedCompStarts,invertedCompEnds) = checkForBreak(nodeIdx,nodeLen,\n",
    "                                             nodePathsIdx,nodeSeqInPath,\n",
    "                                             uniqueNodePathsIDs,pathNodeCount,\n",
    "                                             pathLengths,\n",
    "                                             pathNodeArray,pathDirArray,\n",
    "                                             occupancy,inversion,\n",
    "                                             fromLinks,toLinks,\n",
    "                                             nBins,maxLengthComponent,\n",
    "                                             blockEdges,\n",
    "                                             inversionThreshold=inversionThreshold,\n",
    "                                             debug=debug)\n",
    "        \n",
    "        invertedStarts.update(invertedCompStarts)\n",
    "        invertedEnds.update(invertedCompEnds)\n",
    "        \n",
    "        if debugTime:\n",
    "            print(f'Checking for breaks node {nodeIdx}. Took {time.time() - startNodeTime}')\n",
    "        ###################################\n",
    "        # Breaking component before node. #\n",
    "        ###################################\n",
    "        ## Here component should be broken before node (if determined necessary)\n",
    "        if nodeIdx>1 and \\\n",
    "           (leftPathStartEnd or leftFarLink or isChangedStructure or isNotFitIntoComponent) and \\\n",
    "           nBins>0:\n",
    "            # It is not the first component, and there is at least one flag to break before node and \n",
    "            # there is something to break (the component was not broken after previous node)\n",
    "            if debug:\n",
    "                if leftFarLink:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to left far link.')\n",
    "                elif isChangeOccupancy or isChangeInversion:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to change in inversion or occupancy in a path.')\n",
    "                elif isNotFitIntoComponent:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} because it does not fit into current component.')\n",
    "                else:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to start or end of a path.')\n",
    "\n",
    "            [component,components,\n",
    "            componentNucleotides,\n",
    "            matrix,occupants,\n",
    "            nBins,\n",
    "            nucleotides] = finaliseComponentBase(component,components,\n",
    "                                            componentNucleotides,\n",
    "                                            matrix,occupants,\n",
    "                                            nBins,\n",
    "                                            componentLengths,\n",
    "                                            nucleotides,\n",
    "                                            zoomLevel=zoomLevel,\n",
    "                                            accessions=graph.accessions)\n",
    "            if len(components) not in nodeToComponent[-1]:\n",
    "                nodeToComponent[-1].append(len(components))\n",
    "            componentToNode.append(list(nodesInComp))\n",
    "            nodesInComp = set()\n",
    "        \n",
    "        occupants |= set(uniqueNodePathsIDs)\n",
    "        nodesInComp.add(nodeIdx)\n",
    "        nodeToComponent.append([])\n",
    "        \n",
    "        \n",
    "        #######################################################\n",
    "        # Adding bins and forming components for zoom level 1 #\n",
    "        #######################################################\n",
    "        # TODO: This process for each bin should be parallelised\n",
    "        \n",
    "        # Building nucleotide (real or dummy) for the component.\n",
    "        if isSeq:\n",
    "            nucleotides += graph.nodesData[nodeIdx-1]\n",
    "        # else:\n",
    "        #     nucleotides += graph.nodes[nodeIdx-1]\n",
    "        \n",
    "        # binLength is removed as this function process only single nucleotide level.\n",
    "        \n",
    "        # Preparing annotation for each node and each accession\n",
    "        curNodeAnnotation = {}\n",
    "        \n",
    "        forwardPaths = []\n",
    "        invertedPaths = []\n",
    "        \n",
    "        for j,pathID in enumerate(uniqueNodePathsIDs):\n",
    "            if debugTime:\n",
    "                startTime = time.time()\n",
    "            \n",
    "            pathName = graph.accessions[pathID]\n",
    "            \n",
    "            # get occupancy and inversion for current node in current path.\n",
    "            occ = occupancy[pathID]\n",
    "            inv = inversion[pathID]\n",
    "            \n",
    "            if inv>inversionThreshold:\n",
    "                invertedPaths.append(pathID)\n",
    "            else:\n",
    "                forwardPaths.append(pathID)\n",
    "            \n",
    "            # Creating addition to matrix from this node for this path.\n",
    "            matrixPath = matrix.get(pathID,[[],[]])\n",
    "            \n",
    "            \n",
    "            # Absolute positinal genomic coordinate for given path for each pass of the node.\n",
    "            # NodeStarts are 1-based (position of the first node in the path will be 1).\n",
    "            nodeStarts = np.array([pathNodeLengthsCum[pathID,nodeNumInPath]-nodeLen+1 \\\n",
    "                          for nodeNumInPath in nodeSeqInPath[np.where(nodePathsIdx==pathID)[0]]])\n",
    "            \n",
    "            \n",
    "            # Generating positional pairs for each nucleotide of the node.\n",
    "            posPath = [list(zip(nodeStarts+pos,nodeStarts+pos)) for pos in range(nodeLen)]\n",
    "            \n",
    "            if debugTime:\n",
    "                print(f'Preparation for node {nodeIdx} path {pathName} took {time.time() - startTime}')\n",
    "                annotationTime = time.time()\n",
    "            \n",
    "            ###\n",
    "            # Splitting annotaton into single bins/nucleotides\n",
    "            ###\n",
    "            # Do a test for when number of annotation records X number of nucleotides give benefit of parallelising \n",
    "            # and do an check. If it is larger, then run in parallel, otherwise, do sequencially.\n",
    "#             if len(graph.nodesAnnotation[nodeIdx-1].get(pathName,{}))*nodeLengths[nodeIdx-1]>2e6:\n",
    "#                 blockSize = int(np.ceil(nodeLen/CPUS))\n",
    "#                 bounds = list(range(0,nodeLen + nodeLen%blockSize+1,blockSize))\n",
    "#                 intervals = list(zip(bounds[:-1],bounds[1:]))\n",
    "#                 intervals[-1] = (intervals[-1][0],nodeLen)\n",
    "#                 manager = Manager()\n",
    "#                 annotations = manager.list([[]]*nodeLen)\n",
    "#                 processList = [Process(target=processAnnotationInterval,\n",
    "#                                        args=(*ints,graph.nodesAnnotation[nodeIdx-1].get(pathName,{}),\n",
    "#                                              annotations)) for ints in intervals]\n",
    "#                 [p.start() for p in processList]\n",
    "#                 [p.join() for p in processList]\n",
    "#                 annotations = list(annotations)\n",
    "#             else:\n",
    "#                 annotations = [[]]*nodeLen\n",
    "#                 processAnnotationInterval(0,nodeLen,graph.nodesAnnotation[nodeIdx-1].get(pathName,{}),annotations)\n",
    "            \n",
    "            if debugTime:\n",
    "                print(f'Annotations for node {nodeIdx} path {pathName} finished in {time.time()-annotationTime}, overall time {time.time()-startTime}')\n",
    "                matrixTime = time.time()\n",
    "            \n",
    "            matrixPath[0].extend(range(nBins,nBins+nodeLen))\n",
    "            matrixPath[1].extend(zip([occ]*nodeLen,[inv]*nodeLen,posPath))\n",
    "#             if inv>inversionThreshold:\n",
    "#                 matrixPath[1].extend(list(zip([occ]*nodeLen,[inv]*nodeLen,posPath,annotations)))\n",
    "#             else:\n",
    "#                 matrixPath[1].extend(zip([occ]*nodeLen,[inv]*nodeLen,posPath,annotations))\n",
    "            \n",
    "            matrix[pathID] = matrixPath\n",
    "            \n",
    "            if debugTime:\n",
    "                print(f'MatrixPath for node {nodeIdx} path {pathName} finished in {time.time()-matrixTime}, overall time {time.time()-startTime}')\n",
    "        \n",
    "        forwardPaths.extend(set(range(len(graph.accessions))).difference(forwardPaths+invertedPaths))\n",
    "        \n",
    "        # After all bins are formed, they should be split among components.\n",
    "        # If there are more than one component from the node, then the last component \n",
    "        # should remain open and the rest of checks should go as normal.\n",
    "        # This will allow to attach a small fully followed node after \n",
    "        # (which should be the single node but due to graph construction error was separated).\n",
    "        # Otherwise, if only one component is formed, then the normal checks should follow.\n",
    "        nBinsReduction = 0\n",
    "        if nodeLen>maxLengthComponent:\n",
    "            if debugTime:\n",
    "                postBinTime = time.time()\n",
    "            for blockStart in range(0,nodeLen+1-maxLengthComponent,maxLengthComponent):\n",
    "                blockEnd = blockStart + maxLengthComponent\n",
    "                if len(forwardPaths)>0:\n",
    "#                     component[\"rdepartures\"].append({\n",
    "#                         \"upstream\": component[\"first_bin\"]+maxLengthComponent-1,\n",
    "#                         \"downstream\": component[\"first_bin\"]+maxLengthComponent,\n",
    "#                         \"participants\": forwardPaths,\n",
    "#                         'otherSideRight': False\n",
    "#                     })\n",
    "                    addLink(len(components)+1,'+',len(components)+2,'+',forwardPaths,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "                if len(invertedPaths)>0:\n",
    "#                     component[\"rarrivals\"].append({\n",
    "#                         \"upstream\": component[\"first_bin\"]+maxLengthComponent,\n",
    "#                         \"downstream\": component[\"first_bin\"]+maxLengthComponent-1,\n",
    "#                         \"participants\": invertedPaths,\n",
    "#                         'otherSideRight': False\n",
    "#                     })\n",
    "                    addLink(len(components)+2,'-',len(components)+1,'-',invertedPaths,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "                if debug:\n",
    "                    print(f'Node {nodeIdx}: Component broken inside node {nodeIdx} due to max component length.')\n",
    "                matrixSlice = {}\n",
    "                for pathID,matrixPath in matrix.items():\n",
    "                    matrix[pathID][0] = list(range(nodeLen-blockEnd))\n",
    "                    if inversion[pathID]>inversionThreshold:\n",
    "                        matrixDataSlice = matrixPath[1][-maxLengthComponent:]\n",
    "#                         matrix[pathID][0] = [element-maxLengthComponent for element in matrixPath[0][:-maxLengthComponent]]\n",
    "                        matrix[pathID][1] = matrixPath[1][:-maxLengthComponent]\n",
    "                    else:\n",
    "                        matrixDataSlice = matrixPath[1][:maxLengthComponent]\n",
    "                        #[element-maxLengthComponent for element in matrixPath[0][maxLengthComponent:]]\n",
    "                        matrix[pathID][1] = matrixPath[1][maxLengthComponent:]\n",
    "                    matrixSlice[pathID] = [list(range(len(matrixDataSlice))),matrixDataSlice]\n",
    "                \n",
    "                if inversion[pathID]>inversionThreshold:\n",
    "                    nucleotideSlice = nucleotides[-maxLengthComponent:]\n",
    "                    nucleotides = nucleotides[:-maxLengthComponent]\n",
    "                else:\n",
    "                    nucleotideSlice = nucleotides[:maxLengthComponent]\n",
    "                    nucleotides = nucleotides[maxLengthComponent:]\n",
    "                \n",
    "                component,components,componentNucleotides,_,_,_,_ = \\\n",
    "                    finaliseComponentBase(component,components,componentNucleotides,\n",
    "                                      matrixSlice,occupants,\n",
    "                                      maxLengthComponent,componentLengths,nucleotideSlice,\n",
    "                                      zoomLevel=zoomLevel,accessions=graph.accessions)\n",
    "\n",
    "                nodeToComponent[-1].append(len(components))\n",
    "                componentToNode.append(list(nodesInComp))\n",
    "                nodesInComp = set([nodeIdx])\n",
    "                \n",
    "                nBinsReduction += maxLengthComponent\n",
    "            if debugTime:\n",
    "                print(f'Node splitting for node {nodeIdx} took {time.time()-postBinTime}')\n",
    "        nBins += nodeLen-nBinsReduction\n",
    "        \n",
    "        \n",
    "        if debugTime:\n",
    "            postBinTime = time.time()\n",
    "        #########################################\n",
    "        # Breaking component after current node #\n",
    "        #########################################\n",
    "        # If any path ends on current node, this should be recorded in the component.\n",
    "        if len(pathEnds)>0:\n",
    "            if nBins>0:\n",
    "                component.setdefault(\"ends\",set()).update(pathEnds.tolist())\n",
    "                accEnds = updateEdges(accEnds,pathEnds,len(components)+1)\n",
    "            else:\n",
    "                components[-1].setdefault(\"ends\",set()).update(pathEnds.tolist())\n",
    "                accEnds = updateEdges(accEnds,pathEnds,len(components))\n",
    "                \n",
    "        if len(pathStarts)>0:\n",
    "            if nBins>0:\n",
    "                component.setdefault(\"starts\",set()).update(pathStarts.tolist())\n",
    "                accStarts = updateEdges(accStarts,pathStarts,len(components)+1)\n",
    "            else:\n",
    "                components[-1].setdefault(\"starts\",set()).update(pathStarts.tolist())\n",
    "                accStarts = updateEdges(accStarts,pathStarts,len(components))\n",
    "        \n",
    "        if nodeIdx==len(graph.nodes) and nBins>0:\n",
    "            # Last node in graph.\n",
    "            if debug:\n",
    "                print(f'Node {nodeIdx}: Last node in the last component.')\n",
    "            component,components,componentNucleotides,matrix,occupants,nBins,nucleotides = \\\n",
    "                finaliseComponentBase(component,components,componentNucleotides,matrix,occupants,nBins,componentLengths,nucleotides,\n",
    "                                  zoomLevel=zoomLevel,accessions=graph.accessions)\n",
    "            nodeToComponent[-1].append(len(components))\n",
    "            componentToNode.append(list(nodesInComp))\n",
    "            nodesInComp = set()\n",
    "\n",
    "        elif (rightFarLink or rightPathStartEnd) and nBins>0:\n",
    "            if debug:\n",
    "                if rightFarLink:\n",
    "                    print(f'Node {nodeIdx}: Component broken after node {nodeIdx} due to right far link.')\n",
    "                else:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to start or end of a path.')\n",
    "            component,components,componentNucleotides,matrix,occupants,nBins,nucleotides = \\\n",
    "                finaliseComponentBase(component,components,componentNucleotides,matrix,occupants,nBins,componentLengths,nucleotides,\n",
    "                                  zoomLevel=zoomLevel,accessions=graph.accessions)\n",
    "            nodeToComponent[-1].append(len(components))\n",
    "            componentToNode.append(list(nodesInComp))\n",
    "            nodesInComp = set()\n",
    "        # Not sure why this is needed. It will add com\n",
    "        elif nBins>0:\n",
    "            nodeToComponent[-1].append(len(components)+1)\n",
    "        \n",
    "        if debugTime:\n",
    "            print(f'After node {nodeIdx} component breaking took {time.time() - postBinTime}')\n",
    "            print(f'Processing of node {nodeIdx} took {time.time() - startNodeTime}')\n",
    "    \n",
    "    combineAnnotation(combAnnotation)\n",
    "    \n",
    "    return (numNodes, # number of nodes\n",
    "            numNodesDigits, # \n",
    "            nodeToComponent,\n",
    "            componentToNode,\n",
    "            componentLengths,\n",
    "            components,\n",
    "            componentNucleotides,\n",
    "            fromLinks, toLinks,\n",
    "            fromComponentLinks, toComponentLinks,\n",
    "            accStarts, accEnds,\n",
    "            invertedStarts, invertedEnds,\n",
    "            combAnnotation, combGenPos, combAltChrGenPos, combGenPosSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224a422",
   "metadata": {},
   "source": [
    "## Transfer from nodes to components (links and other structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def splitforwardInversedNodeComp(pathList,component,isInverse):\n",
    "    forward = []\n",
    "    inversed = []\n",
    "    \n",
    "    for pathID in pathList:\n",
    "            try:\n",
    "                if component[\"matrix\"][component[\"occupants\"].index(pathID)][1]>0:\n",
    "                    inversed.append(pathID)\n",
    "                else:\n",
    "                    forward.append(pathID)\n",
    "            except (IndexError,ValueError):\n",
    "                # If it is artificial pass link.\n",
    "                if isInverse:\n",
    "                    inversed.append(pathID)\n",
    "                else:\n",
    "                    forward.append(pathID)\n",
    "                \n",
    "    return forward,inversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f256eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fillLinksBase(nodeInComp,nodeToComponent,fromLinks,toLinks,fromComponentLinks,toComponentLinks,compNum,components,doLeft=True,doRight=True):\n",
    "    component = components[compNum]\n",
    "    for node,isFirstNode in zip([nodeInComp[0],nodeInComp[-1]],[True,False]):\n",
    "        # Processing all external arrival links\n",
    "        nodeToLink = toLinks.get(node,{})\n",
    "        for fromNode in nodeToLink.keys():\n",
    "            intermediateCondition = (node<fromNode)\n",
    "            \n",
    "            la,ra = splitforwardInversedNodeComp(nodeToLink[fromNode],component,intermediateCondition)\n",
    "            \n",
    "            fromFirstCompNum = nodeToComponent[fromNode-1][0]\n",
    "            fromFirstComp = components[fromFirstCompNum-1]\n",
    "            fromLastCompNum = nodeToComponent[fromNode-1][-1]\n",
    "            fromLastComp = components[fromLastCompNum-1]\n",
    "            \n",
    "            if isFirstNode:\n",
    "                #left arrivals\n",
    "                if len(la)>0 and doLeft:\n",
    "                    frd,fld = splitforwardInversedNodeComp(la,fromFirstComp,intermediateCondition)\n",
    "\n",
    "                    # from right departure\n",
    "                    if len(frd)>0 and (fromNode not in nodeInComp) and (fromLastComp['last_bin']+1!=component['first_bin']):\n",
    "                        addLink(fromLastCompNum,'+',compNum+1,'+',frd,fromComponentLinks,toComponentLinks)\n",
    "                    #from left departure\n",
    "                    if len(fld)>0 and (fromNode not in nodeInComp):\n",
    "                        addLink(fromFirstCompNum,'-',compNum+1,'+',fld,fromComponentLinks,toComponentLinks)\n",
    "            \n",
    "            if not isFirstNode:\n",
    "                #right arrivals\n",
    "                if len(ra)>0 and doRight:\n",
    "                    frd,fld = splitforwardInversedNodeComp(ra,fromFirstComp,intermediateCondition)\n",
    "\n",
    "                    #from right departures\n",
    "                    if len(frd)>0 and (fromNode not in nodeInComp):\n",
    "                        addLink(fromLastCompNum,'+',compNum+1,'-',frd,fromComponentLinks,toComponentLinks)\n",
    "                    #from left departures\n",
    "                    if len(fld)>0 and (fromNode not in nodeInComp):\n",
    "                        addLink(fromFirstCompNum,'-',compNum+1,'-',fld,fromComponentLinks,toComponentLinks)\n",
    "            \n",
    "        # Processing all external departure links\n",
    "        nodeFromLink = fromLinks.get(node,{})\n",
    "        for toNode in nodeFromLink.keys():\n",
    "            intermediateCondition = (node>toNode)\n",
    "            \n",
    "            rd,ld = splitforwardInversedNodeComp(nodeFromLink[toNode],component,intermediateCondition)\n",
    "            \n",
    "            toFirstCompNum = nodeToComponent[toNode-1][0]\n",
    "            toFirstComp = components[toFirstCompNum-1]\n",
    "            toLastCompNum = nodeToComponent[toNode-1][-1]\n",
    "            toLastComp = components[toLastCompNum-1]\n",
    "            \n",
    "            if not isFirstNode:\n",
    "                #right departures\n",
    "                if len(rd)>0 and doRight: # Check if doRight is set incorrectly for our case (121->122 at level 4)\n",
    "                    tla,tra = splitforwardInversedNodeComp(rd,toFirstComp,intermediateCondition)\n",
    "\n",
    "                    #to left arrivals\n",
    "                    if len(tla)>0:\n",
    "                        addLink(compNum+1,'+',toFirstCompNum,'+',tla,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "                    #to right arrivals\n",
    "                    if len(tra)>0: # Most probably the problem is here! Check it!\n",
    "                        addLink(compNum+1,'+',toLastCompNum,'-',tra,fromComponentLinks,toComponentLinks)\n",
    "            \n",
    "            if isFirstNode:\n",
    "                #left departures\n",
    "                if len(ld)>0 and doLeft:\n",
    "                    tla,tra = splitforwardInversedNodeComp(ld,toFirstComp,intermediateCondition)\n",
    "\n",
    "                    #to left arrivals\n",
    "                    if len(tla)>0:\n",
    "                        addLink(compNum+1,'-',toFirstCompNum,'+',tla,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "                    if len(tra)>0:\n",
    "                        addLink(compNum+1,'-',toLastCompNum,'-',tra,fromComponentLinks,toComponentLinks)\n",
    "                        \n",
    "    return fromComponentLinks,toComponentLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convertLink(linkFrom,linkTo,translateDict,forwardLinks,isZoom):\n",
    "    # (2247, 2319)\n",
    "    # if linkFrom==2247 and linkTo in [2319,2320]:\n",
    "    #     pdb.set_trace()\n",
    "    \n",
    "    linkSetConv = set()\n",
    "    if isZoom:\n",
    "        linkFound = False\n",
    "        for fromStrand,fromStrandDict in forwardLinks[linkFrom].items():\n",
    "            for toStrand,accessionList in fromStrandDict.get(linkTo,{}).items():\n",
    "                linkFromConv = translateDict[linkFrom-1][0 if fromStrand=='-' else -1]+1\n",
    "                linkToConv = translateDict[linkTo-1][0 if toStrand=='+' else -1]+1\n",
    "                linkSetConv.add((linkFromConv,linkToConv))\n",
    "                linkFound = True\n",
    "        if not linkFound:\n",
    "            # raise RuntimeError(f'Link ({linkFrom},{linkTo}) is requested to convert, but was not found in forwardLinks!')\n",
    "            warnings.warn(f'Link ({linkFrom},{linkTo}) is requested to convert, but was not found in forwardLinks!',\n",
    "                          category=RuntimeWarning)\n",
    "    else:\n",
    "        for fromStrand,fromStrandPairs in forwardLinks[linkFrom].items():\n",
    "            for toNode,toStrand in fromStrandPairs:\n",
    "                if toNode==linkTo:\n",
    "                    linkFromConv = translateDict[linkFrom-1][0 if fromStrand=='-' else -1]\n",
    "                    linkToConv = translateDict[linkTo-1][0 if toStrand=='+' else -1]\n",
    "                    linkSetConv.add((linkFromConv,linkToConv))\n",
    "                    break\n",
    "        \n",
    "    return linkSetConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def recordUpdatedPairedLink(firstLinkSet,secondLinkSet,firstLink,secondLink,substituteLink,pairedLinksConv):\n",
    "    if substituteLink==(firstLink[0],secondLink[1]):\n",
    "        # Straight paired link of inverted double paired link\n",
    "        for fLink in firstLinkSet:\n",
    "            for sLink in secondLinkSet:\n",
    "                pairedLinksConv.setdefault(fLink,{})[sLink] = (fLink[0],sLink[1])\n",
    "        \n",
    "    elif substituteLink==(secondLink[0],firstLink[1]):\n",
    "        # inverted paired link or straight doublePaired link\n",
    "        \n",
    "        for fLink in firstLinkSet:\n",
    "            for sLink in secondLinkSet:\n",
    "                pairedLinksConv.setdefault(fLink,{})[sLink] = (sLink[0],fLink[1])\n",
    "    else:\n",
    "        raise RuntimeError(f'Unusual paired link encountered {firstLink}+{secondLink} -> {substituteLink}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convertRemovableComponents(translateDict,linkLengths,pairedLinks,interconnectedLinks,blockEdges,forwardLinks,isZoom=True):\n",
    "    '''\n",
    "    translateDict should be a dict in format {<old node/component id 0-based>:<new component id 1-based>}\n",
    "    pathNodeInv should be a dict of dicts of the following structure:\n",
    "    {<pathID>:{<nodeId 1-based>:<Bool inv or not>}}\n",
    "    \n",
    "    This is done through fromLinks and toLinks and throught associated directions of available accessions.\n",
    "    For this we need to loop through strands and do it separately for each strand.\n",
    "    \n",
    "    For paired links there is a possibility that a single node link will give several component links. \n",
    "    In this case, the cross product of all first and second links will be added to converted paired links.\n",
    "       \n",
    "    The substitute links should be added only to the paths that contained both first and second links in the first place.\n",
    "        This should be controlled in link removal routine.\n",
    "    \n",
    "    '''\n",
    "    if linkLengths is None or pairedLinks is None or interconnectedLinks is None or blockEdges is None:\n",
    "        return None,None,None,None\n",
    "    processedLinks = {}\n",
    "    print('Converting link to block lengths associations')\n",
    "    linkLengthsConv = {}\n",
    "    for blockLength,linkList in linkLengths.items():\n",
    "        for linkFrom,linkTo in linkList:\n",
    "            linksConv = convertLink(linkFrom,linkTo,translateDict,forwardLinks,isZoom)\n",
    "            linkLengthsConv.setdefault(blockLength,set()).update(linksConv)\n",
    "            for link in linksConv:\n",
    "                processedLinks.setdefault(link,set()).add(blockLength)\n",
    "\n",
    "    print('Converting paired links')\n",
    "    pairedLinksConv = {}\n",
    "    for firstLink,flDict in pairedLinks.items():\n",
    "        firstLinkSet = convertLink(*firstLink,translateDict,forwardLinks,isZoom)\n",
    "        for secondLink,substituteLink in flDict.items():\n",
    "            secondLinkSet = convertLink(*secondLink,translateDict,forwardLinks,isZoom)\n",
    "            recordUpdatedPairedLink(firstLinkSet,secondLinkSet,firstLink,secondLink,substituteLink,pairedLinksConv)\n",
    "    \n",
    "    print('Converting interconnected links')\n",
    "    interconnectedLinksConv = {}\n",
    "    for link,linkList in interconnectedLinks.items():\n",
    "        convertLinks = convertLink(*link,translateDict,forwardLinks,isZoom)\n",
    "        for linkC in convertLinks:\n",
    "            \n",
    "            linkListConv = interconnectedLinksConv.get(linkC,set())\n",
    "            originalLinkListLen = len(linkListConv)\n",
    "            \n",
    "            for linkI in linkList:\n",
    "                linkListConv.update(convertLink(*linkI,translateDict,forwardLinks,isZoom))\n",
    "            \n",
    "            if originalLinkListLen>0:\n",
    "                # join two blocks\n",
    "                processedLinks.pop(linkC,None)\n",
    "                linkListConv.add(linkC)\n",
    "                blockLen = []\n",
    "                for blLen,linkList in list(linkLengthsConv.items()):\n",
    "                    if linkC in linkList:\n",
    "                        linkLengthsConv[blLen] = linkList - linkListConv\n",
    "                        blockLen.append(blLen)\n",
    "                        \n",
    "                maxBlockLen = max(blockLen)\n",
    "                linkLengthsConv[maxBlockLen].update(linkListConv)\n",
    "                \n",
    "                for link in linkListConv:\n",
    "                    interconnectedLinksConv[link] = linkListConv\n",
    "            else:\n",
    "                interconnectedLinksConv[linkC] = linkListConv\n",
    "    \n",
    "    for link,blList in processedLinks.items():\n",
    "        if len(blList)>1:\n",
    "            for blockLength in blList:\n",
    "                linkLengthsConv[blockLength].remove(link)\n",
    "            linkLengthsConv[max(blList)].add(link)\n",
    "    \n",
    "    print('Converting rearrangement blocks')\n",
    "    blockEdgesConv = {translateDict[node-1][-1]:blockLength for node, blockLength in blockEdges.items()}\n",
    "    \n",
    "    return linkLengthsConv,pairedLinksConv,interconnectedLinksConv,blockEdgesConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nodeToComponentLinks(components,componentToNode,nodeToComponent,\n",
    "                         fromLinks,toLinks,graph,\n",
    "                         fromComponentLinks,toComponentLinks,\n",
    "                         linkLengths=None,pairedLinks=None,interconnectedLinks=None,blockEdges=None,\n",
    "                         debug=False):\n",
    "    numComps = len(components)\n",
    "    numCompsDigits = np.int(np.ceil(np.log10(numComps)))\n",
    "    \n",
    "    for compNum in range(numComps):\n",
    "        if debug:    \n",
    "            print(f'Processing component links {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}')\n",
    "        else:\n",
    "            print(f'\\rProcessing component links {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}',end='')\n",
    "\n",
    "        component = components[compNum]\n",
    "        \n",
    "        nodeInComp = componentToNode[compNum]\n",
    "        nodeInComp.sort()\n",
    "\n",
    "        if len(nodeInComp)>1:\n",
    "            fromComponentLinks,toComponentLinks = fillLinksBase(nodeInComp,nodeToComponent,fromLinks,toLinks,fromComponentLinks,toComponentLinks,compNum,components)\n",
    "        elif len(nodeInComp)==1:\n",
    "\n",
    "            mainNode = nodeInComp[0]\n",
    "    #             compForNode = nodeToComponent[mainNode-1]\n",
    "            doLeft = False\n",
    "            if compNum==0:\n",
    "                doLeft = True\n",
    "            elif mainNode not in componentToNode[compNum-1]:\n",
    "                doLeft = True\n",
    "\n",
    "            doRight = False # Check this conditions as they may be causing issue!\n",
    "            if compNum==(len(components)-1):\n",
    "                doRight = True\n",
    "            elif mainNode not in componentToNode[compNum+1]:\n",
    "                doRight = True\n",
    "\n",
    "            fromComponentLinks,toComponentLinks = fillLinksBase(nodeInComp,nodeToComponent,fromLinks,toLinks,fromComponentLinks,toComponentLinks,compNum,components,doLeft,doRight)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Component {compNum} does not have any associated nodes!\")\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    linkLengthsConv,pairedLinksConv,interconnectedLinksConv,blockEdgesConv = \\\n",
    "    convertRemovableComponents(nodeToComponent,linkLengths,pairedLinks,interconnectedLinks,blockEdges,graph.forwardLinks,isZoom=False)\n",
    "    \n",
    "    return fromComponentLinks,toComponentLinks,linkLengthsConv,pairedLinksConv,interconnectedLinksConv,blockEdgesConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaae09a",
   "metadata": {},
   "source": [
    "##  Identifying collapsible Blocks (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compLength(compID,components):\n",
    "    return components[compID-1]['lastCol']-components[compID-1]['firstCol'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09efc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcLengthBlock(startComp,endComp,components):\n",
    "    blockLength = 0\n",
    "    for comp in range(startComp,endComp+1):\n",
    "        blockLength += compLength(comp,components)\n",
    "        \n",
    "    return blockLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88423a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components):\n",
    "    \n",
    "    # Potentially, we need to change this process to use actual paths and take into account the cardinalities/relation of the arrows\n",
    "    # This will make it slower, but more accurate. That also will make linking through removed links more accurate as well.\n",
    "    \n",
    "    blockSet = set()\n",
    "    \n",
    "    accessionFromLinks = fromComponentLinksAcc[accID]\n",
    "    compDir = accCompDir[accID]\n",
    "    endComp = accEnds[accID]\n",
    "    \n",
    "    block = [toComp]\n",
    "    blockLength = compLength(toComp,components)\n",
    "    associatedLinks = set()\n",
    "    if fromComp is not None:\n",
    "        associatedLinks.add((fromComp,toComp))\n",
    "    \n",
    "    curComp = toComp\n",
    "    \n",
    "    while True:\n",
    "        nextCompList = np.array(list(accessionFromLinks.get(curComp,set())))\n",
    "#         distToNextComp = nextCompList-curComp # Do I need it?\n",
    "        \n",
    "        nextCompFollow = None\n",
    "        linksToAssociate = set()\n",
    "        \n",
    "        if compDir[curComp]=='+':\n",
    "            for nextComp in nextCompList:\n",
    "                if compDir[nextComp]=='+' and nextComp==curComp+1:\n",
    "                    nextCompFollow = nextComp\n",
    "                else:\n",
    "                    linksToAssociate.add((curComp,nextComp))\n",
    "        elif compDir[curComp]=='-':\n",
    "            for nextComp in nextCompList:\n",
    "              \n",
    "                if compDir[nextComp]=='-' and nextComp==curComp-1:\n",
    "                    nextCompFollow = nextComp\n",
    "                else:\n",
    "                    linksToAssociate.add((curComp,nextComp))\n",
    "\n",
    "        if nextCompFollow:\n",
    "            if len(linksToAssociate)>0:\n",
    "                # This row adds collapsible block for the case where we can continue to follow the block, but the there is an outgoing arrow\n",
    "                # This usually happens in case of partial repeats.\n",
    "                # There two options here:\n",
    "                # - add associatedLinks, which contains original incoming arrow. In this case original incoming arrow will be removed with the smallest block\n",
    "                # - do not add associatedLinks. In this case, the original incoming arrow will be removed only with the largest block.\n",
    "                blockSet.add((accID,blockLength,tuple(associatedLinks | linksToAssociate),tuple(deepcopy(block))))\n",
    "        else:\n",
    "            # Potentially, we would want to stop the block following if we found another incoming arrow, \n",
    "            # but that is not that simple as this can cause breaking of large repeat due to small extra repeat inside.\n",
    "            associatedLinks.update(linksToAssociate)\n",
    "            break\n",
    "        \n",
    "        blockLength += compLength(nextCompFollow,components)\n",
    "        block.append(nextCompFollow)\n",
    "        curComp = nextCompFollow\n",
    "    \n",
    "    if curComp!=endComp:\n",
    "        blockSet.add((accID,blockLength,tuple(associatedLinks),tuple(block)))\n",
    "        \n",
    "    if fromComp is not None:\n",
    "        if np.abs(toComp-fromComp)>1:\n",
    "            if fromComp<toComp:\n",
    "                blockSet.add((accID,calcLengthBlock(fromComp+1,toComp-1,components),tuple([(fromComp,toComp)]),tuple(list(range(fromComp+1,toComp)))))\n",
    "            elif fromComp>toComp:\n",
    "                blockSet.add((accID,calcLengthBlock(toComp+1,fromComp-1,components),tuple([(fromComp,toComp)]),tuple(list(range(toComp+1,fromComp)))))\n",
    "    \n",
    "    return blockSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b91d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCollapsibleBlockDict(collapsibleBlocks,listOfUpdates):\n",
    "    for accessionID,blockLength,associatedLinks,associatedBlocks in listOfUpdates:\n",
    "        lengthAccessionComb = collapsibleBlocks.setdefault(blockLength,{}).setdefault(accessionID,(set(),set()))\n",
    "        lengthAccessionComb[0].update(associatedLinks)\n",
    "        lengthAccessionComb[1].update(associatedBlocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyCollapsibleBlocks(toComponentLinks,fromComponentLinksAcc,components,accStarts,accEnds,accCompDir):\n",
    "    print('Identifying collapsible blocks!')\n",
    "    \n",
    "    collapsibleBlocks = {}\n",
    "#     collapsibleBlocks = set()\n",
    "#     blockStarts = set()\n",
    "    for toComp,toStrandDict in toComponentLinks.items():\n",
    "        for toStrand,fromCompDict in toStrandDict.items():\n",
    "            for fromComp,fromStrandDict in fromCompDict.items():\n",
    "                for fromStrand,accessionSet in fromStrandDict.items():\n",
    "                    if toStrand!=fromStrand:\n",
    "                        for accID in accessionSet:\n",
    "                            # collapsibleBlocks.update(processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                            updateCollapsibleBlockDict(collapsibleBlocks,\n",
    "                                                       processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                                                                                                              \n",
    "                    elif toStrand=='+' and fromComp+1!=toComp:\n",
    "                        for accID in accessionSet:\n",
    "                            # collapsibleBlocks.update(processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                            updateCollapsibleBlockDict(collapsibleBlocks,\n",
    "                                                       processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                    elif toStrand=='-' and fromComp-1!=toComp:\n",
    "                        for accID in accessionSet:\n",
    "                            # collapsibleBlocks.update(processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                            updateCollapsibleBlockDict(collapsibleBlocks,\n",
    "                                                       processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                            \n",
    "#     for accID,toComp in accStarts.items():\n",
    "#         # collapsibleBlocks.update(processBlock(None,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "#         updateCollapsibleBlockDict(collapsibleBlocks,\n",
    "#                                    processBlock(None,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "    \n",
    "    _collapsibleBlocks = []\n",
    "    for blockLength,accessionDict in collapsibleBlocks.items():\n",
    "        for accessionID,[associatedLinksSet,associatedCompSet] in accessionDict.items():\n",
    "            _collapsibleBlocks.append((accessionID,blockLength,list(associatedLinksSet),list(associatedCompSet)))\n",
    "    \n",
    "    print(f'Identified {len(_collapsibleBlocks)} collapsible block lengths')\n",
    "    return _collapsibleBlocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8c4bb",
   "metadata": {},
   "source": [
    "## Identifying collapsible links and rearrangement blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf41e5",
   "metadata": {},
   "source": [
    "### Identifying path breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def findBreaksInPath(combinedArray,nextNodeDict):\n",
    "    return [pos for pos,node in enumerate(combinedArray[:-1]) \\\n",
    "                      if (node<0 and combinedArray[pos+1]!=-1*nextNodeDict.inverse.get(-1*node,[-1*node-1])[0]) or\\\n",
    "                         (node>0 and combinedArray[pos+1]!=nextNodeDict.get(node,node+1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def identifyPathBreaks(combinedNodeDirArray,pathLengths,pathNextNode):\n",
    "    pathBreakCoordPairs = []\n",
    "    for pathID in range(combinedNodeDirArray.shape[0]):\n",
    "        # separate this block into separate function as it will be used in link processing!\n",
    "        tempBreaks = [(pathID,pos) for pos in findBreaksInPath(combinedNodeDirArray[pathID,:pathLengths[pathID]], pathNextNode[pathID])]\n",
    "                      \n",
    "        pathBreakCoordPairs.extend(tempBreaks)\n",
    "    \n",
    "    return pathBreakCoordPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a96a5",
   "metadata": {},
   "source": [
    "### Block processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def interweaveArrays(a,b):\n",
    "    if len(a.shape)>1 or len(b.shape)>1:\n",
    "        raise ValueError('Both input arrays should be 1D arrays')\n",
    "        \n",
    "    if a.shape[0]!=b.shape[0]:\n",
    "        raise ValueError('Both input arrays should have the same lengths')\n",
    "        \n",
    "    c = np.empty((a.size + b.size,), dtype=a.dtype)\n",
    "    c[0::2] = a\n",
    "    c[1::2] = b\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extractGapsBlocks(block,path,nodeLengths,getComplex=False):\n",
    "    '''\n",
    "    This function either split block by gaps (e.g. block [1,2,4,5,6,8] will yield [1,2],[4,5,6],[8])\n",
    "    \n",
    "    If `getComplex` is set to True, then first gaps are filtered for nodes that are not passed by the path. \n",
    "    After that, edges are identified and then for them nodes not passed by the path are filtered out.\n",
    "    Then we find the longest block out of edges, and then the longest edge combine with all gaps and find \n",
    "    the shortest one. That shortest one is going to be the one returned.\n",
    "    \n",
    "    E.g. block [1,2,4,5,8] will give edges [1,2],[4,5],[8] and gaps [3],[6,7].\n",
    "    \n",
    "    If path does not contain 6, then edges will be the same, but gaps will be [3],[6]\n",
    "    \n",
    "    If path does not contain 3, then edges will be [1,2,4,5],[8] and gaps [6,7]\n",
    "    \n",
    "    The exact block which will be returned depends on sizes of each node.\n",
    "        \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    List of blocks and whether any gaps are identified or not\n",
    "    '''\n",
    "    \n",
    "    gapList = np.where(np.diff(np.sort(block))!=1)[0]\n",
    "    \n",
    "    gapPosInterweaved = interweaveArrays(gapList,gapList+1)\n",
    "\n",
    "    gapEdgeNodes = np.array(block)[gapPosInterweaved]\n",
    "\n",
    "    gapEdgeNodes[1::2] = gapEdgeNodes[1::2]-1\n",
    "    \n",
    "    gaps = np.split(np.arange(1,max(path)+1),gapEdgeNodes)[1::2]\n",
    "    \n",
    "    if len(gaps)>0:\n",
    "        if getComplex:\n",
    "            # It looks like it is possible to identify edges first and then filter gaps for nodes not used by the path\n",
    "            # But that will create edges that contain nodes that are not used by the path, which still bring us to two filtering.\n",
    "            \n",
    "            # Removing parts (or whole) of gaps, which are not actually gaps, but nodes never used by the path.\n",
    "            gaps = list(filter(lambda bl: len(bl)>0,[tuple((gap[np.isin(gap,path)]).tolist()) for gap in gaps]))\n",
    "            \n",
    "            # Removing parts of the edges that turned out to contain nodes not passed by the path\n",
    "            edges = list(filter(lambda bl: len(bl)>0,[tuple((bl[np.isin(bl,path)]).tolist()) for bl in np.split(block,gapList+1)]))\n",
    "\n",
    "            edgesLengths = [sum([nodeLengths[node-1] for node in bl]) for bl in edges]\n",
    "            maxEdgeInd = np.argmax(edgesLengths)\n",
    "            maxEdge = edges[maxEdgeInd]\n",
    "            maxEdgeLength = edgesLengths[maxEdgeInd]\n",
    "            \n",
    "            gapLengths = [sum([nodeLengths[node-1] for node in bl]) for bl in gaps]\n",
    "            gaps += [maxEdge]\n",
    "            gapLengths += [maxEdgeLength]\n",
    "            \n",
    "            minBlockInd = np.argmin(gapLengths)\n",
    "            minBlock = gaps[minBlockInd]\n",
    "            return [tuple(minBlock)],True\n",
    "        else:\n",
    "            return [tuple(bl) for bl in np.split(block,gapList+1)],True\n",
    "    else:\n",
    "        return [tuple(block)],False#checkSplitBlock(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ec405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkSplitBlock(block,gapList=None):\n",
    "    '''\n",
    "    Not used at the moment\n",
    "    \n",
    "    Function checks if the block has any gaps and split into a list of blocks between gaps \n",
    "    (alternatively fill gaps or leave things as they are).\n",
    "    At the moment the gapped block will be converted to list of blocks between gaps\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    `block`: np.array 1D. An array of node ids conprising the block.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    `blockList`: list[np.array]. A list of numpy arrays of eligible blocks.\n",
    "    '''\n",
    "    if gapList is None:\n",
    "        gapList = np.where(np.diff(np.sort(block))!=1)[0]\n",
    "    \n",
    "    if len(gapList>0):\n",
    "        return [tuple(bl) for bl in np.split(block,gapList+1).tolist()]\n",
    "    else:\n",
    "        return [tuple(block)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d10455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def blockListToLengths(blockList,nodeLengths):\n",
    "    return [np.sum([nodeLengths[node-1] for node in block]) for block in blockList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _blockToLengthLink(link,blockList,linkL,nodeLengths):\n",
    "    linkL.append((link,max(blockListToLengths(blockList,nodeLengths))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e00979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convertBlocksToLengths(linksBlocks,nodeLengths):\n",
    "    ''' \n",
    "    Converting blocks associated with each link to lengths and then selecting the longest one (?)\n",
    "    '''\n",
    "    \n",
    "    #  Need to make it parallel!!! It will speed up the process!\n",
    "    \n",
    "    p = Pool(cpu_count()-2)\n",
    "    m = Manager()\n",
    "    linkL = m.list()\n",
    "    numLinks = len(linksBlocks)\n",
    "    for i,_ in enumerate(p.starmap(partial(_blockToLengthLink,linkL=linkL,nodeLengths=nodeLengths),linksBlocks.items()),start=1):\n",
    "        print(f'\\rConverting blocks to block lengths {i}/{numLinks}',end='')\n",
    "    \n",
    "    print('\\nConversion finished.')\n",
    "    \n",
    "    linkLengths = {}\n",
    "    \n",
    "    for linkNum,[link,blockSize] in enumerate(linkL,start=1):\n",
    "        # This option creates a dict <link>:<block length>    \n",
    "        # linkLengths[link] = max(blockListToLengths(blockList,nodeLengths))\n",
    "        print(f'\\rReformating links to block lengths associations {linkNum}/{numLinks}', end = '')\n",
    "        # This option creates a dict <block length>:[<link>,<link>,...]\n",
    "        linkLengths.setdefault(blockSize,set()).add(link)\n",
    "    \n",
    "        # The second option will be easier to work with during layers generation.\n",
    "    print('\\nReformating finished.')\n",
    "    return linkLengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa07de",
   "metadata": {},
   "source": [
    "### Link processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def addToLinkPool(link1,link2,interconnectedLinks):\n",
    "    # Change signature of the function in the downstream function\n",
    "    \n",
    "#     l1PC = set([link1])\n",
    "#     link1Pool = interconnectedLinks.setdefault(link1,set())\n",
    "#     for link in list(link1Pool):\n",
    "#         if link!=link2:\n",
    "#             l1PC.add(link)\n",
    "#             interconnectedLinks[link].add(link2)\n",
    "# #         linksBlocks.setdefault(link2,set()).update(linksBlocks.get(link,set()))\n",
    "    \n",
    "# #     linksBlocks.setdefault(link2,set()).update(linksBlocks.get(link1,set()))\n",
    "    \n",
    "#     l2PC = set([link2])\n",
    "#     link2Pool = interconnectedLinks.setdefault(link2,set())\n",
    "#     for link in list(link2Pool):\n",
    "#         if link!=link1:\n",
    "#             l2PC.add(link)    \n",
    "#             interconnectedLinks[link].add(link1)\n",
    "# #         linksBlocks.setdefault(link1,set()).update(linksBlocks.get(link,set()))\n",
    "    \n",
    "# #     linksBlocks.setdefault(link1,set()).update(linksBlocks.get(link2,set()))\n",
    "    \n",
    "#     link1Pool.update(l2PC)\n",
    "#     link2Pool.update(l1PC)\n",
    "    interconnectedLinks.setdefault(link1,set()).add(link2)\n",
    "    interconnectedLinks.setdefault(link2,set()).add(link1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc922e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def blockFromSingleLink(pathID,link,pathNodeInversionRate,pathNextNode):\n",
    "    '''\n",
    "    Identify block from a single link\n",
    "    It is the block that the link bounds, i.e.:\n",
    "    If link if forward then it is inside the link + any side that is inverted\n",
    "    If link is backward, then it is inside + any side that is normal direction.\n",
    "    '''\n",
    "#     pathNodes = pathNodeArray[pathID]\n",
    "    nodeDir = pathNodeInversionRate[pathID]\n",
    "    leftNode,rightNode = link\n",
    "    leftDir = nodeDir.get(leftNode,False)\n",
    "    rightDir = nodeDir.get(rightNode,False)\n",
    "    \n",
    "    if leftNode<rightNode:\n",
    "        # Next used node after `leftNode`\n",
    "        blockStart = pathNextNode[pathID].get(leftNode,leftNode+1)\n",
    "        # Last used node before `rightNode`\n",
    "        blockEnd = pathNextNode[pathID].inverse.get(rightNode,[rightNode-1])[0]\n",
    "        block = set(range(blockStart,blockEnd+1))\n",
    "        if leftDir:\n",
    "            block.add(leftNode)\n",
    "        if rightDir:\n",
    "            block.add(rightNode)\n",
    "    else:\n",
    "        # Next used node after `leftNode`\n",
    "        blockStart = pathNextNode[pathID].get(rightNode,rightNode+1)\n",
    "        # Last used node before `rightNode`\n",
    "        blockEnd = pathNextNode[pathID].inverse.get(leftNode,[leftNode-1])[0]\n",
    "        \n",
    "        block = set(range(blockStart,blockEnd+1))\n",
    "        if not leftDir:\n",
    "            block.add(leftNode)\n",
    "        if not rightDir:\n",
    "            block.add(rightNode)\n",
    "    \n",
    "    return tuple(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkIndividualLink(link,pathID,usedSecondInPairLink):\n",
    "    '''\n",
    "    Function checks if this link is already second in pair. If it is, then it is not considered separately (return True?). \n",
    "    Otherwise, it should be considered and block generated (using `blockFromSingleLink`) and associated with this link.\n",
    "    '''\n",
    "    return link in usedSecondInPairLink.get(pathID,set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15247d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def processDoublePairedLinks(leftLink,rightLink,pathID,doublePairedLinks,pairedLinks,interconnectedLinks,linksBlocks,pathNextNode):\n",
    "    # Check if it is second link already.\n",
    "    # If it is, pair second link of the current pair with first link of the previous pair\n",
    "    # If not, add second link of the current pair with pathID as a key and first link as a value (or list).\n",
    "    # TBD: Should used links be removed from doublePairedLinks?\n",
    "    \n",
    "    pathDouble = doublePairedLinks.get(pathID,{})\n",
    "    \n",
    "    if leftLink in pathDouble:\n",
    "        firstLeftLink = pathDouble[leftLink]\n",
    "        commonLink = leftLink\n",
    "        secondRightLink = rightLink\n",
    "        if pathNextNode[pathID].get(secondRightLink[0],secondRightLink[0]+1)==firstLeftLink[1]:\n",
    "            pairedLinks.setdefault(secondRightLink,{})[firstLeftLink] = (secondRightLink[0],firstLeftLink[1])\n",
    "            pairedLinks.setdefault(firstLeftLink,{})[secondRightLink] = (secondRightLink[0],firstLeftLink[1])\n",
    "        \n",
    "            addToLinkPool(secondRightLink,firstLeftLink,interconnectedLinks)\n",
    "    \n",
    "    \n",
    "    doublePairedLinks.setdefault(pathID,{})[rightLink] = leftLink\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def processIndividualLink(link,pathID,pathNodeInversionRate,pathNextNode,usedSecondInPairLink):\n",
    "    if usedSecondInPairLink is not None and checkIndividualLink(link,pathID,usedSecondInPairLink):\n",
    "        # If usedSecondInPairPath is provided, check if the link was already second in pair. In that case do not do anything.\n",
    "        return []\n",
    "    \n",
    "#     if pathNextNode[pathID].get(link[0],link[0]+1)==link[1]:\n",
    "#         return []\n",
    "    \n",
    "    \n",
    "    block = blockFromSingleLink(pathID,link,pathNodeInversionRate,pathNextNode)\n",
    "    \n",
    "    return [block]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def recordLinkBlockAssociation(link,blockList,linksBlocks):\n",
    "    linksBlocks.setdefault(link,set()).update(blockList)\n",
    "    \n",
    "#     for iLink in interconnectedLinks.get(link,set()):\n",
    "#         linksBlocks.setdefault(iLink,set()).update(linksBlocks.get(link,set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def findNextNode(node,combinedArray):\n",
    "    return np.where(combinedArray==node)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def processPseudoPair(breakPos,returnPos,pathID,\n",
    "                      pathNodeArray,combinedNodeDirArray,pathNextNode,nodeLengths,\n",
    "                      usedSecondInPairPath,pairedLinks,linksBlocks):\n",
    "    \n",
    "    #######Processing pseudo paired links\n",
    "    mainLink = tuple(pathNodeArray[pathID,breakPos:breakPos+2].tolist())\n",
    "    dirStart = combinedNodeDirArray[pathID,breakPos]\n",
    "    # Collect all unique nodes between breakPos+1:returnPos\n",
    "    # Process block through min(max(edges),gaps) = minBlock\n",
    "    blockList,isGaps = extractGapsBlocks(np.unique(pathNodeArray[pathID,breakPos+1:returnPos]).tolist(),pathNodeArray[pathID],nodeLengths,getComplex=True)\n",
    "\n",
    "    # Find the last non-linear link between breakPos+1:returnPos (let's call it (e,f))\n",
    "    breaksInBlock = findBreaksInPath(combinedNodeDirArray[pathID,breakPos+1:returnPos],pathNextNode[pathID])\n",
    "    \n",
    "    ###########\n",
    "    # When searching for the last non-linear link, do not consider pure change of direction as non-linearity!!!\n",
    "    # I.e. if the links is (4-,3+) or (2+,3-) they are not non-linear for this purpose\n",
    "    # Links like (2-,4+) (given that 3 exist in the path). At the same time, I believe (possibly wrongly), \n",
    "    # that if the direction for the link start is reversed (e.g. 2-,3+), it should already be considered as non-linear.\n",
    "    #########################\n",
    "    \n",
    "    returnLinkStart = None\n",
    "    for auxBreak in breaksInBlock[::-1]:\n",
    "        \n",
    "        node = pathNodeArray[pathID,auxBreak+breakPos+1]\n",
    "        nextNode = pathNodeArray[pathID,auxBreak+1+breakPos+1]\n",
    "        if (dirStart>0 and nextNode!=pathNextNode[pathID].get(node,node+1)) or\\\n",
    "           (dirStart<0 and nextNode!=pathNextNode[pathID].inverse.get(node,node-1)):\n",
    "            returnLinkStart = auxBreak+breakPos+1\n",
    "            break\n",
    "    \n",
    "    if returnLinkStart is not None:\n",
    "        lastNonLinearLink = tuple(pathNodeArray[pathID,returnLinkStart:returnLinkStart+2].tolist())\n",
    "\n",
    "        if not checkIndividualLink(lastNonLinearLink,pathID,usedSecondInPairPath):\n",
    "            # If (e,f) was not used in pairs before, (?) it should be associated with minBlock\n",
    "            recordLinkBlockAssociation(lastNonLinearLink,blockList,linksBlocks)\n",
    "            # (e,f) should be consider as used in pair in the path, but not actually paired!\n",
    "            usedSecondInPairPath.setdefault(pathID,set()).add(lastNonLinearLink)\n",
    "\n",
    "\n",
    "    if (isGaps and checkIndividualLink(mainLink,pathID,usedSecondInPairPath)) or mainLink in pairedLinks:\n",
    "        # If there were gaps and leftLink was second in pair: do not associate leftLink with minBlock\n",
    "        # Reset blockList, so, nothing will be recorded for the main link\n",
    "        blockList = []\n",
    "\n",
    "    ######## End of pseudo pairs processing\n",
    "    \n",
    "    return blockList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def processStartsEnds(mainLink,linkStarts,linkEnds,interconnectedLinks,forwardLinks):\n",
    "    # TODO!!! Need to add checks for whether one link is intersecting the other or one is fully inside.\n",
    "    potentialStartLinks = linkStarts.get(mainLink[0],set())\n",
    "    potentialEndLinks = linkEnds.get(mainLink[1],set())\n",
    "\n",
    "    if mainLink not in potentialStartLinks or mainLink not in potentialEndLinks:\n",
    "        strandSwitch = {'+':'-','-':'+'}\n",
    "        startStrands = set()\n",
    "        endStrands = set()\n",
    "        for startStrand,strandDict in forwardLinks[mainLink[0]].items():\n",
    "                if (mainLink[1],'+') in strandDict:\n",
    "                    startStrands.add(startStrand)\n",
    "                    endStrands.add('+')\n",
    "                if (mainLink[1],'-') in strandDict:\n",
    "                    startStrands.add(startStrand)\n",
    "                    endStrands.add('-')\n",
    "        \n",
    "        if mainLink not in potentialStartLinks:\n",
    "            for link in potentialStartLinks:\n",
    "                for startStrand in startStrands:\n",
    "                    toNodeStrandList = forwardLinks[link[0]].get(strandSwitch[startStrand],[])\n",
    "                    if ((link[1],'+') in toNodeStrandList or (link[1],'-') in toNodeStrandList) and \\\n",
    "                    ((startStrand=='+') and (mainLink[1]>link[1]) or\\\n",
    "                    (startStrand=='-') and (mainLink[1]<link[1])):\n",
    "                        addToLinkPool(mainLink,link,interconnectedLinks)\n",
    "            linkStarts.setdefault(mainLink[0],set()).add(mainLink)\n",
    "\n",
    "        if mainLink not in potentialEndLinks:\n",
    "            for link in potentialEndLinks:\n",
    "                for endStrand in endStrands:\n",
    "                    if ((link[1],strandSwitch[endStrand]) in forwardLinks[link[0]].get('+',[]) or\\\n",
    "                       (link[1],strandSwitch[endStrand]) in forwardLinks[link[0]].get('-',[])) and \\\n",
    "                        ((endStrand=='+') and (mainLink[0]<link[0]) or\\\n",
    "                        (endStrand=='-') and (mainLink[0]>link[0])):\n",
    "                        addToLinkPool(mainLink,link,interconnectedLinks)\n",
    "            linkEnds.setdefault(mainLink[1],set()).add(mainLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def postprocessLinksBlocks(linksBlocks,interconnectedLinks):\n",
    "    G = nx.Graph(interconnectedLinks)\n",
    "    \n",
    "    connLinks = list(nx.connected_components(G))\n",
    "    numConnLinks = len(connLinks)\n",
    "    \n",
    "    for connLinkListNum,connLinkList in enumerate(connLinks):\n",
    "        print(f'\\rPostprocessing interconnected links {connLinkListNum+1}/{numConnLinks}',end='')\n",
    "        blocks = set().union(*[linksBlocks[link] for link in connLinkList])\n",
    "        for link in connLinkList:\n",
    "            interconnectedLinks.setdefault(link,set()).update(connLinkList-set([link]))\n",
    "            linksBlocks[link] = blocks\n",
    "    \n",
    "    print('\\nPreprocessing interconnected links finished.')\n",
    "    \n",
    "#     numInterLinks = len(interconnectedLinks)\n",
    "    \n",
    "#     for recordNum,[link,associatedLinks] in enumerate(interconnectedLinks.items()):\n",
    "#         print(f'\\nPostprocessing links blocks {recordNum+1}/{numInterLinks}',end='')\n",
    "#         for connectedLink in associatedLinks:\n",
    "#             linksBlocks.setdefault(link,set()).update(linksBlocks.get(connectedLink,set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def processPathBreaks(pathBreakCoordPairs,\n",
    "                       pathNodeArray,pathNextNode,combinedNodeDirArray,pathNodeInversionRate,pathLengths,nodeLengths,forwardLinks):\n",
    "    linksBlocks = {}\n",
    "    pairedLinks = {}\n",
    "    interconnectedLinks = {}\n",
    "    linkStarts = {}\n",
    "    linkEnds = {}\n",
    "    doublePairedLinks = {}\n",
    "    usedSecondInPairPath = {}\n",
    "    \n",
    "    print('Processing path breaks...')\n",
    "    numPathBreaks = len(pathBreakCoordPairs)\n",
    "    for breakID,(pathID,breakPos) in enumerate(pathBreakCoordPairs):\n",
    "        print(f'\\rProcessing path break number {breakID+1}/{numPathBreaks}',end='')\n",
    "        leftLink = (pathNodeArray[pathID,breakPos],pathNodeArray[pathID,breakPos+1])\n",
    "        # Normally should be 1, but in case some of the nodes are missed by the path, it can be larger.\n",
    "        # curNextNodeDiff = pathNextNode[pathID].get(leftLink[0],leftLink[0]+1) - leftLink[0]\n",
    "        \n",
    "        if combinedNodeDirArray[pathID,breakPos]<0:\n",
    "            # Inverted node\n",
    "            nextExpectedNode = -1*pathNextNode[pathID].inverse.get(leftLink[0],[leftLink[0]-1])[0]\n",
    "        else:\n",
    "            # normal node\n",
    "            nextExpectedNode = pathNextNode[pathID].get(leftLink[0],leftLink[0]+1)\n",
    "\n",
    "        nextPos = findNextNode(nextExpectedNode,combinedNodeDirArray[pathID,breakPos+1:pathLengths[pathID]])+breakPos+1\n",
    "\n",
    "        blockList = []\n",
    "\n",
    "        if len(nextPos)>0:\n",
    "            # There is the node next-in-order after the break\n",
    "            returnPos = np.sort(nextPos)[0]\n",
    "\n",
    "            # Is it even possible???\n",
    "            if returnPos==breakPos+1:\n",
    "                continue\n",
    "\n",
    "            rightLink = (pathNodeArray[pathID,returnPos-1],pathNodeArray[pathID,returnPos])\n",
    "            substituteLink = (pathNodeArray[pathID,breakPos],pathNodeArray[pathID,returnPos])\n",
    "\n",
    "            # I suspect the first condition cannot be violated by constructtion of the leftLink (always non-linear) \n",
    "            # and substitute link (always linear)\n",
    "            if leftLink!=substituteLink and rightLink!=substituteLink:\n",
    "                blockList,isGaps = extractGapsBlocks(np.unique(pathNodeArray[pathID,breakPos+1:returnPos]).tolist(),pathNodeArray[pathID],nodeLengths)\n",
    "                #################################################################################################\n",
    "                # !!!IMPORTANT!!!: When the link is substituted during generation of next layer, if the new link \n",
    "                # is not (k,k+1) (or (k+1,k) for inverted nodes), then for each path it has to be checked whether\n",
    "                # follow-through links through empty components can be established. Implemented, but need tested.\n",
    "                #################################################################################################\n",
    "\n",
    "                # Adding paired links with their substitution\n",
    "                pairedLinks.setdefault(leftLink,{})[rightLink] = substituteLink\n",
    "                pairedLinks.setdefault(rightLink,{})[leftLink] = substituteLink\n",
    "                usedSecondInPairPath.setdefault(pathID,set()).add(rightLink)\n",
    "\n",
    "                processDoublePairedLinks(leftLink,rightLink,pathID,doublePairedLinks,pairedLinks,interconnectedLinks,linksBlocks,pathNextNode)\n",
    "\n",
    "                addToLinkPool(leftLink,rightLink,interconnectedLinks)\n",
    "                recordLinkBlockAssociation(rightLink,blockList,linksBlocks)\n",
    "            else:\n",
    "                # Paired link is actually not a paired link. Substituting with one of the pair.\n",
    "                \n",
    "                # It is impossible condition. Do I need it here?\n",
    "                if leftLink==substituteLink:\n",
    "                    leftLink = rightLink\n",
    "                \n",
    "                blockList = processPseudoPair(breakPos,returnPos,pathID,\n",
    "                                              pathNodeArray,combinedNodeDirArray,pathNextNode,nodeLengths,\n",
    "                                              usedSecondInPairPath,pairedLinks,linksBlocks)\n",
    "                    \n",
    "        else:\n",
    "            #########################\n",
    "            # Search for loop position ONLY for main link of the same direction (if both from and to are either forward or inverted)\n",
    "            # Additional condition is that it should be backward link (constituting possible repeat start)\n",
    "            # If they are of different direction or not reversed, then treat as single link!\n",
    "            #########################\n",
    "            if ((combinedNodeDirArray[pathID,breakPos]>0 and leftLink[0]>leftLink[1]) or \\\n",
    "               (combinedNodeDirArray[pathID,breakPos]<0 and leftLink[0]<leftLink[1])) and \\\n",
    "               np.prod(combinedNodeDirArray[pathID,breakPos:breakPos+2])>0:\n",
    "                loopPos = findNextNode(combinedNodeDirArray[pathID,breakPos],combinedNodeDirArray[pathID,breakPos+1:pathLengths[pathID]])+breakPos+1\n",
    "            else:\n",
    "                loopPos = []\n",
    "\n",
    "            if len(loopPos)>0:\n",
    "                # Should happen the same as with pseudo paired links above except all searches should happen in breakPos+1:returnPos+1\n",
    "                returnPos = loopPos[0]\n",
    "                blockList = processPseudoPair(breakPos,returnPos+1,pathID,\n",
    "                                              pathNodeArray,combinedNodeDirArray,pathNextNode,nodeLengths,\n",
    "                                              usedSecondInPairPath,pairedLinks,linksBlocks)\n",
    "            else:\n",
    "            \n",
    "                # There is no node next-in-order after the break\n",
    "                # Process a single link as individual\n",
    "                blockList = processIndividualLink(leftLink,pathID,pathNodeInversionRate,pathNextNode,doublePairedLinks)\n",
    "\n",
    "                # Finding associated link in path, which are not paired, but interconnected.\n",
    "                # That is aimed at identifying paired inversed links (start and end of inversed block)\n",
    "                curLinkFrom = combinedNodeDirArray[pathID,breakPos]\n",
    "                curLinkFromDir = np.sign(curLinkFrom) # 1 for normal and -1 for inverted\n",
    "                curLinkFrom *= curLinkFromDir\n",
    "                curLinkTo = combinedNodeDirArray[pathID,breakPos+1]\n",
    "                curLinkToDir = np.sign(curLinkTo) # 1 for normal and -1 for inverted\n",
    "                curLinkTo *= curLinkToDir\n",
    "                \n",
    "                if curLinkFromDir!=curLinkToDir:\n",
    "                    if curLinkFromDir>0:\n",
    "                        potentialNextFrom = -1*curLinkFromDir*pathNextNode[pathID].get(curLinkFrom,curLinkFrom+1)\n",
    "                        potentialNextTo = -1*curLinkToDir*pathNextNode[pathID].get(curLinkTo,curLinkTo+1)\n",
    "                        nextPosFrom = np.where(combinedNodeDirArray[pathID,breakPos:pathLengths[pathID]]==potentialNextFrom)[0]+breakPos\n",
    "                        nextPosTo = np.where(combinedNodeDirArray[pathID,breakPos+1:pathLengths[pathID]]==potentialNextTo)[0]+breakPos+1\n",
    "                    else:\n",
    "                        potentialNextFrom = -1*curLinkFromDir*pathNextNode[pathID].inverse.get(curLinkFrom,[curLinkFrom-1])[0]\n",
    "                        potentialNextTo = -1*curLinkToDir*pathNextNode[pathID].inverse.get(curLinkTo,[curLinkTo-1])[0]\n",
    "                        nextPosFrom = np.where(combinedNodeDirArray[pathID,breakPos+1:pathLengths[pathID]]==potentialNextFrom)[0][::-1]+breakPos+1\n",
    "                        nextPosTo = np.where(combinedNodeDirArray[pathID,breakPos+2:pathLengths[pathID]]==potentialNextTo)[0][::-1]+breakPos+2\n",
    "                    \n",
    "                    \n",
    "                    for posFrom in nextPosFrom:\n",
    "                        fromLink,toLink = pathNodeArray[pathID,posFrom:posFrom+2]\n",
    "                        if curLinkFrom+curLinkFromDir==fromLink:\n",
    "                            addToLinkPool(leftLink,(fromLink,toLink),interconnectedLinks)\n",
    "                            break\n",
    "                        \n",
    "                    for posTo in nextPosTo:\n",
    "                        fromLink,toLink = pathNodeArray[pathID,posTo-1:posTo+1]\n",
    "                        if curLinkTo+curLinkFromDir==toLink:\n",
    "                            addToLinkPool(leftLink,(fromLink,toLink),interconnectedLinks)\n",
    "                            break\n",
    "                            \n",
    "        # processStartsEnds(leftLink,linkStarts,linkEnds,interconnectedLinks,forwardLinks)    \n",
    "        if len(blockList)>0:\n",
    "            \n",
    "#             print(f\"For path {pathID} and link {leftLink} block is {blockList}\")\n",
    "            recordLinkBlockAssociation(leftLink,blockList,linksBlocks)\n",
    "    postprocessLinksBlocks(linksBlocks,interconnectedLinks)\n",
    "    \n",
    "    print('\\nProcessing path breaks finished.')\n",
    "    return linksBlocks,pairedLinks,interconnectedLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72baaf10",
   "metadata": {},
   "source": [
    "### Rearrangement blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def addBlockEdge(edge,size,blockEdges):\n",
    "    curBlockSize = blockEdges.get(edge,0)\n",
    "    blockEdges[edge] = max(curBlockSize,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54842d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def identifyRearrangementBlocks(nodesStructure,nodeLengths):\n",
    "    '''\n",
    "    block Edges is a dict with a structure:\n",
    "    <edge of block>:<size of block>\n",
    "    <edge of block> pointing to the node before (!) the break.\n",
    "    In other words, if it is the start of the block, it will point to the node just before the block,\n",
    "    and if it is the end of the block, it will point to the last node of the block.\n",
    "    '''\n",
    "    \n",
    "    blockEdges = {}\n",
    "    \n",
    "    structQueue = []\n",
    "    indQueue = []\n",
    "    nodeNum = len(nodesStructure)\n",
    "    print('Identifying rearrangement blocks')\n",
    "    for nodeId,nodeStruct in enumerate(nodesStructure):\n",
    "        print(f'\\rProcessing node {nodeId+1}/{nodeNum}',end='')\n",
    "    #     print(f'structQueue: {structQueue}')\n",
    "    #     print(f'indQueue: {indQueue}')\n",
    "        # Check why rearrangement block starts/ends after this node?\n",
    "        \n",
    "        try:\n",
    "    #         print(f'nodeStruct: {nodeStruct}')\n",
    "            blockStartInd = structQueue.index(nodeStruct)\n",
    "    #         print(f'blockStartInd: {blockStartInd}')\n",
    "\n",
    "            blockStart = indQueue[blockStartInd]\n",
    "            blockEnd = nodeId+1\n",
    "            if blockStart+1==blockEnd:\n",
    "                indQueue[-1] = nodeId+1\n",
    "                continue\n",
    "    #         print(f'blockStart: {blockStart}, blockEnd: {blockEnd}')\n",
    "            del structQueue[blockStartInd:]\n",
    "            del indQueue[blockStartInd:]\n",
    "            blockSize = np.sum([nodeLengths[node-1] for node in range(blockStart+1,blockEnd)])\n",
    "            addBlockEdge(blockStart,blockSize,blockEdges)\n",
    "            addBlockEdge(blockEnd-1,blockSize,blockEdges)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        structQueue.append(nodeStruct)\n",
    "        indQueue.append(nodeId+1)\n",
    "    \n",
    "    print('\\nIdentifying rearrangement blocks finished.')\n",
    "    return blockEdges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a81e7",
   "metadata": {},
   "source": [
    "### Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getRemovableStructures(graph = None,\n",
    "                           nodeLengths=None, pathLengths = None, \n",
    "                           pathNodeArray = None, pathDirArray = None,\n",
    "                           pathNextNode = None, forwardLinks = None,\n",
    "                           inversionThreshold=0.5):\n",
    "    # initialising main data structures\n",
    "\n",
    "    # I would rather get ready graph structure\n",
    "    # graph = GenomeGraph(gfaPath=f'{fileDir}{os.path.sep}{filename}',isGFASeq=False)\n",
    "\n",
    "    # Preparing paths for link-block identifications\n",
    "    \n",
    "    if nodeLengths is None or pathLengths is None or pathNodeArray is None or pathDirArray is None and pathNextNode is not None or forwardLinks is None:\n",
    "        if graph is not None:\n",
    "            forwardLinks = graph.forwardLinks\n",
    "            \n",
    "            nodeLengths = calcNodeLengths(graph)\n",
    "\n",
    "            pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum = initialPathAnalysis(graph,nodeLengths)\n",
    "        else:\n",
    "            raise AttributeError(f'Either `graph` or `nodeLengths`, `pathLengths`, `pathNodeArray` and `pathDirArray` should be provided.')\n",
    "\n",
    "    pathNodeInversionRate,nodesStructure,combinedNodeDirArray = getNodesStructurePathNodeInversionRate(pathNodeArray,pathDirArray,pathLengths,inversionThreshold=inversionThreshold)\n",
    "\n",
    "    pathNextNode = getNextNodePath(pathNodeArray,pathLengths)\n",
    "    \n",
    "    pathBreakCoordPairs = identifyPathBreaks(combinedNodeDirArray,pathLengths,pathNextNode)\n",
    "    \n",
    "    linksBlocks,pairedLinks,interconnectedLinks = processPathBreaks(pathBreakCoordPairs,\n",
    "                      pathNodeArray,pathNextNode,combinedNodeDirArray,pathNodeInversionRate,pathLengths,nodeLengths,forwardLinks)\n",
    "    \n",
    "    linkLengths = convertBlocksToLengths(linksBlocks,nodeLengths)\n",
    "    \n",
    "    blockEdges = identifyRearrangementBlocks(nodesStructure,nodeLengths)\n",
    "    \n",
    "    return linkLengths,pairedLinks,interconnectedLinks,blockEdges,pathNodeInversionRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f7476e-a0fd-4c65-83f0-aa84a421ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getBlockEdges(graph = None,\n",
    "                   nodeLengths=None, pathLengths = None, \n",
    "                   pathNodeArray = None, pathDirArray = None,\n",
    "                   pathNextNode = None, forwardLinks = None,\n",
    "                   inversionThreshold=0.5):\n",
    "    # initialising main data structures\n",
    "\n",
    "    # I would rather get ready graph structure\n",
    "    # graph = GenomeGraph(gfaPath=f'{fileDir}{os.path.sep}{filename}',isGFASeq=False)\n",
    "\n",
    "    # Preparing paths for link-block identifications\n",
    "    \n",
    "    if nodeLengths is None or pathLengths is None or pathNodeArray is None or pathDirArray is None and pathNextNode is not None or forwardLinks is None:\n",
    "        if graph is not None:\n",
    "            forwardLinks = graph.forwardLinks\n",
    "            \n",
    "            nodeLengths = calcNodeLengths(graph)\n",
    "\n",
    "            pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum = initialPathAnalysis(graph,nodeLengths)\n",
    "        else:\n",
    "            raise AttributeError(f'Either `graph` or `nodeLengths`, `pathLengths`, `pathNodeArray` and `pathDirArray` should be provided.')\n",
    "\n",
    "    pathNodeInversionRate,nodesStructure,combinedNodeDirArray = getNodesStructurePathNodeInversionRate(pathNodeArray,pathDirArray,pathLengths,inversionThreshold=inversionThreshold)\n",
    "    \n",
    "    blockEdges = identifyRearrangementBlocks(nodesStructure,nodeLengths)\n",
    "    \n",
    "    return blockEdges,pathNodeInversionRate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92bcb0",
   "metadata": {},
   "source": [
    "## Generating zoom layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a7213",
   "metadata": {},
   "source": [
    "### Finalising bin and component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def addLink(fromComp,fromStrand,toComp,toStrand,pathList,fromComponentLinks,toComponentLinks):\n",
    "    fromComponentLinks.setdefault(fromComp,{}).setdefault(fromStrand,{}).\\\n",
    "                       setdefault(toComp,{}).setdefault(toStrand,set()).\\\n",
    "                       update(pathList)\n",
    "    toComponentLinks.setdefault(toComp,{}).setdefault(toStrand,{}).\\\n",
    "                     setdefault(fromComp,{}).setdefault(fromStrand,set()).\\\n",
    "                     update(pathList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getOccInvChange(binColLengths,binBlockLength,binOcc,binInv,prevOcc,prevInv,inversionThreshold=0.5):\n",
    "    occChanged = False\n",
    "    invChanged = False\n",
    "    occ = {}\n",
    "    inv = {}\n",
    "    \n",
    "    for pathID in binOcc:\n",
    "        \n",
    "        # Averaging occupancy\n",
    "        occ[pathID] = sum([bl*bo for bl,bo in zip(binColLengths,binOcc[pathID])])/binBlockLength\n",
    "        # Do comparison through floor and then abs difference > 0\n",
    "        if np.abs(np.floor(occ[pathID]+0.5)-np.floor(prevOcc.get(pathID,occ[pathID])+0.5))>0 \\\n",
    "            and occ[pathID]>0.5 and prevOcc.get(pathID,occ[pathID])>0.5:\n",
    "            occChanged = True\n",
    "        prevOcc[pathID] = occ[pathID]\n",
    "        \n",
    "        # Averaging invertion\n",
    "        inv[pathID] = sum([bl*bo*bi for bl,bo,bi in zip(binColLengths,binOcc[pathID],binInv[pathID])])/(binBlockLength*occ[pathID])\n",
    "        if (inv[pathID]-inversionThreshold)*(prevInv.get(pathID,inv[pathID])-inversionThreshold)<0 or \\\n",
    "        (inv[pathID]-inversionThreshold)*(prevInv.get(pathID,inv[pathID])-inversionThreshold)==0 and \\ \n",
    "        inv[pathID]*prevInv.get(pathID,inv[pathID])>inversionThreshold*inversionThreshold:\n",
    "            # The second comdition after `or` is taking the case where one is equal to inversionThreshold\n",
    "            # and another is more than inversionThreshold.\n",
    "            invChanged = True\n",
    "        prevInv[pathID] = inv[pathID]\n",
    "        \n",
    "    return occChanged,invChanged,occ,inv,prevOcc,prevInv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getOccInv(binColLengths,binBlockLength,binOcc,binInv,inversionThreshold=0.5):\n",
    "    occ = {}\n",
    "    inv = {}\n",
    "    \n",
    "    for pathID in binOcc:\n",
    "        # Averaging occupancy\n",
    "        occ[pathID] = sum([bl*bo for bl,bo in zip(binColLengths,binOcc[pathID])])/binBlockLength\n",
    "        \n",
    "        # Averaging invertion\n",
    "        inv[pathID] = sum([bl*bo*bi for bl,bo,bi in zip(binColLengths,binOcc[pathID],binInv[pathID])])/(binBlockLength*occ[pathID])\n",
    "\n",
    "    return occ,inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6949a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def combineIntervals(posPath):\n",
    "    # posPath = pos.get(pathID)\n",
    "    posArray = np.array(posPath)\n",
    "    posArray = posArray[np.argsort(posArray[:,0]),:]\n",
    "    posIntersect = (posArray[1:,1]-(posArray[:-1,0]-1))*\\\n",
    "                    (posArray[:-1,1]-(posArray[1:,0]-1))\n",
    "    newPos = [[posArray[0,0]]]\n",
    "    candidates = [posArray[0,1]]\n",
    "    for jointNum in range(len(posIntersect)):\n",
    "        if posIntersect[jointNum]>=0:\n",
    "            candidates.extend(posArray[jointNum+1,:].tolist())\n",
    "        else:\n",
    "            newPos[-1].append(np.max(candidates))\n",
    "            newPos.append([posArray[jointNum+1,0]])\n",
    "            candidates = [posArray[jointNum+1,1]]\n",
    "\n",
    "    newPos[-1].append(np.max(candidates))# !!!!    \n",
    "    return newPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def recordBinZoom(occ,inv,binPosArray,nBins,nCols,\n",
    "                  binBlockLength,binBlockLengths,\n",
    "                  binColLengths,\n",
    "                  binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                  matrix,inversionThreshold=0.5):\n",
    "    # need to check for occupancy and inversion change in comparison with previous bin\n",
    "    # and if that happens, break the component before this bin (should be special boolean returned.\n",
    "    \n",
    "    for pathID in binPosArray:\n",
    "        pathMatrix = matrix.setdefault(pathID,[[],[]])\n",
    "        pathMatrix[0].append(nBins)\n",
    "        \n",
    "        # Adding everything to matrix element with Combined positions and Annotations (already combined through set)\n",
    "#         if inv[pathID]>inversionThreshold:\n",
    "#             pathMatrix[1].insert(0,[occ[pathID],inv[pathID],combineIntervals(binPosArray[pathID]),list(binAnn[pathID])])\n",
    "#         else:\n",
    "        pathMatrix[1].append([occ[pathID],inv[pathID],combineIntervals(binPosArray[pathID])])\n",
    "    \n",
    "    binBlockLengths.append(binBlockLength)\n",
    "    \n",
    "    binColStarts.append(binColStart)\n",
    "    binColEnds.append(binColEnd)\n",
    "    \n",
    "    return 0,[],binColStarts,binColEnds,{},{},{},nBins+1,nCols+binBlockLength,binBlockLengths,matrix\n",
    "    # binBlockLength,binColLengths,binColStarts,binColEnds,\n",
    "    # binOcc,binInv,binPosArray,binAnn,nBins,nCols,\n",
    "    # binBlockLengths,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf9229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getAverageInv(binBlockLengths,matrixPathArray):\n",
    "    num = 0\n",
    "    dem = 0\n",
    "    for blockCols,matrixEl in zip(binBlockLengths,matrixPathArray[1]):\n",
    "        num += blockCols*matrixEl[1]\n",
    "        dem += blockCols\n",
    "    return num/dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba160f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def finaliseComponentZoom(component,components,componentLengths,#componentNucleotides,\n",
    "                          nBins,nCols,occupants,\n",
    "                          binBlockLengths,binColStarts,binColEnds,\n",
    "                          matrix,starts,ends,\n",
    "                          forwardPaths,invertedPaths,\n",
    "                          compInvNum,compInvDen,inversionThreshold=0.5):\n",
    "\n",
    "    componentLengths.append(nBins)\n",
    "    component[\"matrix\"].extend(sorted([[pathID,\n",
    "                                 (compInv := int(compInvNum[pathID]/compInvDen[pathID]>inversionThreshold)),\n",
    "                                 [matrixPathArray[0],matrixPathArray[1][::(-1 if compInv else 1)]]] \\\n",
    "                                for pathID,matrixPathArray in matrix.items()],key=lambda el: el[0]))\n",
    "    \n",
    "    component['binsToCols'] = binBlockLengths\n",
    "    component[\"occupants\"] = sorted(list(matrix.keys()))\n",
    "    \n",
    "    component['last_bin'] = component['first_bin'] + nBins - 1\n",
    "    \n",
    "    component['firstCol'] = min(binColStarts)\n",
    "    component['lastCol'] = max(binColEnds)\n",
    "    \n",
    "    # Is it needed?\n",
    "    component['binColStarts'] = binColStarts\n",
    "    component['binColEnds'] = binColEnds\n",
    "    \n",
    "    curStarts = starts.intersection(forwardPaths)\n",
    "    if len(curStarts)>0:\n",
    "        component['starts'] = list(curStarts)\n",
    "    starts -= set(forwardPaths)\n",
    "        \n",
    "    curEnds = ends.intersection(invertedPaths)\n",
    "    if len(curEnds)>0:\n",
    "        component['ends'] = list(curEnds)\n",
    "    ends -= set(invertedPaths)    \n",
    "        \n",
    "#     componentNucleotides.append(nucleotides)\n",
    "    \n",
    "    firstBin = component['last_bin'] + 1\n",
    "#     firstCol = component['lastCol'] + 1\n",
    "    components.append(component)\n",
    "    component = deepcopy(componentTemplate)\n",
    "    component['first_bin'] = firstBin\n",
    "#     component['firstCol'] = firstCol\n",
    "    return component,components,componentLengths,0,0,set(),[],[],[],{},starts,ends,{},{}\n",
    "    # component,components,componentLengths,(componentNucleotides),nBins,nCols,occupants,\n",
    "    # binBlockLengths,binColStarts,binColEnds,matrix,starts,ends,compInvNum,compInvDen"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da5de9d8-ab5d-4dd9-9f06-4469f8b57303",
   "metadata": {},
   "source": [
    "def finaliseBinZoom(compNum,\n",
    "                    binOcc,binInv,binPosArray,binAnn,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,prevOcc,prevInv,\n",
    "                    newComponent,newComponents,newComponentLengths,#compAccDir,#newComponentNucleotides,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,linkLengths,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,pathsToInversion,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=0.5):\n",
    "    \n",
    "    preservedPrevInv = deepcopy(prevInv)\n",
    "    \n",
    "    occChanged,invChanged,occ,inv,prevOcc,prevInv = \\\n",
    "    getOccInvChange(binColLengths,binBlockLength,binOcc,binInv,prevOcc,prevInv,inversionThreshold=inversionThreshold)\n",
    "    \n",
    "    # Consider removing this condition and joining all bins together. But not now :)\n",
    "    # occ,inv = getOccInv(binColLengths,binBlockLength,binOcc,binInv,inversionThreshold=inversionThreshold)\n",
    "    \n",
    "    if (occChanged or invChanged) and nBins>0:\n",
    "        \n",
    "        # cut the matrix and remove the last added bin for the latest component and \n",
    "        # check that there is something to finalise (that it was not the only bin)\n",
    "\n",
    "        # Add direct link\n",
    "        if invChanged:\n",
    "            for pathID in forwardPaths|invertedPaths:\n",
    "                if preservedPrevInv.get(pathID,0)>inversionThreshold:\n",
    "                    fromStrand = '-'\n",
    "                else:\n",
    "                    fromStrand = '+'\n",
    "                    \n",
    "                if inv.get(pathID,0)>inversionThreshold:\n",
    "                    toStrand = '-'\n",
    "                else:\n",
    "                    toStrand = '+'\n",
    "                \n",
    "                if fromStrand=='-' and toStrand=='-':\n",
    "                    addLink(len(newComponents)+2,toStrand,len(newComponents)+1,fromStrand,[pathID],newFromComponentLinks,newToComponentLinks)\n",
    "                elif fromStrand=='+' and toStrand=='+':\n",
    "                    addLink(len(newComponents)+1,fromStrand,len(newComponents)+2,toStrand,[pathID],newFromComponentLinks,newToComponentLinks)\n",
    "                \n",
    "#                 if fromStrand!=toStrand:\n",
    "#                     linkLengths.setdefault(nCols,set()).add((len(newComponents)+1,len(newComponents)+2))\n",
    "                # These links should go into link-length association with the new component column length\n",
    "                # More probably these links will be removed on the next step. But this is happening on the path per path basis\n",
    "                # and lengths should be calculated on the same path to path basis as well!!! That can be taken from 'binColLengths' without\n",
    "                # the last element!!!\n",
    "            \n",
    "        else:\n",
    "            if len(forwardPaths)>0:\n",
    "                addLink(len(newComponents)+1,'+',len(newComponents)+2,'+',forwardPaths,newFromComponentLinks,newToComponentLinks)\n",
    "            if len(invertedPaths)>0:\n",
    "                addLink(len(newComponents)+2,'-',len(newComponents)+1,'-',invertedPaths,newFromComponentLinks,newToComponentLinks)\n",
    "        \n",
    "        # Add new element to newToOldInd\n",
    "        newToOldInd.append([compNum])\n",
    "        # Add number of next element to oldToNewInd\n",
    "        oldToNewInd[-1].append(len(newComponents))\n",
    "            \n",
    "        newComponent,newComponents,newComponentLengths,\\\n",
    "        nBins,nCols,_,binBlockLengths,binColStarts,binColEnds,\\\n",
    "        matrix,starts,ends = \\\n",
    "            finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "                                  nBins,nCols,occupants,binBlockLengths,\n",
    "                                  binColStarts,binColEnds,\n",
    "                                  matrix,starts,ends,\n",
    "                                  forwardPaths,invertedPaths,inversionThreshold=inversionThreshold)\n",
    "\n",
    "    for pathID in pathsToInversion:\n",
    "        invertedPaths.add(pathID)\n",
    "        forwardPaths -= set([pathID])\n",
    "\n",
    "    \n",
    "    binBlockLength,binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,nBins,nCols,binBlockLengths,matrix = \\\n",
    "    recordBinZoom(occ,inv,binPosArray,\n",
    "                    nBins,nCols,binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "    \n",
    "    return binColLengths,binColStarts,binColEnds,\\\n",
    "            binOcc,binInv,binPosArray,binAnn,nBins,nCols,\\\n",
    "            binBlockLength,binBlockLengths,matrix,\\\n",
    "            prevOcc,prevInv,\\\n",
    "            newComponent,newComponents,newComponentLengths,\\\n",
    "            newFromComponentLinks,newToComponentLinks,\\\n",
    "            occupants,\\\n",
    "            starts,ends,newToOldInd,oldToNewInd,\\\n",
    "            forwardPaths,invertedPaths,set() # The last one is pathsToInversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def finaliseBinZoom(compNum,\n",
    "                    binOcc,binInv,binPosArray,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    newComponent,newComponents,newComponentLengths,#compAccDir,#newComponentNucleotides,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,linkLengths,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,pathsToInversion,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=0.5):\n",
    "    \n",
    "#     preservedPrevInv = deepcopy(prevInv)\n",
    "    \n",
    "#     occChanged,invChanged,occ,inv,prevOcc,prevInv = \\\n",
    "#     getOccInvChange(binColLengths,binBlockLength,binOcc,binInv,prevOcc,prevInv,inversionThreshold=inversionThreshold)\n",
    "    \n",
    "    # Consider removing this condition and joining all bins together. But not now :)\n",
    "    occ,inv = getOccInv(binColLengths,binBlockLength,binOcc,binInv,inversionThreshold=inversionThreshold)\n",
    "    \n",
    "#     if (occChanged or invChanged) and nBins>0:\n",
    "        \n",
    "#         # cut the matrix and remove the last added bin for the latest component and \n",
    "#         # check that there is something to finalise (that it was not the only bin)\n",
    "\n",
    "#         # Add direct link\n",
    "#         if invChanged:\n",
    "#             for pathID in forwardPaths|invertedPaths:\n",
    "#                 if preservedPrevInv.get(pathID,0)>inversionThreshold:\n",
    "#                     fromStrand = '-'\n",
    "#                 else:\n",
    "#                     fromStrand = '+'\n",
    "                    \n",
    "#                 if inv.get(pathID,0)>inversionThreshold:\n",
    "#                     toStrand = '-'\n",
    "#                 else:\n",
    "#                     toStrand = '+'\n",
    "                \n",
    "#                 if fromStrand=='-' and toStrand=='-':\n",
    "#                     addLink(len(newComponents)+2,toStrand,len(newComponents)+1,fromStrand,[pathID],newFromComponentLinks,newToComponentLinks)\n",
    "#                 elif fromStrand=='+' and toStrand=='+':\n",
    "#                     addLink(len(newComponents)+1,fromStrand,len(newComponents)+2,toStrand,[pathID],newFromComponentLinks,newToComponentLinks)\n",
    "                \n",
    "# #                 if fromStrand!=toStrand:\n",
    "# #                     linkLengths.setdefault(nCols,set()).add((len(newComponents)+1,len(newComponents)+2))\n",
    "#                 # These links should go into link-length association with the new component column length\n",
    "#                 # More probably these links will be removed on the next step. But this is happening on the path per path basis\n",
    "#                 # and lengths should be calculated on the same path to path basis as well!!! That can be taken from 'binColLengths' without\n",
    "#                 # the last element!!!\n",
    "            \n",
    "#         else:\n",
    "#             if len(forwardPaths)>0:\n",
    "#                 addLink(len(newComponents)+1,'+',len(newComponents)+2,'+',forwardPaths,newFromComponentLinks,newToComponentLinks)\n",
    "#             if len(invertedPaths)>0:\n",
    "#                 addLink(len(newComponents)+2,'-',len(newComponents)+1,'-',invertedPaths,newFromComponentLinks,newToComponentLinks)\n",
    "        \n",
    "#         # Add new element to newToOldInd\n",
    "#         newToOldInd.append([compNum])\n",
    "#         # Add number of next element to oldToNewInd\n",
    "#         oldToNewInd[-1].append(len(newComponents))\n",
    "            \n",
    "#         newComponent,newComponents,newComponentLengths,\\\n",
    "#         nBins,nCols,_,binBlockLengths,binColStarts,binColEnds,\\\n",
    "#         matrix,starts,ends = \\\n",
    "#             finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "#                                   nBins,nCols,occupants,binBlockLengths,\n",
    "#                                   binColStarts,binColEnds,\n",
    "#                                   matrix,starts,ends,\n",
    "#                                   forwardPaths,invertedPaths,inversionThreshold=inversionThreshold)\n",
    "\n",
    "    for pathID in pathsToInversion:\n",
    "        invertedPaths.add(pathID)\n",
    "        forwardPaths -= set([pathID])\n",
    "\n",
    "    \n",
    "    binBlockLength,binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,nBins,nCols,binBlockLengths,matrix = \\\n",
    "    recordBinZoom(occ,inv,binPosArray,\n",
    "                    nBins,nCols,binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "    \n",
    "    return binColLengths,binColStarts,binColEnds,\\\n",
    "            binOcc,binInv,binPosArray,nBins,nCols,\\\n",
    "            binBlockLength,binBlockLengths,matrix,\\\n",
    "            newComponent,newComponents,newComponentLengths,\\\n",
    "            newFromComponentLinks,newToComponentLinks,\\\n",
    "            occupants,\\\n",
    "            starts,ends,newToOldInd,oldToNewInd,\\\n",
    "            forwardPaths,invertedPaths,set() # The last one is pathsToInversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbd658",
   "metadata": {},
   "source": [
    "### Break component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1691fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getMatrixPathElement(matrix,pathID):\n",
    "    res = [el for el in matrix if el[0]==pathID]\n",
    "    if len(res)==1:\n",
    "        return res[0]\n",
    "    elif len(res)>0:\n",
    "        warnings.warn(f\"More than one element for path {pathID} is found!\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkChange(compNum,components,zoomLevel,blockEdges):\n",
    "    doBreak = False\n",
    "    curComp = components[compNum]\n",
    "#     nextComp = components[compNum+1]\n",
    "    \n",
    "    if compNum+1 in blockEdges:\n",
    "        return True\n",
    "    \n",
    "#     if sum(curComp['binsToCols'])<zoomLevel or sum(nextComp['binsToCols'])<zoomLevel:\n",
    "#         return False\n",
    "    \n",
    "#     paths = list(set(curComp['occupants'])|set(nextComp['occupants']))\n",
    "#     for pathID in paths:\n",
    "#         curPathMatrix = getMatrixPathElement(curComp['matrix'],pathID)\n",
    "#         nextPathMatrix = getMatrixPathElement(nextComp['matrix'],pathID)\n",
    "\n",
    "        \n",
    "#         if curPathMatrix is not None and nextPathMatrix is not None:\n",
    "#             curEdgeBinOcc = curPathMatrix[2][1][-1 if curPathMatrix[1]==0 else 0][0] # the last index==1 gives inversion\n",
    "#             nextEdgeBinOcc = nextPathMatrix[2][1][0 if nextPathMatrix[1]==0 else -1][0]\n",
    "#             # Checking for breaking in occupancy\n",
    "#             if np.abs(np.floor(nextEdgeBinOcc+0.5)-np.floor(curEdgeBinOcc+0.5))>0 \\\n",
    "#                 and nextEdgeBinOcc>0.5 and curEdgeBinOcc>0.5: # we do not want to break off small ends of larger components\n",
    "#                 doBreak = True\n",
    "#                 break\n",
    "            \n",
    "#             # Checking for breaking in inversion (using recorded binary inversion)\n",
    "#             if curPathMatrix[1]!=nextPathMatrix[1]:\n",
    "#                 doBreak = True\n",
    "#                 break\n",
    "#         else:\n",
    "#             # If one of the component in the path has empty block.\n",
    "#             # At the moment nothing is happening here, but potentially we can enforce break if that is the case.\n",
    "#             pass\n",
    "    return doBreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def joinComponents(leftComp,rightComp, maxLengthComponent, inversionThreshold=0.5):\n",
    "    '''\n",
    "    !!!  Currently not used\n",
    "    \n",
    "    If the joining was successful, the function will return a joined component.\n",
    "    \n",
    "    If the joining was not successful and was aborted for one of the following reasons, it will return a list of original components. \n",
    "    The reasons for aborting the joining can be the following:\n",
    "    - In one of the paths the invertion is lower than threshold in one component and higher in the other.\n",
    "    - Left component contains at least one end\n",
    "    - Right component contains at least one start\n",
    "    \n",
    "    The function will not check links for coming or going on the right of the left component and left of the right component. \n",
    "    It will just get left links from left component and right links from right component and assign them to the new component.\n",
    "    '''\n",
    "    \n",
    "    if leftComp['last_bin']-leftComp['first_bin']+1 + rightComp['last_bin']-rightComp['first_bin']+1 > maxLengthComponent:\n",
    "        return [leftComp,rightComp]\n",
    "    \n",
    "    if leftComp.get('ends',False):\n",
    "        # End of a path\n",
    "        return [leftComp,rightComp]\n",
    "    \n",
    "    newComp = {}\n",
    "    newComp['first_bin'] = min(leftComp['first_bin'],rightComp['first_bin'])\n",
    "    newComp['last_bin'] = max(leftComp['last_bin'],rightComp['last_bin'])\n",
    "    newComp['firstCol'] = min(leftComp['firstCol'],rightComp['firstCol'])\n",
    "    newComp['lastCol'] = max(leftComp['lastCol'],rightComp['lastCol'])\n",
    "    \n",
    "    leftCompNumBins = leftComp['last_bin']-leftComp['first_bin']+1\n",
    "    \n",
    "    newComp['occupants'] = list(set(leftComp['occupants']).union(rightComp['occupants']))\n",
    "    \n",
    "    for pathID in newComp['occupants']:\n",
    "        leftPathElement = getMatrixPathElement(leftComp['matrix'],pathID)\n",
    "        rightPathElement = getMatrixPathElement(rightComp['matrix'],pathID)\n",
    "        if leftPathElement is None and rightPathElement is None:\n",
    "            continue\n",
    "        \n",
    "        if leftPathElement is None:\n",
    "            if len([el for el in rightPathElement[2][1] if el[2][0][0]==1 or el[2][-1][0]==1])>0:\n",
    "                # Start of a path\n",
    "                return [leftComp,rightComp]\n",
    "            rightPathElement[2][0] = [el+leftCompNumBins for el in rightPathElement[2][0]]\n",
    "            newComp.setdefault(\"matrix\",[]).append(rightPathElement)\n",
    "            continue\n",
    "        \n",
    "        if rightPathElement is None:\n",
    "            newComp.setdefault(\"matrix\",[]).append(leftPathElement)\n",
    "            continue\n",
    "        \n",
    "        if (leftPathElement[1]>inversionThreshold and rightPathElement[1]<=inversionThreshold) or \\\n",
    "           (leftPathElement[1]<=inversionThreshold and rightPathElement[1]>inversionThreshold):\n",
    "            return [leftComp,rightComp]\n",
    "        \n",
    "        newPathElement = []\n",
    "        newPathElement.append(pathID)\n",
    "        newPathElement.append(leftPathElement[1])\n",
    "        pathMatrix = []\n",
    "        pathMatrix.append(leftPathElement[2][0] + [el+leftCompNumBins for el in rightPathElement[2][0]])\n",
    "        pathMatrix.append(leftPathElement[2][1] + rightPathElement[2][1])\n",
    "        newPathElement.append(pathMatrix)\n",
    "        newComp.setdefault(\"matrix\",[]).append(newPathElement)\n",
    "        \n",
    "    newComp['larrivals'] = leftComp['larrivals']\n",
    "    newComp['ldepartures'] = leftComp['ldepartures']\n",
    "    newComp['rarrivals'] = rightComp['rarrivals']\n",
    "    newComp['rdepartures'] = rightComp['rdepartures']\n",
    "    ends = list(set(leftComp.get('ends',[])).union(rightComp.get('ends',[])))\n",
    "    if len(ends)>0:\n",
    "        newComp['ends'] = ends\n",
    "    \n",
    "    return newComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884dff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkLinksZoom(compNum,fromComponentLinks,toComponentLinks):\n",
    "    # Check only outgoing from the right and incoming to the right\n",
    "    # and check outgoing from the left on and incoming to the left on the next node.\n",
    "    if any(['-' in toNodeDicts for toNodeDicts in fromComponentLinks.get(compNum+1,{}).get('+',{}).values()]):\n",
    "        # If there is an outgoing link from positive block (right) to negative block (anywhere)\n",
    "        return True\n",
    "\n",
    "    if any(['+' in fromNodeDicts for fromNodeDicts in toComponentLinks.get(compNum+1,{}).get('-',{}).values()]):\n",
    "        # If there is an incoming link to the negative block (right) from positive block (anywhere)\n",
    "        return True\n",
    "    \n",
    "    if any([toNodes!=compNum+2 for toNodes in fromComponentLinks.get(compNum+1,{}).get('+',{}).keys()]):\n",
    "        # If there is an outgoing link from positive block (right) to anywhere \n",
    "        # (positive block because negative downstream was excluded above) except the next component\n",
    "        return True\n",
    "    \n",
    "    if any([fromNodes!=compNum+2 for fromNodes in toComponentLinks.get(compNum+1,{}).get('-',{}).keys()]):\n",
    "        # If there is an incoming link to negative block (right) from anywhere\n",
    "        # (negavive block because positive upstream was excluded above) except the next component\n",
    "        return True\n",
    "    \n",
    "    if any([fromNodes!=compNum+1 or '-' in fromNodesDict for fromNodes,fromNodesDict in toComponentLinks.get(compNum+2,{}).get('+',{}).items()]):\n",
    "        # If there is an incoming link to positive block of next component (left) from anywhere except current component\n",
    "        return True\n",
    "    \n",
    "    if any([toNodes!=compNum+1 or '+' in toNodesDict for toNodes,toNodesDict in fromComponentLinks.get(compNum+2,{}).get('-',{}).items()]):\n",
    "        # If there is an outgoing link from negative block (left) to anywhere except current component\n",
    "        return True\n",
    "    \n",
    "    if not (('+' in fromComponentLinks.get(compNum+1,{}).get('+',{}).get(compNum+2,{})) or \\\n",
    "            ('-' in toComponentLinks.get(compNum+1,{}).get('-',{}).get(compNum+2,{}))):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkForBreaksZoom(zoomLevel,compNum,components,fromComponentLinks,toComponentLinks, blockEdges):\n",
    "    if compNum<len(components)-1:\n",
    "        breakByLinks = checkLinksZoom(compNum,fromComponentLinks,toComponentLinks)\n",
    "        breakByChange = checkChange(compNum,components,zoomLevel, blockEdges)\n",
    "    else:\n",
    "        return [false]\n",
    "    return [breakByLinks,breakByChange]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d307439c",
   "metadata": {},
   "source": [
    "### Update links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fca5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def splitPositiveNegative(compID,accs,components):\n",
    "    '''\n",
    "    This function simply pulls all accession presented in the component and split them into forward and inversed.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    `compID`: int. Number of the component in the current zoom layer (0-based).\n",
    "    `accs`: int or Iterable. Should provide either overall number of accession/paths in the graph or \n",
    "            a list of all (intended) accessions for the given component. It is used only for carrying over links \n",
    "            through empty components for some accessions.\n",
    "    `components`: list[dict]. List of component dictionaries, one of the main data structure representing zoom layer.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    `posAcc`: list[int]. IDs of accession which has forward direction in given component.\n",
    "    `negAcc`: list[int]. IDs of accession which has inverse direction in given component.\n",
    "    \n",
    "    '''\n",
    "    if isinstance(accs,int):\n",
    "        emptyAcc = set(range(accs))\n",
    "    elif isinstance(accs,Iterable):\n",
    "        emptyAcc = set(accs)\n",
    "    else:\n",
    "        raise TypeError(f'`accs` should be either int or Iterable, but {type(accs)} was given.')\n",
    "    posAcc = []\n",
    "    negAcc = []\n",
    "    for pathID,pathInversion,_ in components[compID]['matrix']:\n",
    "        emptyAcc -= set([pathID])\n",
    "        if pathInversion==1:\n",
    "            negAcc.append(pathID)\n",
    "        else:\n",
    "            posAcc.append(pathID)\n",
    "    \n",
    "#     for pathID in allAcc:\n",
    "#         negAcc.append(pathID)\n",
    "#         posAcc.append(pathID)\n",
    "    \n",
    "    return posAcc,negAcc,emptyAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def intersectAccLists(accList,dirDict):\n",
    "    overallLinkAccList = set()\n",
    "    for linkAccList in dirDict.values():\n",
    "        overallLinkAccList.update(linkAccList)\n",
    "    return set(accList).intersection(overallLinkAccList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2001abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def updateLinks(newToOldInd,oldToNewInd,\n",
    "                fromComponentLinks,toComponentLinks,\n",
    "                linkLengths,pairedLinks,interconnectedLinks,blockEdges,accStarts,accEnds,components,compAccDir,\n",
    "                newFromComponentLinks={},newToComponentLinks={}):\n",
    "    '''\n",
    "    newToOldInd and oldToNewInd: both index and values are 0-based numbers of components \n",
    "    in previous and current zoomlayer.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    for newComp,oldCompList in enumerate(newToOldInd):\n",
    "        leftOldCompId = oldCompList[0] + 1\n",
    "        rightOldCompId = oldCompList[-1] + 1\n",
    "        newCompId = newComp + 1\n",
    "        \n",
    "        newCompPosAcc,newCompNegAcc,newCompEmptyAcc = splitPositiveNegative(newComp,list(accStarts.keys()),components)\n",
    "        \n",
    "        # The next two if blocks set conditions for processing or not processing left and right of the current new component\n",
    "        # The side should not be processed if the end of the previous node is coming from the same component \n",
    "        # (on lower zoom level) as the begininng of the current component.\n",
    "        if newComp>0:\n",
    "            if oldCompList[0]==newToOldInd[newComp-1][-1]:\n",
    "                doLeft = False\n",
    "            else:\n",
    "                doLeft = True\n",
    "        else:\n",
    "            doLeft = True\n",
    "            \n",
    "        if newComp<len(newToOldInd)-1:\n",
    "            if oldCompList[-1]==newToOldInd[newComp+1][0]:\n",
    "                doRight = False\n",
    "            else:\n",
    "                doRight = True\n",
    "        else:\n",
    "            doRight = True\n",
    "        \n",
    "        # Departure on the right (from positive block)\n",
    "        if doRight:\n",
    "#             for fromComp in [leftOldCompId,rightOldCompId]:\n",
    "            fromComp = rightOldCompId\n",
    "            for toCompDict in fromComponentLinks.get(fromComp,{}).values():\n",
    "                for toOldComp,toOldCompDirDict in toCompDict.items():\n",
    "                    # To positive strand\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][0]\n",
    "                    toCompPosAcc,toCompNegAcc,toCompEmptyAcc = splitPositiveNegative(toNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[toNewCompId][0]==toOldComp-1:\n",
    "                        # Getting accession list which come out from positive and goes to positive.\n",
    "                        accList = intersectAccLists(list(set(newCompPosAcc).intersection(toCompPosAcc)),\n",
    "                                                    toOldCompDirDict)\n",
    "    #                     accList = list(set(newCompPosAcc).intersection(toCompPosAcc).intersection(toOldCompDirDict.get('+',[])))\n",
    "\n",
    "                        if len(accList)>0:\n",
    "                            if not(toNewCompId+1==newCompId and \\\n",
    "                                (fromComp-1!=newToOldInd[toNewCompId][-1] or toOldComp-1!=newToOldInd[toNewCompId][0])):\n",
    "                                # If the link is self loop (which happens sometimes), then it has to come out from right component\n",
    "                                # and go to the left component, otherwise it should not be carried forward.\n",
    "                                addLink(newCompId,'+',toNewCompId+1,'+',\n",
    "                                        accList,\n",
    "                                        newFromComponentLinks,newToComponentLinks)\n",
    "                        \n",
    "                        ### Wrap creating empty links into a separate function!!!\n",
    "                        if fromComp+1==toOldComp and newCompId+1==toNewCompId+1:\n",
    "                            continuityLinks = set(fromComponentLinks.get(fromComp,{}).get('+',{}).get(fromComp+1,{}).get('+',[]))\n",
    "                            emptyLinks = (set(newCompPosAcc)|set(newCompEmptyAcc)).intersection(set(toCompPosAcc)|set(toCompEmptyAcc)).intersection(continuityLinks)\n",
    "                            if len(emptyLinks)>0:\n",
    "                                addLink(newCompId,'+',toNewCompId+1,'+',emptyLinks,newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                    # To negative strand\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][-1]\n",
    "                    toCompPosAcc,toCompNegAcc,toCompEmptyAcc = splitPositiveNegative(toNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[toNewCompId][-1]==toOldComp-1:\n",
    "                        # Getting accession list which come out from positive and goes to negative.\n",
    "                        accList = intersectAccLists(list(set(newCompPosAcc).intersection(toCompNegAcc)),\n",
    "                                                    toOldCompDirDict)\n",
    "    #                     accList = list(set(newCompPosAcc).intersection(toCompNegAcc).intersection(toOldCompDirDict.get('-',[])))\n",
    "                        if len(accList)>0:\n",
    "                            addLink(newCompId,'+',toNewCompId+1,'-',\n",
    "                                    accList,\n",
    "                                    newFromComponentLinks,newToComponentLinks)\n",
    "        \n",
    "        # Departure on the left (from negative block)\n",
    "        if doLeft:\n",
    "#             for fromComp in [leftOldCompId,rightOldCompId]:\n",
    "            fromComp = leftOldCompId\n",
    "#             toCompDict = fromComponentLinks.get(fromComp,{}).get('-',{})\n",
    "            for toCompDict in fromComponentLinks.get(fromComp,{}).values():\n",
    "                for toOldComp,toOldCompDirDict in toCompDict.items():\n",
    "                    # To positive strand\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][0]\n",
    "                    toCompPosAcc,toCompNegAcc,toCompEmptyAcc = splitPositiveNegative(toNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[toNewCompId][0]==toOldComp-1:\n",
    "                        # Getting accession list which come out from negative and goes to positive.\n",
    "                        accList = intersectAccLists(list(set(newCompNegAcc).intersection(toCompPosAcc)),\n",
    "                                                    toOldCompDirDict)\n",
    "    #                     accList = list(set(newCompNegAcc).intersection(toCompPosAcc).intersection(toOldCompDirDict.get('+',[])))\n",
    "                        if len(accList)>0:\n",
    "                            addLink(newCompId,'-',toNewCompId+1,'+',\n",
    "                                    accList,\n",
    "                                    newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                    # to Negative strand\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][-1]\n",
    "                    toCompPosAcc,toCompNegAcc,toCompEmptyAcc = splitPositiveNegative(toNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[toNewCompId][-1]==toOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompNegAcc).intersection(toCompNegAcc)),\n",
    "                                                    toOldCompDirDict)\n",
    "    #                     accList = list(set(newCompNegAcc).intersection(toCompNegAcc).intersection(toOldCompDirDict.get('-',[])))\n",
    "                        if len(accList)>0:\n",
    "                            if not (toNewCompId+1==newCompId and \\\n",
    "                                (fromComp-1!=newToOldInd[toNewCompId][0] or toOldComp-1!=newToOldInd[toNewCompId][-1])):\n",
    "                                # If the link is self loop (which happens sometimes), then it has to come out from left component\n",
    "                                # and go to the right component, otherwise it should not be carried forward.\n",
    "                                addLink(newCompId,'-',toNewCompId+1,'-',\n",
    "                                        accList,\n",
    "                                        newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                        if fromComp-1==toOldComp and newCompId-1==toNewCompId+1:\n",
    "                            continuityLinks = set(fromComponentLinks.get(fromComp,{}).get('-',{}).get(fromComp+1,{}).get('-',[]))\n",
    "                            emptyLinks = (set(newCompNegAcc)|set(newCompEmptyAcc)).intersection(set(toCompNegAcc)|set(toCompEmptyAcc)).intersection(continuityLinks)\n",
    "                            if len(emptyLinks)>0:\n",
    "                                addLink(newCompId,'-',toNewCompId+1,'-',emptyLinks,newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "\n",
    "        # Arrival on the left (to positive block)\n",
    "        if doLeft:\n",
    "#             for toComp in [leftOldCompId,rightOldCompId]:\n",
    "            toComp = leftOldCompId\n",
    "#             fromCompDict = toComponentLinks.get(toComp,{}).get('+',{})\n",
    "            for fromCompDict in toComponentLinks.get(toComp,{}).values():\n",
    "                for fromOldComp,fromOldCompDirDict in fromCompDict.items():\n",
    "                    # From positive strand\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][-1]\n",
    "                    fromCompPosAcc,fromCompNegAcc,fromCompEmptyAcc = splitPositiveNegative(fromNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the from comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[fromNewCompId][-1]==fromOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompPosAcc).intersection(fromCompPosAcc)),\n",
    "                                                    fromOldCompDirDict)\n",
    "    #                     accList = list(set(newCompPosAcc).intersection(fromCompPosAcc).intersection(fromOldCompDirDict.get('+',[])))\n",
    "                        if len(accList)>0:\n",
    "                            if not (fromNewCompId+1==newCompId and \\\n",
    "                                (fromOldComp-1!=newToOldInd[fromNewCompId][-1] or toComp-1!=newToOldInd[fromNewCompId][0])):\n",
    "                                # If the link is self loop (which happens sometimes), then it has to come out from right component\n",
    "                                # and go to the left component, otherwise it should not be carried forward.\n",
    "                                addLink(fromNewCompId+1,'+',newCompId,'+',\n",
    "                                        accList,\n",
    "                                        newFromComponentLinks,newToComponentLinks)\n",
    "                        if toComp-1==fromOldComp and newCompId-1==fromNewCompId+1:\n",
    "                            continuityLinks = set(toComponentLinks.get(toComp,{}).get('+',{}).get(toComp-1,{}).get('+',[]))\n",
    "                            emptyLinks = (set(newCompPosAcc)|set(newCompEmptyAcc)).intersection(set(fromCompPosAcc)|set(fromCompEmptyAcc)).intersection(continuityLinks)\n",
    "                            if len(emptyLinks)>0:\n",
    "                                addLink(fromNewCompId+1,'+',newCompId,'+',emptyLinks,newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                    # From negative strand\n",
    "                    # Getting to comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][0]\n",
    "                    fromCompPosAcc,fromCompNegAcc,fromCompEmptyAcc = splitPositiveNegative(fromNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[fromNewCompId][0]==fromOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompPosAcc).intersection(fromCompNegAcc)),\n",
    "                                                    fromOldCompDirDict)\n",
    "    #                     accList = list(set(newCompPosAcc).intersection(fromCompNegAcc).intersection(fromOldCompDirDict.get('-',[])))\n",
    "                        if len(accList)>0:\n",
    "                            addLink(fromNewCompId+1,'-',newCompId,'+',\n",
    "                                    accList,\n",
    "                                    newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "        if doRight:\n",
    "            # Arrival on the right (to negative block)\n",
    "#             for toComp in [leftOldCompId,rightOldCompId]:\n",
    "            toComp = rightOldCompId\n",
    "#             fromCompDict = toComponentLinks.get(toComp,{}).get('-',{})\n",
    "            for fromCompDict in toComponentLinks.get(toComp,{}).values():\n",
    "                for fromOldComp,fromOldCompDirDict in fromCompDict.items():\n",
    "                    # From positive strand\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][-1]\n",
    "                    fromCompPosAcc,fromCompNegAcc,fromCompEmptyAcc = splitPositiveNegative(fromNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the from comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[fromNewCompId][0]==fromOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompNegAcc).intersection(fromCompPosAcc)),\n",
    "                                                    fromOldCompDirDict)\n",
    "    #                     accList = list(set(newCompNegAcc).intersection(fromCompPosAcc).intersection(fromOldCompDirDict.get('+',[])))\n",
    "                        if len(accList)>0:\n",
    "                            addLink(fromNewCompId+1,'+',newCompId,'-',\n",
    "                                    accList,\n",
    "                                    newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                    # From negative strand\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][0]\n",
    "                    fromCompPosAcc,fromCompNegAcc,fromCompEmptyAcc = splitPositiveNegative(fromNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the from comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[fromNewCompId][-1]==fromOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompNegAcc).intersection(fromCompNegAcc)),\n",
    "                                                    fromOldCompDirDict)\n",
    "    #                     accList = list(set(newCompNegAcc).intersection(fromCompNegAcc).intersection(fromOldCompDirDict.get('-',[])))\n",
    "                        if len(accList)>0:\n",
    "                            if not (fromNewCompId+1==newCompId and \\\n",
    "                                (fromOldComp-1!=newToOldInd[fromNewCompId][0] or toComp-1!=newToOldInd[fromNewCompId][-1])):\n",
    "                                # If the link is self loop (which happens sometimes), then it has to come out from left component\n",
    "                                # and go to the right component, otherwise it should not be carried forward.\n",
    "                                addLink(fromNewCompId+1,'-',newCompId,'-',\n",
    "                                        accList,\n",
    "                                        newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                        if toComp+1==fromOldComp and newCompId+1==fromNewCompId+1:\n",
    "                            continuityLinks = set(toComponentLinks.get(toComp,{}).get('-',{}).get(toComp-1,{}).get('-',[]))\n",
    "                            emptyLinks = (set(newCompNegAcc)|set(newCompEmptyAcc)).intersection(set(fromCompNegAcc)|set(fromCompEmptyAcc)).intersection(continuityLinks)\n",
    "                            if len(emptyLinks)>0:\n",
    "                                addLink(fromNewCompId+1,'-',newCompId,'-',emptyLinks,newFromComponentLinks,newToComponentLinks)\n",
    "    \n",
    "    for acc in accStarts.keys():\n",
    "        accStarts[acc] = oldToNewInd[accStarts[acc]-1][0]+1\n",
    "        accEnds[acc] = oldToNewInd[accEnds[acc]-1][0]+1\n",
    "    \n",
    "    linkLengthsConv,pairedLinksConv,interconnectedLinksConv,blockEdgesConv = \\\n",
    "        convertRemovableComponents(oldToNewInd,linkLengths,pairedLinks,interconnectedLinks,blockEdges,fromComponentLinks)\n",
    "#     if min(linkLengths.keys())==9:\n",
    "#         pdb.set_trace()\n",
    "    return newFromComponentLinks,newToComponentLinks,accStarts,accEnds,linkLengthsConv,pairedLinksConv,interconnectedLinksConv,blockEdgesConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16cf680",
   "metadata": {},
   "source": [
    "### Main layer generation function + assistant function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def isStartEnd(compNum,components):\n",
    "    isBreak = False\n",
    "    leftComp = components[compNum]\n",
    "    if compNum<len(components)-1:\n",
    "        rightComp = components[compNum+1]\n",
    "    else:\n",
    "        rightComp = None\n",
    "    \n",
    "    \n",
    "    for path,compInvBin,pathMatrix in leftComp['matrix']:\n",
    "        if compInvBin==1:\n",
    "            if path in leftComp.get('starts',[]):\n",
    "                isBreak = True\n",
    "        else:\n",
    "            if path in leftComp.get('ends',[]):\n",
    "                isBreak = True\n",
    "    \n",
    "    if rightComp is not None:\n",
    "        for path,compInvBin,pathMatrix in rightComp['matrix']:\n",
    "            if compInvBin==1:\n",
    "                if path in rightComp.get('ends',[]):\n",
    "                    isBreak = True\n",
    "            else:\n",
    "                if path in rightComp.get('starts',[]):\n",
    "                    isBreak = True\n",
    "    \n",
    "    return isBreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nextLayerZoom(zoomLevel,components,componentLengths,#componentNucleotides,\n",
    "                  fromComponentLinks,toComponentLinks,graph,\n",
    "                  accStarts,accEnds,\n",
    "                  maxLengthComponent,\n",
    "                  linkLengths,pairedLinks,interconnectedLinks,blockEdges,\n",
    "                  inversionThreshold=0.5,\n",
    "                  debug=False,debugTime=False):\n",
    "\n",
    "    print('\\n===========================')\n",
    "    print(f'Zoom level {zoomLevel}')\n",
    "    print('===========================')\n",
    "    \n",
    "    numComponents = len(components)\n",
    "    numComponentsDigits = np.int(np.ceil(np.log10(numComponents)))\n",
    "    \n",
    "    newComponent = deepcopy(componentTemplate)\n",
    "    newComponents = []\n",
    "    newComponentLengths = []\n",
    "    newComponentNucleotides = []\n",
    "\n",
    "    newFromComponentLinks = {}\n",
    "    newToComponentLinks = {}\n",
    "    \n",
    "#     collapsibleBlocksUpdate = []\n",
    "\n",
    "    occupants = set()\n",
    "    #nucleotides = '' \n",
    "    newToOldInd = [[]]\n",
    "    oldToNewInd = []\n",
    "    \n",
    "    binMeanOcc = {}\n",
    "    binMeanInv = {}\n",
    "    binOcc = {}\n",
    "    binInv = {}\n",
    "    binPosArray = {}\n",
    "    binAnn = {}\n",
    "    \n",
    "    binColStarts = []\n",
    "    binColEnds = []\n",
    "    binColLengths = []\n",
    "    binBlockLength = 0\n",
    "    binBlockLengths = []\n",
    "\n",
    "    matrix = {}\n",
    "    nBins = 0\n",
    "    nCols = 0\n",
    "\n",
    "    starts = set()\n",
    "    ends = set()\n",
    "\n",
    "#     prevOcc = {}\n",
    "#     prevInv = {}\n",
    "#     prevCompInv = {pathID:compInvOld for pathID,compInvOld,pathMatrix in components[0]['matrix']}\n",
    "    compInvNum = {}\n",
    "    compInvDen = {}\n",
    "    \n",
    "    compAccDir = {}\n",
    "    \n",
    "    for compNum,component in enumerate(components):\n",
    "        if debug or debugTime:\n",
    "            print(f'Processing component {compNum+1:0{numComponentsDigits}}/{numComponents:0{numComponentsDigits}}')\n",
    "        else:\n",
    "            print(f'\\rProcessing component {compNum+1:0{numComponentsDigits}}/{numComponents:0{numComponentsDigits}}',end='')\n",
    "        pathsToInversion = set()\n",
    "        forwardPaths = set(range(len(graph.accessions)))\n",
    "        invertedPaths = set()\n",
    "        \n",
    "        oldToNewInd.append([]) # len(newComponents)\n",
    "        newToOldInd[-1].append(compNum)\n",
    "        occupants.update(component['occupants'])\n",
    "        starts.update(component.get('starts',[]))\n",
    "        ends.update(component.get('ends',[]))\n",
    "        compNumBins = component['last_bin']-component['first_bin']+1\n",
    "        for binNum in range(0,compNumBins):\n",
    "            if binBlockLength>0:\n",
    "                binColStart = min(binColStart,component['binColStarts'][binNum])\n",
    "                binColEnd = max(binColEnd,component['binColEnds'][binNum])\n",
    "            else:\n",
    "                binColStart = component['binColStarts'][binNum]\n",
    "                binColEnd = component['binColEnds'][binNum]\n",
    "\n",
    "            binColLengths.append(component['binsToCols'][binNum])\n",
    "            binBlockLength += binColLengths[-1]\n",
    "            # check this process for order of added bins\n",
    "            # compInvBin should be calculated on the fly as average of added bins weighted by colLength\n",
    "            # It should be kept until the component closed.\n",
    "            # If average inversion changes from one side to the other, then inverted paths should be changed,\n",
    "            # and possibly some lists should be reversed.\n",
    "            \n",
    "            for pathID,oldCompInv,pathMatrix in component['matrix']:\n",
    "                compInvBin = compInvNum.get(pathID,oldCompInv)/compInvDen.get(pathID,1)\n",
    "                if compInvBin==1:\n",
    "                    pathsToInversion.add(pathID)\n",
    "                    compAccDir.setdefault(compNum,{})[pathID]='-'\n",
    "                else:\n",
    "                    pathsToInversion.discard(pathID)\n",
    "                    compAccDir.setdefault(compNum,{})[pathID]='+'\n",
    "                occupiedBins = pathMatrix[0]\n",
    "                binsMatrix = pathMatrix[1]\n",
    "\n",
    "                try:\n",
    "                    # For inverted old components reading should happen from the other side to the front.\n",
    "                    if oldCompInv==1:\n",
    "                        binPos = occupiedBins.index(componentLengths[compNum] - 1 - binNum)\n",
    "                    else:\n",
    "                        binPos = occupiedBins.index(binNum)\n",
    "                        \n",
    "                    binOcc.setdefault(pathID,[]).append(binsMatrix[binPos][0])\n",
    "                    binInv.setdefault(pathID,[]).append(binsMatrix[binPos][1])\n",
    "                    binPosArray.setdefault(pathID,[]).extend(binsMatrix[binPos][2])\n",
    "                    # binAnn.setdefault(pathID,set()).update(binsMatrix[binPos][3])\n",
    "                    \n",
    "                    compInvNum[pathID] = compInvNum.get(pathID,0) + binColLengths[-1]*binOcc[pathID][-1]*binInv[pathID][-1]\n",
    "                    compInvDen[pathID] = compInvDen.get(pathID,0) + binColLengths[-1]*binOcc[pathID][-1]\n",
    "#                     binColLengths.setdefault(pathID,[]).append(binColLength)\n",
    "#                     binBlockLengthAddition = max([binBlockLengthAddition,binColLength])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            # Finding out the size of the next bin to add\n",
    "            if binNum+1<compNumBins:\n",
    "                #If this component (old) has not ended yet, then get the size of the next bin\n",
    "                nextBinColLength = component['binsToCols'][binNum+1]\n",
    "            elif compNum+1<len(components):\n",
    "                # If we already read the last bin of the current component\n",
    "                # and it is not the last component, then we can do one of the two options:\n",
    "                \n",
    "                # Option 1: Get the first bin of the next component\n",
    "                # This will allow us to avoid adding a large bin to the small last bin of the previous component.\n",
    "                # But if the first bin of the next component was really small (can happen only if it was a a one bin component \n",
    "                # or there was a particular reason to break bin, it will still allow to add part of the component to the newly \n",
    "                # forming bin and the rest to the new bin\n",
    "                nextBinColLength = components[compNum+1]['binsToCols'][0]\n",
    "                \n",
    "                # Option 2: Get the whole size of the next component\n",
    "                # This option will not allow spliting a component in any way in such a way that a bin will get pieces of two \n",
    "                # neighbouring components. It will allow adding a very small single bin component to the bin which partially \n",
    "                # used by the end of previous component.\n",
    "                # nextBinColLength = sum(components[compNum+1]['binsToCols'])\n",
    "                \n",
    "            else:\n",
    "                nextBinColLength = 0\n",
    "            if binBlockLength+nextBinColLength > zoomLevel and binBlockLength>0:\n",
    "                \n",
    "                # If bin got equal or larger than target zoom level bin size \n",
    "                # (it can grow over by less than previous zoom level)\n",
    "                # then bin is closing and new bin will be formed.\n",
    "                [binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,matrix,\n",
    "                    newComponent,newComponents,newComponentLengths,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,\n",
    "                    starts,ends,newToOldInd,oldToNewInd,\n",
    "                    forwardPaths,invertedPaths,pathsToInversion] = \\\n",
    "                finaliseBinZoom(compNum,binOcc,binInv,binPosArray,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    newComponent,newComponents,newComponentLengths,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,linkLengths,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,pathsToInversion,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "\n",
    "            if nBins==maxLengthComponent:\n",
    "                \n",
    "                if nBins>0:\n",
    "                \n",
    "                    # Add links from current component to the next one\n",
    "                    if len(forwardPaths)>0:\n",
    "                        addLink(len(newComponents)+1,'+',len(newComponents)+2,'+',forwardPaths,newFromComponentLinks,newToComponentLinks)\n",
    "                    if len(invertedPaths)>0:\n",
    "                        addLink(len(newComponents)+2,'-',len(newComponents)+1,'-',invertedPaths,newFromComponentLinks,newToComponentLinks)\n",
    "                    # Add new element to newToOldInd\n",
    "                    \n",
    "                    if binNum==componentLengths[compNum]-1:\n",
    "                        newToOldInd.append([])\n",
    "                    else:\n",
    "                        newToOldInd.append([compNum])\n",
    "                    # Add number of next element to oldToNewInd\n",
    "                    oldToNewInd[-1].append(len(newComponents))\n",
    "                    \n",
    "                    # close component\n",
    "\n",
    "                    newComponent,newComponents,newComponentLengths,\\\n",
    "                    nBins,nCols,occupants,binBlockLengths,binColStarts,binColEnds,\\\n",
    "                    matrix,starts,ends,compInvNum,compInvDen = \\\n",
    "                        finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "                                              nBins,nCols,occupants,binBlockLengths,\n",
    "                                              binColStarts,binColEnds,\n",
    "                                              matrix,starts,ends,\n",
    "                                              forwardPaths,invertedPaths,\n",
    "                                              compInvNum,compInvDen,inversionThreshold=inversionThreshold)\n",
    "                    occupants = set(component['occupants'])\n",
    "        \n",
    "        isEndBreak = isStartEnd(compNum,components)\n",
    "        \n",
    "        if isEndBreak and binBlockLength>0:\n",
    "            [binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,nBins,nCols,\n",
    "            binBlockLength,binBlockLengths,matrix,\n",
    "            newComponent,newComponents,newComponentLengths,\n",
    "            newFromComponentLinks,newToComponentLinks,\n",
    "            occupants,\n",
    "            starts,ends,newToOldInd,oldToNewInd,\n",
    "            forwardPaths,invertedPaths,pathsToInversion] = \\\n",
    "                finaliseBinZoom(compNum,binOcc,binInv,binPosArray,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    newComponent,newComponents,newComponentLengths,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,linkLengths,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,pathsToInversion,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "            \n",
    "        if compNum==len(components)-1:\n",
    "            # Close the bin\n",
    "            if binBlockLength>0:\n",
    "                [binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,nBins,nCols,\n",
    "                binBlockLength,binBlockLengths,matrix,\n",
    "                newComponent,newComponents,newComponentLengths,\n",
    "                newFromComponentLinks,newToComponentLinks,\n",
    "                occupants,\n",
    "                starts,ends,newToOldInd,oldToNewInd,\n",
    "                forwardPaths,invertedPaths,pathsToInversion] = \\\n",
    "                    finaliseBinZoom(compNum,binOcc,binInv,binPosArray,\n",
    "                        nBins,nCols,\n",
    "                        binBlockLength,binBlockLengths,binColLengths,\n",
    "                        binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                        matrix,\n",
    "                        newComponent,newComponents,newComponentLengths,\n",
    "                        newFromComponentLinks,newToComponentLinks,\n",
    "                        occupants,linkLengths,\n",
    "                        starts,ends,\n",
    "                        forwardPaths,invertedPaths,pathsToInversion,\n",
    "                        newToOldInd,oldToNewInd,\n",
    "                        inversionThreshold=inversionThreshold)\n",
    "            \n",
    "            # break the last component\n",
    "            if nBins>0:\n",
    "                \n",
    "                oldToNewInd[-1].append(len(newComponents))\n",
    "                \n",
    "                newComponent,newComponents,newComponentLengths,\\\n",
    "                nBins,nCols,occupants,binBlockLengths,binColStarts,binColEnds,\\\n",
    "                matrix,starts,ends,compInvNum,compInvDen = \\\n",
    "                    finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "                                          nBins,nCols,occupants,binBlockLengths,\n",
    "                                          binColStarts,binColEnds,\n",
    "                                          matrix,starts,ends,\n",
    "                                          range(len(graph.accessions)),range(len(graph.accessions)),\n",
    "                                          compInvNum,compInvDen,inversionThreshold=inversionThreshold)\n",
    "\n",
    "        elif isEndBreak or any(checkForBreaksZoom(zoomLevel,compNum,components,fromComponentLinks,toComponentLinks,blockEdges)):\n",
    "            # Break at the end of the component because of the links\n",
    "            if binBlockLength>0:\n",
    "                [binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,nBins,nCols,\n",
    "                binBlockLength,binBlockLengths,matrix,\n",
    "                newComponent,newComponents,newComponentLengths,\n",
    "                newFromComponentLinks,newToComponentLinks,\n",
    "                occupants,\n",
    "                starts,ends,newToOldInd,oldToNewInd,\n",
    "                forwardPaths,invertedPaths,pathsToInversion] = \\\n",
    "                finaliseBinZoom(compNum,binOcc,binInv,binPosArray,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    newComponent,newComponents,newComponentLengths,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,linkLengths,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,pathsToInversion,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "            \n",
    "            # Break component\n",
    "            if nBins>0:\n",
    "                \n",
    "                newToOldInd.append([])\n",
    "                oldToNewInd[-1].append(len(newComponents))\n",
    "                \n",
    "                newComponent,newComponents,newComponentLengths,\\\n",
    "                nBins,nCols,occupants,binBlockLengths,binColStarts,binColEnds,\\\n",
    "                matrix,starts,ends,compInvNum,compInvDen = \\\n",
    "                    finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "                                          nBins,nCols,occupants,binBlockLengths,\n",
    "                                          binColStarts,binColEnds,\n",
    "                                          matrix,starts,ends,\n",
    "                                          range(len(graph.accessions)),range(len(graph.accessions)),\n",
    "                                          compInvNum,compInvDen,inversionThreshold=inversionThreshold)\n",
    "                \n",
    "        elif nBins>0 or binBlockLength>0:\n",
    "            oldToNewInd[-1].append(len(newComponents))\n",
    "    \n",
    "    print('\\nProcessing component finished.')\n",
    "    \n",
    "    newFromComponentLinks,newToComponentLinks,accStarts,accEnds,newLinkLengths,newPairedLinks,newInterconnectedLinks,newBlockEdges = \\\n",
    "        updateLinks(newToOldInd,oldToNewInd,fromComponentLinks,toComponentLinks,\n",
    "                    linkLengths,pairedLinks,interconnectedLinks,blockEdges,\n",
    "                    accStarts,accEnds,\n",
    "                    newComponents,compAccDir,newFromComponentLinks,newToComponentLinks)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return newComponents,newComponentLengths,\\\n",
    "            newFromComponentLinks,newToComponentLinks,\\\n",
    "            accStarts,accEnds,newLinkLengths,newPairedLinks,newInterconnectedLinks,newBlockEdges\\\n",
    "            ,oldToNewInd,newToOldInd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0f26a",
   "metadata": {},
   "source": [
    "## Clear elements too small to show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b13b68c",
   "metadata": {},
   "source": [
    "### Removing links and rearrangement blocks associated to too small blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72578f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def removeLink(fromComponentLinks,toComponentLinks,linkList,remLinks,link,pairedLink=None,subLink=None,subLinks=None,remLinkAccessions=None):\n",
    "    '''\n",
    "    This function remove the main link.\n",
    "    \n",
    "    If paired and substitute links are provided, the paired link will be checked (if it is not removed or \n",
    "    in the queue to be removed), it will be added to the queue\n",
    "    \n",
    "    After that common accessions for the same strand (for each separately) for start of main link and and end of paired link\n",
    "    are found and substitute link is established for all such accessions.\n",
    "    \n",
    "    If the substitute link is not (k,k+1), but (k,k+p), then in componentLinks all links (k,k+1),(k+1,k+1),...,(k+p-1,k+p)\n",
    "    are established.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    accessionMainLink = {}\n",
    "\n",
    "    if pairedLink is not None and subLink is not None and subLinks is not None and remLinkAccessions is not None:\n",
    "        processPair = True\n",
    "    else:\n",
    "        processPair = False\n",
    "        \n",
    "    if link not in remLinks: # Check validity.\n",
    "        # removing links from fromComponentLinks\n",
    "        for fromStrand,fromStrandDict in list(fromComponentLinks.get(link[0],{}).items()):\n",
    "\n",
    "            try:\n",
    "                if processPair:\n",
    "                    toCompDict = fromComponentLinks[link[0]][fromStrand].pop(link[1])\n",
    "                    for toStrand,accessionList in list(toCompDict.items()):\n",
    "                        if toStrand==fromStrand and link[0]+(1 if toStrand=='+' else -1)==link[1]:\n",
    "                            fromComponentLinks[link[0]][fromStrand].setdefault(link[1],{}).setdefault(toStrand,set()).update(accessionList)\n",
    "                        accessionMainLink.setdefault(fromStrand,set()).update(accessionList)\n",
    "                else:\n",
    "                    allCleared = True\n",
    "                    for toStrand,accessionList in list(fromStrandDict.get(link[1],{}).items()):\n",
    "                        if toStrand!=fromStrand or link[0]+(1 if toStrand=='+' else -1)!=link[1]:\n",
    "                            del fromComponentLinks[link[0]][fromStrand][link[1]][toStrand]\n",
    "                        else:\n",
    "                            allCleared = False\n",
    "                    \n",
    "                    if allCleared:\n",
    "                        del fromComponentLinks[link[0]][fromStrand][link[1]]\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "\n",
    "            if len(fromComponentLinks[link[0]][fromStrand])==0:\n",
    "                del fromComponentLinks[link[0]][fromStrand]\n",
    "\n",
    "        if link[0] in fromComponentLinks:\n",
    "            if len(fromComponentLinks[link[0]])==0:\n",
    "                del fromComponentLinks[link[0]]\n",
    "\n",
    "        # removing links from toComponentLinks\n",
    "        for toStrand,toStrandDict in list(toComponentLinks.get(link[1],{}).items()):\n",
    "\n",
    "            try:\n",
    "                allCleared = True\n",
    "                for fromStrand,accessionList in list(toStrandDict.get(link[0],{}).items()):\n",
    "                    if toStrand!=fromStrand or link[0]+(1 if toStrand=='+' else -1)!=link[1]:\n",
    "                        del toComponentLinks[link[1]][toStrand][link[0]][fromStrand]\n",
    "                    else:\n",
    "                        allCleared = False\n",
    "                \n",
    "                if allCleared:\n",
    "                    del toComponentLinks[link[1]][toStrand][link[0]]\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "            if len(toComponentLinks[link[1]][toStrand])==0:\n",
    "                del toComponentLinks[link[1]][toStrand]\n",
    "\n",
    "        if link[1] in toComponentLinks:\n",
    "            if len(toComponentLinks[link[1]])==0:\n",
    "                del toComponentLinks[link[1]]\n",
    "\n",
    "        remLinks.add(link)\n",
    "    \n",
    "    if processPair:\n",
    "        if len(accessionMainLink)>0:\n",
    "            remLinkAccessions[link]==accessionMainLink\n",
    "        else:\n",
    "            accessionMainLink = remLinkAccessions.get(link,{})\n",
    "            \n",
    "    if processPair and len(accessionMainLink)>0 and subLink not in subLinks:\n",
    "        if pairedLink not in linkList and pairedLink not in remLinks:\n",
    "            # If for some reason paired link is not in the list to be removed or removed already, \n",
    "            # it should also be removed. \n",
    "            # BE CAREFUL \n",
    "            # Although, if there is an issue with moving from layer to layer this can mask the issue.\n",
    "            \n",
    "            # The paired link is not removed here, it is added to the linkList and will be processed separately.\n",
    "            linkList.add(pairedLink)\n",
    "        \n",
    "        # Here we need to get accession list for each toStrand for paired link (for the end of link)\n",
    "        accessionPaired = {}\n",
    "        for toStrand,toStrandDict in list(toComponentLinks.get(link[1],{}).items()):\n",
    "\n",
    "            try:\n",
    "                fromCompDict = toComponentLinks[link[1]][toStrand].pop(link[0])\n",
    "                for fromStrand,accessionList in fromCompDict:\n",
    "                    accessionPaired.setdefault(toStrand,set()).update(accessionList)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        \n",
    "        subLinks.add(subLink)\n",
    "        \n",
    "        for strand,strandAccMain in accessionMainLink.items():\n",
    "            # Then intersect it with accessionsMainLink\n",
    "            strandAccPaired = accessionPaired.get(strand,set())\n",
    "            accIntersect = strandAccMain & strandAccPaired\n",
    "\n",
    "            # Establish substitute links \n",
    "            step = 1 if strand=='+' else -1\n",
    "            \n",
    "            for fromComp in range(subLink[0],subLink[1],step):\n",
    "                toComp = fromComp + step\n",
    "                if (strand=='+' and fromComp>toComp) or (strand=='-' and fromComp<toComp):\n",
    "                    _fromComp = toComp\n",
    "                    _toComp = fromComp\n",
    "                else:\n",
    "                    _fromComp = fromComp\n",
    "                    _toComp = toComp\n",
    "                    \n",
    "                addLink(_fromComp,strand,_toComp,strand,accIntersect,fromComponentLinks,toComponentLinks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8376aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def processCollapsibleBlocks(zoomLevel,linkLengths,pairedLinks,interconnectedLinks,fromComponentLinks,toComponentLinks):\n",
    "    \n",
    "    # Need to remove the links below zoom level everywhere, but the substitute links,\n",
    "    # associated with the pair should be established ONLY for paths where both links from the pair present!\n",
    "    remLinkAccessions = {}\n",
    "    for blockLength in sorted(list(linkLengths.keys())):\n",
    "        if blockLength<zoomLevel:\n",
    "            linkList = linkLengths.pop(blockLength)\n",
    "            remLinks = set()\n",
    "            subLinks = set()\n",
    "            \n",
    "            while len(linkList)>0:\n",
    "                link = linkList.pop()\n",
    "                try:\n",
    "                    pairedDict = pairedLinks.pop(link)\n",
    "                \n",
    "                    for pairedLink,subLink in pairedDict.items():\n",
    "                        removeLink(fromComponentLinks,toComponentLinks,linkList,remLinks,link,pairedLink,subLink,subLinks,remLinkAccessions)\n",
    "                except KeyError:\n",
    "                    removeLink(fromComponentLinks,toComponentLinks,linkList,remLinks,link)\n",
    "                \n",
    "                try:\n",
    "                    interconnectedLinks.pop(link)\n",
    "                except KeyError:\n",
    "                    warnings.warn(f'Link {link} was not found in interconnectedLinks. Possibly it was removed earlier, but it is better to double check.')\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df365be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clearRearrangementBlocks(zoomLevel,blockEdges):\n",
    "    return {edge:size for edge,size in blockEdges.items() if size>=zoomLevel}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eee058",
   "metadata": {},
   "source": [
    "### Find isolated blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3278f",
   "metadata": {},
   "source": [
    "#### Identify empty edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ff9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def testStartEnd(compNum,isLeft,components,accStarts,accEnds):\n",
    "    if isLeft:\n",
    "        startInv = 0\n",
    "        endInv = 1\n",
    "    else:\n",
    "        startInv = 1\n",
    "        endInv = 0\n",
    "        \n",
    "    for accStart,startComp in accStarts.items():\n",
    "        if startComp == compNum:\n",
    "            comp = components[compNum-1]\n",
    "            try:\n",
    "                accessionInd = comp['occupants'].index(accStart)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if comp['matrix'][accessionInd][1]==startInv:\n",
    "                return True\n",
    "    \n",
    "    for accEnd,endComp in accEnds.items():\n",
    "        if endComp == compNum:\n",
    "            comp = components[compNum-1]\n",
    "            try:\n",
    "                accessionInd = comp['occupants'].index(accStart)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if comp['matrix'][accessionInd][1]==endInv:\n",
    "                return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def findEmptyEdges(fromComponentLinks,toComponentLinks,accStarts,accEnds,components):\n",
    "    '''\n",
    "    Identify all empty edges by simply finding components that do not appear either in toComponentLinks (left empty)\n",
    "    or fromComponentLinks (right empty)\n",
    "    '''\n",
    "    \n",
    "    allCompSet = set((np.array(range(len(components)))+1).tolist())\n",
    "    toLinkedSet = set(toComponentLinks.keys())\n",
    "    fromLinkedSet = set(fromComponentLinks.keys())\n",
    "\n",
    "    leftEmptyCandidates = list(allCompSet - toLinkedSet)\n",
    "\n",
    "    leftEmptyList = []\n",
    "\n",
    "    for leftEmptyCand in leftEmptyCandidates:\n",
    "        if testStartEnd(leftEmptyCand,True,components,accStarts,accEnds):\n",
    "            continue\n",
    "\n",
    "        if '-' in fromComponentLinks.get(leftEmptyCand,{}):\n",
    "            continue\n",
    "\n",
    "        leftEmptyList.append(leftEmptyCand)\n",
    "\n",
    "    rightEmptyCandidates = list(allCompSet - fromLinkedSet)\n",
    "\n",
    "    rightEmptyList = []\n",
    "\n",
    "    for rightEmptyCand in rightEmptyCandidates:\n",
    "        if testStartEnd(rightEmptyCand,False,components,accStarts,accEnds):\n",
    "            continue\n",
    "\n",
    "        if '-' in toComponentLinks.get(rightEmptyCand,{}):\n",
    "            continue\n",
    "\n",
    "        rightEmptyList.append(rightEmptyCand)\n",
    "        \n",
    "    return leftEmptyList,rightEmptyList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f46c8",
   "metadata": {},
   "source": [
    "#### Identify isolated blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41916d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkExternalLinks(blockStart,blockEnd,fromComponentLinks,toComponentLinks,components):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    componentID: int. If an external links found, then a list of components inside the block involved \n",
    "                    in external links returned. If no external links found, then empty list is returned.\n",
    "    '''\n",
    "    \n",
    "    externalLinksComponents = []\n",
    "    \n",
    "    for compID in range(blockStart,blockEnd+1):\n",
    "        passToNext = False\n",
    "        \n",
    "        if len(components[compID-1].get('ends',[]))>0 or len(components[compID-1].get('starts',[]))>0:\n",
    "            externalLinksComponents.append(compID)\n",
    "            continue\n",
    "        \n",
    "        for fromStrandDict in fromComponentLinks.get(compID,{}).values():\n",
    "            for toComp in fromStrandDict.keys():\n",
    "                if toComp>blockEnd or toComp<blockStart:\n",
    "                    externalLinksComponents.append(compID)\n",
    "                    passToNext = True\n",
    "                    break\n",
    "            if passToNext:\n",
    "                break\n",
    "        \n",
    "        if passToNext:\n",
    "            continue\n",
    "            \n",
    "        for toStrandDict in toComponentLinks.get(compID,{}).values():\n",
    "            for fromComp in toStrandDict.keys():\n",
    "                if fromComp>blockEnd or fromComp<blockStart:\n",
    "                    externalLinksComponents.append(compID)\n",
    "                    passToNext = True\n",
    "                    break\n",
    "            if passToNext:\n",
    "                break\n",
    "    \n",
    "    return externalLinksComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def createNewBoundaries(blockStart,blockEnd,externalLinksComps,leftEmptyList,rightEmptyList):\n",
    "    leftEmptyArray = np.sort(np.array(leftEmptyList))\n",
    "    rightEmptyArray = np.sort(np.array(rightEmptyList))\n",
    "    \n",
    "    if externalLinksComps[0]==blockStart:\n",
    "        suitableStarts = np.where((leftEmptyArray>blockStart)&(leftEmptyArray<=blockEnd))[0]\n",
    "        if len(suitableStarts)>0:\n",
    "            blockSplit = [[leftEmptyArray[suitableStarts[0]]]]\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        blockSplit = [[blockStart]]\n",
    "    \n",
    "    doEnd = True\n",
    "    \n",
    "    for breakNum,breakPoint in enumerate(externalLinksComps):\n",
    "        \n",
    "        # Adding end\n",
    "        if doEnd:\n",
    "            suitableEnds = np.where((rightEmptyArray>=blockSplit[-1][0]) & (rightEmptyArray<breakPoint))[0]\n",
    "            if len(suitableEnds)>0:\n",
    "                blockSplit[-1].append(rightEmptyArray[suitableEnds[-1]])\n",
    "            else:\n",
    "                del blockSplit[-1]\n",
    "        \n",
    "        #adding start\n",
    "        if breakNum+1<len(externalLinksComps):\n",
    "            nextBoundary = externalLinksComps[breakNum+1]\n",
    "        else:\n",
    "            nextBoundary = blockEnd+1\n",
    "            \n",
    "        if breakPoint<blockEnd:\n",
    "            suitableStarts = np.where((leftEmptyArray>breakPoint) & (leftEmptyArray<=nextBoundary))[0]\n",
    "            if len(suitableStarts)>0:\n",
    "                blockSplit.append([leftEmptyArray[suitableStarts[0]]])\n",
    "                doEnd = True\n",
    "            else:\n",
    "                doEnd = False\n",
    "        else:\n",
    "            doEnd = False\n",
    "            break\n",
    "    \n",
    "    if doEnd:\n",
    "        suitableEnds = np.where((rightEmptyArray>=blockSplit[-1][0]) & (rightEmptyArray<=blockEnd))[0]\n",
    "        if len(suitableEnds)>0:\n",
    "            blockSplit[-1].append(rightEmptyArray[suitableEnds[-1]])\n",
    "        else:\n",
    "            del blockSplit[-1]\n",
    "    \n",
    "    if len(blockSplit)>0:\n",
    "        if len(blockSplit[0])>0:\n",
    "            return blockSplit\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for `createNewBoundaries`\n",
    "import numpy as np\n",
    "\n",
    "st = [2,5,6,8]\n",
    "end = [2,3,4,6,8,9,10,11]\n",
    "\n",
    "blocks = [[2,11],[2,3],[5,11],[8,11],[8,9],[8,11]]\n",
    "blockSplits = [[[2,3],[5,11]],[[2,2]],[[6,6],[8,11]],[[8,9]],[[8,8]],[]]\n",
    "externals = [[4],[3],[5,7],[10],[9],[8,9,10,11]]\n",
    "\n",
    "for bl,blSpl,ext in zip(blocks,blockSplits,externals):\n",
    "    blSplTT = createNewBoundaries(*bl,ext,st,end)\n",
    "    assert blSpl == blSplTT,f'Expected {blSpl}, but got {blSplTT}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84764d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another test for `createNewBoundaries`\n",
    "leftEmptyList = [2056, 3080, 3081, 2092, 2099, 1593, 3643, 2627, 1116, 2653, 2655, 3168, 2658, 613, 1637, 1638, 106, 1654, 2695, 2192, 1169, 1686, 2714, 3757, 2233, 3781, 723, 1240, 224, 1761, 1762, 1766, 3323, 1804, 786, 2331, 802, 2850, 807, 811, 1839, 1841, 3396, 3397, 1863, 3400, 843, 3423, 1898, 1899, 882, 884, 3463, 402, 2451, 3478, 408, 3482, 934, 426, 1962, 3504, 3516, 3519, 3520, 451, 1994, 1995, 972, 2506, 463, 3024, 1493, 1494, 3542, 1525]\n",
    "rightEmptyList = [402, 2451, 3478, 407, 280, 3482, 2848, 802, 934, 807, 426, 811, 2091, 2092, 3757, 1839, 3504, 1841, 3516, 3519, 3405, 463, 722, 1240, 1761, 1762, 1766, 1899]\n",
    "blockStart = 3396\n",
    "blockEnd = 3405\n",
    "externalLinksComps = [3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405]\n",
    "\n",
    "createNewBoundaries(blockStart,blockEnd,externalLinksComps,leftEmptyList,rightEmptyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def identifyIsolatedBlocks(leftEmptyList,rightEmptyList,fromComponentLinks,toComponentLinks,components):\n",
    "    if len(leftEmptyList)==0 or len(rightEmptyList)==0:\n",
    "        return []\n",
    "    \n",
    "    leftmostLeftEmpty = min(leftEmptyList)\n",
    "    rightmostRightEmpty = max(rightEmptyList)\n",
    "\n",
    "    isolatedBlockCandidates = []\n",
    "    isolatedBlockList = []\n",
    "\n",
    "    if leftmostLeftEmpty<=rightmostRightEmpty:\n",
    "        isolatedBlockCandidates.append([leftmostLeftEmpty,rightmostRightEmpty])\n",
    "\n",
    "    while len(isolatedBlockCandidates)>0:\n",
    "\n",
    "        isolatedBlock = isolatedBlockCandidates.pop()\n",
    "\n",
    "        externalLinksComps = checkExternalLinks(*isolatedBlock,fromComponentLinks,toComponentLinks,components)\n",
    "\n",
    "        if len(externalLinksComps)==0:\n",
    "            isolatedBlockList.append(isolatedBlock)\n",
    "        else:\n",
    "            isolatedBlockCandidates.extend(createNewBoundaries(*isolatedBlock,externalLinksComps,leftEmptyList,rightEmptyList))\n",
    "    \n",
    "    return isolatedBlockList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac3fdb",
   "metadata": {},
   "source": [
    "### Removing Isolated Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def updateLinksRemoveComp(oldToNewInd,fromComponentLinks,toComponentLinks,\n",
    "                          linkLengths,pairedLinks,interconnectedLinks,blockEdges,accStarts,accEnds):\n",
    "    \n",
    "    newFromComponentLinks={}\n",
    "    newToComponentLinks={}\n",
    "    \n",
    "    for oldFromComp,fromCompDict in fromComponentLinks.items():\n",
    "        if oldFromComp-1 in oldToNewInd:\n",
    "            newFromCompDict = newFromComponentLinks.setdefault(oldToNewInd[oldFromComp-1][0]+1,{})\n",
    "            for fromStrand,fromStrandDict in fromCompDict.items():\n",
    "                newFromStrandDict = newFromCompDict.setdefault(fromStrand,{})\n",
    "                for toComp,toCompDict in fromStrandDict.items():\n",
    "                    if toComp-1 in oldToNewInd:\n",
    "                        newFromStrandDict[oldToNewInd[toComp-1][0]+1] = toCompDict\n",
    "                \n",
    "    for oldToComp,toCompDict in toComponentLinks.items():\n",
    "        if oldToComp-1 in oldToNewInd:\n",
    "            newToCompDict = newToComponentLinks.setdefault(oldToNewInd[oldToComp-1][0]+1,{})\n",
    "            for toStrand,toStrandDict in toCompDict.items():\n",
    "                newToStrandDict = newToCompDict.setdefault(toStrand,{})\n",
    "                for fromComp,fromCompDict in toStrandDict.items():\n",
    "                    if fromComp-1 in oldToNewInd:\n",
    "                        newToStrandDict[oldToNewInd[fromComp-1][0]+1] = fromCompDict\n",
    "    \n",
    "    for acc in accStarts.keys():\n",
    "        accStarts[acc] = oldToNewInd[accStarts[acc]-1][0]+1\n",
    "        accEnds[acc] = oldToNewInd[accEnds[acc]-1][0]+1\n",
    "    \n",
    "    newLinkLengths = {}\n",
    "    for blockLength,linkList in linkLengths.items():\n",
    "        for link in linkList:\n",
    "            if (link[0]-1 not in oldToNewInd and link[1]-1 not in oldToNewInd):\n",
    "                continue\n",
    "            elif (link[0]-1 not in oldToNewInd or link[1]-1 not in oldToNewInd):\n",
    "                raise RuntimeError(f'One side of link {link} is found in the isolated block, and another one not. \\\n",
    "                It is against definition of isolated block.')\n",
    "            \n",
    "            newLinkFrom = oldToNewInd[link[0]-1][0]+1\n",
    "            newLinkTo = oldToNewInd[link[1]-1][0]+1\n",
    "#             if newLinkFrom==2965 and newLinkTo in [2962,2963]:\n",
    "#                 pdb.set_trace()\n",
    "            newLinkLengths.setdefault(blockLength,set()).add((newLinkFrom,newLinkTo))\n",
    "    \n",
    "    newPairedLinks = {}\n",
    "    for mainLink,pairedDict in pairedLinks.items():\n",
    "        for pairedLink,subLink in pairedDict.items():\n",
    "            isInIsolatedBlock = [side-1 not in oldToNewInd for side in itertools.chain(mainLink,pairedLink,subLink)]\n",
    "            if all(isInIsolatedBlock):\n",
    "                continue\n",
    "            elif any(isInIsolatedBlock):\n",
    "                raise RuntimeError(f'All sides of paired links {mainLink} - {pairedLink} : {subLink} should be \\\n",
    "                either in or out of isolated block but at least one side is inside and at least one outside.')\n",
    "            \n",
    "            newMainLink = (oldToNewInd[mainLink[0]-1][0]+1,oldToNewInd[mainLink[1]-1][0]+1)\n",
    "            newPairedLink = (oldToNewInd[pairedLink[0]-1][0]+1,oldToNewInd[pairedLink[1]-1][0]+1)\n",
    "            newSubLink = (oldToNewInd[subLink[0]-1][0]+1,oldToNewInd[subLink[1]-1][0]+1)\n",
    "#             if newMainLink[0]==2964 and newMainLink[1] in [2961,2962]:\n",
    "#                 pdb.set_trace()\n",
    "            newPairedLinks.setdefault(newMainLink,{})[newPairedLink] = newSubLink\n",
    "    \n",
    "    newInterconnectedLinks = {}\n",
    "    for linkC,linkList in interconnectedLinks.items():\n",
    "        if (linkC[0]-1 not in oldToNewInd and linkC[1]-1 not in oldToNewInd):\n",
    "            continue\n",
    "        elif (linkC[0]-1 not in oldToNewInd or linkC[1]-1 not in oldToNewInd):\n",
    "            raise RuntimeError(f'One side of link {link} (key of interconnectedLinks) is found in the isolated block, and another one not. \\\n",
    "                It is against definition of isolated block.')\n",
    "        newLinkC = (oldToNewInd[linkC[0]-1][0]+1,oldToNewInd[linkC[1]-1][0]+1)\n",
    "        for link in linkList:\n",
    "            if (link[0]-1 not in oldToNewInd and link[1]-1 not in oldToNewInd):\n",
    "                continue\n",
    "            elif (link[0]-1 not in oldToNewInd or link[1]-1 not in oldToNewInd):\n",
    "                raise RuntimeError(f'One side of link {link} (link from values of interconnectedLinks for key {linkC}) is found in the isolated block, and another one not. \\\n",
    "                It is against definition of isolated block.')\n",
    "            newInterconnectedLinks.setdefault(newLinkC,set()).add((oldToNewInd[link[0]-1][0]+1,oldToNewInd[link[1]-1][0]+1))\n",
    "        if len(newInterconnectedLinks[newLinkC])==0:\n",
    "            # Is it correct procedure?\n",
    "            newInterconnectedLinks.pop(newLinkC)\n",
    "        \n",
    "    # Update blockEdges\n",
    "    newBlockEdges = {}\n",
    "    for comp,blockLength in blockEdges.items():\n",
    "        if comp-1 in oldToNewInd:\n",
    "            newBlockEdges[oldToNewInd[comp-1][0]+1] = blockLength\n",
    "    \n",
    "    return newFromComponentLinks,newToComponentLinks,accStarts,accEnds,newLinkLengths,newPairedLinks,newInterconnectedLinks,newBlockEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def removeIsolatedBlocks(isolatedBlockList,components,componentLengths,\n",
    "                         fromComponentLinks,toComponentLinks,\n",
    "                         accStarts,accEnds,linkLengths,pairedLinks,interconnectedLinks,blockEdges):\n",
    "    if len(isolatedBlockList)>0:\n",
    "    \n",
    "        newToOldInd = list(range(len(components)))\n",
    "\n",
    "        for isolatedBlockStart,isolatedBlockEnd in sorted(isolatedBlockList,key=lambda el: el[1],reverse=True):\n",
    "            # deleting components and creating translation from new index to old index\n",
    "            for compToRemove in range(isolatedBlockEnd,isolatedBlockStart-1,-1):\n",
    "                del components[compToRemove-1]\n",
    "                del componentLengths[compToRemove-1]\n",
    "                del newToOldInd[compToRemove-1]\n",
    "\n",
    "        # Converting new to old index to old to new index\n",
    "        oldToNewInd = {el:[ind] for ind,el in enumerate(newToOldInd)}\n",
    "        # Converting new to old index from list to dict (not sure it is needed in the first place)\n",
    "    #     newToOldInd = {ind:[el] for ind,el in enumerate(newToOldInd)}\n",
    "\n",
    "        # `oldToNewInd` as well as `newToOldInd` are 0-based both index and values. To connect them to links (which are 1-based), \n",
    "        # for indexing you need to do linkComp-1, to get back to links, +1, `oldToNewInd[linkComp-1][0]+1`\n",
    "\n",
    "        # updating links\n",
    "        fromComponentLinks,toComponentLinks,accStarts,accEnds,linkLengths,pairedLinks,interconnectedLinks,blockEdges = \\\n",
    "            updateLinksRemoveComp(oldToNewInd,fromComponentLinks,toComponentLinks,\n",
    "                                  linkLengths,pairedLinks,interconnectedLinks,blockEdges,\n",
    "                                  accStarts,accEnds)\n",
    "    else:\n",
    "        oldToNewInd = {}\n",
    "        newToOldInd = []\n",
    "    return components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,\\\n",
    "            linkLengths,pairedLinks,interconnectedLinks,blockEdges,\\\n",
    "            oldToNewInd,newToOldInd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a81a7",
   "metadata": {},
   "source": [
    "### Clearing small element wrapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a258eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clearInvisible(zoomLevel,linkLengths,pairedLinks,interconnectedLinks,blockEdges,\n",
    "                   fromComponentLinks,toComponentLinks,\n",
    "                   accStarts,accEnds,\n",
    "                   components,componentLengths):\n",
    "    print('Removing links according to collapsible blocks')\n",
    "    \n",
    "    # TODO This process should be changed to linkLengths dict using paired links\n",
    "    numOfComponents = len(components)\n",
    "    # Link removal\n",
    "    processCollapsibleBlocks(zoomLevel,linkLengths,pairedLinks,interconnectedLinks,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "    blockEdges = clearRearrangementBlocks(zoomLevel,blockEdges)\n",
    "    \n",
    "    # Identify empty (without links) edges\n",
    "    leftEmptyList,rightEmptyList = findEmptyEdges(fromComponentLinks,toComponentLinks,accStarts,accEnds,components)\n",
    "\n",
    "    # Identify isolated blocks ,i.e. without any links on both sides and no outside links from inside\n",
    "    isolatedBlockList = identifyIsolatedBlocks(leftEmptyList,rightEmptyList,fromComponentLinks,toComponentLinks,components)\n",
    "    \n",
    "    # Remove identified isolated blocks\n",
    "    components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,\\\n",
    "    linkLengths,pairedLinks,interconnectedLinks,blockEdges,\\\n",
    "    oldToNewInd,newToOldInd = \\\n",
    "    removeIsolatedBlocks(isolatedBlockList,components,componentLengths,\n",
    "                         fromComponentLinks,toComponentLinks,\n",
    "                         accStarts,accEnds,\n",
    "                         linkLengths,pairedLinks,interconnectedLinks,blockEdges)\n",
    "    \n",
    "    print(f'All links associated with collapsibleComponents <{zoomLevel} were removed. \\\n",
    "    {numOfComponents-len(components)} components were deleted as isolated.')\n",
    "    \n",
    "    return components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,\\\n",
    "            linkLengths,pairedLinks,interconnectedLinks,blockEdges,\\\n",
    "            oldToNewInd,newToOldInd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b164ee",
   "metadata": {},
   "source": [
    "## Exporting layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def createZoomLevelDir(outputPath,outputName,zoomLevel):\n",
    "    '''\n",
    "    Creates a directory for zoom level chunks. The function will take care of correct directory level separator.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    `outputPath`: str. Absolute path to location where the visualisation data should be created\n",
    "    `outputName`: str. The name of the visualisation case, will be a directory at the path given by `outputPath`\n",
    "    `zoomLevel`: int or str. zoom level (maximum number of nucleotides in a single column/bin).\n",
    "                 A directory will be ceated\n",
    "                 \n",
    "    Return\n",
    "    ======\n",
    "    The function does not return anything, but creates a directory tree `outputPath`, \n",
    "    within it creates a directory `outputName` and inside it creates a directory `zoomLevel`\n",
    "    '''\n",
    "    \n",
    "    os.makedirs(f'{outputPath}{os.path.sep}{outputName}{os.path.sep}{zoomLevel}',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def finaliseChunk(rootStruct,zoomLevel,chunk,nucleotides,nBins,chunkNum,curCompCols,prevTotalCols,outputPath,outputName):\n",
    "    endChunkBin = chunk['components'][-1]['last_bin']\n",
    "    endChunkCol = chunk['components'][-1]['lastCol']\n",
    "    chunk['last_bin'] = endChunkBin\n",
    "    chunk['last_col'] = endChunkCol\n",
    "    \n",
    "    localPath = f'{outputPath}{os.path.sep}{outputName}{os.path.sep}{zoomLevel}{os.path.sep}'\n",
    "    \n",
    "    fileName = f'chunk{chunkNum}_zoom{zoomLevel}.schematic.json'\n",
    "    \n",
    "    with open(f'{localPath}{fileName}','w') as f:\n",
    "        json.dump(chunk,f,cls=NpEncoder)\n",
    "    \n",
    "    rootStruct['zoom_levels'][zoomLevel]['files'].append({\n",
    "        'file': fileName,\n",
    "        'first_bin':chunk['first_bin'],\n",
    "        'first_col':chunk['first_col'],\n",
    "        'last_bin':chunk['last_bin'],\n",
    "        'last_col':chunk['last_col'],\n",
    "#         'x':prevTotalCols\n",
    "    })\n",
    "    \n",
    "    if nucleotides!='':\n",
    "        fastaName = f'seq_chunk{chunkNum}_zoom{zoomLevel}.fa'\n",
    "        rootStruct['zoom_levels'][zoomLevel]['files'][-1]['fasta'] = fastaName\n",
    "        \n",
    "        with open(f'{localPath}{fastaName}','w') as f:\n",
    "            f.write(f'>first_bin:{chunk[\"first_bin\"]} last_bin:{chunk[\"last_bin\"]}\\n')\n",
    "            f.write(nucleotides)\n",
    "        \n",
    "    chunk = deepcopy(chunkTemplate)\n",
    "    chunk['first_bin'] = endChunkBin + 1\n",
    "    chunk['first_col'] = endChunkCol + 1\n",
    "    return rootStruct,chunk,0,chunkNum + 1,prevTotalCols+curCompCols,0,'' #rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b46a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def addLinksToComp(compNum,components,fromComponentLinks,toComponentLinks):\n",
    "    component = deepcopy(components[compNum])\n",
    "    \n",
    "    toCompDict = toComponentLinks.get(compNum+1,{}) # !!! Check that in fromComponentLinks component numbering is 1-based\n",
    "    if '+' in toCompDict:\n",
    "        for fromCompNum,fromCompDict in toCompDict['+'].items():\n",
    "            fromComp = components[fromCompNum-1]\n",
    "            for fromStrand,participants in fromCompDict.items():\n",
    "                doAddArrival = True\n",
    "                if fromStrand=='+':\n",
    "                    upstreamBin = fromComp['last_bin']\n",
    "                    upstreamCol = fromComp['lastCol']\n",
    "                    fromRight = True\n",
    "                    if component['first_bin']-upstreamBin==1:\n",
    "                        doAddArrival = False\n",
    "                elif fromStrand=='-':\n",
    "                    upstreamBin = fromComp['first_bin']\n",
    "                    upstreamCol = fromComp['firstCol']\n",
    "                    fromRight = False\n",
    "                else:\n",
    "                    raise ValueError(f'Unrecognised direction of node link {fromStrand}')\n",
    "                if doAddArrival:\n",
    "                    component['larrivals'].append({\n",
    "                            'upstream': upstreamBin,\n",
    "                            'downstream': component['first_bin'],\n",
    "                            'upstreamCol': upstreamCol,\n",
    "                            'downstreamCol': component['firstCol'],\n",
    "                            'otherSideRight': fromRight,\n",
    "                            'participants': participants\n",
    "                        })\n",
    "    \n",
    "    if '-' in toCompDict:\n",
    "        for fromCompNum,fromCompDict in toCompDict['-'].items():\n",
    "            fromComp = components[fromCompNum-1]\n",
    "            for fromStrand,participants in fromCompDict.items():\n",
    "                if fromStrand=='+':\n",
    "                    upstreamBin = fromComp['last_bin']\n",
    "                    upstreamCol = fromComp['lastCol']\n",
    "                    fromRight = True\n",
    "                elif fromStrand=='-':\n",
    "                    upstreamBin = fromComp['first_bin']\n",
    "                    upstreamCol = fromComp['firstCol']\n",
    "                    fromRight = False\n",
    "                else:\n",
    "                    raise ValueError(f'Unrecognised direction of node link {fromStrand}')\n",
    "                component['rarrivals'].append({\n",
    "                        'upstream': upstreamBin,\n",
    "                        'downstream': component['last_bin'],\n",
    "                        'upstreamCol': upstreamCol,\n",
    "                        'downstreamCol': component['lastCol'],\n",
    "                        'otherSideRight': fromRight,\n",
    "                        'participants': participants\n",
    "                    })\n",
    "    \n",
    "    fromCompDict = fromComponentLinks.get(compNum+1,{}) # !!! Check that in fromComponentLinks component numbering is 1-based\n",
    "    if '+' in fromCompDict:\n",
    "        for toCompNum,toCompDict in fromCompDict['+'].items():\n",
    "            toComp = components[toCompNum-1]\n",
    "            for toStrand,participants in toCompDict.items():\n",
    "                if toStrand=='+':\n",
    "                    downstreamBin = toComp['first_bin']\n",
    "                    downstreamCol = toComp['firstCol']\n",
    "                    toRight = False\n",
    "                elif toStrand=='-':\n",
    "                    downstreamBin = toComp['last_bin']\n",
    "                    downstreamCol = toComp['lastCol']\n",
    "                    toRight = True\n",
    "                else:\n",
    "                    raise ValueError(f'Unrecognised direction of node link {toStrand}')\n",
    "                component['rdepartures'].append({\n",
    "                        'upstream': component['last_bin'],\n",
    "                        'downstream': downstreamBin,\n",
    "                        'upstreamCol': component['lastCol'],\n",
    "                        'downstreamCol': downstreamCol,\n",
    "                        'otherSideRight': toRight,\n",
    "                        'participants': participants\n",
    "                    })\n",
    "    if '-' in fromCompDict:\n",
    "        for toCompNum,toCompDict in fromCompDict['-'].items():\n",
    "            toComp = components[toCompNum-1]\n",
    "            for toStrand,participants in toCompDict.items():\n",
    "                doAddDeparture = True\n",
    "                if toStrand=='+':\n",
    "                    downstreamBin = toComp['first_bin']\n",
    "                    downstreamCol = toComp['firstCol']\n",
    "                    toRight = False\n",
    "                elif toStrand=='-':\n",
    "                    downstreamBin = toComp['last_bin']\n",
    "                    downstreamCol = toComp['lastCol']\n",
    "                    toRight = True\n",
    "                    if component['first_bin']-downstreamBin==1:\n",
    "                        doAddDeparture = False\n",
    "                else:\n",
    "                    raise ValueError(f'Unrecognised direction of node link {toStrand}')\n",
    "                if doAddDeparture:\n",
    "                    component['ldepartures'].append({\n",
    "                            'upstream': component['first_bin'],\n",
    "                            'downstream': downstreamBin,\n",
    "                            'upstreamCol': component['firstCol'],\n",
    "                            'downstreamCol': downstreamCol,\n",
    "                            'otherSideRight': toRight,\n",
    "                            'participants': participants\n",
    "                        })\n",
    "        \n",
    "    return component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def checkLinks(leftComp,rightComp):\n",
    "    leftRdepCond = np.all([link['upstream']+1==link['downstream'] for link in leftComp['rdepartures']])\n",
    "    leftRarrCond = np.all([link['upstream']-1==link['downstream'] for link in leftComp['rarrivals']])\n",
    "\n",
    "    rightRdepCond = np.all([link['upstream']-1==link['downstream'] for link in rightComp['ldepartures']])\n",
    "    rightRarrCond = np.all([link['upstream']+1==link['downstream'] for link in rightComp['larrivals']])\n",
    "    \n",
    "    return leftRdepCond and leftRarrCond and rightRarrCond and rightRdepCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def searchIndicesPosRecord(redisConn,redisCaseID,zoomLevel,accessions,posMapping):\n",
    "    for pathID,posMappingPath in posMapping.items():\n",
    "        iset_add(redisConn, f'{redisCaseID}.{zoomLevel}.{accessions[pathID]}.Pos',posMappingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exportLayer(zoomLevel,components,componentNucleotides,\n",
    "                fromComponentLinks,toComponentLinks,\n",
    "                rootStruct,\n",
    "                outputPath,outputName,\n",
    "                maxLengthComponent,maxLengthChunk,\n",
    "                inversionThreshold=0.5,\n",
    "                redisConn=None,\n",
    "                redisCaseID=None,\n",
    "                accessions=None,\n",
    "                debug=False):\n",
    "    \n",
    "    #Create the directory to hold zoomLevel chunks and fasta files (if available)\n",
    "    createZoomLevelDir(outputPath,outputName,zoomLevel)\n",
    "\n",
    "    chunkList = rootStruct[\"zoom_levels\"].setdefault(zoomLevel,{\n",
    "        \"last_bin\": components[-1][\"last_bin\"],\n",
    "        \"last_col\": components[-1][\"lastCol\"],\n",
    "        \"files\":[]\n",
    "    })\n",
    "    # Recording data to files for zoom level\n",
    "\n",
    "    #     chunkTemplate = {\n",
    "    #     \"json_version\":17,\n",
    "    #     \"bin_width\":1,\n",
    "    #     \"first_bin\":1,\n",
    "    #     \"includes_connectors\": True,\n",
    "    #     \"components\": []\n",
    "    # }    \n",
    "    chunk = deepcopy(chunkTemplate)\n",
    "    chunkNum = 0\n",
    "    prevTotalCols = 0\n",
    "    curCompCols = 0\n",
    "    nucleotides = ''\n",
    "    nBins = 0\n",
    "    numComps = len(components)\n",
    "    numCompsDigits = np.int(np.ceil(np.log10(numComps)))\n",
    "    \n",
    "    if redisConn:\n",
    "        accessions = rootStruct[\"pathNames\"]\n",
    "    posMapping = {}\n",
    "    geneMapping = {}\n",
    "    for compNum in range(numComps):\n",
    "        if debug:    \n",
    "            print(f'Recording component {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}')\n",
    "        else:\n",
    "            print(f'\\rRecording component {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}',end='')\n",
    "        component = addLinksToComp(compNum,components,fromComponentLinks,toComponentLinks)\n",
    "#         print(f'Component Length is {component[\"last_bin\"]-component[\"first_bin\"]+1}')\n",
    "#         redisStartTime = time.time()\n",
    "        if redisConn is not None:\n",
    "            \n",
    "            for pathID,inv,matrixPathArray in component['matrix']:\n",
    "#                 print(f'Recording search indices for path {accessions[pathID]}')\n",
    "                pathRedisStartTime = time.time()\n",
    "                for binNum,binMatrix in zip(*matrixPathArray):\n",
    "                    if binMatrix[1]>inversionThreshold:\n",
    "                        overallBin = component['last_bin']-binNum\n",
    "                    else:\n",
    "                        overallBin = component['first_bin']+binNum\n",
    "                    \n",
    "                    posMapping.setdefault(pathID,{}).update({int(overallBin):[(int(posStart),int(posEnd)) for posStart,posEnd in binMatrix[2]]})\n",
    "\n",
    "#                     geneList = binMatrix[3]\n",
    "#                     for gene in geneList:\n",
    "#                         geneMappingPath = geneMapping.get(pathID,{})\n",
    "#                         if gene not in geneMappingPath:#not redisConn.hexists(f'{zoomLevel}.{accessions[pathID]}.Gene',gene):\n",
    "#                             geneMapping.setdefault(pathID,{}).update({gene:(overallBin,:overallBin)})\n",
    "                            \n",
    "#                 print(f'Recording search indices for path {accessions[pathID]} took {time.time()-pathRedisStartTime}')\n",
    "#         print(f'Overall recording of search indices for component {compNum+1} is {time.time()-redisStartTime}')\n",
    "        \n",
    "#         print(f'Joining component {compNum}')\n",
    "#         joinStartTime = time.time()\n",
    "        nBins += component[\"last_bin\"]-component[\"first_bin\"]+1\n",
    "#         if len(chunk['components'])>0:\n",
    "#             if checkLinks(chunk[\"components\"][-1],component):\n",
    "#                 newComp = joinComponents(chunk[\"components\"].pop(),component,maxLengthComponent,inversionThreshold)\n",
    "#                 if isinstance(newComp,list):\n",
    "#                     chunk[\"components\"].append(newComp[0])\n",
    "#                     component = newComp[1]\n",
    "#                 else:\n",
    "#                     component = newComp\n",
    "        if len(componentNucleotides)>0:\n",
    "            nucleotides += componentNucleotides[compNum]\n",
    "        chunk[\"components\"].append(component)\n",
    "        \n",
    "#         print(f'Joining took {time.time() - joinStartTime}')\n",
    "        \n",
    "        # End of chunk\n",
    "        if compNum<len(components)-1:\n",
    "            if len(chunk['components'])>=maxLengthChunk:\n",
    "            #nBins+components[compNum+1][\"last_bin\"]-components[compNum+1][\"first_bin\"]+1>maxLengthChunk:\n",
    "#                 print(f'Recording chunk')\n",
    "#                 chunkStartTime = time.time()\n",
    "                rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols,nucleotides = finaliseChunk(\n",
    "                                                                                          rootStruct,\n",
    "                                                                                          zoomLevel,\n",
    "                                                                                          chunk,\n",
    "                                                                                          nucleotides,\n",
    "                                                                                          nBins,\n",
    "                                                                                          chunkNum,\n",
    "                                                                                          curCompCols,\n",
    "                                                                                          prevTotalCols,\n",
    "                                                                                          outputPath,\n",
    "                                                                                          outputName)\n",
    "#                 print(f'Chunk recorded in {time.time() - chunkStartTime}')\n",
    "        else:\n",
    "#             print(f'Recording chunk')\n",
    "#             chunkStartTime = time.time()\n",
    "            rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols,nucleotides = finaliseChunk(\n",
    "                                                                                      rootStruct,\n",
    "                                                                                      zoomLevel,\n",
    "                                                                                      chunk,\n",
    "                                                                                      nucleotides,\n",
    "                                                                                      nBins,\n",
    "                                                                                      chunkNum,\n",
    "                                                                                      curCompCols,\n",
    "                                                                                      prevTotalCols,\n",
    "                                                                                      outputPath,\n",
    "                                                                                      outputName)\n",
    "#             print(f'Chunk recorded in {time.time() - chunkStartTime}')\n",
    "    if redisConn is not None:\n",
    "        searchIndicesPosRecord(redisConn,redisCaseID,zoomLevel,accessions,posMapping)\n",
    "        # searchIndicesGeneRecord(redisConn,zoomLevel,accessions,geneMapping)\n",
    "        try:\n",
    "            redisConn.bgsave()\n",
    "        except ResponseError:\n",
    "            pass\n",
    "    if not debug:\n",
    "        print()\n",
    "    \n",
    "    print(f'Recording zoom level {zoomLevel} finished.') # Zoom level time is {time.time() - zoomTime}. Time elapsed {time.time() - startTime}')\n",
    "\n",
    "    return rootStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4170850",
   "metadata": {},
   "source": [
    "## Main exporter wrapper with its helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compLinksToAccCompLinks(compLinks,doCompDir=False):\n",
    "    accCompLinks = {}\n",
    "    if doCompDir:\n",
    "        accCompDir = {}\n",
    "    \n",
    "    for comp1,comp1Dict in compLinks.items():\n",
    "        for strand1,strand1Dict in comp1Dict.items():\n",
    "            for comp2,comp2Dict in strand1Dict.items():\n",
    "                for strand2,accList in comp2Dict.items():\n",
    "                    for acc in accList:\n",
    "                        # Do we need to include strand or component only is enough. Here are two options, just choose one:\n",
    "#                         accCompLinks.setdefault(acc,{}).setdefault((comp1,strand1),set()).add((comp2,strand2))\n",
    "                        accCompLinks.setdefault(acc,{}).setdefault(comp1,set()).add(comp2)\n",
    "                        \n",
    "                        if doCompDir:\n",
    "                            accCompDir.setdefault(acc,{})[comp1] = strand1\n",
    "                            accCompDir.setdefault(acc,{})[comp2] = strand2\n",
    "    if doCompDir:\n",
    "        return accCompLinks,accCompDir\n",
    "    else:\n",
    "        return accCompLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c86728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def recordZoomLevelForDebug(zoomNodeToComponent,\n",
    "                            zoomComponentToNodes,\n",
    "                            zoomComponents,\n",
    "                            nodeToComponent,\n",
    "                            componentToNodes,\n",
    "                            components,\n",
    "                            zoomLevel):\n",
    "    '''\n",
    "    A function which records result of segmentation to dictionaries, \n",
    "    which holds results for all zoom levels.\n",
    "    It is currently used only for debugging purposes and in normal operation \n",
    "    all zoom level dictionaries are not created and used.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    Parameters are self-explanatory. Those starting from `zoom` are dictionary\n",
    "    holding all zoom levels, whereas the same parameter names without `zoom`\n",
    "    in the beginning are data for zoom level given in `zoomLevel` parameter.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    Returns modified dictionaries with `zoom` in the beginning of the names. Theoretically,\n",
    "    it should work without return at all (through pointers passed to the function), but it\n",
    "    did not work before and to be on the safe side, this is done through return.\n",
    "    \n",
    "    '''\n",
    "    zoomNodeToComponent[zoomLevel] = nodeToComponent\n",
    "    zoomComponentToNodes[zoomLevel] = componentToNodes\n",
    "#     zoomComponentLengths[zoomLevel] = componentLengths\n",
    "    zoomComponents[zoomLevel] = components\n",
    "#     zoomCompNucleotides[zoomLevel] = componentNucleotides\n",
    "#     zoomAccStarts[zoomLevel] = accStarts\n",
    "#     zoomAccEnds[zoomLevel] = accEnds\n",
    "    \n",
    "    return  zoomNodeToComponent, \\\n",
    "            zoomComponentToNodes, \\\n",
    "            zoomComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11811a1d-59b6-4ef1-a7c7-3ef428687b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def searchIndicesGeneRecord(redisConn,redisCaseID,geneMapping,genPosMapping,altChrGenPosMapping,genPosSearchMapping):\n",
    "    for pathID,geneMappingPath in geneMapping.items():\n",
    "        iset_add(redisConn,f'{redisCaseID}.{pathID}.Gene',geneMappingPath)\n",
    "    for pathID,genPosMappingPath in genPosMapping.items():\n",
    "        iset_add(redisConn,f'{redisCaseID}.{pathID}.GenPos',genPosMappingPath)\n",
    "    for pathID,genPosSearchMappingPath in genPosSearchMapping.items():\n",
    "        iset_add(redisConn,f'{redisCaseID}.{pathID}.GenPosSearch',genPosSearchMappingPath)\n",
    "    for pathID,altChrGenPosMappingPath in altChrGenPosMapping.items():\n",
    "        iset_add(redisConn,f'{redisCaseID}.{pathID}.AltChrGenPos',altChrGenPosMappingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a54742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exportToPantograph(graph=None, inputPath=None, GenomeGraphParams={}, \n",
    "                       outputPath=None, outputName=None, outputSuffix=None, \n",
    "                       isSeq=True,\n",
    "                       nodeLengths=None,\n",
    "                       redisConn=None,\n",
    "                       listOfExports=['schematise', 'genomeToPangenome', 'annotationToGenome'],\n",
    "                       zoomLevels=[1], fillZoomLevels=True, maxLengthComponent=100, maxLengthChunk=20, inversionThreshold=0.5,\n",
    "                       debug=False, returnDebugData=False):\n",
    "    \n",
    "    if graph is None:\n",
    "        if inputPath is not None:\n",
    "            print('Loading Genome')\n",
    "            graph = GenomeGraph(gfaPath=inputPath, isGFASeq=isSeq, **GenomeGraphParams)\n",
    "        else:\n",
    "            raise ValueError(\"Either graph or inputpath to GFA file should be provided\")\n",
    "\n",
    "    if outputPath is None and outputName is None:\n",
    "        if inputPath is not None:\n",
    "            if outputSuffix is not None:\n",
    "                outputPath, outputName = pathConvert(inputPath, suffix = outputSuffix)\n",
    "            else:\n",
    "                outputPath, outputName = pathConvert(inputPath)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"If inputPath is not given, then outputPath and outputName should be provided.\")\n",
    "    else:\n",
    "        if outputSuffix is not None:\n",
    "            outputName = outputName + outputSuffix\n",
    "    print(f'Recording Pantograph data to {outputPath}{os.path.sep}{outputName}')\n",
    "\n",
    "#     numNodes = len(graph.nodes)\n",
    "#     numNodesDigits = np.int(np.ceil(np.log10(numNodes)))\n",
    "#     fromLinks = {}\n",
    "#     toLinks = {}\n",
    "\n",
    "    rootStruct = deepcopy(rootStructTemplate)\n",
    "    rootStruct[\"pathNames\"] = graph.accessions\n",
    "\n",
    "    if returnDebugData:\n",
    "        # temporary structure for testing, in normal mode each zoomlevel \n",
    "        # should be just saved as soon as it is processed and only previous and current zoom level should be preserved.\n",
    "        zoomComponentLengths = {}\n",
    "        zoomNodeToComponent = {}\n",
    "        zoomComponentToNodes = {}\n",
    "        zoomComponents = {}  \n",
    "        zoomCompNucleotides = {}\n",
    "        zoomAccStarts = {}\n",
    "        zoomAccEnds = {}\n",
    "        zoomFromComponentLinks = {}\n",
    "        zoomToComponentLinks = {}\n",
    "        \n",
    "        zoomLinkLengths = {}\n",
    "        zoomPairedLinks = {}\n",
    "        zoomInterconnectedLinks = {}\n",
    "        zoomBlockEdges = {}\n",
    "        \n",
    "        zoomOldToNewRemoval = {}\n",
    "        zoomNewToOldRemoval = {}\n",
    "        zoomLinkLengthsRemoval = {}\n",
    "        zoomPairedLinksRemoval = {}\n",
    "        zoomInterconnectedLinksRemoval = {}\n",
    "        zoomBlockEdgesRemoval = {}\n",
    "        \n",
    "        zoomFromComponentLinksRemoval = {}\n",
    "        zoomToComponentLinksRemoval = {}\n",
    "        \n",
    "        \n",
    "    if nodeLengths is None:\n",
    "        nodeLengths = calcNodeLengths(graph)\n",
    "\n",
    "    pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum = initialPathAnalysis(graph,nodeLengths)\n",
    "    \n",
    "    if zoomLevels[0]>1:\n",
    "        zoomLevels = [1] + zoomLevels\n",
    "    \n",
    "    if len(zoomLevels)>1 or fillZoomLevels:\n",
    "        linkLengths,pairedLinks,interconnectedLinks,blockEdges,pathNodeInversion = \\\n",
    "                    getRemovableStructures(nodeLengths = nodeLengths, pathLengths = pathLengths, \n",
    "                                           pathNodeArray = pathNodeArray, pathDirArray = pathDirArray,forwardLinks = graph.forwardLinks,\n",
    "                                           inversionThreshold = inversionThreshold)\n",
    "    else:\n",
    "        linkLengths = None\n",
    "        pairedLinks = None\n",
    "        interconnectedLinks = None\n",
    "        blockEdges,pathNodeInversion = getBlockEdges(nodeLengths = nodeLengths, pathLengths = pathLengths, \n",
    "                                   pathNodeArray = pathNodeArray, pathDirArray = pathDirArray,forwardLinks = graph.forwardLinks,\n",
    "                                   inversionThreshold = inversionThreshold)\n",
    "    \n",
    "    if returnDebugData:\n",
    "        initialLinkLengths = deepcopy(linkLengths)\n",
    "        initialPairedLinks = deepcopy(pairedLinks)\n",
    "        initialInterconnectedLinks = deepcopy(interconnectedLinks)\n",
    "        initialBlockEdges = deepcopy(blockEdges)\n",
    "    \n",
    "    #Process lowest level zoom to create component structure.\n",
    "    [numNodes, # number of nodes\n",
    "    numNodesDigits, # \n",
    "    nodeToComponent,\n",
    "    componentToNode,\n",
    "    componentLengths,\n",
    "    components,\n",
    "    componentNucleotides,\n",
    "    fromLinks,toLinks,\n",
    "    fromComponentLinks,toComponentLinks,\n",
    "    accStarts,accEnds,\n",
    "    invertedStarts,invertedEnds,\n",
    "    combAnnotation,combGenPos,combAltChrGenPos,combGenPosSearch] = baseLayerZoom(graph,\n",
    "                                      outputPath,outputName,\n",
    "                                      pathNodeArray,pathDirArray,\n",
    "                                      pathLengths,nodeLengths,\n",
    "                                      pathNodeLengthsCum,\n",
    "                                      maxLengthComponent,\n",
    "                                      blockEdges,\n",
    "                                      inversionThreshold=inversionThreshold,\n",
    "                                      isSeq=isSeq)\n",
    "    print()\n",
    "    if returnDebugData:\n",
    "        zoomNodeToComponent,zoomComponentToNodes, zoomComponents = \\\n",
    "        recordZoomLevelForDebug(zoomNodeToComponent,zoomComponentToNodes,zoomComponents,\n",
    "                                nodeToComponent,componentToNode,components,\n",
    "                                1)\n",
    "    \n",
    "    if redisConn is not None:\n",
    "        searchIndicesGeneRecord(redisConn,outputName,combAnnotation,combGenPos,combAltChrGenPos, combGenPosSearch)\n",
    "    \n",
    "    fromComponentLinks,toComponentLinks, \\\n",
    "    linkLengths,pairedLinks,interconnectedLinks,blockEdges = \\\n",
    "    nodeToComponentLinks(components,componentToNode,nodeToComponent,\n",
    "                         fromLinks,toLinks,graph,\n",
    "                         fromComponentLinks,toComponentLinks,\n",
    "                         linkLengths,pairedLinks,interconnectedLinks,blockEdges,debug=debug)\n",
    "    \n",
    "    if returnDebugData:\n",
    "        zoomFromComponentLinks[1] = deepcopy(fromComponentLinks)\n",
    "        zoomToComponentLinks[1] = deepcopy(toComponentLinks)\n",
    "        zoomLinkLengths[1] = deepcopy(linkLengths)\n",
    "        zoomPairedLinks[1] = deepcopy(pairedLinks)\n",
    "        zoomInterconnectedLinks[1] = deepcopy(interconnectedLinks)\n",
    "    \n",
    "    rootStruct = deepcopy(rootStructTemplate)\n",
    "    rootStruct[\"pathNames\"] = graph.accessions\n",
    "    rootStruct[\"pangenome_length\"] = np.sum(componentLengths)\n",
    "\n",
    "    exportLayer(1,components,componentNucleotides,\n",
    "                fromComponentLinks,toComponentLinks,\n",
    "                rootStruct,\n",
    "                outputPath,outputName,\n",
    "                maxLengthComponent,maxLengthChunk,\n",
    "                inversionThreshold=inversionThreshold,\n",
    "                redisConn=redisConn,redisCaseID=outputName)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if len(zoomLevels)>1 or fillZoomLevels:\n",
    "        # Converting link dicts from component first to path/accession first. \n",
    "        # It is needed only for collapsible block identification which happens only once.\n",
    "        # So, they should be removed after collapsible blocks are removed.\n",
    "        # First line also returns dictionary giving direction (inversion) of each component in each accession.\n",
    "        # fromComponentLinksAcc,accCompDir = compLinksToAccCompLinks(fromComponentLinks,doCompDir=True)\n",
    "        # toComponentLinksAcc = compLinksToAccCompLinks(toComponentLinks)\n",
    "\n",
    "        # This identifies collapsible block starts based on links.\n",
    "        # For forward components\n",
    "        # positiveBlockStarts = getBackwardPositiveLinks(toComponentLinks,toComponentLinksAcc,accStarts,accEnds)\n",
    "        # For inversed components\n",
    "        # negativeBlockStarts = getForwardNegativeLinks(toComponentLinks,toComponentLinksAcc,accStarts,accEnds,invertedStarts)\n",
    "\n",
    "        # Identifying all collapsible blocks.\n",
    "        # The return is a list of tuples containg the following elements:\n",
    "        # accession ID, length of block, list of associated links, list of associated components.\n",
    "        # collapsibleBlocks = identifyCollapsibleBlocks(toComponentLinks,fromComponentLinksAcc,components,accStarts,accEnds,accCompDir)\n",
    "        # collapsibleBlocks = identifyCollapsibleBlocks(positiveBlockStarts,negativeBlockStarts,\n",
    "        #                                               accStarts,accEnds,\n",
    "        #                                               fromComponentLinksAcc,toComponentLinksAcc,accCompDir,\n",
    "        #                                               components)\n",
    "\n",
    "        # if returnDebugData:\n",
    "        #     retCollapsibleBlocks = deepcopy(collapsibleBlocks)\n",
    "\n",
    "        # del fromComponentLinksAcc\n",
    "        # del toComponentLinksAcc\n",
    "        # del accCompDir\n",
    "        # del positiveBlockStarts\n",
    "        # del negativeBlockStarts\n",
    "    # elif returnDebugData:\n",
    "    #     retCollapsibleBlocks = []\n",
    "\n",
    "    _zoomLevels = deepcopy(zoomLevels)\n",
    "    \n",
    "    if fillZoomLevels:\n",
    "        if len(linkLengths)>0:\n",
    "            maxLinkLength = max(linkLengths.keys())\n",
    "        else:\n",
    "            maxLinkLength = 0\n",
    "        if len(blockEdges)>0:\n",
    "            maxRearrangementLength = max(blockEdges.values())\n",
    "        else:\n",
    "            maxRearrangementLength = 0\n",
    "            \n",
    "        maxBlock = max(maxLinkLength,maxRearrangementLength)\n",
    "\n",
    "        while _zoomLevels[-1]<=maxBlock:\n",
    "            _zoomLevels.append(_zoomLevels[-1]*2)\n",
    "    \n",
    "    for zoomLevel in _zoomLevels[1:]:\n",
    "        \n",
    "#         print('fromComponentLinks')\n",
    "#         print(fromComponentLinks)\n",
    "        \n",
    "#         print('linkLengths')\n",
    "#         print(linkLengths)\n",
    "        \n",
    "#         print('pairedLinks')\n",
    "#         print(pairedLinks)\n",
    "        try:\n",
    "        \n",
    "            # Collapsing is done through removing some particular links (not satisfying specific conditions)\n",
    "            components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,\\\n",
    "            linkLengths,pairedLinks,interconnectedLinks,blockEdges,\\\n",
    "            oldToNewInd,newToOldInd = \\\n",
    "            clearInvisible(zoomLevel,linkLengths,pairedLinks,interconnectedLinks,blockEdges,\n",
    "                           fromComponentLinks,toComponentLinks,\n",
    "                           accStarts,accEnds,components,componentLengths)\n",
    "\n",
    "            if returnDebugData:\n",
    "                zoomOldToNewRemoval[zoomLevel] = deepcopy(oldToNewInd)\n",
    "                zoomNewToOldRemoval[zoomLevel] = deepcopy(newToOldInd)\n",
    "                zoomLinkLengthsRemoval[zoomLevel] = deepcopy(linkLengths)\n",
    "                zoomPairedLinksRemoval[zoomLevel] = deepcopy(pairedLinks)\n",
    "                zoomInterconnectedLinksRemoval[zoomLevel] = deepcopy(interconnectedLinks)\n",
    "                zoomBlockEdgesRemoval[zoomLevel] = deepcopy(blockEdges)\n",
    "                zoomFromComponentLinksRemoval[zoomLevel] = deepcopy(fromComponentLinks)\n",
    "                zoomToComponentLinksRemoval[zoomLevel] = deepcopy(toComponentLinks)\n",
    "\n",
    "#             if zoomLevel==36:\n",
    "#                 break\n",
    "\n",
    "            # Process next zoom level\n",
    "            components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,\\\n",
    "            linkLengths,pairedLinks,interconnectedLinks,blockEdges,oldToNewInd,newToOldInd= \\\n",
    "            nextLayerZoom(zoomLevel,\n",
    "                          components,componentLengths,#componentNucleotides,\n",
    "                          fromComponentLinks,toComponentLinks,graph,\n",
    "                          accStarts,accEnds,\n",
    "                          maxLengthComponent,linkLengths,pairedLinks,interconnectedLinks,blockEdges,\n",
    "                          inversionThreshold=inversionThreshold)\n",
    "\n",
    "            if returnDebugData:\n",
    "                zoomNodeToComponent, zoomComponentToNodes, zoomComponents = \\\n",
    "                recordZoomLevelForDebug(zoomNodeToComponent,zoomComponentToNodes,zoomComponents,\n",
    "                                        oldToNewInd,newToOldInd,components,\n",
    "                                        zoomLevel)\n",
    "\n",
    "                zoomFromComponentLinks[zoomLevel] = deepcopy(fromComponentLinks)\n",
    "                zoomToComponentLinks[zoomLevel] = deepcopy(toComponentLinks)\n",
    "                zoomLinkLengths[zoomLevel] = deepcopy(linkLengths)\n",
    "                zoomPairedLinks[zoomLevel] = deepcopy(pairedLinks)\n",
    "                zoomInterconnectedLinks[zoomLevel] = deepcopy(interconnectedLinks)\n",
    "\n",
    "\n",
    "            # Zoom level should be split into chunks and recorded.\n",
    "            exportLayer(zoomLevel,components,[],#componentNucleotides,\n",
    "                    fromComponentLinks,toComponentLinks,\n",
    "                    rootStruct,\n",
    "                    outputPath,outputName,\n",
    "                    maxLengthComponent,maxLengthChunk,\n",
    "                    inversionThreshold=inversionThreshold,\n",
    "                    redisConn=redisConn,redisCaseID=outputName)\n",
    "        except RuntimeError as error:\n",
    "            print(error)\n",
    "            print(traceback.format_exc())\n",
    "            break\n",
    "    \n",
    "    with open(f'{outputPath}{os.path.sep}{outputName}{os.path.sep}bin2file.json','w') as f:\n",
    "        json.dump(rootStruct,f,cls=NpEncoder)\n",
    "    \n",
    "    if returnDebugData:\n",
    "        return initialLinkLengths, initialPairedLinks, initialInterconnectedLinks, initialBlockEdges, \\\n",
    "                zoomNodeToComponent,zoomComponentToNodes,zoomComponents,\\\n",
    "                zoomFromComponentLinks, zoomToComponentLinks, zoomLinkLengths, zoomPairedLinks, zoomInterconnectedLinks, \\\n",
    "                zoomOldToNewRemoval, zoomNewToOldRemoval, \\\n",
    "                zoomLinkLengthsRemoval, zoomPairedLinksRemoval, zoomInterconnectedLinksRemoval, zoomBlockEdgesRemoval, \\\n",
    "                zoomFromComponentLinksRemoval, zoomToComponentLinksRemoval, \\\n",
    "                graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01064a",
   "metadata": {},
   "source": [
    "intial -> zoom[1] -> zoom_removal[zl_1] -> zoom[zl_1] -> zoom_removal[zl_2] -> zoom[zl_2] -> ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

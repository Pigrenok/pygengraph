{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-lecture",
   "metadata": {},
   "source": [
    "# Export module\n",
    "\n",
    "> Provides functionality to export graph to Pantograph data storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_init.ipynb.\n",
      "Converted 01_graph.ipynb.\n",
      "Converted 02_tree.ipynb.\n",
      "Converted 03_synteny.ipynb.\n",
      "Converted 04_utils.ipynb.\n",
      "Converted 05_export.ipynb.\n",
      "Converted deBruijnGraphProcessing.ipynb.\n",
      "Converted graphTesting.ipynb.\n",
      "Converted index (2).ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import pdb\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sortedcontainers import SortedSet\n",
    "from multiprocessing import Process, Manager, cpu_count\n",
    "\n",
    "from redis import ResponseError\n",
    "\n",
    "from pangraph_constructor.utils import pathConvert,NpEncoder,adjustZoomLevels\n",
    "from pangraph_constructor.utils import iset_add,getDBID,resetDB\n",
    "from pangraph_constructor.graph import GenomeGraph,initialPathAnalysis,calcNodeLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "componentTemplate = {\n",
    "    \"first_bin\": 1,\n",
    "    \"last_bin\": 1,\n",
    "    \"firstCol\": 1,\n",
    "    \"lastCol\": 1,\n",
    "    \"occupants\": [],\n",
    "    \"matrix\": [],\n",
    "    \"larrivals\": [],\n",
    "    \"rarrivals\": [],\n",
    "    \"ldepartures\": [],\n",
    "    \"rdepartures\": [],\n",
    "    \"x\": 0\n",
    "}\n",
    "\n",
    "chunkTemplate = {\n",
    "    \"json_version\":19,\n",
    "    \"first_bin\": 1,\n",
    "    \"first_col\": 1,\n",
    "    \"last_bin\": 1,\n",
    "    \"last_col\": 1,\n",
    "    \"includes_connectors\": True,\n",
    "    \"components\": []\n",
    "}\n",
    "\n",
    "rootStructTemplate = {\n",
    "    \"json_version\": 19,\n",
    "    \"pangenome_length\": 0,#pangenomeLength, #total number of bp in pangenome\n",
    "    \"includes_connectors\": True,\n",
    "    \"zoom_levels\": {}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-oxide",
   "metadata": {},
   "source": [
    "## New version of exporting to Pantograph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-opinion",
   "metadata": {},
   "source": [
    "**Notation and terminology**\n",
    "\n",
    "In documentation, we refer to graph nucleotides, columns and components. Components contain columns and columns contain nucleotides.\n",
    "\n",
    "In the code variable names and comments use slightly different notation. Columns in documentation are bins in code and comments, whereas graph nucleotides in documentation are called columns in the code and comments. This happened for the legacy reasons, i.e. originally there was no nucleotide numbers (columns) in the visualised graph structure and components were split into bins (literally, equal sized bins). It is not true anymore, but old terminology left here.\n",
    "\n",
    "Ideally all variable names and comments should be changes in line with documentation notation, but I have no idea when this can happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def outLeftRight(nodeInversionInPath,leftFarLink,rightFarLink,reason,debug=False,inversionThreshold=0.5):\n",
    "    \n",
    "    if (nodeInversionInPath<=inversionThreshold):\n",
    "#         if debug:\n",
    "#             print(f'Node {nodeIdx}: Component will be broken after node {nodeIdx} due to {reason} to node {nextNode}.')\n",
    "        rightFarLink = True\n",
    "    else:\n",
    "#         if debug:\n",
    "#             print(f'Node {nodeIdx}: Component will be broken before node {nodeIdx} due to {reason} to node {nextNode}.')\n",
    "        leftFarLink = True\n",
    "        \n",
    "    return leftFarLink,rightFarLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def recordLinks(nodeIdx,nextNode,pathID,step,nodeInversionInPath,nonLinearCond,pathNodeArray,fromLinks,toLinks,debug=False,inversionThreshold=0.5):\n",
    "    leftFarLink = False\n",
    "    rightFarLink = False\n",
    "    if nonLinearCond:\n",
    "        if debug:\n",
    "            print(f'Non-linear link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "        fromLinks.setdefault(nodeIdx,{}).setdefault(nextNode,[]).append(pathID)\n",
    "        toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "        leftFarLink,rightFarLink = outLeftRight(nodeInversionInPath,leftFarLink,rightFarLink,'backward link',debug=debug,inversionThreshold=0.5)\n",
    "            \n",
    "    else:\n",
    "        if np.any([node in pathNodeArray[pathID,:] for node in range(nodeIdx+1*step,nextNode,step)]):\n",
    "            if debug:\n",
    "                print(f'Jump link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "            fromLinks.setdefault(nodeIdx,{}).setdefault(nextNode,[]).append(pathID)\n",
    "            toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "            \n",
    "            leftFarLink,rightFarLink = outLeftRight(nodeInversionInPath,leftFarLink,rightFarLink,'forward jumping link',debug=debug,inversionThreshold=0.5)\n",
    "        else:\n",
    "            startNode = None\n",
    "            endNode = None\n",
    "\n",
    "            if step==-1:\n",
    "                startNode = nodeIdx\n",
    "                endNode = nextNode\n",
    "                if debug:\n",
    "                    print(f'Intermediate nodes for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "            elif step==1:\n",
    "                startNode = nodeIdx\n",
    "                endNode = nextNode\n",
    "                if debug:\n",
    "                    print(f'Intermediate nodes for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f'Jump link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "                fromLinks.setdefault(nodeIdx,{}).setdefault(nextNode,[]).append(pathID)\n",
    "                toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "                leftFarLink,rightFarLink = outLeftRight(nodeInversionInPath,leftFarLink,rightFarLink,'forward jumping link',debug=debug,inversionThreshold=0.5)\n",
    "\n",
    "            if startNode is not None and endNode is not None and step is not None:\n",
    "                for intermediateNodeIdx in range(startNode,endNode,step):\n",
    "                    if debug:\n",
    "                        print(f'Adding link from node {intermediateNodeIdx} to node {intermediateNodeIdx+1*step} for path {pathID}')\n",
    "                    fromLinks.setdefault(intermediateNodeIdx,{}).setdefault(intermediateNodeIdx+1*step,[]).append(pathID)\n",
    "                    toLinks.setdefault(intermediateNodeIdx+1*step,{}).setdefault(intermediateNodeIdx,[]).append(pathID)\n",
    "    return leftFarLink,rightFarLink,fromLinks,toLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def checkForBreak(nodeIdx,nodeLen,\n",
    "                  nodePathsIdx,nodeSeqInPath,\n",
    "                  uniqueNodePathsIDs,pathNodeCount,\n",
    "                  pathLengths,\n",
    "                  pathNodeArray,pathDirArray,\n",
    "                  occupancy,inversion,\n",
    "                  fromLinks,toLinks,\n",
    "                  nBins,maxLengthComponent,\n",
    "                  inversionThreshold=0.5,\n",
    "                  debug=False):\n",
    "    '''\n",
    "    Function to check whether the component should be broken before (left) and/or after (right) it.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    `nodeIdx`: int. Numerical (1 based) node ID within the graph (consecutive number of the node)\n",
    "               in the graph order.\n",
    "    \n",
    "    #######\n",
    "    The following 5 parameters are calculated in `nodeStat` function externally and passed here:\n",
    "    `nodeLen`: int. Length of the node in nucleotides\n",
    "    `nodePathsIdx`: numpy.array. A 1D numpy.array which contain ids of the paths \n",
    "                    for each appearance of the node ID in each path.\n",
    "    `nodeSeqInPath`: numpy.array. A 1D numpy.array with positions of given node in every path. \n",
    "                     The path to which this position is related to can be found from `nodePathsIdx`, \n",
    "                     e.g. if `nodeSeqInPath[i]` is `k`, then node with node ID `nodeIdx`\n",
    "                     appear in path `nodePathsIdx[i]` at position `k`.\n",
    "    `uniqueNodePathsIDs`: Iterable[int]. Usually a list or 1D numpy.array holding unique IDs of paths \n",
    "                          which pass this node at least once.\n",
    "    `pathNodeCount`: numpy.array.: A 1D array (the same length as `uniqueNodePathsIDs`) which \n",
    "                     contains number of times the node appear in each path from `uniqueNodePathsIDs`,\n",
    "                     e.g. if `pathNodeCount[i]` is `k` then node with ID nodeIdx appears in path\n",
    "                     `uniqueNodePathsIds[i]` `k` times.\n",
    "    #######\n",
    "    \n",
    "    `occupancy`: dict. A dictionary containing occupancy (number of times given path passed the given \n",
    "                 node) of the previous node (in terms of graph order) for each path than passed \n",
    "                 through previous node. The dictionary has path IDs as keys.\n",
    "    `inversion`: dict. A dictionary containing inversion (fraction of copies of the node in the path \n",
    "                 that are inverted) of the previous node (in terms of graph order) for each path than \n",
    "                 passed through previous node. The dictionary has path IDs as keys.\n",
    "    `fromLinks`: dict[dict[list]]. Dictionary which holds links from each processed node.\n",
    "    `toLinks`: dict[dict[list]]. Dictionary which holds links to each processed node.\n",
    "    `nBins`: int. Number of bins recorded in the current component.\n",
    "    `maxLengthComponent`: int. Maximum number of bins allowed in a component. Used to break too \n",
    "                          long components into smaller more manageable blocks.\n",
    "    `pathDirArray`: 2D numpy.array. Each row (corresponding to specific path in graph) contains directionality\n",
    "                    of each node in the path. See `initialPathAnalysis` for details.\n",
    "    `inversionThreshold`: float (default: 0.5). A threshold after which the node is considered inverted.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    `leftFarLink`: bool. Shows whether there is a far link on the left that will require component break.\n",
    "    `rightFarLink`: bool. Shows whether there is a far link on the right that will require component break.\n",
    "    `leftPathStartEnd`: bool. Shows whether there is a start or end of the path on the left of the node.\n",
    "    `rightPathStartEnd`: bool. Shows whether there is a start or end of the path on the right of the node.\n",
    "    `isChangedOccupancy`: bool. Shows whether the occupancy of at least one path significantly changed \n",
    "                          from previous node. If previous node was missing, and current node has any \n",
    "                          occupancy, it will be False as it does not constitute a component break.\n",
    "    `isChangeInversion`: bool. Shows whether the inversion of at least one path significantly changed \n",
    "                          from previous node.\n",
    "    `isNotFitIntoComponent`: bool. Shows whether this node won't fit into the currently forming component\n",
    "                             and it should be broken before the current node.\n",
    "    `pathStarts`: list. Contains list of path IDs which start from this node.\n",
    "    `pathEnds`: list. Contains list of path IDs which end on this node.\n",
    "    `fromLinks`: dict[dict[list]]\n",
    "    `toLinks`: \n",
    "    `occupancy`: dict. A dictionary containing occupancy (number of times given path passed the given \n",
    "                 node) of the current node (in terms of graph order) for each path than passed \n",
    "                 through previous node. The dictionary has path IDs as keys.\n",
    "    `inversion`: dict. A dictionary containing inversion (fraction of copies of the node in the path \n",
    "                 that are inverted) of the current node (in terms of graph order) for each path than \n",
    "                 passed through previous node. The dictionary has path IDs as keys.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Boolean indicator of far incoming link on the left and right\n",
    "    leftFarLink = False\n",
    "    rightFarLink = False\n",
    "\n",
    "    # Boolean if at least one path starts from this node and start is on the left or right\n",
    "    leftPathStart = False\n",
    "    rightPathStart = False\n",
    "    # Boolean if at least one path ends on this node and end is on the left or right\n",
    "    leftPathEnd = False\n",
    "    rightPathEnd = False\n",
    "\n",
    "    # Indicator whether occupancy changed from one node to the next\n",
    "    isChangedOccupancy = False\n",
    "    \n",
    "    # Indicator whether inversion is changed from one side of\n",
    "    # `inversionThreshold` to the other.\n",
    "    isChangeInversion = False\n",
    "    \n",
    "    # Indicator whether this node does not fit into current component.\n",
    "    isNotFitIntoComponent = False\n",
    "\n",
    "    pathEnds = np.sort(np.unique([pathIdx for pathIdx,nodeInSeq in zip(nodePathsIdx,nodeSeqInPath) if nodeInSeq==pathLengths[pathIdx]-1]))\n",
    "    pathStarts = np.sort(np.unique([pathIdx for pathIdx,nodeInSeq in zip(nodePathsIdx,nodeSeqInPath) if nodeInSeq==0]))\n",
    "    \n",
    "    invertedEnds = set()\n",
    "    invertedStarts = set()\n",
    "    \n",
    "    # Check whether adding this node to the current component will violate the limitation\n",
    "    # for maximum component length. Is it still needed with proper treatment of partially\n",
    "    # visible components in the front-end???\n",
    "    if nBins+nodeLen>maxLengthComponent:\n",
    "        isNotFitIntoComponent = True\n",
    "    \n",
    "    # Check whether component should be broken before current node.\n",
    "    for j, pathID in enumerate(uniqueNodePathsIDs):\n",
    "        \n",
    "        # Check whether occupancy changed from previous node.\n",
    "        # That will require breaking component before current node.\n",
    "        if nodeIdx>1:\n",
    "            if np.abs(pathNodeCount[j]-occupancy.get(pathID,0))>0 and occupancy.get(pathID,0)>0:\n",
    "                isChangedOccupancy = True\n",
    "        \n",
    "        # Calculate occupancy of current node for path\n",
    "        # It is simply how many times this node is passed by current path.\n",
    "        occupancy[pathID] = pathNodeCount[j]\n",
    "        \n",
    "        # Calculate inversion rate of current node for path\n",
    "        # It is ratio of how many times the node is passed in reversed direction\n",
    "        # by the path to overall occupancy of the node by the path.\n",
    "        nodePositions = np.where(nodePathsIdx==pathID)[0]\n",
    "        \n",
    "        nodeInversionInPath = np.sum([int(pathDirArray[pathID,nodeNumInPath]) \\\n",
    "                          for nodeNumInPath in nodeSeqInPath[nodePositions]])\\\n",
    "                          /occupancy[pathID]\n",
    "        \n",
    "        # Check whether inversion is switched from one side of `inversionThreshold` to the other side.\n",
    "        if nodeIdx>1 and (nodeInversionInPath-inversionThreshold)*(inversion.get(pathID, nodeInversionInPath)-inversionThreshold)<0:\n",
    "            isChangeInversion = True\n",
    "        # Record current inversion for current pathID for bins generation.\n",
    "        inversion[pathID] = nodeInversionInPath\n",
    "\n",
    "        # Get indexes of positions of the node in the path\n",
    "        \n",
    "        \n",
    "        # Check whether the node \n",
    "        if nodeInversionInPath<=inversionThreshold:\n",
    "            # not inverted node\n",
    "            leftPathStart = leftPathStart or (pathID in pathStarts)\n",
    "            rightPathEnd = rightPathEnd or (pathID in pathEnds)\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f'Node {nodeIdx}, accession {graph.accessions[pathID]}, inversion {nodeInversionInPath}')\n",
    "            # inverted node\n",
    "            rightPathStart = rightPathStart or (pathID in pathStarts)\n",
    "            \n",
    "            if pathID in pathStarts:\n",
    "                invertedStarts.add(pathID)\n",
    "            \n",
    "            leftPathEnd = leftPathEnd or (pathID in pathEnds)\n",
    "            \n",
    "            if pathID in pathEnds:\n",
    "                invertedEnds.add(pathID)\n",
    "        \n",
    "        for nodePos in nodePositions:\n",
    "            # Boolean flags to whether check and record incoming and outgoing links\n",
    "            checkIn = False\n",
    "            checkOut = False\n",
    "            # Get the sequencial number of node in the path (for current passing), can be several for duplicated nodes\n",
    "            nodePositionInPath = nodeSeqInPath[nodePos]\n",
    "            \n",
    "            if nodePositionInPath<(pathLengths[pathID]-1):\n",
    "                # if not last node in the path\n",
    "                checkOut = True\n",
    "                nextNode = pathNodeArray[pathID,nodePositionInPath+1]\n",
    "                nextNodePositions = np.where(pathNodeArray[pathID,:]==nextNode)[0]\n",
    "                nextNodeInversionInPath = np.sum([int(pathDirArray[pathID,nodeInPathPos]) for nodeInPathPos in nextNodePositions])/len(nextNodePositions)\n",
    "                if debug:\n",
    "                    print(f'Node {nodeIdx}, next node {nextNode}, path {pathID}, number in path {nodePositionInPath}, length of path {pathLengths[pathID]}')\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(\"Last node in path\")\n",
    "            \n",
    "            if nodePositionInPath>0:\n",
    "                checkIn = True\n",
    "                prevNode = pathNodeArray[pathID,nodePositionInPath-1]\n",
    "                prevNodePositions = np.where(pathNodeArray[pathID,:]==prevNode)[0]\n",
    "                prevNodeInversionInPath = np.sum([int(pathDirArray[pathID,nodeInPathPos]) for nodeInPathPos in prevNodePositions])/len(prevNodePositions)\n",
    "                if debug:\n",
    "                    print(f'Node {nodeIdx}, previous node {nextNode}, path {pathID}, number in path {nodePositionInPath}, length of path {pathLengths[pathID]}')\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(\"First node in path\")\n",
    "            \n",
    "            \n",
    "            if nodeInversionInPath<=inversionThreshold:\n",
    "            # Not inverted node\n",
    "            # For the node find the links going to the left of the node\n",
    "                if checkIn:\n",
    "                    # node is not the first\n",
    "                    if debug:\n",
    "                        print(f\"IncomingLinks: {prevNode} -> {nodeIdx}\")\n",
    "                        print(f'Existing known links: {fromLinks.get(prevNode,{})}')\n",
    "\n",
    "                    if prevNode+1!=nodeIdx:\n",
    "                        # Link in the path does not go between consecutive nodes (from previous to current)\n",
    "                        # This means that there is a links coming to the left of the node\n",
    "                        if (prevNode<nodeIdx and nodeIdx in fromLinks.get(prevNode,{})) or (prevNode>=nodeIdx):\n",
    "                            # If we are not picking up passing through empty blocks as far link\n",
    "                            # Tandem duplicates are included as they cause an arrow to the left of the node.\n",
    "                            leftFarLink = True\n",
    "                if checkOut:\n",
    "                    # node is not the last\n",
    "                    \n",
    "                    # Find out whether it is a non-linear (e.g. reversed link or link from inversed to non-inversed node).\n",
    "                    if nextNodeInversionInPath<=inversionThreshold:\n",
    "                        # The inversion is the same for two consecutive (in path) nodes\n",
    "                        # Link will be non-linear if previous node is staying further in linearised graph\n",
    "                        nonLinearCond = (nodeIdx>=nextNode)\n",
    "                        # Step for checking for jumping over link\n",
    "                        step = 1\n",
    "                    else:\n",
    "                        # The inversion is not the same for two consecutive nodes.\n",
    "                        nonLinearCond = True\n",
    "                        # Step is not used and assigned for consistency\n",
    "                        step =0\n",
    "                        \n",
    "                    # Process links from (!) this node.\n",
    "                    _leftFarLink,_rightFarLink,fromLinks,toLinks = \\\n",
    "                    recordLinks(nodeIdx,nextNode,pathID,\n",
    "                                step,nodeInversionInPath,\n",
    "                                nonLinearCond,\n",
    "                                pathNodeArray,\n",
    "                                fromLinks,toLinks,\n",
    "                                debug=debug,\n",
    "                                inversionThreshold=inversionThreshold)\n",
    "                    \n",
    "                    leftFarLink = leftFarLink or _leftFarLink\n",
    "                    rightFarLink = rightFarLink or _rightFarLink\n",
    "                            \n",
    "            else:\n",
    "                #Inverted node\n",
    "                # For the node find the links goint from the left of the node\n",
    "                if checkOut:\n",
    "                    # node is not the last\n",
    "                    # Find out whether it is a non-linear (e.g. reversed link or link from inversed to non-inversed node).\n",
    "                    if nextNodeInversionInPath>inversionThreshold:\n",
    "                        # The inversion is the same for two consecutive (in path) nodes\n",
    "\n",
    "                        # Link will be non-linear if previous node is staying further in linearised graph\n",
    "                        nonLinearCond  = (nodeIdx<=nextNode)\n",
    "                        # Step for checking for jumping over link\n",
    "                        step = -1\n",
    "                    else:\n",
    "                        # The inversion is not the same for two consecutive nodes.\n",
    "                        nonLinearCond = True\n",
    "                        # Step is not used and assigned for consistency\n",
    "                        step = 0\n",
    "                        \n",
    "                    _leftFarLink,_rightFarLink,fromLinks,toLinks = \\\n",
    "                    recordLinks(nodeIdx,nextNode,pathID,\n",
    "                                step,nodeInversionInPath,\n",
    "                                nonLinearCond,\n",
    "                                pathNodeArray,\n",
    "                                fromLinks,toLinks,\n",
    "                                debug=debug,\n",
    "                                inversionThreshold=inversionThreshold)\n",
    "                    \n",
    "                    leftFarLink = leftFarLink or _leftFarLink\n",
    "                    rightFarLink = rightFarLink or _rightFarLink\n",
    "                \n",
    "                if checkIn:\n",
    "                    # The node is not the first\n",
    "                    if debug:\n",
    "                        print(f\"IncomingLinks: {nodeIdx} -> {nextNode}\")\n",
    "                        print(f'Existing known links: {toLinks.get(nextNode,{})}')\n",
    "\n",
    "                    if nodeIdx-1!=nextNode:\n",
    "                        # Link does not go between consecutive blocks (from this to previous one)\n",
    "                        if (nodeIdx>nextNode and nodeIdx in toLinks.get(nextNode,{})) or (nodeIdx<=nextNode):\n",
    "                            # If we are not picking up passing through empty blocks as far link\n",
    "                            # Tandems duplicates are included as they also cause an arrow from the left of the node.\n",
    "                            rightFarLink = True\n",
    "        \n",
    "    return (leftFarLink,rightFarLink,\n",
    "            leftPathStart or leftPathEnd,\n",
    "            rightPathStart or rightPathEnd,\n",
    "            isChangedOccupancy,isChangeInversion,\n",
    "            isNotFitIntoComponent,\n",
    "            pathStarts,pathEnds,\n",
    "            fromLinks,toLinks,\n",
    "            occupancy,inversion,\n",
    "            invertedStarts,invertedEnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def createZoomLevelDir(outputPath,outputName,zoomLevel):\n",
    "    '''\n",
    "    Creates a directory for zoom level chunks. The function will take care of correct directory level separator.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    `outputPath`: str. Absolute path to location where the visualisation data should be created\n",
    "    `outputName`: str. The name of the visualisation case, will be a directory at the path given by `outputPath`\n",
    "    `zoomLevel`: int or str. zoom level (maximum number of nucleotides in a single column/bin).\n",
    "                 A directory will be ceated\n",
    "                 \n",
    "    Return\n",
    "    ======\n",
    "    The function does not return anything, but creates a directory tree `outputPath`, \n",
    "    within it creates a directory `outputName` and inside it creates a directory `zoomLevel`\n",
    "    '''\n",
    "    \n",
    "    os.makedirs(f'{outputPath}{os.path.sep}{outputName}{os.path.sep}{zoomLevel}',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def recordZoomLevelForDebug(zoomNodeToComponent,\n",
    "                            zoomComponentToNodes,\n",
    "                            zoomComponentLengths,\n",
    "                            zoomComponents,\n",
    "                            zoomCompNucleotides,\n",
    "                            zoomAccStarts,\n",
    "                            zoomAccEnds,\n",
    "                            nodeToComponent,\n",
    "                            componentToNodes,\n",
    "                            componentLengths,\n",
    "                            components,\n",
    "                            componentNucleotides,\n",
    "                            accStarts,\n",
    "                            accEnds,\n",
    "                            zoomLevel):\n",
    "    '''\n",
    "    A function which records result of segmentation to dictionaries, \n",
    "    which holds results for all zoom levels.\n",
    "    It is currently used only for debugging purposes and in normal operation \n",
    "    all zoom level dictionaries are not created and used.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    Parameters are self-explanatory. Those starting from `zoom` are dictionary\n",
    "    holding all zoom levels, whereas the same parameter names without `zoom`\n",
    "    in the beginning are data for zoom level given in `zoomLevel` parameter.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    Returns modified dictionaries with `zoom` in the beginning of the names. Theoretically,\n",
    "    it should work without return at all (through pointers passed to the function), but it\n",
    "    did not work before and to be on the safe side, this is done through return.\n",
    "    \n",
    "    '''\n",
    "    zoomNodeToComponent[zoomLevel] = nodeToComponent\n",
    "    zoomComponentToNodes[zoomLevel] = componentToNodes\n",
    "    zoomComponentLengths[zoomLevel] = componentLengths\n",
    "    zoomComponents[zoomLevel] = components\n",
    "    zoomCompNucleotides[zoomLevel] = componentNucleotides\n",
    "    zoomAccStarts[zoomLevel] = accStarts\n",
    "    zoomAccEnds[zoomLevel] = accEnds\n",
    "    \n",
    "    return  zoomNodeToComponent, \\\n",
    "            zoomComponentToNodes, \\\n",
    "            zoomComponentLengths, \\\n",
    "            zoomComponents, \\\n",
    "            zoomCompNucleotides, \\\n",
    "            zoomAccStarts, \\\n",
    "            zoomAccEnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nodeStat(nodeIdx,pathNodeArray,nodeLengths):\n",
    "    '''\n",
    "    Function calculate information about node as part of the overall graph.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    `nodeIdx`: int. Number of the node in the graph (1 based).\n",
    "    `pathNodeArray`: numpy.array. A 2D array (<number of paths> x <max lengths of path>), \n",
    "                     where each line present sequence of node IDs in a particular path.\n",
    "                     Path ordered as they are present in the graph.\n",
    "    `nodeLengths`: list or numpy.array. An 1D subscribable structure \n",
    "                   (normally, list or 1D numpy.array is expected) where each element i\n",
    "                   is the length of the node ID (1 based) i+1.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    `nodePathsIdx`: numpy.array. A 1D numpy.array which contain ids of the paths \n",
    "                    for each appearance of the node ID in each path.\n",
    "    `nodeSeqInPath`: numpy.array. A 1D numpy.array with positions of given node in every path. \n",
    "                     The path to which this position is related to can be found from `nodePathsIdx`, \n",
    "                     e.g. if `nodeSeqInPath[i]` is `k`, then node with node ID `nodeIdx`\n",
    "                     appear in path `nodePathsIdx[i]` at position `k`.\n",
    "    `nodeLen`: int. Length of the node (in terms of nucleotides, real or simulated).\n",
    "    `uniqueNodePathsIDs`: numpy.array. A 1D array containing all path IDs (0 based, non-repeated) \n",
    "                          that contains the node.\n",
    "    `pathNodeCount`: numpy.array.: A 1D array (the same length as `uniqueNodePathsIDs`) which \n",
    "                     contains number of times the node appear in each path from `uniqueNodePathsIDs`,\n",
    "                     e.g. if `pathNodeCount[i]` is `k` then node with ID nodeIdx appears in path\n",
    "                     `uniqueNodePathsIds[i]` `k` times.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Find positions of the node in each path\n",
    "    nodePathsIdx, nodeSeqInPath = np.where(pathNodeArray == nodeIdx)\n",
    "    # Find node length\n",
    "    nodeLen = nodeLengths[nodeIdx-1]\n",
    "\n",
    "    # Find unique path IDs (numerical) and cound of given node in each path.\n",
    "    uniqueNodePathsIDs,pathNodeCount = np.unique(nodePathsIdx,return_counts=True)\n",
    "    \n",
    "    return nodePathsIdx,nodeSeqInPath,nodeLen,uniqueNodePathsIDs,pathNodeCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def finaliseComponentBase(component,\n",
    "                      components,componentNucleotides,\n",
    "                      matrix,occupants,nBins,componentLengths,nucleotides,zoomLevel,accessions,inversionThreshold=0.5):\n",
    "    componentLengths.append(nBins)\n",
    "    component[\"matrix\"].extend([[pathID,\n",
    "                                 int(matrixPathArray[1][0][1]>inversionThreshold),\n",
    "                                 matrixPathArray] \\\n",
    "                                for pathID,matrixPathArray in matrix.items()])\n",
    "    component['binsToCols'] = [1]*nBins\n",
    "    \n",
    "    component[\"occupants\"] = sorted(list(occupants))\n",
    "    component['last_bin'] = component['first_bin'] + nBins - 1\n",
    "    component['lastCol'] = component['firstCol'] + nBins - 1\n",
    "    component['binColStarts'] = list(range(component['firstCol'],component['lastCol']+1))\n",
    "    component['binColEnds'] = list(range(component['firstCol'],component['lastCol']+1))\n",
    "    componentNucleotides.append(nucleotides)\n",
    "    \n",
    "    firstBin = component['last_bin'] + 1\n",
    "    firstCol = component['lastCol'] + 1\n",
    "    components.append(component)\n",
    "    component = deepcopy(componentTemplate)\n",
    "    component['first_bin'] = firstBin\n",
    "    component['firstCol'] = firstCol\n",
    "    return component,components,componentNucleotides,{},set(),0,''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def processAnnotationInterval(posStart,posEnd,annotation,res):\n",
    "    for pos in range(posStart,posEnd):\n",
    "        r = []\n",
    "        for name,intervals in annotation.items():\n",
    "            for interval in intervals:\n",
    "                if pos<=interval[1] and pos>=interval[0]:\n",
    "                    r.append(name)\n",
    "        res[pos] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def updateEdges(accEdge,edgeAccessions,compNum):\n",
    "    '''\n",
    "    Function fills up either accStarts or accEnds (on which component each accession starts and \n",
    "    on which ends). `compNum` is assumed to be 1-based.\n",
    "    '''\n",
    "    \n",
    "    for accID in edgeAccessions:\n",
    "        accEdge[accID] = compNum\n",
    "        \n",
    "    return accEdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def baseLayerZoom(graph,\n",
    "                  outputPath,outputName,\n",
    "                  pathNodeArray,pathDirArray,\n",
    "                  pathLengths,nodeLengths,\n",
    "                  pathNodeLengthsCum,\n",
    "                  maxLengthComponent,\n",
    "                  CPUS = cpu_count(),\n",
    "                  inversionThreshold=0.5,\n",
    "                  isSeq=True,\n",
    "                  debug=False,\n",
    "                  debugTime=False):\n",
    "\n",
    "    zoomLevel = 1\n",
    "    \n",
    "    #Create the directory to hold zoomLevel chunks and fasta files (if available)\n",
    "#     createZoomLevelDir(outputPath,outputName,zoomLevel)\n",
    "    \n",
    "\n",
    "    print('\\n===========================')\n",
    "    print(f'Zoom level {zoomLevel}')\n",
    "    print('===========================')\n",
    "    zoom_level_struct = {}\n",
    "    zoom_level_struct[\"files\"] = []\n",
    "    \n",
    "    accStarts = {}\n",
    "    accEnds = {}\n",
    "    \n",
    "    invertedStarts = set()\n",
    "    invertedEnds = set()\n",
    "    \n",
    "    nodeToComponent = []\n",
    "    componentToNode = []\n",
    "    componentLengths = []\n",
    "    components = []\n",
    "    componentNucleotides = []\n",
    "\n",
    "    component = deepcopy(componentTemplate)\n",
    "    \n",
    "    numNodes = len(graph.nodes)\n",
    "    numNodesDigits = np.int(np.ceil(np.log10(numNodes)))\n",
    "    \n",
    "    fromLinks = {}\n",
    "    toLinks = {}\n",
    "    \n",
    "    fromComponentLinks = {}\n",
    "    toComponentLinks = {}\n",
    "    \n",
    "    occupants = set()\n",
    "    nucleotides = ''\n",
    "    matrix = {}\n",
    "\n",
    "    nodeLinks = []\n",
    "\n",
    "    nBins = 0\n",
    "#     previousInv = {}\n",
    "    binLength = 0\n",
    "    occupancy = {}\n",
    "    inversion = {}\n",
    "    pos = {} #???\n",
    "    nodesInComp = set()\n",
    "    annotationNames = {}\n",
    "#     breakComponentWhenBinEnds = False\n",
    "#         breakCompBeforeBin = False\n",
    "#     binOpen = False\n",
    "#     breakComponent = False\n",
    "#     forceBreak = False\n",
    "    \n",
    "    for nodeIdx in range(1,numNodes+1):\n",
    "        if debug or debugTime:\n",
    "            print(f'Processing node {nodeIdx:0{numNodesDigits}}/{numNodes:0{numNodesDigits}}')\n",
    "        else:\n",
    "            print(f'\\nProcessing node {nodeIdx:0{numNodesDigits}}/{numNodes:0{numNodesDigits}}',end='')\n",
    "        \n",
    "        if debugTime:\n",
    "            startNodeTime = time.time()\n",
    "        ######################\n",
    "        # Node preprocessing #\n",
    "        ######################\n",
    "        \n",
    "        # Get some onfo about the node\n",
    "        nodePathsIdx,nodeSeqInPath,nodeLen,uniqueNodePathsIDs,pathNodeCount = \\\n",
    "        nodeStat(nodeIdx,pathNodeArray,nodeLengths)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Check whether the component should be broken before and/or after current node\n",
    "        (leftFarLink,rightFarLink,\n",
    "        leftPathStartEnd,\n",
    "        rightPathStartEnd,\n",
    "        isChangeOccupancy,isChangeInversion,\n",
    "        isNotFitIntoComponent,\n",
    "        pathStarts,pathEnds,\n",
    "        fromLinks,toLinks,\n",
    "        occupancy,inversion,\n",
    "        invertedCompStarts,invertedCompEnds) = checkForBreak(nodeIdx,nodeLen,\n",
    "                                             nodePathsIdx,nodeSeqInPath,\n",
    "                                             uniqueNodePathsIDs,pathNodeCount,\n",
    "                                             pathLengths,\n",
    "                                             pathNodeArray,pathDirArray,\n",
    "                                             occupancy,inversion,\n",
    "                                             fromLinks,toLinks,\n",
    "                                             nBins,maxLengthComponent,\n",
    "                                             inversionThreshold=inversionThreshold,\n",
    "                                             debug=debug)\n",
    "        \n",
    "        invertedStarts.update(invertedCompStarts)\n",
    "        invertedEnds.update(invertedCompEnds)\n",
    "        \n",
    "        if debugTime:\n",
    "            print(f'Checking for breaks node {nodeIdx}. Took {time.time() - startNodeTime}')\n",
    "        ###################################\n",
    "        # Breaking component before node. #\n",
    "        ###################################\n",
    "        ## Here component should be broken before node (if determined necessary)\n",
    "        if nodeIdx>1 and \\\n",
    "           (leftPathStartEnd or leftFarLink or isChangeInversion or isChangeOccupancy or isNotFitIntoComponent) and \\\n",
    "           nBins>0:\n",
    "            # It is not the first component, and there is at least one flag to break before node and \n",
    "            # there is something to break (the component was not broken after previous node)\n",
    "            if debug:\n",
    "                if leftFarLink:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to left far link.')\n",
    "                elif isChangeOccupancy or isChangeInversion:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to change in inversion or occupancy in a path.')\n",
    "                elif isNotFitIntoComponent:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} because it does not fit into current component.')\n",
    "                else:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to start or end of a path.')\n",
    "\n",
    "            [component,components,\n",
    "            componentNucleotides,\n",
    "            matrix,occupants,\n",
    "            nBins,\n",
    "            nucleotides] = finaliseComponentBase(component,components,\n",
    "                                            componentNucleotides,\n",
    "                                            matrix,occupants,\n",
    "                                            nBins,\n",
    "                                            componentLengths,\n",
    "                                            nucleotides,\n",
    "                                            zoomLevel=zoomLevel,\n",
    "                                            accessions=graph.accessions)\n",
    "            if len(components) not in nodeToComponent[-1]:\n",
    "                nodeToComponent[-1].append(len(components))\n",
    "            componentToNode.append(list(nodesInComp))\n",
    "            nodesInComp = set()\n",
    "        \n",
    "        occupants |= set(uniqueNodePathsIDs)\n",
    "        nodesInComp.add(nodeIdx)\n",
    "        nodeToComponent.append([])\n",
    "        \n",
    "        \n",
    "        #######################################################\n",
    "        # Adding bins and forming components for zoom level 1 #\n",
    "        #######################################################\n",
    "        # TODO: This process for each bin should be parallelised\n",
    "        \n",
    "        # Building nucleotide (real or dummy) for the component.\n",
    "        if isSeq:\n",
    "            nucleotides += graph.nodesData[nodeIdx-1]\n",
    "        else:\n",
    "            nucleotides += graph.nodes[nodeIdx-1]\n",
    "        \n",
    "        # binLength is removed as this function process only single nucleotide level.\n",
    "        \n",
    "        # Preparing annotation for each node and each accession\n",
    "        curNodeAnnotation = {}\n",
    "        \n",
    "        forwardPaths = []\n",
    "        invertedPaths = []\n",
    "        \n",
    "        for j,pathID in enumerate(uniqueNodePathsIDs):\n",
    "            if debugTime:\n",
    "                startTime = time.time()\n",
    "            \n",
    "            pathName = graph.accessions[pathID]\n",
    "            \n",
    "            # get occupancy and inversion for current node in current path.\n",
    "            occ = occupancy[pathID]\n",
    "            inv = inversion[pathID]\n",
    "            \n",
    "            if inv>inversionThreshold:\n",
    "                invertedPaths.append(pathID)\n",
    "            else:\n",
    "                forwardPaths.append(pathID)\n",
    "            \n",
    "            # Creating addition to matrix from this node for this path.\n",
    "            matrixPath = matrix.get(pathID,[[],[]])\n",
    "            \n",
    "            \n",
    "            # Absolute positinal genomic coordinate for given path for each pass of the node.\n",
    "            # NodeStarts are 1-based (position of the first node in the path will be 1).\n",
    "            nodeStarts = np.array([pathNodeLengthsCum[pathID,nodeNumInPath]-nodeLen+1 \\\n",
    "                          for nodeNumInPath in nodeSeqInPath[np.where(nodePathsIdx==pathID)[0]]])\n",
    "            \n",
    "            \n",
    "            # Generating positional pairs for each nucleotide of the node.\n",
    "            posPath = [list(zip(nodeStarts+pos,nodeStarts+pos)) for pos in range(nodeLen)]\n",
    "            \n",
    "            if debugTime:\n",
    "                print(f'Preparation for node {nodeIdx} path {pathName} took {time.time() - startTime}')\n",
    "                annotationTime = time.time()\n",
    "            \n",
    "            ###\n",
    "            # Splitting annotaton into single bins/nucleotides\n",
    "            ###\n",
    "            # Do a test for when number of annotation records X number of nucleotides give benefit of parallelising \n",
    "            # and do an check. If it is larger, then run in parallel, otherwise, do sequencially.\n",
    "            if len(graph.nodesAnnotation[nodeIdx-1][pathName])*nodeLengths[nodeIdx-1]>2e6:\n",
    "                blockSize = int(np.ceil(nodeLen/CPUS))\n",
    "                bounds = list(range(0,nodeLen + nodeLen%blockSize+1,blockSize))\n",
    "                intervals = list(zip(bounds[:-1],bounds[1:]))\n",
    "                intervals[-1] = (intervals[-1][0],nodeLen)\n",
    "                manager = Manager()\n",
    "                annotations = manager.list([[]]*nodeLen)\n",
    "                processList = [Process(target=processAnnotationInterval,\n",
    "                                       args=(*ints,graph.nodesAnnotation[nodeIdx-1][pathName],\n",
    "                                             annotations)) for ints in intervals]\n",
    "                [p.start() for p in processList]\n",
    "                [p.join() for p in processList]\n",
    "                annotations = list(annotations)\n",
    "            else:\n",
    "                annotations = [[]]*nodeLen\n",
    "                processAnnotationInterval(0,nodeLen,graph.nodesAnnotation[nodeIdx-1][pathName],annotations)\n",
    "            \n",
    "            if debugTime:\n",
    "                print(f'Annotations for node {nodeIdx} path {pathName} finished in {time.time()-annotationTime}, overall time {time.time()-startTime}')\n",
    "                matrixTime = time.time()\n",
    "            \n",
    "            matrixPath[0].extend(range(nBins,nBins+nodeLen))\n",
    "            matrixPath[1].extend(zip([occ]*nodeLen,[inv]*nodeLen,posPath,annotations))\n",
    "#             if inv>inversionThreshold:\n",
    "#                 matrixPath[1].extend(list(zip([occ]*nodeLen,[inv]*nodeLen,posPath,annotations)))\n",
    "#             else:\n",
    "#                 matrixPath[1].extend(zip([occ]*nodeLen,[inv]*nodeLen,posPath,annotations))\n",
    "            \n",
    "            matrix[pathID] = matrixPath\n",
    "            \n",
    "            if debugTime:\n",
    "                print(f'MatrixPath for node {nodeIdx} path {pathName} finished in {time.time()-matrixTime}, overall time {time.time()-startTime}')\n",
    "        \n",
    "        forwardPaths.extend(set(range(len(graph.accessions))).difference(forwardPaths+invertedPaths))\n",
    "        \n",
    "        # After all bins are formed, they should be split among components.\n",
    "        # If there are more than one component from the node, then the last component \n",
    "        # should remain open and the rest of checks should go as normal.\n",
    "        # This will allow to attach a small fully followed node after \n",
    "        # (which should be the single node but due to graph construction error was separated).\n",
    "        # Otherwise, if only one component is formed, then the normal checks should follow.\n",
    "        nBinsReduction = 0\n",
    "        if nodeLen>maxLengthComponent:\n",
    "            if debugTime:\n",
    "                postBinTime = time.time()\n",
    "            for blockStart in range(0,nodeLen+1-maxLengthComponent,maxLengthComponent):\n",
    "                blockEnd = blockStart + maxLengthComponent\n",
    "                if len(forwardPaths)>0:\n",
    "#                     component[\"rdepartures\"].append({\n",
    "#                         \"upstream\": component[\"first_bin\"]+maxLengthComponent-1,\n",
    "#                         \"downstream\": component[\"first_bin\"]+maxLengthComponent,\n",
    "#                         \"participants\": forwardPaths,\n",
    "#                         'otherSideRight': False\n",
    "#                     })\n",
    "                    addLink(len(components)+1,'+',len(components)+2,'+',forwardPaths,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "                if len(invertedPaths)>0:\n",
    "#                     component[\"rarrivals\"].append({\n",
    "#                         \"upstream\": component[\"first_bin\"]+maxLengthComponent,\n",
    "#                         \"downstream\": component[\"first_bin\"]+maxLengthComponent-1,\n",
    "#                         \"participants\": invertedPaths,\n",
    "#                         'otherSideRight': False\n",
    "#                     })\n",
    "                    addLink(len(components)+2,'-',len(components)+1,'-',invertedPaths,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "                if debug:\n",
    "                    print(f'Node {nodeIdx}: Component broken inside node {nodeIdx} due to max component length.')\n",
    "                matrixSlice = {}\n",
    "                for pathID,matrixPath in matrix.items():\n",
    "                    matrix[pathID][0] = list(range(nodeLen-blockEnd))\n",
    "                    if inversion[pathID]>inversionThreshold:\n",
    "                        matrixDataSlice = matrixPath[1][-maxLengthComponent:]\n",
    "#                         matrix[pathID][0] = [element-maxLengthComponent for element in matrixPath[0][:-maxLengthComponent]]\n",
    "                        matrix[pathID][1] = matrixPath[1][:-maxLengthComponent]\n",
    "                    else:\n",
    "                        matrixDataSlice = matrixPath[1][:maxLengthComponent]\n",
    "                        #[element-maxLengthComponent for element in matrixPath[0][maxLengthComponent:]]\n",
    "                        matrix[pathID][1] = matrixPath[1][maxLengthComponent:]\n",
    "                    matrixSlice[pathID] = [list(range(len(matrixDataSlice))),matrixDataSlice]\n",
    "                \n",
    "                if inversion[pathID]>inversionThreshold:\n",
    "                    nucleotideSlice = nucleotides[-maxLengthComponent:]\n",
    "                    nucleotides = nucleotides[:-maxLengthComponent]\n",
    "                else:\n",
    "                    nucleotideSlice = nucleotides[:maxLengthComponent]\n",
    "                    nucleotides = nucleotides[maxLengthComponent:]\n",
    "                \n",
    "                component,components,componentNucleotides,_,_,_,_ = \\\n",
    "                    finaliseComponentBase(component,components,componentNucleotides,\n",
    "                                      matrixSlice,occupants,\n",
    "                                      maxLengthComponent,componentLengths,nucleotideSlice,\n",
    "                                      zoomLevel=zoomLevel,accessions=graph.accessions)\n",
    "\n",
    "                nodeToComponent[-1].append(len(components))\n",
    "                componentToNode.append(list(nodesInComp))\n",
    "                nodesInComp = set([nodeIdx])\n",
    "                \n",
    "                nBinsReduction += maxLengthComponent\n",
    "            if debugTime:\n",
    "                print(f'Node splitting for node {nodeIdx} took {time.time()-postBinTime}')\n",
    "        nBins += nodeLen-nBinsReduction\n",
    "        \n",
    "        \n",
    "        if debugTime:\n",
    "            postBinTime = time.time()\n",
    "        #########################################\n",
    "        # Breaking component after current node #\n",
    "        #########################################\n",
    "        # If any path ends on current node, this should be recorded in the component.\n",
    "        if len(pathEnds)>0:\n",
    "            if nBins>0:\n",
    "                component.setdefault(\"ends\",set()).update(pathEnds.tolist())\n",
    "                accEnds = updateEdges(accEnds,pathEnds,len(components)+1)\n",
    "            else:\n",
    "                components[-1].setdefault(\"ends\",set()).update(pathEnds.tolist())\n",
    "                accEnds = updateEdges(accEnds,pathEnds,len(components))\n",
    "                \n",
    "        if len(pathStarts)>0:\n",
    "            if nBins>0:\n",
    "                component.setdefault(\"starts\",set()).update(pathStarts.tolist())\n",
    "                accStarts = updateEdges(accStarts,pathStarts,len(components)+1)\n",
    "            else:\n",
    "                components[-1].setdefault(\"starts\",set()).update(pathStarts.tolist())\n",
    "                accStarts = updateEdges(accStarts,pathStarts,len(components))\n",
    "        \n",
    "        if nodeIdx==len(graph.nodes) and nBins>0:\n",
    "            # Last node in graph.\n",
    "            if debug:\n",
    "                print(f'Node {nodeIdx}: Last node in the last component.')\n",
    "            component,components,componentNucleotides,matrix,occupants,nBins,nucleotides = \\\n",
    "                finaliseComponentBase(component,components,componentNucleotides,matrix,occupants,nBins,componentLengths,nucleotides,\n",
    "                                  zoomLevel=zoomLevel,accessions=graph.accessions)\n",
    "            nodeToComponent[-1].append(len(components))\n",
    "            componentToNode.append(list(nodesInComp))\n",
    "            nodesInComp = set()\n",
    "\n",
    "        elif (rightFarLink or rightPathStartEnd) and nBins>0:\n",
    "            if debug:\n",
    "                if rightFarLink:\n",
    "                    print(f'Node {nodeIdx}: Component broken after node {nodeIdx} due to right far link.')\n",
    "                else:\n",
    "                    print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to start or end of a path.')\n",
    "            component,components,componentNucleotides,matrix,occupants,nBins,nucleotides = \\\n",
    "                finaliseComponentBase(component,components,componentNucleotides,matrix,occupants,nBins,componentLengths,nucleotides,\n",
    "                                  zoomLevel=zoomLevel,accessions=graph.accessions)\n",
    "            nodeToComponent[-1].append(len(components))\n",
    "            componentToNode.append(list(nodesInComp))\n",
    "            nodesInComp = set()\n",
    "        # Not sure why this is needed. It will add com\n",
    "        elif nBins>0:\n",
    "            nodeToComponent[-1].append(len(components)+1)\n",
    "        \n",
    "        if debugTime:\n",
    "            print(f'After node {nodeIdx} component breaking took {time.time() - postBinTime}')\n",
    "            print(f'Processing of node {nodeIdx} took {time.time() - startNodeTime}')\n",
    "    return (numNodes, # number of nodes\n",
    "            numNodesDigits, # \n",
    "            nodeToComponent,\n",
    "            componentToNode,\n",
    "            componentLengths,\n",
    "            components,\n",
    "            componentNucleotides,\n",
    "            fromLinks,toLinks,\n",
    "            fromComponentLinks,toComponentLinks,\n",
    "            accStarts,accEnds,\n",
    "            invertedStarts,invertedEnds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def splitforwardInversedNodeComp(pathList,component,isInverse):\n",
    "    forward = []\n",
    "    inversed = []\n",
    "    \n",
    "    for pathID in pathList:\n",
    "            try:\n",
    "                if component[\"matrix\"][component[\"occupants\"].index(pathID)][1]>0:\n",
    "                    inversed.append(pathID)\n",
    "                else:\n",
    "                    forward.append(pathID)\n",
    "            except (IndexError,ValueError):\n",
    "                # If it is artificial pass link.\n",
    "                if isInverse:\n",
    "                    inversed.append(pathID)\n",
    "                else:\n",
    "                    forward.append(pathID)\n",
    "                \n",
    "    return forward,inversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nodeToComponentLinks(components,componentToNode,nodeToComponent,fromLinks,toLinks,fromComponentLinks,toComponentLinks,debug=False):\n",
    "    numComps = len(components)\n",
    "    numCompsDigits = np.int(np.ceil(np.log10(numComps)))\n",
    "\n",
    "    for compNum in range(numComps):\n",
    "        if debug:    \n",
    "            print(f'Processing component links {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}')\n",
    "        else:\n",
    "            print(f'\\nProcessing component links {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}',end='')\n",
    "\n",
    "        component = components[compNum]\n",
    "        \n",
    "#         if component['first_bin']==17957:\n",
    "#             pdb.set_trace()\n",
    "        \n",
    "        nodeInComp = componentToNode[compNum]\n",
    "        nodeInComp.sort()\n",
    "\n",
    "        if len(nodeInComp)>1:\n",
    "            fromComponentLinks,toComponentLinks = fillLinksBase(nodeInComp,nodeToComponent,fromLinks,toLinks,fromComponentLinks,toComponentLinks,compNum,components)\n",
    "        elif len(nodeInComp)==1:\n",
    "\n",
    "            mainNode = nodeInComp[0]\n",
    "    #             compForNode = nodeToComponent[mainNode-1]\n",
    "            doLeft = False\n",
    "            if compNum==0:\n",
    "                doLeft = True\n",
    "            elif mainNode not in componentToNode[compNum-1]:\n",
    "                doLeft = True\n",
    "\n",
    "            doRight = False # Check this conditions as they may be causing issue!\n",
    "            if compNum==(len(components)-1):\n",
    "                doRight = True\n",
    "            elif mainNode not in componentToNode[compNum+1]:\n",
    "                doRight = True\n",
    "\n",
    "            fromComponentLinks,toComponentLinks = fillLinksBase(nodeInComp,nodeToComponent,fromLinks,toLinks,fromComponentLinks,toComponentLinks,compNum,components,doLeft,doRight)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Component {compNum} does not have any associated nodes!\")\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    return fromComponentLinks,toComponentLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fillLinksBase(nodeInComp,nodeToComponent,fromLinks,toLinks,fromComponentLinks,toComponentLinks,compNum,components,doLeft=True,doRight=True):\n",
    "    component = components[compNum]\n",
    "    for node,isFirstNode in zip([nodeInComp[0],nodeInComp[-1]],[True,False]):\n",
    "        # Processing all external arrival links\n",
    "        nodeToLink = toLinks.get(node,{})\n",
    "        for fromNode in nodeToLink.keys():\n",
    "            intermediateCondition = (node<fromNode)\n",
    "            \n",
    "            la,ra = splitforwardInversedNodeComp(nodeToLink[fromNode],component,intermediateCondition)\n",
    "            \n",
    "            fromFirstCompNum = nodeToComponent[fromNode-1][0]\n",
    "            fromFirstComp = components[fromFirstCompNum-1]\n",
    "            fromLastCompNum = nodeToComponent[fromNode-1][-1]\n",
    "            fromLastComp = components[fromLastCompNum-1]\n",
    "            \n",
    "            if isFirstNode:\n",
    "                #left arrivals\n",
    "                if len(la)>0 and doLeft:\n",
    "                    frd,fld = splitforwardInversedNodeComp(la,fromFirstComp,intermediateCondition)\n",
    "\n",
    "                    # from right departure\n",
    "                    if len(frd)>0 and (fromNode not in nodeInComp) and (fromLastComp['last_bin']+1!=component['first_bin']):\n",
    "                        addLink(fromLastCompNum,'+',compNum+1,'+',frd,fromComponentLinks,toComponentLinks)\n",
    "                    #from left departure\n",
    "                    if len(fld)>0 and (fromNode not in nodeInComp):\n",
    "                        addLink(fromFirstCompNum,'-',compNum+1,'+',fld,fromComponentLinks,toComponentLinks)\n",
    "            \n",
    "            if not isFirstNode:\n",
    "                #right arrivals\n",
    "                if len(ra)>0 and doRight:\n",
    "                    frd,fld = splitforwardInversedNodeComp(ra,fromFirstComp,intermediateCondition)\n",
    "\n",
    "                    #from right departures\n",
    "                    if len(frd)>0 and (fromNode not in nodeInComp):\n",
    "                        addLink(fromLastCompNum,'+',compNum+1,'-',frd,fromComponentLinks,toComponentLinks)\n",
    "                    #from left departures\n",
    "                    if len(fld)>0 and (fromNode not in nodeInComp):\n",
    "                        addLink(fromFirstCompNum,'-',compNum+1,'-',fld,fromComponentLinks,toComponentLinks)\n",
    "            \n",
    "        # Processing all external departure links\n",
    "        nodeFromLink = fromLinks.get(node,{})\n",
    "        for toNode in nodeFromLink.keys():\n",
    "            intermediateCondition = (node>toNode)\n",
    "            \n",
    "            rd,ld = splitforwardInversedNodeComp(nodeFromLink[toNode],component,intermediateCondition)\n",
    "            \n",
    "            toFirstCompNum = nodeToComponent[toNode-1][0]\n",
    "            toFirstComp = components[toFirstCompNum-1]\n",
    "            toLastCompNum = nodeToComponent[toNode-1][-1]\n",
    "            toLastComp = components[toLastCompNum-1]\n",
    "            \n",
    "            if not isFirstNode:\n",
    "                #right departures\n",
    "                if len(rd)>0 and doRight: # Check if doRight is set incorrectly for our case (121->122 at level 4)\n",
    "                    tla,tra = splitforwardInversedNodeComp(rd,toFirstComp,intermediateCondition)\n",
    "\n",
    "                    #to left arrivals\n",
    "                    if len(tla)>0:\n",
    "                        addLink(compNum+1,'+',toFirstCompNum,'+',tla,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "                    #to right arrivals\n",
    "                    if len(tra)>0: # Most probably the problem is here! Check it!\n",
    "                        addLink(compNum+1,'+',toLastCompNum,'-',tra,fromComponentLinks,toComponentLinks)\n",
    "            \n",
    "            if isFirstNode:\n",
    "                #left departures\n",
    "                if len(ld)>0 and doLeft:\n",
    "                    tla,tra = splitforwardInversedNodeComp(ld,toFirstComp,intermediateCondition)\n",
    "\n",
    "                    #to left arrivals\n",
    "                    if len(tla)>0:\n",
    "                        addLink(compNum+1,'-',toFirstCompNum,'+',tla,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "                    if len(tra)>0:\n",
    "                        addLink(compNum+1,'-',toLastCompNum,'-',tra,fromComponentLinks,toComponentLinks)\n",
    "                        \n",
    "    return fromComponentLinks,toComponentLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def addLink(fromComp,fromStrand,toComp,toStrand,pathList,fromComponentLinks,toComponentLinks):\n",
    "    fromComponentLinks.setdefault(fromComp,{}).setdefault(fromStrand,{}).\\\n",
    "                       setdefault(toComp,{}).setdefault(toStrand,set()).\\\n",
    "                       update(pathList)\n",
    "    toComponentLinks.setdefault(toComp,{}).setdefault(toStrand,{}).\\\n",
    "                     setdefault(fromComp,{}).setdefault(fromStrand,set()).\\\n",
    "                     update(pathList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def finaliseChunk(rootStruct,zoomLevel,chunk,nucleotides,nBins,chunkNum,curCompCols,prevTotalCols,outputPath,outputName):\n",
    "    endChunkBin = chunk['components'][-1]['last_bin']\n",
    "    endChunkCol = chunk['components'][-1]['lastCol']\n",
    "    chunk['last_bin'] = endChunkBin\n",
    "    chunk['last_col'] = endChunkCol\n",
    "    \n",
    "    localPath = f'{outputPath}{os.path.sep}{outputName}{os.path.sep}{zoomLevel}{os.path.sep}'\n",
    "    \n",
    "    fileName = f'chunk{chunkNum}_zoom{zoomLevel}.schematic.json'\n",
    "    \n",
    "    with open(f'{localPath}{fileName}','w') as f:\n",
    "        json.dump(chunk,f,cls=NpEncoder)\n",
    "    \n",
    "    rootStruct['zoom_levels'][zoomLevel]['files'].append({\n",
    "        'file': fileName,\n",
    "        'first_bin':chunk['first_bin'],\n",
    "        'first_col':chunk['first_col'],\n",
    "        'last_bin':chunk['last_bin'],\n",
    "        'last_col':chunk['last_col'],\n",
    "#         'x':prevTotalCols\n",
    "    })\n",
    "    \n",
    "    if zoomLevel==1:\n",
    "        fastaName = f'seq_chunk{chunkNum}_zoom{zoomLevel}.fa'\n",
    "        rootStruct['zoom_levels'][zoomLevel]['files'][-1]['fasta'] = fastaName\n",
    "        \n",
    "        with open(f'{localPath}{fastaName}','w') as f:\n",
    "            f.write(f'>first_bin:{chunk[\"first_bin\"]} last_bin:{chunk[\"last_bin\"]}\\n')\n",
    "            f.write(nucleotides)\n",
    "        \n",
    "    chunk = deepcopy(chunkTemplate)\n",
    "    chunk['first_bin'] = endChunkBin + 1\n",
    "    chunk['first_col'] = endChunkCol + 1\n",
    "    return rootStruct,chunk,0,chunkNum + 1,prevTotalCols+curCompCols,0,'' #rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def addLinksToComp(compNum,components,fromComponentLinks,toComponentLinks):\n",
    "    component = deepcopy(components[compNum])\n",
    "    \n",
    "    toCompDict = toComponentLinks.get(compNum+1,{}) # !!! Check that in fromComponentLinks component numbering is 1-based\n",
    "    if '+' in toCompDict:\n",
    "        for fromCompNum,fromCompDict in toCompDict['+'].items():\n",
    "            fromComp = components[fromCompNum-1]\n",
    "            for fromStrand,participants in fromCompDict.items():\n",
    "                doAddArrival = True\n",
    "                if fromStrand=='+':\n",
    "                    upstreamBin = fromComp['last_bin']\n",
    "                    fromRight = True\n",
    "                    if component['first_bin']-upstreamBin==1:\n",
    "                        doAddArrival = False\n",
    "                elif fromStrand=='-':\n",
    "                    upstreamBin = fromComp['first_bin']\n",
    "                    fromRight = False\n",
    "                else:\n",
    "                    raise ValueError(f'Unrecognised direction of node link {fromStrand}')\n",
    "                if doAddArrival:\n",
    "                    component['larrivals'].append({\n",
    "                            'upstream': upstreamBin,\n",
    "                            'downstream': component['first_bin'],\n",
    "                            'otherSideRight': fromRight,\n",
    "                            'participants': participants\n",
    "                        })\n",
    "    \n",
    "    if '-' in toCompDict:\n",
    "        for fromCompNum,fromCompDict in toCompDict['-'].items():\n",
    "            fromComp = components[fromCompNum-1]\n",
    "            for fromStrand,participants in fromCompDict.items():\n",
    "                if fromStrand=='+':\n",
    "                    upstreamBin = fromComp['last_bin']\n",
    "                    fromRight = True\n",
    "                elif fromStrand=='-':\n",
    "                    upstreamBin = fromComp['first_bin']\n",
    "                    fromRight = False\n",
    "                else:\n",
    "                    raise ValueError(f'Unrecognised direction of node link {fromStrand}')\n",
    "                component['rarrivals'].append({\n",
    "                        'upstream': upstreamBin,\n",
    "                        'downstream': component['last_bin'],\n",
    "                        'otherSideRight': fromRight,\n",
    "                        'participants': participants\n",
    "                    })\n",
    "    \n",
    "    fromCompDict = fromComponentLinks.get(compNum+1,{}) # !!! Check that in fromComponentLinks component numbering is 1-based\n",
    "    if '+' in fromCompDict:\n",
    "        for toCompNum,toCompDict in fromCompDict['+'].items():\n",
    "            toComp = components[toCompNum-1]\n",
    "            for toStrand,participants in toCompDict.items():\n",
    "                if toStrand=='+':\n",
    "                    downstreamBin = toComp['first_bin']\n",
    "                    toRight = False\n",
    "                elif toStrand=='-':\n",
    "                    downstreamBin = toComp['last_bin']\n",
    "                    toRight = True\n",
    "                else:\n",
    "                    raise ValueError(f'Unrecognised direction of node link {toStrand}')\n",
    "                component['rdepartures'].append({\n",
    "                        'upstream': component['last_bin'],\n",
    "                        'downstream': downstreamBin,\n",
    "                        'otherSideRight': toRight,\n",
    "                        'participants': participants\n",
    "                    })\n",
    "    if '-' in fromCompDict:\n",
    "        for toCompNum,toCompDict in fromCompDict['-'].items():\n",
    "            toComp = components[toCompNum-1]\n",
    "            for toStrand,participants in toCompDict.items():\n",
    "                doAddDeparture = True\n",
    "                if toStrand=='+':\n",
    "                    downstreamBin = toComp['first_bin']\n",
    "                    toRight = False\n",
    "                elif toStrand=='-':\n",
    "                    downstreamBin = toComp['last_bin']\n",
    "                    toRight = True\n",
    "                    if component['first_bin']-downstreamBin==1:\n",
    "                        doAddDeparture = False\n",
    "                else:\n",
    "                    raise ValueError(f'Unrecognised direction of node link {toStrand}')\n",
    "                if doAddDeparture:\n",
    "                    component['ldepartures'].append({\n",
    "                            'upstream': component['first_bin'],\n",
    "                            'downstream': downstreamBin,\n",
    "                            'otherSideRight': toRight,\n",
    "                            'participants': participants\n",
    "                        })\n",
    "        \n",
    "    return component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def checkLinks(leftComp,rightComp):\n",
    "    leftRdepCond = np.all([link['upstream']+1==link['downstream'] for link in leftComp['rdepartures']])\n",
    "    leftRarrCond = np.all([link['upstream']-1==link['downstream'] for link in leftComp['rarrivals']])\n",
    "\n",
    "    rightRdepCond = np.all([link['upstream']-1==link['downstream'] for link in rightComp['ldepartures']])\n",
    "    rightRarrCond = np.all([link['upstream']+1==link['downstream'] for link in rightComp['larrivals']])\n",
    "    \n",
    "    return leftRdepCond and leftRarrCond and rightRarrCond and rightRdepCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getMatrixPathElement(matrix,pathID):\n",
    "    res = [el for el in matrix if el[0]==pathID]\n",
    "    if len(res)==1:\n",
    "        return res[0]\n",
    "    elif len(res)>0:\n",
    "        warnings.warn(f\"More than one element for path {pathID} is found!\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def joinComponents(leftComp,rightComp, maxLengthComponent, inversionThreshold=0.5):\n",
    "    '''\n",
    "    If the joining was successful, the function will return a joined component.\n",
    "    \n",
    "    If the joining was not successful and was aborted for one of the following reasons, it will return a list of original components. \n",
    "    The reasons for aborting the joining can be the following:\n",
    "    - In one of the paths the invertion is lower than threshold in one component and higher in the other.\n",
    "    - Left component contains at least one end\n",
    "    - Right component contains at least one start\n",
    "    \n",
    "    The function will not check links for coming or going on the right of the left component and left of the right component. \n",
    "    It will just get left links from left component and right links from right component and assign them to the new component.\n",
    "    '''\n",
    "    \n",
    "    if leftComp['last_bin']-leftComp['first_bin']+1 + rightComp['last_bin']-rightComp['first_bin']+1 > maxLengthComponent:\n",
    "        return [leftComp,rightComp]\n",
    "    \n",
    "    if leftComp.get('ends',False):\n",
    "        # End of a path\n",
    "        return [leftComp,rightComp]\n",
    "    \n",
    "    newComp = {}\n",
    "    newComp['first_bin'] = min(leftComp['first_bin'],rightComp['first_bin'])\n",
    "    newComp['last_bin'] = max(leftComp['last_bin'],rightComp['last_bin'])\n",
    "    newComp['firstCol'] = min(leftComp['firstCol'],rightComp['firstCol'])\n",
    "    newComp['lastCol'] = max(leftComp['lastCol'],rightComp['lastCol'])\n",
    "    \n",
    "    leftCompNumBins = leftComp['last_bin']-leftComp['first_bin']+1\n",
    "    \n",
    "    newComp['occupants'] = list(set(leftComp['occupants']).union(rightComp['occupants']))\n",
    "    \n",
    "    for pathID in newComp['occupants']:\n",
    "        leftPathElement = getMatrixPathElement(leftComp['matrix'],pathID)\n",
    "        rightPathElement = getMatrixPathElement(rightComp['matrix'],pathID)\n",
    "        if leftPathElement is None and rightPathElement is None:\n",
    "            continue\n",
    "        \n",
    "        if leftPathElement is None:\n",
    "            if len([el for el in rightPathElement[2][1] if el[2][0][0]==1 or el[2][-1][0]==1])>0:\n",
    "                # Start of a path\n",
    "                return [leftComp,rightComp]\n",
    "            rightPathElement[2][0] = [el+leftCompNumBins for el in rightPathElement[2][0]]\n",
    "            newComp.setdefault(\"matrix\",[]).append(rightPathElement)\n",
    "            continue\n",
    "        \n",
    "        if rightPathElement is None:\n",
    "            newComp.setdefault(\"matrix\",[]).append(leftPathElement)\n",
    "            continue\n",
    "        \n",
    "        if (leftPathElement[1]>inversionThreshold and rightPathElement[1]<=inversionThreshold) or \\\n",
    "           (leftPathElement[1]<=inversionThreshold and rightPathElement[1]>inversionThreshold):\n",
    "            return [leftComp,rightComp]\n",
    "        \n",
    "        newPathElement = []\n",
    "        newPathElement.append(pathID)\n",
    "        newPathElement.append(leftPathElement[1])\n",
    "        pathMatrix = []\n",
    "        pathMatrix.append(leftPathElement[2][0] + [el+leftCompNumBins for el in rightPathElement[2][0]])\n",
    "        pathMatrix.append(leftPathElement[2][1] + rightPathElement[2][1])\n",
    "        newPathElement.append(pathMatrix)\n",
    "        newComp.setdefault(\"matrix\",[]).append(newPathElement)\n",
    "        \n",
    "    newComp['larrivals'] = leftComp['larrivals']\n",
    "    newComp['ldepartures'] = leftComp['ldepartures']\n",
    "    newComp['rarrivals'] = rightComp['rarrivals']\n",
    "    newComp['rdepartures'] = rightComp['rdepartures']\n",
    "    ends = list(set(leftComp.get('ends',[])).union(rightComp.get('ends',[])))\n",
    "    if len(ends)>0:\n",
    "        newComp['ends'] = ends\n",
    "    \n",
    "    return newComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def searchIndicesPosRecord(redisConn,zoomLevel,accessions,posMapping):\n",
    "    for pathID,posMappingPath in posMapping.items():\n",
    "        iset_add(redisConn, f'{zoomLevel}.{accessions[pathID]}.Pos',posMappingPath)\n",
    "\n",
    "def searchIndicesGeneRecord(redisConn,zoomLevel,accessions,geneMapping):\n",
    "    for pathID,geneMappingPath in geneMapping.items():\n",
    "        redisConn.hmset( f'{zoomLevel}.{accessions[pathID]}.Gene',geneMappingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def exportLayer(zoomLevel,components,componentNucleotides,\n",
    "                fromComponentLinks,toComponentLinks,\n",
    "                rootStruct,\n",
    "                outputPath,outputName,\n",
    "                maxLengthComponent,maxLengthChunk,\n",
    "                inversionThreshold=0.5,\n",
    "                redisConn=None,\n",
    "                accessions=None,\n",
    "                debug=False):\n",
    "    \n",
    "    #Create the directory to hold zoomLevel chunks and fasta files (if available)\n",
    "    createZoomLevelDir(outputPath,outputName,zoomLevel)\n",
    "\n",
    "    chunkList = rootStruct[\"zoom_levels\"].setdefault(zoomLevel,{\n",
    "        \"last_bin\": components[-1][\"last_bin\"],\n",
    "        \"last_col\": components[-1][\"lastCol\"],\n",
    "        \"files\":[]\n",
    "    })\n",
    "    # Recording data to files for zoom level\n",
    "\n",
    "    #     chunkTemplate = {\n",
    "    #     \"json_version\":17,\n",
    "    #     \"bin_width\":1,\n",
    "    #     \"first_bin\":1,\n",
    "    #     \"includes_connectors\": True,\n",
    "    #     \"components\": []\n",
    "    # }    \n",
    "    chunk = deepcopy(chunkTemplate)\n",
    "    chunkNum = 0\n",
    "    prevTotalCols = 0\n",
    "    curCompCols = 0\n",
    "    nucleotides = ''\n",
    "    nBins = 0\n",
    "    numComps = len(components)\n",
    "    numCompsDigits = np.int(np.ceil(np.log10(numComps)))\n",
    "    \n",
    "    if redisConn:\n",
    "        accessions = rootStruct[\"pathNames\"]\n",
    "    posMapping = {}\n",
    "    geneMapping = {}\n",
    "    for compNum in range(numComps):\n",
    "        if debug:    \n",
    "            print(f'Recording component {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}')\n",
    "        else:\n",
    "            print(f'\\nRecording component {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}',end='')\n",
    "        component = addLinksToComp(compNum,components,fromComponentLinks,toComponentLinks)\n",
    "#         print(f'Component Length is {component[\"last_bin\"]-component[\"first_bin\"]+1}')\n",
    "#         redisStartTime = time.time()\n",
    "        if redisConn is not None:\n",
    "            \n",
    "            for pathID,inv,matrixPathArray in component['matrix']:\n",
    "#                 print(f'Recording search indices for path {accessions[pathID]}')\n",
    "                pathRedisStartTime = time.time()\n",
    "                for binNum,binMatrix in zip(*matrixPathArray):\n",
    "                    if binMatrix[1]>inversionThreshold:\n",
    "                        overallBin = component['last_bin']-binNum\n",
    "                    else:\n",
    "                        overallBin = component['first_bin']+binNum\n",
    "                    \n",
    "#                     if pathID==5 and overallBin==20350:\n",
    "#                         pdb.set_trace()\n",
    "                    \n",
    "                    posMapping.setdefault(pathID,{}).update({int(overallBin):[(int(posStart),int(posEnd)) for posStart,posEnd in binMatrix[2]]})\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    geneList = binMatrix[3]\n",
    "                    for gene in geneList:\n",
    "                        if gene not in geneMapping.get(pathID,{}):#not redisConn.hexists(f'{zoomLevel}.{accessions[pathID]}.Gene',gene):\n",
    "                            geneMapping.setdefault(pathID,{}).update({gene:overallBin})\n",
    "                            \n",
    "#                 print(f'Recording search indices for path {accessions[pathID]} took {time.time()-pathRedisStartTime}')\n",
    "#         print(f'Overall recording of search indices for component {compNum+1} is {time.time()-redisStartTime}')\n",
    "        \n",
    "#         print(f'Joining component {compNum}')\n",
    "#         joinStartTime = time.time()\n",
    "        nBins += component[\"last_bin\"]-component[\"first_bin\"]+1\n",
    "#         if len(chunk['components'])>0:\n",
    "#             if checkLinks(chunk[\"components\"][-1],component):\n",
    "#                 newComp = joinComponents(chunk[\"components\"].pop(),component,maxLengthComponent,inversionThreshold)\n",
    "#                 if isinstance(newComp,list):\n",
    "#                     chunk[\"components\"].append(newComp[0])\n",
    "#                     component = newComp[1]\n",
    "#                 else:\n",
    "#                     component = newComp\n",
    "        if zoomLevel==1:\n",
    "            nucleotides += componentNucleotides[compNum]\n",
    "        chunk[\"components\"].append(component)\n",
    "        \n",
    "#         print(f'Joining took {time.time() - joinStartTime}')\n",
    "        \n",
    "        # End of chunk\n",
    "        if compNum<len(components)-1:\n",
    "            if len(chunk['components'])>=maxLengthChunk:\n",
    "            #nBins+components[compNum+1][\"last_bin\"]-components[compNum+1][\"first_bin\"]+1>maxLengthChunk:\n",
    "#                 print(f'Recording chunk')\n",
    "#                 chunkStartTime = time.time()\n",
    "                rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols,nucleotides = finaliseChunk(\n",
    "                                                                                          rootStruct,\n",
    "                                                                                          zoomLevel,\n",
    "                                                                                          chunk,\n",
    "                                                                                          nucleotides,\n",
    "                                                                                          nBins,\n",
    "                                                                                          chunkNum,\n",
    "                                                                                          curCompCols,\n",
    "                                                                                          prevTotalCols,\n",
    "                                                                                          outputPath,\n",
    "                                                                                          outputName)\n",
    "#                 print(f'Chunk recorded in {time.time() - chunkStartTime}')\n",
    "        else:\n",
    "#             print(f'Recording chunk')\n",
    "#             chunkStartTime = time.time()\n",
    "            rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols,nucleotides = finaliseChunk(\n",
    "                                                                                      rootStruct,\n",
    "                                                                                      zoomLevel,\n",
    "                                                                                      chunk,\n",
    "                                                                                      nucleotides,\n",
    "                                                                                      nBins,\n",
    "                                                                                      chunkNum,\n",
    "                                                                                      curCompCols,\n",
    "                                                                                      prevTotalCols,\n",
    "                                                                                      outputPath,\n",
    "                                                                                      outputName)\n",
    "#             print(f'Chunk recorded in {time.time() - chunkStartTime}')\n",
    "    if redisConn is not None:\n",
    "        searchIndicesPosRecord(redisConn,zoomLevel,accessions,posMapping)\n",
    "        searchIndicesGeneRecord(redisConn,zoomLevel,accessions,geneMapping)\n",
    "        try:\n",
    "            redisConn.bgsave()\n",
    "        except ResponseError:\n",
    "            pass\n",
    "    if not debug:\n",
    "        print()\n",
    "    \n",
    "    print(f'Recording zoom level {zoomLevel} finished.') # Zoom level time is {time.time() - zoomTime}. Time elapsed {time.time() - startTime}')\n",
    "\n",
    "    return rootStruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def combineIntervals(posPath):\n",
    "    # posPath = pos.get(pathID)\n",
    "    posArray = np.array(posPath)\n",
    "    posArray = posArray[np.argsort(posArray[:,0]),:]\n",
    "    posIntersect = (posArray[1:,1]-(posArray[:-1,0]-1))*\\\n",
    "                    (posArray[:-1,1]-(posArray[1:,0]-1))\n",
    "    newPos = [[posArray[0,0]]]\n",
    "    candidates = [posArray[0,1]]\n",
    "    for jointNum in range(len(posIntersect)):\n",
    "        if posIntersect[jointNum]>=0:\n",
    "            candidates.extend(posArray[jointNum+1,:].tolist())\n",
    "        else:\n",
    "            newPos[-1].append(np.max(candidates))\n",
    "            newPos.append([posArray[jointNum+1,0]])\n",
    "            candidates = [posArray[jointNum+1,1]]\n",
    "\n",
    "    newPos[-1].append(np.max(candidates))# !!!!    \n",
    "    return newPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def checkLinksZoom(compNum,fromComponentLinks,toComponentLinks):\n",
    "    # Check only outgoing from the right and incoming to the right\n",
    "    # and check outgoing from the left on and incoming to the left on the next node.\n",
    "    if any(['-' in toNodeDicts for toNodeDicts in fromComponentLinks.get(compNum+1,{}).get('+',{}).values()]):\n",
    "        # If there is an outgoing link from positive block (right) to negative block (anywhere)\n",
    "        return True\n",
    "\n",
    "    if any(['+' in fromNodeDicts for fromNodeDicts in toComponentLinks.get(compNum+1,{}).get('-',{}).values()]):\n",
    "        # If there is an incoming link to the negative block (right) from positive block (anywhere)\n",
    "        return True\n",
    "    \n",
    "    if any([toNodes!=compNum+2 for toNodes in fromComponentLinks.get(compNum+1,{}).get('+',{}).keys()]):\n",
    "        # If there is an outgoing link from positive block (right) to anywhere \n",
    "        # (positive block because negative downstream was excluded above) except the next component\n",
    "        return True\n",
    "    \n",
    "    if any([fromNodes!=compNum+2 for fromNodes in toComponentLinks.get(compNum+1,{}).get('-',{}).keys()]):\n",
    "        # If there is an incoming link to negative block (right) from anywhere\n",
    "        # (negavive block because positive upstream was excluded above) except the next component\n",
    "        return True\n",
    "    \n",
    "    if any([fromNodes!=compNum+1 or '-' in fromNodesDict for fromNodes,fromNodesDict in toComponentLinks.get(compNum+2,{}).get('+',{}).items()]):\n",
    "        # If there is an incoming link to positive block of next component (left) from anywhere except current component\n",
    "        return True\n",
    "    \n",
    "    if any([toNodes!=compNum+1 or '+' in toNodesDict for toNodes,toNodesDict in fromComponentLinks.get(compNum+2,{}).get('-',{}).items()]):\n",
    "        # If there is an outgoing link from negative block (left) to anywhere except current component\n",
    "        return True\n",
    "    \n",
    "    if not (('+' in fromComponentLinks.get(compNum+1,{}).get('+',{}).get(compNum+2,{})) or \\\n",
    "            ('-' in toComponentLinks.get(compNum+1,{}).get('-',{}).get(compNum+2,{}))):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def finaliseComponentZoom(component,components,componentLengths,#componentNucleotides,\n",
    "                          nBins,nCols,occupants,\n",
    "                          binBlockLengths,binColStarts,binColEnds,\n",
    "                          matrix,starts,ends,\n",
    "                          forwardPaths,invertedPaths,inversionThreshold=0.5):\n",
    "    \n",
    "    componentLengths.append(nBins)\n",
    "    component[\"matrix\"].extend(sorted([[pathID,\n",
    "                                 int(matrixPathArray[1][0][1]>inversionThreshold),\n",
    "                                 matrixPathArray] \\\n",
    "                                for pathID,matrixPathArray in matrix.items()],key=lambda el: el[0]))\n",
    "    \n",
    "    component['binsToCols'] = binBlockLengths\n",
    "    component[\"occupants\"] = sorted(list(matrix.keys()))\n",
    "    \n",
    "    component['last_bin'] = component['first_bin'] + nBins - 1\n",
    "    \n",
    "    component['firstCol'] = min(binColStarts)\n",
    "    component['lastCol'] = max(binColEnds)\n",
    "    \n",
    "    # Is it needed?\n",
    "    component['binColStarts'] = binColStarts\n",
    "    component['binColEnds'] = binColEnds\n",
    "    \n",
    "    curStarts = starts.intersection(forwardPaths)\n",
    "    if len(curStarts)>0:\n",
    "        component['starts'] = list(curStarts)\n",
    "    starts -= set(forwardPaths)\n",
    "        \n",
    "    curEnds = ends.intersection(invertedPaths)\n",
    "    if len(curEnds)>0:\n",
    "        component['ends'] = list(curEnds)\n",
    "    ends -= set(invertedPaths)    \n",
    "        \n",
    "#     componentNucleotides.append(nucleotides)\n",
    "    \n",
    "    firstBin = component['last_bin'] + 1\n",
    "#     firstCol = component['lastCol'] + 1\n",
    "    components.append(component)\n",
    "    component = deepcopy(componentTemplate)\n",
    "    component['first_bin'] = firstBin\n",
    "#     component['firstCol'] = firstCol\n",
    "    return component,components,componentLengths,0,0,set(),[],[],[],{},starts,ends\n",
    "    # component,components,componentLengths,(componentNucleotides),nBins,nCols,occupants,\n",
    "    # binBlockLengths,binColStarts,binColEnds,matrix,starts,ends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-vocabulary",
   "metadata": {},
   "source": [
    "Changed how inversion was calculated (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getOccInvChange(binColLengths,binBlockLength,binOcc,binInv,prevOcc,prevInv,inversionThreshold=0.5):\n",
    "    occChanged = False\n",
    "    invChanged = False\n",
    "    occ = {}\n",
    "    inv = {}\n",
    "    for pathID in binOcc:\n",
    "        # Averaging occupancy\n",
    "        occ[pathID] = sum([bl*bo for bl,bo in zip(binColLengths,binOcc[pathID])])/binBlockLength\n",
    "        # Do comparison through floor and then abs difference > 0\n",
    "        if np.abs(np.floor(occ[pathID]+0.5)-np.floor(prevOcc.get(pathID,occ[pathID])+0.5))>0:\n",
    "            occChanged = True\n",
    "        prevOcc[pathID] = occ[pathID]\n",
    "        \n",
    "        # Averaging invertion\n",
    "        inv[pathID] = sum([bl*bo*bi for bl,bo,bi in zip(binColLengths,binOcc[pathID],binInv[pathID])])/(binBlockLength*occ[pathID])\n",
    "        if (inv[pathID]-inversionThreshold)*(prevInv.get(pathID,inv[pathID])-inversionThreshold)<0 or \\\n",
    "        (inv[pathID]-inversionThreshold)*(prevInv.get(pathID,inv[pathID])-inversionThreshold)==0 and \\ \n",
    "        inv[pathID]*prevInv.get(pathID,inv[pathID])>inversionThreshold*inversionThreshold:\n",
    "            # The second comdition after or is taking the case where one is equal to inversionThreshold\n",
    "            # and another is more than inversionThreshold.\n",
    "            invChanged = True\n",
    "        prevInv[pathID] = inv[pathID]\n",
    "        \n",
    "    return occChanged,invChanged,occ,inv,prevOcc,prevInv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def recordBinZoom(occ,inv,binPosArray,binAnn,nBins,nCols,\n",
    "                  binBlockLength,binBlockLengths,\n",
    "                  binColLengths,\n",
    "                  binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                  matrix,inversionThreshold=0.5):\n",
    "    # need to check for occupancy and inversion change in comparison with previous bin\n",
    "    # and if that happens, break the component before this bin (should be special boolean returned.\n",
    "    \n",
    "    for pathID in binPosArray:\n",
    "        pathMatrix = matrix.setdefault(pathID,[[],[]])\n",
    "        pathMatrix[0].append(nBins)\n",
    "        \n",
    "        # Adding everything to matrix element with Combined positions and Annotations (already combined through set)\n",
    "        if inv[pathID]>inversionThreshold:\n",
    "            pathMatrix[1].insert(0,[occ[pathID],inv[pathID],combineIntervals(binPosArray[pathID]),list(binAnn[pathID])])\n",
    "        else:\n",
    "            pathMatrix[1].append([occ[pathID],inv[pathID],combineIntervals(binPosArray[pathID]),list(binAnn[pathID])])\n",
    "    \n",
    "    binBlockLengths.append(binBlockLength)\n",
    "    \n",
    "    binColStarts.append(binColStart)\n",
    "    binColEnds.append(binColEnd)\n",
    "    \n",
    "    return 0,[],binColStarts,binColEnds,{},{},{},{},nBins+1,nCols+binBlockLength,binBlockLengths,matrix\n",
    "    # binBlockLength,binColLengths,binColStarts,binColEnds,\n",
    "    # binOcc,binInv,binPosArray,binAnn,nBins,nCols,\n",
    "    # binBlockLengths,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def finaliseBinZoom(compNum,\n",
    "                    binOcc,binInv,binPosArray,binAnn,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    prevOcc,prevInv,\n",
    "                    newComponent,newComponents,newComponentLengths,#compAccDir,#newComponentNucleotides,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,collapsibleBlocks,#nucleotides,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=0.5):\n",
    "    \n",
    "    preservedPrevInv = deepcopy(prevInv)\n",
    "    \n",
    "    occChanged,invChanged,occ,inv,prevOcc,prevInv = \\\n",
    "    getOccInvChange(binColLengths,binBlockLength,binOcc,binInv,prevOcc,prevInv,inversionThreshold=inversionThreshold)\n",
    "    \n",
    "    if (occChanged or invChanged) and nBins>0:\n",
    "        \n",
    "        # cut the matrix and remove the last added bin for the latest component and \n",
    "        # check that there is something to finalise (that it was not the only bin)\n",
    "\n",
    "        # Add direct link\n",
    "        if invChanged:\n",
    "            for pathID in forwardPaths|invertedPaths:\n",
    "                if preservedPrevInv.get(pathID,0)>inversionThreshold:\n",
    "                    fromStrand = '-'\n",
    "                else:\n",
    "                    fromStrand = '+'\n",
    "                    \n",
    "                if inv.get(pathID,0)>inversionThreshold:\n",
    "                    toStrand = '-'\n",
    "                else:\n",
    "                    toStrand = '+'\n",
    "                \n",
    "                if fromStrand=='-' and toStrand=='-':\n",
    "                    addLink(len(newComponents)+2,toStrand,len(newComponents)+1,fromStrand,[pathID],newFromComponentLinks,newToComponentLinks)\n",
    "                elif fromStrand=='+' and toStrand=='+':\n",
    "                    addLink(len(newComponents)+1,fromStrand,len(newComponents)+2,toStrand,[pathID],newFromComponentLinks,newToComponentLinks)\n",
    "                \n",
    "                if fromStrand!=toStrand:\n",
    "                    collapsibleBlocks.append((pathID,nCols,[(len(newComponents)+1,len(newComponents)+2)],[len(newComponents)+1]))\n",
    "                # These links should go into collapsible blocks associated with the new component column length\n",
    "                # More probably these links will be removed on the next step. But this is happening on the path per path basis\n",
    "                # and lengths should be calculated on the same path to path basis as well!!! That can be taken from 'binColLengths' without\n",
    "                # the last element!!!\n",
    "            \n",
    "        else:\n",
    "            if len(forwardPaths)>0:\n",
    "                addLink(len(newComponents)+1,'+',len(newComponents)+2,'+',forwardPaths,newFromComponentLinks,newToComponentLinks)\n",
    "            if len(invertedPaths)>0:\n",
    "                addLink(len(newComponents)+2,'-',len(newComponents)+1,'-',invertedPaths,newFromComponentLinks,newToComponentLinks)\n",
    "        \n",
    "        # Add new element to newToOldInd\n",
    "        newToOldInd.append([compNum])\n",
    "        # Add number of next element to oldToNewInd\n",
    "        oldToNewInd[-1].append(len(newComponents))\n",
    "            \n",
    "        newComponent,newComponents,newComponentLengths,\\\n",
    "        nBins,nCols,_,binBlockLengths,binColStarts,binColEnds,\\\n",
    "        matrix,starts,ends = \\\n",
    "            finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "                                  nBins,nCols,occupants,binBlockLengths,\n",
    "                                  binColStarts,binColEnds,\n",
    "                                  matrix,starts,ends,\n",
    "                                  forwardPaths,invertedPaths,inversionThreshold=inversionThreshold)\n",
    "\n",
    "        \n",
    "\n",
    "    binBlockLength,binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,binAnn,nBins,nCols,binBlockLengths,matrix = \\\n",
    "    recordBinZoom(occ,inv,binPosArray,binAnn,\n",
    "                    nBins,nCols,binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "    \n",
    "    return binColLengths,binColStarts,binColEnds,\\\n",
    "            binOcc,binInv,binPosArray,binAnn,nBins,nCols,\\\n",
    "            binBlockLength,binBlockLengths,matrix,prevOcc,prevInv,\\\n",
    "            newComponent,newComponents,newComponentLengths,\\\n",
    "            newFromComponentLinks,newToComponentLinks,\\\n",
    "            occupants,collapsibleBlocks,\\\n",
    "            starts,ends,newToOldInd,oldToNewInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def checkChange(compNum,components,zoomLevel):\n",
    "    doBreak = False\n",
    "    curComp = components[compNum]\n",
    "    nextComp = components[compNum+1]\n",
    "    \n",
    "    if sum(curComp['binsToCols'])<zoomLevel or sum(nextComp['binsToCols'])<zoomLevel:\n",
    "        return False\n",
    "    \n",
    "    paths = list(set(curComp['occupants'])|set(nextComp['occupants']))\n",
    "    for pathID in paths:\n",
    "        curPathMatrix = getMatrixPathElement(curComp['matrix'],pathID)\n",
    "        nextPathMatrix = getMatrixPathElement(nextComp['matrix'],pathID)\n",
    "\n",
    "        \n",
    "        if curPathMatrix is not None and nextPathMatrix is not None:\n",
    "            curEdgeBinOcc = curPathMatrix[2][1][-1 if curPathMatrix[1]==0 else 0][0] # the last index==1 gives inversion\n",
    "            nextEdgeBinOcc = nextPathMatrix[2][1][0 if nextPathMatrix[1]==0 else -1][0]\n",
    "            # Checking for breaking in occupancy\n",
    "            if np.abs(np.floor(nextEdgeBinOcc+0.5)-np.floor(curEdgeBinOcc+0.5))>0:\n",
    "                doBreak = True\n",
    "            \n",
    "            # Checking for breaking in inversion (using recorded binary inversion)\n",
    "            if curPathMatrix[1]!=nextPathMatrix[1]:\n",
    "                doBreak = True\n",
    "        \n",
    "        else:\n",
    "            # If one of the component in the path has empty block.\n",
    "            # At the moment nothing is happening here, but potentially we can enforce break if that is the case.\n",
    "            pass\n",
    "    return doBreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def checkForBreaksZoom(zoomLevel,compNum,components,fromComponentLinks,toComponentLinks):\n",
    "    if compNum<len(components)-1:\n",
    "        breakByLinks = checkLinksZoom(compNum,fromComponentLinks,toComponentLinks)\n",
    "        breakByChange = checkChange(compNum,components,zoomLevel)\n",
    "    else:\n",
    "        return [false]\n",
    "    return [breakByLinks,breakByChange]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def isStartEnd(compNum,components):\n",
    "    isBreak = False\n",
    "    leftComp = components[compNum]\n",
    "    if compNum<len(components)-1:\n",
    "        rightComp = components[compNum+1]\n",
    "    else:\n",
    "        rightComp = None\n",
    "    \n",
    "    \n",
    "    for path,compInvBin,pathMatrix in leftComp['matrix']:\n",
    "        if compInvBin==1:\n",
    "            if path in leftComp.get('starts',[]):\n",
    "                isBreak = True\n",
    "        else:\n",
    "            if path in leftComp.get('ends',[]):\n",
    "                isBreak = True\n",
    "    \n",
    "    if rightComp is not None:\n",
    "        for path,compInvBin,pathMatrix in rightComp['matrix']:\n",
    "            if compInvBin==1:\n",
    "                if path in rightComp.get('ends',[]):\n",
    "                    isBreak = True\n",
    "            else:\n",
    "                if path in rightComp.get('starts',[]):\n",
    "                    isBreak = True\n",
    "    \n",
    "    return isBreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nextLayerZoom(zoomLevel,components,componentLengths,#componentNucleotides,\n",
    "                  fromComponentLinks,toComponentLinks,graph,\n",
    "                  collapsibleBlocks,accStarts,accEnds,\n",
    "                  maxLengthComponent,inversionThreshold=0.5,\n",
    "                  debug=False,debugTime=False):\n",
    "\n",
    "    print('\\n===========================')\n",
    "    print(f'Zoom level {zoomLevel}')\n",
    "    print('===========================')\n",
    "    \n",
    "    # removing links and isolated components\n",
    "    ### !!! Function to process these things should go here.\n",
    "    \n",
    "    \n",
    "    numComponents = len(components)\n",
    "    numComponentsDigits = np.int(np.ceil(np.log10(numComponents)))\n",
    "    \n",
    "    newComponent = deepcopy(componentTemplate)\n",
    "    newComponents = []\n",
    "    newComponentLengths = []\n",
    "    newComponentNucleotides = []\n",
    "\n",
    "    newFromComponentLinks = {}\n",
    "    newToComponentLinks = {}\n",
    "    \n",
    "    collapsibleBlocksUpdate = []\n",
    "\n",
    "    occupants = set()\n",
    "    #nucleotides = '' \n",
    "    newToOldInd = [[]]\n",
    "    oldToNewInd = []\n",
    "    \n",
    "    binMeanOcc = {}\n",
    "    binMeanInv = {}\n",
    "    binOcc = {}\n",
    "    binInv = {}\n",
    "    binPosArray = {}\n",
    "    binAnn = {}\n",
    "    \n",
    "    binColStarts = []\n",
    "    binColEnds = []\n",
    "    binColLengths = []\n",
    "    binBlockLength = 0\n",
    "    binBlockLengths = []\n",
    "\n",
    "    matrix = {}\n",
    "    nBins = 0\n",
    "    nCols = 0\n",
    "\n",
    "    starts = set()\n",
    "    ends = set()\n",
    "\n",
    "    prevOcc = {}\n",
    "    prevInv = {}\n",
    "    \n",
    "    compAccDir = {}\n",
    "    \n",
    "    for compNum,component in enumerate(components):\n",
    "        \n",
    "#         if zoomLevel==16:\n",
    "#             pdb.set_trace()\n",
    "        \n",
    "        if debug or debugTime:\n",
    "            print(f'Processing component {compNum+1:0{numComponentsDigits}}/{numComponents:0{numComponentsDigits}}')\n",
    "        else:\n",
    "            print(f'\\nProcessing component {compNum+1:0{numComponentsDigits}}/{numComponents:0{numComponentsDigits}}',end='')\n",
    "        \n",
    "        forwardPaths = set(range(len(graph.accessions)))\n",
    "        invertedPaths = set()\n",
    "        \n",
    "        oldToNewInd.append([]) # len(newComponents)\n",
    "        newToOldInd[-1].append(compNum)\n",
    "        occupants.update(component['occupants'])\n",
    "        starts.update(component.get('starts',[]))\n",
    "        ends.update(component.get('ends',[]))\n",
    "        for binNum in range(0,component['last_bin']-component['first_bin']+1):\n",
    "            if binBlockLength>0:\n",
    "                binColStart = min(binColStart,component['binColStarts'][binNum])\n",
    "                binColEnd = max(binColEnd,component['binColEnds'][binNum])\n",
    "            else:\n",
    "                binColStart = component['binColStarts'][binNum]\n",
    "                binColEnd = component['binColEnds'][binNum]\n",
    "\n",
    "            binColLengths.append(component['binsToCols'][binNum])\n",
    "            binBlockLength += binColLengths[-1]\n",
    "            for pathID,compInvBin,pathMatrix in component['matrix']:\n",
    "                if compInvBin==1:\n",
    "                    invertedPaths.add(pathID)\n",
    "                    forwardPaths -= set([pathID])\n",
    "                    compAccDir.setdefault(compNum,{})[pathID]='-'\n",
    "                else:\n",
    "                    compAccDir.setdefault(compNum,{})[pathID]='+'\n",
    "                occupiedBins = pathMatrix[0]\n",
    "                binsMatrix = pathMatrix[1]\n",
    "                try:\n",
    "                    # TODO: For inverted columns reading should happen from the other side to the front.\n",
    "                    if compInvBin==1:\n",
    "                        binPos = occupiedBins.index(componentLengths[compNum] - 1 - binNum)\n",
    "                    else:\n",
    "                        binPos = occupiedBins.index(binNum)\n",
    "                        \n",
    "                    binOcc.setdefault(pathID,[]).append(binsMatrix[binPos][0])\n",
    "                    binInv.setdefault(pathID,[]).append(binsMatrix[binPos][1])\n",
    "                    binPosArray.setdefault(pathID,[]).extend(binsMatrix[binPos][2])\n",
    "                    binAnn.setdefault(pathID,set()).update(binsMatrix[binPos][3])\n",
    "                    \n",
    "#                     binColLengths.setdefault(pathID,[]).append(binColLength)\n",
    "#                     binBlockLengthAddition = max([binBlockLengthAddition,binColLength])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            if binBlockLength >= zoomLevel:\n",
    "                # Probably this needs to be changed to binBlockLength + current bin size >= zoomLevel and \n",
    "                # not include the current bin into the new bin.\n",
    "                \n",
    "                # If bin got equal or larger than target zoom level bin size \n",
    "                # (it can grow over by less than previous zoom level)\n",
    "                # then bin is closing and new bin will be formed.\n",
    "                [binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,binAnn,nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,matrix,prevOcc,prevInv,\n",
    "                    newComponent,newComponents,newComponentLengths,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,collapsibleBlocksUpdate,\n",
    "                    starts,ends,newToOldInd,oldToNewInd] = \\\n",
    "                finaliseBinZoom(compNum,binOcc,binInv,binPosArray,binAnn,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    prevOcc,prevInv,\n",
    "                    newComponent,newComponents,newComponentLengths,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,collapsibleBlocksUpdate,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "\n",
    "            if nBins==maxLengthComponent:\n",
    "#                 if component['first_bin']==14889:\n",
    "#                     pdb.set_trace()\n",
    "                # Break component due to length\n",
    "#                 pdb.set_trace()\n",
    "                # Finalise bin\n",
    "#                 if binBlockLength>0:\n",
    "#                     [binColLengths,binOcc,binInv,binPosArray,binAnn,nBins,nCols,binBlockLength,binBlockLengths,matrix,prevOcc,prevInv,\n",
    "#                         newComponent,newComponents,newComponentLengths,\n",
    "#                         newFromComponentLinks,newToComponentLinks,\n",
    "#                         occupants,collapsibleBlocksUpdate,\n",
    "#                         starts,ends,newToOldInd,oldToNewInd] = \\\n",
    "#                     finaliseBinZoom(compNum,binOcc,binInv,binPosArray,binAnn,\n",
    "#                         nBins,nCols,\n",
    "#                         binBlockLength,binColLengths,binBlockLengths,\n",
    "#                         matrix,\n",
    "#                         prevOcc,prevInv,\n",
    "#                         newComponent,newComponents,newComponentLengths,\n",
    "#                         newFromComponentLinks,newToComponentLinks,\n",
    "#                         occupants,collapsibleBlocksUpdate,\n",
    "#                         starts,ends,\n",
    "#                         forwardPaths,invertedPaths,\n",
    "#                         newToOldInd,oldToNewInd,\n",
    "#                         inversionThreshold=inversionThreshold)\n",
    "                \n",
    "                if nBins>0:\n",
    "                \n",
    "                    # Add links from current component to the next one\n",
    "                    if len(forwardPaths)>0:\n",
    "                        addLink(len(newComponents)+1,'+',len(newComponents)+2,'+',forwardPaths,newFromComponentLinks,newToComponentLinks)\n",
    "                    if len(invertedPaths)>0:\n",
    "                        addLink(len(newComponents)+2,'-',len(newComponents)+1,'-',invertedPaths,newFromComponentLinks,newToComponentLinks)\n",
    "                    # Add new element to newToOldInd\n",
    "                    \n",
    "                    if binNum==componentLengths[compNum]-1:\n",
    "                        newToOldInd.append([])\n",
    "                    else:\n",
    "                        newToOldInd.append([compNum])\n",
    "                    # Add number of next element to oldToNewInd\n",
    "                    oldToNewInd[-1].append(len(newComponents))\n",
    "                    \n",
    "#                     keepNucl = nucleotides[-1]\n",
    "                    # close component\n",
    "\n",
    "                    newComponent,newComponents,newComponentLengths,\\\n",
    "                    nBins,nCols,occupants,binBlockLengths,binColStarts,binColEnds,\\\n",
    "                    matrix,starts,ends = \\\n",
    "                        finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "                                              nBins,nCols,occupants,binBlockLengths,\n",
    "                                              binColStarts,binColEnds,\n",
    "                                              matrix,starts,ends,\n",
    "                                              forwardPaths,invertedPaths,inversionThreshold=inversionThreshold)\n",
    "#                     nucleotides = keepNucl\n",
    "                    occupants = set(component['occupants'])\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        isEndBreak = isStartEnd(compNum,components)\n",
    "        \n",
    "        if isEndBreak and binBlockLength>0:\n",
    "            [binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,binAnn,nBins,nCols,\n",
    "            binBlockLength,binBlockLengths,matrix,prevOcc,prevInv,\n",
    "            newComponent,newComponents,newComponentLengths,\n",
    "            newFromComponentLinks,newToComponentLinks,\n",
    "            occupants,collapsibleBlocksUpdate,\n",
    "            starts,ends,newToOldInd,oldToNewInd] = \\\n",
    "                finaliseBinZoom(compNum,binOcc,binInv,binPosArray,binAnn,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    prevOcc,prevInv,\n",
    "                    newComponent,newComponents,newComponentLengths,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,collapsibleBlocksUpdate,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "            \n",
    "        if compNum==len(components)-1:\n",
    "            # Close the bin\n",
    "            if binBlockLength>0:\n",
    "                [binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,binAnn,nBins,nCols,\n",
    "                binBlockLength,binBlockLengths,matrix,prevOcc,prevInv,\n",
    "                newComponent,newComponents,newComponentLengths,\n",
    "                newFromComponentLinks,newToComponentLinks,\n",
    "                occupants,collapsibleBlocksUpdate,\n",
    "                starts,ends,newToOldInd,oldToNewInd] = \\\n",
    "                    finaliseBinZoom(compNum,binOcc,binInv,binPosArray,binAnn,\n",
    "                        nBins,nCols,\n",
    "                        binBlockLength,binBlockLengths,binColLengths,\n",
    "                        binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                        matrix,\n",
    "                        prevOcc,prevInv,\n",
    "                        newComponent,newComponents,newComponentLengths,\n",
    "                        newFromComponentLinks,newToComponentLinks,\n",
    "                        occupants,collapsibleBlocksUpdate,\n",
    "                        starts,ends,\n",
    "                        forwardPaths,invertedPaths,\n",
    "                        newToOldInd,oldToNewInd,\n",
    "                        inversionThreshold=inversionThreshold)\n",
    "#                 [binColLengths,binOcc,binInv,binPosArray,binAnn,nBins,nCols,binBlockLength,binBlockLengths,matrix,prevOcc,prevInv,\n",
    "#                     newComponent,newComponents,newComponentLengths,\n",
    "#                     newFromComponentLinks,newToComponentLinks,\n",
    "#                     occupants,collapsibleBlocksUpdate,\n",
    "#                     starts,ends,newToOldInd,oldToNewInd] = \\\n",
    "#                 finaliseBinZoom(compNum,binOcc,binInv,binPosArray,binAnn,\n",
    "#                     nBins,nCols,\n",
    "#                     binBlockLength,binColLengths,binBlockLengths,\n",
    "#                     matrix,\n",
    "#                     prevOcc,prevInv,\n",
    "#                     newComponent,newComponents,newComponentLengths,\n",
    "#                     newFromComponentLinks,newToComponentLinks,\n",
    "#                     occupants,collapsibleBlocksUpdate,\n",
    "#                     starts,ends,\n",
    "#                     forwardPaths,invertedPaths,\n",
    "#                     newToOldInd,oldToNewInd,\n",
    "#                     inversionThreshold=inversionThreshold)\n",
    "            \n",
    "            # break the last component\n",
    "            if nBins>0:\n",
    "                \n",
    "                oldToNewInd[-1].append(len(newComponents))\n",
    "                \n",
    "                newComponent,newComponents,newComponentLengths,\\\n",
    "                nBins,nCols,occupants,binBlockLengths,binColStarts,binColEnds,\\\n",
    "                matrix,starts,ends = \\\n",
    "                    finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "                                          nBins,nCols,occupants,binBlockLengths,\n",
    "                                          binColStarts,binColEnds,\n",
    "                                          matrix,starts,ends,\n",
    "                                          range(len(graph.accessions)),range(len(graph.accessions)),inversionThreshold=inversionThreshold)\n",
    "\n",
    "        elif any(checkForBreaksZoom(zoomLevel,compNum,components,fromComponentLinks,toComponentLinks)):\n",
    "            # Break at the end of the component because of the links\n",
    "#             pdb.set_trace()\n",
    "            if binBlockLength>0:\n",
    "                [binColLengths,binColStarts,binColEnds,binOcc,binInv,binPosArray,binAnn,nBins,nCols,\n",
    "                binBlockLength,binBlockLengths,matrix,prevOcc,prevInv,\n",
    "                newComponent,newComponents,newComponentLengths,\n",
    "                newFromComponentLinks,newToComponentLinks,\n",
    "                occupants,collapsibleBlocksUpdate,\n",
    "                starts,ends,newToOldInd,oldToNewInd] = \\\n",
    "                finaliseBinZoom(compNum,binOcc,binInv,binPosArray,binAnn,\n",
    "                    nBins,nCols,\n",
    "                    binBlockLength,binBlockLengths,binColLengths,\n",
    "                    binColStart,binColStarts,binColEnd,binColEnds,\n",
    "                    matrix,\n",
    "                    prevOcc,prevInv,\n",
    "                    newComponent,newComponents,newComponentLengths,\n",
    "                    newFromComponentLinks,newToComponentLinks,\n",
    "                    occupants,collapsibleBlocksUpdate,\n",
    "                    starts,ends,\n",
    "                    forwardPaths,invertedPaths,\n",
    "                    newToOldInd,oldToNewInd,\n",
    "                    inversionThreshold=inversionThreshold)\n",
    "            \n",
    "#                 [binColLengths,binOcc,binInv,binPosArray,binAnn,nBins,nCols,binBlockLength,binBlockLengths,matrix,prevOcc,prevInv,\n",
    "#                     newComponent,newComponents,newComponentLengths,\n",
    "#                     newFromComponentLinks,newToComponentLinks,\n",
    "#                     occupants,collapsibleBlocksUpdate,\n",
    "#                     starts,ends,newToOldInd,oldToNewInd] = \\\n",
    "#                 finaliseBinZoom(compNum,binOcc,binInv,binPosArray,binAnn,\n",
    "#                     nBins,nCols,\n",
    "#                     binBlockLength,binColLengths,binBlockLengths,\n",
    "#                     matrix,\n",
    "#                     prevOcc,prevInv,\n",
    "#                     newComponent,newComponents,newComponentLengths,\n",
    "#                     newFromComponentLinks,newToComponentLinks,\n",
    "#                     occupants,collapsibleBlocksUpdate,\n",
    "#                     starts,ends,\n",
    "#                     forwardPaths,invertedPaths,\n",
    "#                     newToOldInd,oldToNewInd,\n",
    "#                     inversionThreshold=inversionThreshold)\n",
    "            \n",
    "            # Break component\n",
    "            if nBins>0:\n",
    "                \n",
    "                newToOldInd.append([])\n",
    "                oldToNewInd[-1].append(len(newComponents))\n",
    "                \n",
    "                newComponent,newComponents,newComponentLengths,\\\n",
    "                nBins,nCols,occupants,binBlockLengths,binColStarts,binColEnds,\\\n",
    "                matrix,starts,ends = \\\n",
    "                    finaliseComponentZoom(newComponent,newComponents,newComponentLengths,\n",
    "                                          nBins,nCols,occupants,binBlockLengths,\n",
    "                                          binColStarts,binColEnds,\n",
    "                                          matrix,starts,ends,\n",
    "                                          range(len(graph.accessions)),range(len(graph.accessions)),inversionThreshold=inversionThreshold)\n",
    "                \n",
    "        elif nBins>0 or binBlockLength>0:\n",
    "            oldToNewInd[-1].append(len(newComponents))\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    \n",
    "    newFromComponentLinks,newToComponentLinks,accStarts,accEnds,collapsibleBlocks = \\\n",
    "        updateLinks(newToOldInd,oldToNewInd,fromComponentLinks,toComponentLinks,collapsibleBlocks,accStarts,accEnds,\n",
    "                    newComponents,compAccDir,newFromComponentLinks,newToComponentLinks)\n",
    "    \n",
    "    collapsibleBlocks.extend(collapsibleBlocksUpdate)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return newComponents,newComponentLengths,\\\n",
    "            newFromComponentLinks,newToComponentLinks,\\\n",
    "            accStarts,accEnds,collapsibleBlocks\n",
    "#,newToOldInd,oldToNewInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def splitPositiveNegative(compID,accs,components):\n",
    "    '''\n",
    "    This function simply pulls all accession presented in the component and split them into forward and inversed.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    `compID`: int. Number of the component in the current zoom layer (0-based).\n",
    "    `accs`: int or Iterable. Should provide either overall number of accession/paths in the graph or \n",
    "            a list of all (intended) accessions for the given component. It is used only for carrying over links \n",
    "            through empty components for some accessions.\n",
    "    `components`: list[dict]. List of component dictionaries, one of the main data structure representing zoom layer.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    `posAcc`: list[int]. IDs of accession which has forward direction in given component.\n",
    "    `negAcc`: list[int]. IDs of accession which has inverse direction in given component.\n",
    "    \n",
    "    '''\n",
    "    if isinstance(accs,int):\n",
    "        emptyAcc = set(range(accs))\n",
    "    elif isinstance(accs,Iterable):\n",
    "        emptyAcc = set(accs)\n",
    "    else:\n",
    "        raise TypeError(f'`accs` should be either int or Iterable, but {type(accs)} was given.')\n",
    "    posAcc = []\n",
    "    negAcc = []\n",
    "    for pathID,pathInversion,_ in components[compID]['matrix']:\n",
    "        emptyAcc -= set([pathID])\n",
    "        if pathInversion==1:\n",
    "            negAcc.append(pathID)\n",
    "        else:\n",
    "            posAcc.append(pathID)\n",
    "    \n",
    "#     for pathID in allAcc:\n",
    "#         negAcc.append(pathID)\n",
    "#         posAcc.append(pathID)\n",
    "    \n",
    "    return posAcc,negAcc,emptyAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def intersectAccLists(accList,dirDict):\n",
    "    overallLinkAccList = set()\n",
    "    for linkAccList in dirDict.values():\n",
    "        overallLinkAccList.update(linkAccList)\n",
    "    return set(accList).intersection(overallLinkAccList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def updateLinks(newToOldInd,oldToNewInd,\n",
    "                fromComponentLinks,toComponentLinks,\n",
    "                collapsibleBlocks,accStarts,accEnds,components,compAccDir,\n",
    "                newFromComponentLinks={},newToComponentLinks={}):\n",
    "    '''\n",
    "    newToOldInd and oldToNewInd: both index and values are 0-based numbers of components \n",
    "    in previous and current zoomlayer.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for newComp,oldCompList in enumerate(newToOldInd):\n",
    "        \n",
    "        \n",
    "        leftOldCompId = oldCompList[0] + 1\n",
    "        rightOldCompId = oldCompList[-1] + 1\n",
    "        newCompId = newComp + 1\n",
    "        \n",
    "        newCompPosAcc,newCompNegAcc,newCompEmptyAcc = splitPositiveNegative(newComp,list(accStarts.keys()),components)\n",
    "        \n",
    "        # The next two if blocks set conditions for processing or not processing left and right of the current new component\n",
    "        # The side should not be processed if the end of the previous node is coming from the same component \n",
    "        # (on lower zoom level) as the begininng of the current component.\n",
    "        if newComp>0:\n",
    "            if oldCompList[0]==newToOldInd[newComp-1][-1]:\n",
    "                doLeft = False\n",
    "            else:\n",
    "                doLeft = True\n",
    "        else:\n",
    "            doLeft = True\n",
    "            \n",
    "        if newComp<len(newToOldInd)-1:\n",
    "            if oldCompList[-1]==newToOldInd[newComp+1][0]:\n",
    "                doRight = False\n",
    "            else:\n",
    "                doRight = True\n",
    "        else:\n",
    "            doRight = True\n",
    "        \n",
    "        # Departure on the right (from positive block)\n",
    "        if doRight:\n",
    "#             for fromComp in [leftOldCompId,rightOldCompId]:\n",
    "            fromComp = rightOldCompId\n",
    "            for toCompDict in fromComponentLinks.get(fromComp,{}).values():\n",
    "                for toOldComp,toOldCompDirDict in toCompDict.items():\n",
    "                    # To positive strand\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][0]\n",
    "                    toCompPosAcc,toCompNegAcc,toCompEmptyAcc = splitPositiveNegative(toNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[toNewCompId][0]==toOldComp-1:\n",
    "                        # Getting accession list which come out from positive and goes to positive.\n",
    "                        accList = intersectAccLists(list(set(newCompPosAcc).intersection(toCompPosAcc)),\n",
    "                                                    toOldCompDirDict)\n",
    "    #                     accList = list(set(newCompPosAcc).intersection(toCompPosAcc).intersection(toOldCompDirDict.get('+',[])))\n",
    "\n",
    "                        if len(accList)>0:\n",
    "                            if not(toNewCompId+1==newCompId and \\\n",
    "                                (fromComp-1!=newToOldInd[toNewCompId][-1] or toOldComp-1!=newToOldInd[toNewCompId][0])):\n",
    "                                # If the link is self loop (which happens sometimes), then it has to come out from right component\n",
    "                                # and go to the left component, otherwise it should not be carried forward.\n",
    "                                addLink(newCompId,'+',toNewCompId+1,'+',\n",
    "                                        accList,\n",
    "                                        newFromComponentLinks,newToComponentLinks)\n",
    "                        \n",
    "                        ### Wrap creating empty links into a separate function!!!\n",
    "                        if fromComp+1==toOldComp and newCompId+1==toNewCompId+1:\n",
    "                            continuityLinks = set(fromComponentLinks.get(fromComp,{}).get('+',{}).get(fromComp+1,{}).get('+',[]))\n",
    "                            emptyLinks = (set(newCompPosAcc)|set(newCompEmptyAcc)).intersection(set(toCompPosAcc)|set(toCompEmptyAcc)).intersection(continuityLinks)\n",
    "                            if len(emptyLinks)>0:\n",
    "                                addLink(newCompId,'+',toNewCompId+1,'+',emptyLinks,newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                    # To negative strand\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][-1]\n",
    "                    toCompPosAcc,toCompNegAcc,toCompEmptyAcc = splitPositiveNegative(toNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[toNewCompId][-1]==toOldComp-1:\n",
    "                        # Getting accession list which come out from positive and goes to negative.\n",
    "                        accList = intersectAccLists(list(set(newCompPosAcc).intersection(toCompNegAcc)),\n",
    "                                                    toOldCompDirDict)\n",
    "    #                     accList = list(set(newCompPosAcc).intersection(toCompNegAcc).intersection(toOldCompDirDict.get('-',[])))\n",
    "                        if len(accList)>0:\n",
    "                            addLink(newCompId,'+',toNewCompId+1,'-',\n",
    "                                    accList,\n",
    "                                    newFromComponentLinks,newToComponentLinks)\n",
    "        \n",
    "        # Departure on the left (from negative block)\n",
    "        if doLeft:\n",
    "#             for fromComp in [leftOldCompId,rightOldCompId]:\n",
    "            fromComp = leftOldCompId\n",
    "#             toCompDict = fromComponentLinks.get(fromComp,{}).get('-',{})\n",
    "            for toCompDict in fromComponentLinks.get(fromComp,{}).values():\n",
    "                for toOldComp,toOldCompDirDict in toCompDict.items():\n",
    "                    # To positive strand\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][0]\n",
    "                    toCompPosAcc,toCompNegAcc,toCompEmptyAcc = splitPositiveNegative(toNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[toNewCompId][0]==toOldComp-1:\n",
    "                        # Getting accession list which come out from negative and goes to positive.\n",
    "                        accList = intersectAccLists(list(set(newCompNegAcc).intersection(toCompPosAcc)),\n",
    "                                                    toOldCompDirDict)\n",
    "    #                     accList = list(set(newCompNegAcc).intersection(toCompPosAcc).intersection(toOldCompDirDict.get('+',[])))\n",
    "                        if len(accList)>0:\n",
    "                            addLink(newCompId,'-',toNewCompId+1,'+',\n",
    "                                    accList,\n",
    "                                    newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                    # to Negative strand\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][-1]\n",
    "                    toCompPosAcc,toCompNegAcc,toCompEmptyAcc = splitPositiveNegative(toNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[toNewCompId][-1]==toOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompNegAcc).intersection(toCompNegAcc)),\n",
    "                                                    toOldCompDirDict)\n",
    "    #                     accList = list(set(newCompNegAcc).intersection(toCompNegAcc).intersection(toOldCompDirDict.get('-',[])))\n",
    "                        if len(accList)>0:\n",
    "                            if not (toNewCompId+1==newCompId and \\\n",
    "                                (fromComp-1!=newToOldInd[toNewCompId][0] or toOldComp-1!=newToOldInd[toNewCompId][-1])):\n",
    "                                # If the link is self loop (which happens sometimes), then it has to come out from left component\n",
    "                                # and go to the right component, otherwise it should not be carried forward.\n",
    "                                addLink(newCompId,'-',toNewCompId+1,'-',\n",
    "                                        accList,\n",
    "                                        newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                        if fromComp-1==toOldComp and newCompId-1==toNewCompId+1:\n",
    "                            continuityLinks = set(fromComponentLinks.get(fromComp,{}).get('-',{}).get(fromComp+1,{}).get('-',[]))\n",
    "                            emptyLinks = (set(newCompNegAcc)|set(newCompEmptyAcc)).intersection(set(toCompNegAcc)|set(toCompEmptyAcc)).intersection(continuityLinks)\n",
    "                            if len(emptyLinks)>0:\n",
    "                                addLink(newCompId,'-',toNewCompId+1,'-',emptyLinks,newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "\n",
    "        # Arrival on the left (to positive block)\n",
    "        if doLeft:\n",
    "#             for toComp in [leftOldCompId,rightOldCompId]:\n",
    "            toComp = leftOldCompId\n",
    "#             fromCompDict = toComponentLinks.get(toComp,{}).get('+',{})\n",
    "            for fromCompDict in toComponentLinks.get(toComp,{}).values():\n",
    "                for fromOldComp,fromOldCompDirDict in fromCompDict.items():\n",
    "                    # From positive strand\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][-1]\n",
    "                    fromCompPosAcc,fromCompNegAcc,fromCompEmptyAcc = splitPositiveNegative(fromNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the from comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[fromNewCompId][-1]==fromOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompPosAcc).intersection(fromCompPosAcc)),\n",
    "                                                    fromOldCompDirDict)\n",
    "    #                     accList = list(set(newCompPosAcc).intersection(fromCompPosAcc).intersection(fromOldCompDirDict.get('+',[])))\n",
    "                        if len(accList)>0:\n",
    "                            if not (fromNewCompId+1==newCompId and \\\n",
    "                                (fromOldComp-1!=newToOldInd[fromNewCompId][-1] or toComp-1!=newToOldInd[fromNewCompId][0])):\n",
    "                                # If the link is self loop (which happens sometimes), then it has to come out from right component\n",
    "                                # and go to the left component, otherwise it should not be carried forward.\n",
    "                                addLink(fromNewCompId+1,'+',newCompId,'+',\n",
    "                                        accList,\n",
    "                                        newFromComponentLinks,newToComponentLinks)\n",
    "                        if toComp-1==fromOldComp and newCompId-1==fromNewCompId+1:\n",
    "                            continuityLinks = set(toComponentLinks.get(toComp,{}).get('+',{}).get(toComp-1,{}).get('+',[]))\n",
    "                            emptyLinks = (set(newCompPosAcc)|set(newCompEmptyAcc)).intersection(set(fromCompPosAcc)|set(fromCompEmptyAcc)).intersection(continuityLinks)\n",
    "                            if len(emptyLinks)>0:\n",
    "                                addLink(fromNewCompId+1,'+',newCompId,'+',emptyLinks,newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                    # From negative strand\n",
    "                    # Getting to comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][0]\n",
    "                    fromCompPosAcc,fromCompNegAcc,fromCompEmptyAcc = splitPositiveNegative(fromNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[fromNewCompId][0]==fromOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompPosAcc).intersection(fromCompNegAcc)),\n",
    "                                                    fromOldCompDirDict)\n",
    "    #                     accList = list(set(newCompPosAcc).intersection(fromCompNegAcc).intersection(fromOldCompDirDict.get('-',[])))\n",
    "                        if len(accList)>0:\n",
    "                            addLink(fromNewCompId+1,'-',newCompId,'+',\n",
    "                                    accList,\n",
    "                                    newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "        if doRight:\n",
    "            # Arrival on the right (to negative block)\n",
    "#             for toComp in [leftOldCompId,rightOldCompId]:\n",
    "            toComp = rightOldCompId\n",
    "#             fromCompDict = toComponentLinks.get(toComp,{}).get('-',{})\n",
    "            for fromCompDict in toComponentLinks.get(toComp,{}).values():\n",
    "                for fromOldComp,fromOldCompDirDict in fromCompDict.items():\n",
    "                    # From positive strand\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][-1]\n",
    "                    fromCompPosAcc,fromCompNegAcc,fromCompEmptyAcc = splitPositiveNegative(fromNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the from comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[fromNewCompId][0]==fromOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompNegAcc).intersection(fromCompPosAcc)),\n",
    "                                                    fromOldCompDirDict)\n",
    "    #                     accList = list(set(newCompNegAcc).intersection(fromCompPosAcc).intersection(fromOldCompDirDict.get('+',[])))\n",
    "                        if len(accList)>0:\n",
    "                            addLink(fromNewCompId+1,'+',newCompId,'-',\n",
    "                                    accList,\n",
    "                                    newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                    # From negative strand\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][0]\n",
    "                    fromCompPosAcc,fromCompNegAcc,fromCompEmptyAcc = splitPositiveNegative(fromNewCompId,list(accStarts.keys()),components)\n",
    "                    # Check whether the from comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[fromNewCompId][-1]==fromOldComp-1:\n",
    "                        accList = intersectAccLists(list(set(newCompNegAcc).intersection(fromCompNegAcc)),\n",
    "                                                    fromOldCompDirDict)\n",
    "    #                     accList = list(set(newCompNegAcc).intersection(fromCompNegAcc).intersection(fromOldCompDirDict.get('-',[])))\n",
    "                        if len(accList)>0:\n",
    "                            if not (fromNewCompId+1==newCompId and \\\n",
    "                                (fromOldComp-1!=newToOldInd[fromNewCompId][0] or toComp-1!=newToOldInd[fromNewCompId][-1])):\n",
    "                                # If the link is self loop (which happens sometimes), then it has to come out from left component\n",
    "                                # and go to the right component, otherwise it should not be carried forward.\n",
    "                                addLink(fromNewCompId+1,'-',newCompId,'-',\n",
    "                                        accList,\n",
    "                                        newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "                        if toComp+1==fromOldComp and newCompId+1==fromNewCompId+1:\n",
    "                            continuityLinks = set(toComponentLinks.get(toComp,{}).get('-',{}).get(toComp-1,{}).get('-',[]))\n",
    "                            emptyLinks = (set(newCompNegAcc)|set(newCompEmptyAcc)).intersection(set(fromCompNegAcc)|set(fromCompEmptyAcc)).intersection(continuityLinks)\n",
    "                            if len(emptyLinks)>0:\n",
    "                                addLink(fromNewCompId+1,'-',newCompId,'-',emptyLinks,newFromComponentLinks,newToComponentLinks)\n",
    "    \n",
    "    for acc in accStarts.keys():\n",
    "        accStarts[acc] = oldToNewInd[accStarts[acc]-1][0]+1\n",
    "        accEnds[acc] = oldToNewInd[accEnds[acc]-1][0]+1\n",
    "        \n",
    "    for blockID,[accessionID,blockLength,associatedLinks,associatedComponents] in enumerate(collapsibleBlocks):\n",
    "#         if zoomLevel==144 and accessionID==13 and blockLength==378:\n",
    "#             pdb.set_trace()\n",
    "        collapsibleBlocks[blockID] = (accessionID,blockLength,\n",
    "                  [(oldToNewInd[link[0]-1][0 if compAccDir[link[0]-1].get(accessionID,'+')=='-' else -1]+1,\\\n",
    "                    oldToNewInd[link[1]-1][0 if compAccDir[link[1]-1].get(accessionID,'+')=='+' else -1]+1) \\\n",
    "                   for link in associatedLinks],\n",
    "                  [compID+1 for comp in associatedComponents for compID in oldToNewInd[comp-1]])\n",
    "    \n",
    "    return newFromComponentLinks,newToComponentLinks,accStarts,accEnds,collapsibleBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calcLengthBlock(startComp,endComp,components):\n",
    "    blockLength = 0\n",
    "    for comp in range(startComp,endComp+1):\n",
    "        blockLength += compLength(comp,components)\n",
    "        \n",
    "    return blockLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components):\n",
    "    \n",
    "    # Potentially, we need to change this process to use actual paths and take into account the cardinalities/relation of the arrows\n",
    "    # This will make it slower, but more accurate. That also will make linking through removed links more accurate as well.\n",
    "    \n",
    "    blockSet = set()\n",
    "    \n",
    "    accessionFromLinks = fromComponentLinksAcc[accID]\n",
    "    compDir = accCompDir[accID]\n",
    "    endComp = accEnds[accID]\n",
    "    \n",
    "    block = [toComp]\n",
    "    blockLength = compLength(toComp,components)\n",
    "    associatedLinks = set()\n",
    "    if fromComp is not None:\n",
    "        associatedLinks.add((fromComp,toComp))\n",
    "    \n",
    "    curComp = toComp\n",
    "    \n",
    "    while True:\n",
    "        nextCompList = np.array(list(accessionFromLinks.get(curComp,set())))\n",
    "#         distToNextComp = nextCompList-curComp # Do I need it?\n",
    "        \n",
    "        nextCompFollow = None\n",
    "        linksToAssociate = set()\n",
    "        \n",
    "        if compDir[curComp]=='+':\n",
    "            for nextComp in nextCompList:\n",
    "                if compDir[nextComp]=='+' and nextComp==curComp+1:\n",
    "                    nextCompFollow = nextComp\n",
    "                else:\n",
    "                    linksToAssociate.add((curComp,nextComp))\n",
    "        elif compDir[curComp]=='-':\n",
    "            for nextComp in nextCompList:\n",
    "              \n",
    "                if compDir[nextComp]=='-' and nextComp==curComp-1:\n",
    "                    nextCompFollow = nextComp\n",
    "                else:\n",
    "                    linksToAssociate.add((curComp,nextComp))\n",
    "\n",
    "        if nextCompFollow:\n",
    "#             if len(linksToAssociate)==0:\n",
    "#                 pdb.set_trace()\n",
    "            if len(linksToAssociate)>0:\n",
    "                # This row adds collapsible block for the case where we can continue to follow the block, but the there is an outgoing arrow\n",
    "                # This usually happens in case of partial repeats.\n",
    "                # There two options here:\n",
    "                # - add associatedLinks, which contains original incoming arrow. In this case original incoming arrow will be removed with the smallest block\n",
    "                # - do not add associatedLinks. In this case, the original incoming arrow will be removed only with the largest block.\n",
    "                blockSet.add((accID,blockLength,tuple(associatedLinks | linksToAssociate),tuple(deepcopy(block))))\n",
    "        else:\n",
    "            # Potentially, we would want to stop the block following if we found another incoming arrow, \n",
    "            # but that is not that simple as this can cause breaking of large repeat due to small extra repeat inside.\n",
    "            associatedLinks.update(linksToAssociate)\n",
    "            break\n",
    "        \n",
    "        blockLength += compLength(nextCompFollow,components)\n",
    "        block.append(nextCompFollow)\n",
    "        curComp = nextCompFollow\n",
    "    \n",
    "#     if len(associatedLinks)==0:\n",
    "#         pdb.set_trace()\n",
    "    if curComp!=endComp:\n",
    "        blockSet.add((accID,blockLength,tuple(associatedLinks),tuple(block)))\n",
    "        \n",
    "    if fromComp is not None:\n",
    "        if np.abs(toComp-fromComp)>1:\n",
    "            if fromComp<toComp:\n",
    "                blockSet.add((accID,calcLengthBlock(fromComp+1,toComp-1,components),tuple([(fromComp,toComp)]),tuple(list(range(fromComp+1,toComp)))))\n",
    "            elif fromComp>toComp:\n",
    "                blockSet.add((accID,calcLengthBlock(toComp+1,fromComp-1,components),tuple([(fromComp,toComp)]),tuple(list(range(toComp+1,fromComp)))))\n",
    "    \n",
    "    return blockSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def updateCollapsibleBlockDict(collapsibleBlocks,listOfUpdates):\n",
    "    for accessionID,blockLength,associatedLinks,associatedBlocks in listOfUpdates:\n",
    "        lengthAccessionComb = collapsibleBlocks.setdefault(blockLength,{}).setdefault(accessionID,(set(),set()))\n",
    "        lengthAccessionComb[0].update(associatedLinks)\n",
    "        lengthAccessionComb[1].update(associatedBlocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def identifyCollapsibleBlocks(toComponentLinks,fromComponentLinksAcc,components,accStarts,accEnds,accCompDir):\n",
    "    print('Identifying collapsible blocks!')\n",
    "    \n",
    "    collapsibleBlocks = {}\n",
    "#     collapsibleBlocks = set()\n",
    "#     blockStarts = set()\n",
    "    for toComp,toStrandDict in toComponentLinks.items():\n",
    "        for toStrand,fromCompDict in toStrandDict.items():\n",
    "            for fromComp,fromStrandDict in fromCompDict.items():\n",
    "                for fromStrand,accessionSet in fromStrandDict.items():\n",
    "                    if toStrand!=fromStrand:\n",
    "                        for accID in accessionSet:\n",
    "                            # collapsibleBlocks.update(processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                            updateCollapsibleBlockDict(collapsibleBlocks,\n",
    "                                                       processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                                                                                                              \n",
    "                    elif toStrand=='+' and fromComp+1!=toComp:\n",
    "                        for accID in accessionSet:\n",
    "                            # collapsibleBlocks.update(processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                            updateCollapsibleBlockDict(collapsibleBlocks,\n",
    "                                                       processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                    elif toStrand=='-' and fromComp-1!=toComp:\n",
    "                        for accID in accessionSet:\n",
    "                            # collapsibleBlocks.update(processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                            updateCollapsibleBlockDict(collapsibleBlocks,\n",
    "                                                       processBlock(fromComp,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "                            \n",
    "#     for accID,toComp in accStarts.items():\n",
    "#         # collapsibleBlocks.update(processBlock(None,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "#         updateCollapsibleBlockDict(collapsibleBlocks,\n",
    "#                                    processBlock(None,toComp,accID,accEnds,accCompDir,fromComponentLinksAcc,components))\n",
    "    \n",
    "    _collapsibleBlocks = []\n",
    "    for blockLength,accessionDict in collapsibleBlocks.items():\n",
    "        for accessionID,[associatedLinksSet,associatedCompSet] in accessionDict.items():\n",
    "            _collapsibleBlocks.append((accessionID,blockLength,list(associatedLinksSet),list(associatedCompSet)))\n",
    "    \n",
    "    print(f'Identified {len(_collapsibleBlocks)} collapsible block lengths')\n",
    "    return _collapsibleBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compLinksToAccCompLinks(compLinks,doCompDir=False):\n",
    "    accCompLinks = {}\n",
    "    if doCompDir:\n",
    "        accCompDir = {}\n",
    "    \n",
    "    for comp1,comp1Dict in compLinks.items():\n",
    "        for strand1,strand1Dict in comp1Dict.items():\n",
    "            for comp2,comp2Dict in strand1Dict.items():\n",
    "                for strand2,accList in comp2Dict.items():\n",
    "                    for acc in accList:\n",
    "                        # Do we need to include strand or component only is enough. Here are two options, just choose one:\n",
    "#                         accCompLinks.setdefault(acc,{}).setdefault((comp1,strand1),set()).add((comp2,strand2))\n",
    "                        accCompLinks.setdefault(acc,{}).setdefault(comp1,set()).add(comp2)\n",
    "                        \n",
    "                        if doCompDir:\n",
    "                            accCompDir.setdefault(acc,{})[comp1] = strand1\n",
    "                            accCompDir.setdefault(acc,{})[comp2] = strand2\n",
    "    if doCompDir:\n",
    "        return accCompLinks,accCompDir\n",
    "    else:\n",
    "        return accCompLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compLength(compID,components):\n",
    "    return components[compID-1]['lastCol']-components[compID-1]['firstCol'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def removeLink(fromComp,toComp,accessionID,fromComponentLinks,toComponentLinks):\n",
    "    '''\n",
    "    At the moment this function will remove link from `fromComp` to 'toComp' for \n",
    "    specific accession `accessionID` irrespective of strands.\n",
    "    \n",
    "    If any dict on any hierarchical level gets empty, it will be removed as well.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # removing links from fromComponentLinks\n",
    "    fromStrandsToRemove = []\n",
    "    for fromStrand,fromStrandDict in fromComponentLinks.get(fromComp,{}).items():\n",
    "        toStrandsToRemove = []\n",
    "            \n",
    "        for toStrand,accessionList in fromStrandDict.get(toComp,{}).items():\n",
    "            try:\n",
    "                accessionList.remove(accessionID)\n",
    "            except KeyError:\n",
    "                pass\n",
    "            if len(accessionList)==0:\n",
    "                toStrandsToRemove.append(toStrand)\n",
    "        \n",
    "        for toStrand in toStrandsToRemove:\n",
    "            del fromStrandDict[toComp][toStrand]\n",
    "        if toComp in fromStrandDict:\n",
    "            if len(fromStrandDict[toComp])==0:\n",
    "                del fromStrandDict[toComp]\n",
    "        \n",
    "        if len(fromStrandDict)==0:\n",
    "            fromStrandsToRemove.append(fromStrand)\n",
    "    \n",
    "    for fromStrand in fromStrandsToRemove:\n",
    "        del fromComponentLinks[fromComp][fromStrand]\n",
    "    \n",
    "    if fromComp in fromComponentLinks:\n",
    "        if len(fromComponentLinks[fromComp])==0:\n",
    "            del fromComponentLinks[fromComp]\n",
    "            \n",
    "    # removing links from toComponentLinks\n",
    "    toStrandsToRemove = []\n",
    "    for toStrand,toStrandDict in toComponentLinks.get(toComp,{}).items():\n",
    "        fromStrandsToRemove = []\n",
    "            \n",
    "        for fromStrand,accessionList in toStrandDict.get(fromComp,{}).items():\n",
    "            try:\n",
    "                accessionList.remove(accessionID)\n",
    "            except KeyError:\n",
    "                pass\n",
    "            if len(accessionList)==0:\n",
    "                fromStrandsToRemove.append(fromStrand)\n",
    "        \n",
    "        for fromStrand in fromStrandsToRemove:\n",
    "            del toStrandDict[fromComp][fromStrand]\n",
    "        if fromComp in toStrandDict:\n",
    "            if len(toStrandDict[fromComp])==0:\n",
    "                del toStrandDict[fromComp]\n",
    "        \n",
    "        if len(toStrandDict)==0:\n",
    "            toStrandsToRemove.append(toStrand)\n",
    "    \n",
    "    for toStrand in toStrandsToRemove:\n",
    "        del toComponentLinks[toComp][toStrand]\n",
    "    \n",
    "    if toComp in toComponentLinks:\n",
    "        if len(toComponentLinks[toComp])==0:\n",
    "            del toComponentLinks[toComp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def processCollapsibleBlocks(zoomLevel,collapsibleBlocks,fromComponentLinks,toComponentLinks):\n",
    "#     if zoomLevel==576:\n",
    "#         pdb.set_trace()\n",
    "    \n",
    "    idToRemove = []\n",
    "    for blockID,[accessionID,blockLength,linkList,componentList] in enumerate(collapsibleBlocks):\n",
    "        if blockLength<zoomLevel:\n",
    "            idToRemove.append(blockID)\n",
    "            for link in linkList:\n",
    "                removeLink(*link,accessionID,fromComponentLinks,toComponentLinks)\n",
    "\n",
    "    # Remove blocks that already been cleared\n",
    "    for blockID in sorted(idToRemove,reverse=True):\n",
    "        del collapsibleBlocks[blockID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def testStartEnd(compNum,isLeft,components,accStarts,accEnds):\n",
    "    if isLeft:\n",
    "        startInv = 0\n",
    "        endInv = 1\n",
    "    else:\n",
    "        startInv = 1\n",
    "        endInv = 0\n",
    "        \n",
    "    for accStart,startComp in accStarts.items():\n",
    "        if startComp == compNum:\n",
    "            comp = components[compNum-1]\n",
    "            try:\n",
    "                accessionInd = comp['occupants'].index(accStart)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if comp['matrix'][accessionInd][1]==startInv:\n",
    "                return True\n",
    "    \n",
    "    for accEnd,endComp in accEnds.items():\n",
    "        if endComp == compNum:\n",
    "            comp = components[compNum-1]\n",
    "            try:\n",
    "                accessionInd = comp['occupants'].index(accStart)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if comp['matrix'][accessionInd][1]==endInv:\n",
    "                return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def findEmptyEdges(fromComponentLinks,toComponentLinks,accStarts,accEnds,components):\n",
    "    '''\n",
    "    Identify all empty edges by simply finding components that do not appear either in toComponentLinks (left empty)\n",
    "    or fromComponentLinks (right empty)\n",
    "    '''\n",
    "    \n",
    "    allCompSet = set((np.array(range(len(components)))+1).tolist())\n",
    "    toLinkedSet = set(toComponentLinks.keys())\n",
    "    fromLinkedSet = set(fromComponentLinks.keys())\n",
    "\n",
    "    leftEmptyCandidates = list(allCompSet - toLinkedSet)\n",
    "\n",
    "    leftEmptyList = []\n",
    "\n",
    "    for leftEmptyCand in leftEmptyCandidates:\n",
    "        if testStartEnd(leftEmptyCand,True,components,accStarts,accEnds):\n",
    "            continue\n",
    "\n",
    "        if '-' in fromComponentLinks.get(leftEmptyCand,{}):\n",
    "            continue\n",
    "\n",
    "        leftEmptyList.append(leftEmptyCand)\n",
    "\n",
    "    rightEmptyCandidates = list(allCompSet - fromLinkedSet)\n",
    "\n",
    "    rightEmptyList = []\n",
    "\n",
    "    for rightEmptyCand in rightEmptyCandidates:\n",
    "        if testStartEnd(rightEmptyCand,False,components,accStarts,accEnds):\n",
    "            continue\n",
    "\n",
    "        if '-' in toComponentLinks.get(rightEmptyCand,{}):\n",
    "            continue\n",
    "\n",
    "        rightEmptyList.append(rightEmptyCand)\n",
    "        \n",
    "    return leftEmptyList,rightEmptyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def checkExternalLinks(blockStart,blockEnd,fromComponentLinks,toComponentLinks,components):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    componentID: int. If an external links found, then a list of components inside the block involved \n",
    "                    in external links returned. If no external links found, then empty list is returned.\n",
    "    '''\n",
    "    \n",
    "    externalLinksComponents = []\n",
    "    \n",
    "    for compID in range(blockStart,blockEnd+1):\n",
    "        passToNext = False\n",
    "        \n",
    "        if len(components[compID-1].get('ends',[]))>0 or len(components[compID-1].get('starts',[]))>0:\n",
    "            externalLinksComponents.append(compID)\n",
    "            continue\n",
    "        \n",
    "        for fromStrandDict in fromComponentLinks.get(compID,{}).values():\n",
    "            for toComp in fromStrandDict.keys():\n",
    "                if toComp>blockEnd or toComp<blockStart:\n",
    "                    externalLinksComponents.append(compID)\n",
    "                    passToNext = True\n",
    "                    break\n",
    "            if passToNext:\n",
    "                break\n",
    "        \n",
    "        if passToNext:\n",
    "            continue\n",
    "            \n",
    "        for toStrandDict in toComponentLinks.get(compID,{}).values():\n",
    "            for fromComp in toStrandDict.keys():\n",
    "                if fromComp>blockEnd or fromComp<blockStart:\n",
    "                    externalLinksComponents.append(compID)\n",
    "                    passToNext = True\n",
    "                    break\n",
    "            if passToNext:\n",
    "                break\n",
    "    \n",
    "    return externalLinksComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def createNewBoundaries(blockStart,blockEnd,externalLinksComps):\n",
    "    blockSplit = [[blockStart]]\n",
    "    \n",
    "    previousBreakPoint = blockStart\n",
    "    for breakPoint in externalLinksComps:\n",
    "        \n",
    "        if breakPoint==blockSplit[-1][0]:\n",
    "            blockSplit[-1][0] = breakPoint+1\n",
    "            \n",
    "        else:\n",
    "            blockSplit[-1].append(breakPoint-1)\n",
    "            blockSplit.append([breakPoint+1])\n",
    "        \n",
    "    if blockEnd>=blockSplit[-1][0]:\n",
    "        blockSplit[-1].append(blockEnd)\n",
    "    else:\n",
    "        del blockSplit[-1]\n",
    "\n",
    "    return blockSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def identifyIsolatedBlocks(leftEmptyList,rightEmptyList,fromComponentLinks,toComponentLinks,components):\n",
    "    if len(leftEmptyList)==0 or len(rightEmptyList)==0:\n",
    "        return []\n",
    "    \n",
    "    leftmostLeftEmpty = min(leftEmptyList)\n",
    "    rightmostRightEmpty = max(rightEmptyList)\n",
    "\n",
    "    isolatedBlockCandidates = []\n",
    "    isolatedBlockList = []\n",
    "\n",
    "    if leftmostLeftEmpty<=rightmostRightEmpty:\n",
    "        isolatedBlockCandidates.append([leftmostLeftEmpty,rightmostRightEmpty])\n",
    "\n",
    "    while len(isolatedBlockCandidates)>0:\n",
    "\n",
    "        isolatedBlock = isolatedBlockCandidates.pop()\n",
    "\n",
    "        externalLinksComps = checkExternalLinks(*isolatedBlock,fromComponentLinks,toComponentLinks,components)\n",
    "\n",
    "        if len(externalLinksComps)==0:\n",
    "            isolatedBlockList.append(isolatedBlock)\n",
    "        else:\n",
    "            isolatedBlockCandidates.extend(createNewBoundaries(*isolatedBlock,externalLinksComps))\n",
    "    \n",
    "    return isolatedBlockList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def updateLinksRemoveComp(oldToNewInd,fromComponentLinks,toComponentLinks,collapsibleBlocks,accStarts,accEnds):\n",
    "    \n",
    "    newFromComponentLinks={}\n",
    "    newToComponentLinks={}\n",
    "    \n",
    "    for oldFromComp,fromCompDict in fromComponentLinks.items():\n",
    "        if oldFromComp-1 in oldToNewInd:\n",
    "            newFromCompDict = newFromComponentLinks.setdefault(oldToNewInd[oldFromComp-1][0]+1,{})\n",
    "            for fromStrand,fromStrandDict in fromCompDict.items():\n",
    "                newFromStrandDict = newFromCompDict.setdefault(fromStrand,{})\n",
    "                for toComp,toCompDict in fromStrandDict.items():\n",
    "                    if toComp-1 in oldToNewInd:\n",
    "                        newFromStrandDict[oldToNewInd[toComp-1][0]+1] = toCompDict\n",
    "                \n",
    "    for oldToComp,toCompDict in toComponentLinks.items():\n",
    "        if oldToComp-1 in oldToNewInd:\n",
    "            newToCompDict = newToComponentLinks.setdefault(oldToNewInd[oldToComp-1][0]+1,{})\n",
    "            for toStrand,toStrandDict in toCompDict.items():\n",
    "                newToStrandDict = newToCompDict.setdefault(toStrand,{})\n",
    "                for fromComp,fromCompDict in toStrandDict.items():\n",
    "                    if fromComp-1 in oldToNewInd:\n",
    "                        newToStrandDict[oldToNewInd[fromComp-1][0]+1] = fromCompDict\n",
    "    \n",
    "    for acc in accStarts.keys():\n",
    "        accStarts[acc] = oldToNewInd[accStarts[acc]-1][0]+1\n",
    "        accEnds[acc] = oldToNewInd[accEnds[acc]-1][0]+1\n",
    "    \n",
    "    collapsibleBlocksToRemove = []\n",
    "    for blockID,[accessionID,blockLength,associatedLinks,associatedComponents] in enumerate(collapsibleBlocks[::-1]):\n",
    "        collapsibleBlocks[blockID] = (accessionID,blockLength,\n",
    "                                      [[oldToNewInd[link[0]-1][0]+1,oldToNewInd[link[1]-1][0]+1] for link in associatedLinks \\\n",
    "                                           if link[0]-1 in oldToNewInd and link[1]-1 in oldToNewInd],\n",
    "                                      [oldToNewInd[comp-1][0]+1 for comp in associatedComponents \\\n",
    "                                           if comp-1 in oldToNewInd])\n",
    "        if len(collapsibleBlocks[blockID][2])==0:\n",
    "            collapsibleBlocksToRemove.append(blockID)\n",
    "    \n",
    "    if len(collapsibleBlocksToRemove)>0:\n",
    "        for blockID in sorted(collapsibleBlocksToRemove,reverse=True):\n",
    "            del collapsibleBlocks[blockID]\n",
    "    \n",
    "    return newFromComponentLinks,newToComponentLinks,accStarts,accEnds,collapsibleBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def removeIsolatedBlocks(isolatedBlockList,components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks):\n",
    "    if len(isolatedBlockList)==0:\n",
    "        return components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks\n",
    "    \n",
    "    newToOldInd = list(range(len(components)))\n",
    "    \n",
    "    for isolatedBlockStart,isolatedBlockEnd in sorted(isolatedBlockList,key=lambda el: el[1],reverse=True):\n",
    "        # deleting components and creating translation from new index to old index\n",
    "        for compToRemove in range(isolatedBlockEnd,isolatedBlockStart-1,-1):\n",
    "            del components[compToRemove-1]\n",
    "            del componentLengths[compToRemove-1]\n",
    "            del newToOldInd[compToRemove-1]\n",
    "    \n",
    "    # Converting new to old index to old to new index\n",
    "    oldToNewInd = {el:[ind] for ind,el in enumerate(newToOldInd)}\n",
    "    # Converting new to old index from list to dict (not sure it is needed in the first place)\n",
    "#     newToOldInd = {ind:[el] for ind,el in enumerate(newToOldInd)}\n",
    "    \n",
    "    \n",
    "    # updating links\n",
    "    fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks = \\\n",
    "        updateLinksRemoveComp(oldToNewInd,fromComponentLinks,toComponentLinks,collapsibleBlocks,accStarts,accEnds)\n",
    "    return components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clearInvisible(zoomLevel,collapsibleBlocks,fromComponentLinks,toComponentLinks,accStarts,accEnds,components,componentLengths):\n",
    "    print('Removing links according to collapsible blocks')\n",
    "    numOfCollapsibleBlocks = len(collapsibleBlocks)\n",
    "    numOfComponents = len(components)\n",
    "    # Link removal\n",
    "    processCollapsibleBlocks(zoomLevel,collapsibleBlocks,fromComponentLinks,toComponentLinks)\n",
    "    \n",
    "    # Identify empty (without links) edges\n",
    "    leftEmptyList,rightEmptyList = findEmptyEdges(fromComponentLinks,toComponentLinks,accStarts,accEnds,components)\n",
    "\n",
    "    # Identify isolated blocks ,i.e. without any links on both sides and no outside links from inside\n",
    "    isolatedBlockList = identifyIsolatedBlocks(leftEmptyList,rightEmptyList,fromComponentLinks,toComponentLinks,components)\n",
    "\n",
    "    # Remove identified isolated blocks\n",
    "    components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks = \\\n",
    "    removeIsolatedBlocks(isolatedBlockList,components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks)\n",
    "    \n",
    "    print(f'All links associated with collapsibleComponents <{zoomLevel} were removed. Used {numOfCollapsibleBlocks - len(collapsibleBlocks)}, \\\n",
    "    {numOfComponents-len(components)} were deleted as isolated.')\n",
    "    \n",
    "    return components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def exportToPantograph(graph=None, inputPath=None, GenomeGraphParams={}, \n",
    "                                    outputPath=None, outputName=None, outputSuffix=None, \n",
    "                                    isSeq=True,\n",
    "                                    redisConn=None,\n",
    "                                    listOfExports=['schematise', 'genomeToPangenome', 'annotationToGenome'],\n",
    "                                    zoomLevels=[1], fillZoomLevels=True, maxLengthComponent=100, maxLengthChunk=20, inversionThreshold=0.5,\n",
    "                                    debug=False, returnDebugData=False):\n",
    "    \n",
    "    if graph is None:\n",
    "        if inputPath is not None:\n",
    "            print('Loading Genome')\n",
    "            graph = GenomeGraph(gfaPath=inputPath, isGFASeq=isSeq, **GenomeGraphParams)\n",
    "        else:\n",
    "            raise ValueError(\"Either graph or inputpath to GFA file should be provided\")\n",
    "\n",
    "    if outputPath is None and outputName is None:\n",
    "        if inputPath is not None:\n",
    "            if outputSuffix is not None:\n",
    "                outputPath, outputName = pathConvert(inputPath, suffix = outputSuffix)\n",
    "            else:\n",
    "                outputPath, outputName = pathConvert(inputPath)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"If inputPath is not given, then outputPath and outputName should be provided.\")\n",
    "    else:\n",
    "        if outputSuffix is not None:\n",
    "            outputName = outputName + outputSuffix\n",
    "    print(f'Recording Pantograph data to {outputPath}{os.path.sep}{outputName}')\n",
    "\n",
    "#     numNodes = len(graph.nodes)\n",
    "#     numNodesDigits = np.int(np.ceil(np.log10(numNodes)))\n",
    "#     fromLinks = {}\n",
    "#     toLinks = {}\n",
    "\n",
    "    rootStruct = deepcopy(rootStructTemplate)\n",
    "    rootStruct[\"pathNames\"] = graph.accessions\n",
    "\n",
    "    if returnDebugData:\n",
    "        # temporary structure for testing, in normal mode each zoomlevel \n",
    "        # should be just saved as soon as it is processed and only previous and current zoom level should be preserved.\n",
    "        zoomComponentLengths = {}\n",
    "        zoomNodeToComponent = {}\n",
    "        zoomComponentToNodes = {}\n",
    "        zoomComponents = {}  \n",
    "        zoomCompNucleotides = {}\n",
    "        zoomAccStarts = {}\n",
    "        zoomAccEnds = {}\n",
    "\n",
    "    nodeLengths = calcNodeLengths(graph)\n",
    "\n",
    "    pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum = initialPathAnalysis(graph,nodeLengths)\n",
    "    \n",
    "    #!!!!!! Process lowest level zoom to create component structure.\n",
    "    [numNodes, # number of nodes\n",
    "    numNodesDigits, # \n",
    "    nodeToComponent,\n",
    "    componentToNode,\n",
    "    componentLengths,\n",
    "    components,\n",
    "    componentNucleotides,\n",
    "    fromLinks,toLinks,\n",
    "    fromComponentLinks,toComponentLinks,\n",
    "    accStarts,accEnds,invertedStarts,invertedEnds] = baseLayerZoom(graph,\n",
    "                                      outputPath,outputName,\n",
    "                                      pathNodeArray,pathDirArray,\n",
    "                                      pathLengths,nodeLengths,\n",
    "                                      pathNodeLengthsCum,\n",
    "                                      maxLengthComponent,\n",
    "                                      inversionThreshold=inversionThreshold,\n",
    "                                      isSeq=isSeq)\n",
    "    print()\n",
    "    if returnDebugData:\n",
    "        zoomNodeToComponent,zoomComponentToNodes,zoomComponentLengths, \\\n",
    "        zoomComponents,zoomCompNucleotides,zoomAccStarts,zoomAccEnds = \\\n",
    "        recordZoomLevelForDebug(zoomNodeToComponent,zoomComponentToNodes,zoomComponentLengths,zoomComponents,zoomCompNucleotides,zoomAccStarts,zoomAccEnds,\n",
    "                                nodeToComponent,componentToNode,componentLengths,components,componentNucleotides,accStarts,accEnds,\n",
    "                                1)\n",
    "    \n",
    "    fromComponentLinks,toComponentLinks = \\\n",
    "    nodeToComponentLinks(components,\n",
    "                         componentToNode,\n",
    "                         nodeToComponent,\n",
    "                         fromLinks,\n",
    "                         toLinks,\n",
    "                         fromComponentLinks,\n",
    "                         toComponentLinks)\n",
    "    \n",
    "    \n",
    "    rootStruct = deepcopy(rootStructTemplate)\n",
    "    rootStruct[\"pathNames\"] = graph.accessions\n",
    "    rootStruct[\"pangenome_length\"] = np.sum(componentLengths)\n",
    "\n",
    "    exportLayer(1,components,componentNucleotides,\n",
    "                fromComponentLinks,toComponentLinks,\n",
    "                rootStruct,\n",
    "                outputPath,outputName,\n",
    "                maxLengthComponent,maxLengthChunk,\n",
    "                inversionThreshold=inversionThreshold,\n",
    "                redisConn=redisConn)\n",
    "    \n",
    "    if len(zoomLevels)>1 or fillZoomLevels:\n",
    "        # Converting link dicts from component first to path/accession first. \n",
    "        # It is needed only for collapsible block identification which happens only once.\n",
    "        # So, they should be removed after collapsible blocks are removed.\n",
    "        # First line also returns dictionary giving direction (inversion) of each component in each accession.\n",
    "        fromComponentLinksAcc,accCompDir = compLinksToAccCompLinks(fromComponentLinks,doCompDir=True)\n",
    "#         toComponentLinksAcc = compLinksToAccCompLinks(toComponentLinks)\n",
    "\n",
    "#         # This identifies collapsible block starts based on links.\n",
    "#         # For forward components\n",
    "#         positiveBlockStarts = getBackwardPositiveLinks(toComponentLinks,toComponentLinksAcc,accStarts,accEnds)\n",
    "#         # For inversed components\n",
    "#         negativeBlockStarts = getForwardNegativeLinks(toComponentLinks,toComponentLinksAcc,accStarts,accEnds,invertedStarts)\n",
    "\n",
    "        # Identifying all collapsible blocks.\n",
    "        # The return is a list of tuples containg the following elements:\n",
    "        # accession ID, length of block, list of associated links, list of associated components.\n",
    "        collapsibleBlocks = identifyCollapsibleBlocks(toComponentLinks,fromComponentLinksAcc,components,accStarts,accEnds,accCompDir)\n",
    "#         collapsibleBlocks = identifyCollapsibleBlocks(positiveBlockStarts,negativeBlockStarts,\n",
    "#                                                       accStarts,accEnds,\n",
    "#                                                       fromComponentLinksAcc,toComponentLinksAcc,accCompDir,\n",
    "#                                                       components)\n",
    "\n",
    "        if returnDebugData:\n",
    "            retCollapsibleBlocks = deepcopy(collapsibleBlocks)\n",
    "\n",
    "        del fromComponentLinksAcc\n",
    "#         del toComponentLinksAcc\n",
    "        del accCompDir\n",
    "#         del positiveBlockStarts\n",
    "#         del negativeBlockStarts\n",
    "    elif returnDebugData:\n",
    "        retCollapsibleBlocks = []\n",
    "\n",
    "    _zoomLevels = deepcopy(zoomLevels)\n",
    "    \n",
    "    if fillZoomLevels:\n",
    "        maxBlock = max(collapsibleBlocks,key=lambda bl: bl[1])\n",
    "\n",
    "        while _zoomLevels[-1]<maxBlock[1]:\n",
    "            _zoomLevels.append(_zoomLevels[-1]*2)\n",
    "    \n",
    "    for zoomLevel in _zoomLevels[1:]:\n",
    "        \n",
    "        # Collapsing is done through removing some particular links (not satisfying specific conditions)\n",
    "        components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks = \\\n",
    "        clearInvisible(zoomLevel,collapsibleBlocks,fromComponentLinks,toComponentLinks,\n",
    "                       accStarts,accEnds,components,componentLengths)\n",
    "        \n",
    "        # Process next zoom level\n",
    "        components,componentLengths,fromComponentLinks,toComponentLinks,accStarts,accEnds,collapsibleBlocks = \\\n",
    "        nextLayerZoom(zoomLevel,\n",
    "                      components,componentLengths,#componentNucleotides,\n",
    "                      fromComponentLinks,toComponentLinks,graph,\n",
    "                      collapsibleBlocks,accStarts,accEnds,\n",
    "                      maxLengthComponent,inversionThreshold=inversionThreshold)\n",
    "        \n",
    "        if returnDebugData:\n",
    "            zoomNodeToComponent,zoomComponentToNodes,zoomComponentLengths, \\\n",
    "            zoomComponents,zoomCompNucleotides,zoomAccStarts,zoomAccEnds = \\\n",
    "            recordZoomLevelForDebug(zoomNodeToComponent,zoomComponentToNodes,zoomComponentLengths,zoomComponents,zoomCompNucleotides,zoomAccStarts,zoomAccEnds,\n",
    "                                    [],[],componentLengths,components,[],[],[],\n",
    "                                    zoomLevel)\n",
    "        # Zoom level should be split into chunks and recorded.\n",
    "        exportLayer(zoomLevel,components,[],#componentNucleotides,\n",
    "                fromComponentLinks,toComponentLinks,\n",
    "                rootStruct,\n",
    "                outputPath,outputName,\n",
    "                maxLengthComponent,maxLengthChunk,\n",
    "                inversionThreshold=inversionThreshold,\n",
    "                redisConn=redisConn)\n",
    "        \n",
    "    \n",
    "    with open(f'{outputPath}{os.path.sep}{outputName}{os.path.sep}bin2file.json','w') as f:\n",
    "        json.dump(rootStruct,f,cls=NpEncoder)\n",
    "    \n",
    "    if returnDebugData:\n",
    "        return zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,zoomAccStarts,zoomAccEnds, \\\n",
    "                invertedStarts,invertedEnds,toComponentLinks,fromComponentLinks,retCollapsibleBlocks,fromLinks,toLinks,graph,rootStruct"
   ]
  },
  {
   "cell_type": "raw",
   "id": "varying-beatles",
   "metadata": {},
   "source": [
    "def calcOccupancyInversion(pathID,pathNum,nodeLen,pathNodeCount,nodePathsIdx,nodeSeqInPath,pathDirArray,occupancy,inversion):\n",
    "'''\n",
    "Calculates occupancy and inversion for current node and given path. The function updates `occupancy` and `inversion`\n",
    "dictionaries and return them back.\n",
    "\n",
    "Parameters\n",
    "==========\n",
    "`pathID`: int. Identifier (numerical) of the path. It is the number of path in the whole list of paths of the graph.\n",
    "`pathNum`: int. Number of path among paths which passes current node. \n",
    "           It is the number of pathID in the `uniqueNodePathsIDs` (see `checkForBreaks` for more details.)\n",
    "`nodeLen`: length of the current node.\n",
    "`pathNodeCount`: 1D subscribable[int]. A list or 1D numpy.array which contains number of times the current node\n",
    "                 is passed by given path. E.g. if path `pathID` (with number `pathNum`, see above) passes current node\n",
    "                 k times, then `pathNodeCount[pathNum] == k`.\n",
    "`nodePathsIdx`: 1D subscribable[int]. A 1D numpy.array or list which contain ids of the paths \n",
    "                for each appearance of the node ID in each path. See `nodeStat` for details.\n",
    "`nodeSeqInPath`: 1D subscribable[int]. A 1D numpy.array or list with positions of given node in every path. \n",
    "                 The path to which this position is related to can be found from `nodePathsIdx`, \n",
    "                 e.g. if `nodeSeqInPath[i]` is `k`, then node with node ID `nodeIdx`\n",
    "                 appear in path `nodePathsIdx[i]` at position `k`. See `nodeStat` for details.\n",
    "`pathDirArray`: 2D numpy.array. Each row (corresponding to specific path in graph) contains directionality\n",
    "                of each node in the path. See `initialPathAnalysis` for details.\n",
    "`occupancy`: dict. Dictionary with overall occupancy for current component. Path IDs are keys. \n",
    "             It contains a sum of actual times each node is passed by the path with path ID multiplied \n",
    "             by node length. To get average occupancy of a path in the component, it should be divided \n",
    "             by the component length (in terms of nucleotides).\n",
    "`inversion`: dict. Dictionary with overall inversion for current component. Path IDs are keys. \n",
    "             It contains a sum of actual times each node is passed in reverse by the path with path ID \n",
    "             multiplied by node length and divided by its (node) occupancy. To get average occupancy \n",
    "             of a path in the component, it should be divided by the component length (in terms of nucleotides).\n",
    "             \n",
    "Returns\n",
    "=======\n",
    "`occupancy`: dict. See parameters for description. The dictionary is updated with information for current node.\n",
    "`inversion`: dict. See parameters for description. The dictionary is updated with information for current node.\n",
    "`nodeInversion`: float. Calculated inversion rate for current node.\n",
    "'''\n",
    "    \n",
    "    # calculating occupancy for current node\n",
    "    # Do we need it?\n",
    "    pOcc = occupancy.setdefault(pathID, 0)\n",
    "    pOcc += pathNodeCount[j]*nodeLen\n",
    "    occupancy[pathID] = pOcc  # Occupancy\n",
    "\n",
    "    # Calculate inversion of current node\n",
    "    localInv = 0\n",
    "    for nodeNumInPath in nodeSeqInPath[np.where(nodePathsIdx==pathID)[0]]:\n",
    "        localInv += int(pathDirArray[pathID,nodeNumInPath])\n",
    "\n",
    "    pInv = inversion.get(pathID,0)\n",
    "    # Do we need to multiply it by node length?\n",
    "    # Most probably it is needed for larger components\n",
    "    # Bigger question is why we add it to the pInv, not just assign?\n",
    "    pInv += localInv*nodeLen/pathNodeCount[j]\n",
    "    inversion[pathID] = pInv\n",
    "    \n",
    "    return occupancy,inversion,localInv/pathNodeCount[j]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-position",
   "metadata": {},
   "source": [
    "components: keys: 0-based, values: occupants: 0-based, binNumbers: 0-based  \n",
    "componentToNode: keys: 0-based, values: 1-based  \n",
    "nodeToComponent: keys: 0-based, values: 1-based  \n",
    "fromLinks: top level keys (from nodes): 1-based, bottom level keys (to nodes): 1-based, values (list of participants): 0-based  \n",
    "toLinks: top level keys (to nodes): 1-based, bottom level keys (from nodes): 1-based, values (list of participants): 0-based  \n",
    "fromComponentLinks: top level keys (from components): 1-based, bottom level keys (to components): 1-based, values (set of participants): 0-based  \n",
    "toComponentLinks: top level keys (to components): 1-based, bottom level keys (from components): 1-based, values (set of participants): 0-based  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-bedroom",
   "metadata": {},
   "source": [
    "## Old version of the exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-rouge",
   "metadata": {},
   "source": [
    "### Old vertions of functions of new routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be deleted\n",
    "def getBackwardPositiveLinks(toComponentLinks,toComponentLinksAcc,accStarts,accEnds):\n",
    "    '''\n",
    "    Function gets toComponentLinks dict structure (output from `baseLayerZoom` (partially) and \n",
    "    `nodeToComponentLinks` (finalised) on base layer and by `nextLayerZoom` on every other zoom layer).\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    toComponentLinks: dict{int:dict{str:dict{int:dict{str:list[int]}}}}. This input is an hierarchical structure of dicts\n",
    "                    which holds all links between components on the current zoom layer. This structure is internal and \n",
    "                    produced by `baseLayerZoom` (partially) and `nodeToComponentLinks` (finalised) on base layer and \n",
    "                    by `nextLayerZoom` on every other zoom layer.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    compAccessionBackLinks: list[tuple(int)]. A list of tuples of component ids (1-based) (outgoing and incoming) and accessions \n",
    "                            where reversed (backward) links are coming.\n",
    "    \n",
    "    '''\n",
    "    allBlockStarts = []\n",
    "#     backLinksThroughStart = []\n",
    "#     forwardLinksThroughEnd = []\n",
    "    \n",
    "    for toComp,toCompDict in toComponentLinks.items():\n",
    "\n",
    "        # We are interested only in backward links coming to forward components (per accession, not overall)\n",
    "        for fromComp,fromCompDict in toCompDict.get('+',{}).items():\n",
    "            if fromComp>=toComp:\n",
    "                for accList in fromCompDict.values():\n",
    "                    for acc in accList:\n",
    "                        leftEnd = min(accStarts[acc],accEnds[acc])\n",
    "                        rightEnd = max(accStarts[acc],accEnds[acc])\n",
    "                        if fromComp>rightEnd and toComp<=rightEnd and not (fromComp>=leftEnd and toComp<leftEnd):\n",
    "                            if np.all(np.array(list(toComponentLinksAcc[acc][toComp]))>=toComp):\n",
    "                                continue\n",
    "                        \n",
    "                        \n",
    "#                         if fromComp-1 in toComponentLinksAcc[acc].get(toComp-1,set()):\n",
    "#                             continue\n",
    "                        \n",
    "                        if fromComp>=leftEnd and toComp<leftEnd:\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "                        else:\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "            else:\n",
    "                # Identify forward links through end\n",
    "                for accList in fromCompDict.values():\n",
    "                    for acc in accList:\n",
    "                        rightEnd = max(accStarts[acc],accEnds[acc])\n",
    "                        if fromComp<rightEnd and toComp>rightEnd:\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "    \n",
    "    \n",
    "    return allBlockStarts        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be deleted\n",
    "def getForwardNegativeLinks(toComponentLinks,toComponentLinksAcc,accStarts,accEnds,invertedStarts):\n",
    "    '''\n",
    "    Function gets toCOmponentLinks dict structure (output from `baseLayerZoom` (partially) and \n",
    "    `nodeToComponentLinks` (finalised) on base layer and by `nextLayerZoom` on every other zoom layer).\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    toComponentLinks: dict{int:dict{str:dict{int:dict{str:list[int]}}}}. This input is an hierarchical structure of dicts\n",
    "                    which holds all links between components on the current zoom layer. This structure is internal and \n",
    "                    produced by `baseLayerZoom` (partially) and `nodeToComponentLinks` (finalised) on base layer and \n",
    "                    by `nextLayerZoom` on every other zoom layer.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    compAccessionBackLinks: list[tuple(int)]. A list of tuples of component ids (1-based) (outgoing and incoming) and accessions \n",
    "                            where reversed (backward) links are coming.\n",
    "    \n",
    "    '''\n",
    "    allBlockStarts = []\n",
    "#     backwardNegLinks = []\n",
    "#     backLinksThroughStart = []\n",
    "#     forwardLinksThroughEnd = []\n",
    "    \n",
    "    for toComp,toCompDict in toComponentLinks.items():\n",
    "\n",
    "        # We are interested only in backward links coming to forward components (per accession, not overall)\n",
    "        for fromComp,fromCompDict in toCompDict.get('-',{}).items():\n",
    "            if fromComp<=toComp:\n",
    "                for accList in fromCompDict.values():\n",
    "                    for acc in accList:\n",
    "                        leftEnd = min(accStarts[acc],accEnds[acc])\n",
    "                        rightEnd = max(accStarts[acc],accEnds[acc])\n",
    "                        \n",
    "                        if fromComp<leftEnd and toComp>=leftEnd and not (fromComp<rightEnd and toComp>=rightEnd):\n",
    "                            if np.all(np.array(list(toComponentLinksAcc[acc][toComp]))<=toComp):\n",
    "                                continue\n",
    "                            \n",
    "                        if fromComp<=rightEnd and toComp>rightEnd:\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "                        else:\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "            else:\n",
    "                \n",
    "                # Identify backward links through start\n",
    "                outsideLinkAdded = False\n",
    "                for fromStrand,accList in fromCompDict.items():\n",
    "                    for acc in accList:\n",
    "                        leftEnd = min(accStarts[acc],accEnds[acc])\n",
    "                        adjustment = int(fromStrand=='-')\n",
    "                        if fromComp-adjustment>=leftEnd and toComp<leftEnd:\n",
    "                            outsideLinkAdded = True\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "                        elif fromStrand=='+':\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "                        else:\n",
    "                            if all([fComp>=toComp for fComp,fCompDict in toCompDict.get('-',{}).items() if acc in fCompDict.get('+',[])]) \\\n",
    "                            and not (fromComp+1 in toComponentLinksAcc[acc].get(toComp+1,set())): # Not sure why this condition is here...\n",
    "                                allBlockStarts.append((fromComp,toComp,acc)) #backwardNegativeLinks were appended here originally\n",
    "                \n",
    "#                 if not outsideLinkAdded:\n",
    "#                     for acc in fromCompDict.get('+',[]):\n",
    "                        \n",
    "    \n",
    "    # Adding inverted starts as the start of the inverted blocks as they cannot be picked up by any links.\n",
    "    for accInvStart in invertedStarts:\n",
    "        allBlockStarts.append((None,accStarts[accInvStart],accInvStart))\n",
    "    \n",
    "    return allBlockStarts#,backwardNegLinks   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be deleted\n",
    "def checkOvercoming(block,accessionFromLinks,accessionToLinks):\n",
    "    '''\n",
    "    Probably, it is not a correct way of doing this, although, we can still leave this, \n",
    "    but also follow the following rule (this should be implemented in `processNegativeLink`):\n",
    "    \n",
    "    If inverted block start have at least one backward link incoming to it, \n",
    "    we need to look for arrow straight \"before\" the \"end\" (left end) of this block,\n",
    "    which goes forward beyond the start (right start) of this block and add this arrow to associated links.\n",
    "    '''\n",
    "    minComp = min(block)\n",
    "    maxComp = max(block)\n",
    "    \n",
    "    associatedLinks = []\n",
    "    \n",
    "    if maxComp+1 in accessionFromLinks.get(minComp-1, set()):\n",
    "        associatedLinks.append((minComp-1,maxComp+1))\n",
    "    if maxComp+1 in accessionToLinks.get(minComp-1, set()):\n",
    "        associatedLinks.append((maxComp+1,minComp-1))\n",
    "                                         \n",
    "    return associatedLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be deleted\n",
    "def addToNewBlockStarts(extendedLinks,compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts):\n",
    "    newPositiveBlockStarts.update([(fromComp,toComp,accessionID) for fromComp,toComp in extendedLinks if compDir[toComp]=='+'])\n",
    "    newNegativeBlockStarts.update([(fromComp,toComp,accessionID) for fromComp,toComp in extendedLinks if compDir[toComp]=='-'])\n",
    "    return newPositiveBlockStarts,newNegativeBlockStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be deleted\n",
    "def processBackwardLink(fromComp,toComp,accessionID,accStarts,accEnds,fromComponentLinksAcc,toComponentLinksAcc,accCompDir,components):\n",
    "    accessionLinks = fromComponentLinksAcc[accessionID]\n",
    "    accessionToLinks = toComponentLinksAcc[accessionID]\n",
    "    \n",
    "    compDir = accCompDir[accessionID]\n",
    "    \n",
    "    leftEnd = min(accStarts[accessionID],accEnds[accessionID])\n",
    "    rightEnd = max(accStarts[accessionID],accEnds[accessionID])\n",
    "    isOverEnd = (fromComp<rightEnd and toComp>rightEnd)\n",
    "    isOverStart = (fromComp>=leftEnd and toComp<leftEnd)\n",
    "#     if fromComp==4 and toComp==2:\n",
    "#         pdb.set_trace()\n",
    "\n",
    "    # This list will include tuples in the following structure:\n",
    "    # (accessionID, blockLength, associatedLinks, includedComponents)\n",
    "    blockList = []\n",
    "    block = [toComp]\n",
    "    blockLength = compLength(toComp,components)\n",
    "    associatedLinks = [(fromComp,toComp)]\n",
    "    newPositiveBlockStarts = set()\n",
    "    newNegativeBlockStarts = set()\n",
    "    if fromComp>=toComp:\n",
    "        # If it is forward link, then we need to check whether there are any backward link\n",
    "        # coming to the same component and associate them with this block as well\n",
    "        for fc in accessionToLinks[toComp]:\n",
    "            if fc<toComp:\n",
    "                isBackward = True\n",
    "                if (fc,toComp) not in associatedLinks:\n",
    "                    associatedLinks.append((fc,toComp))\n",
    "    curComp = toComp\n",
    "    \n",
    "    isBackward = False\n",
    "    doBreak = False\n",
    "    \n",
    "#     if accessionID==3 and fromComp==3 and toComp==2:\n",
    "#         pdb.set_trace()\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # Include any forward links coming inside the block\n",
    "        extraLinks = []\n",
    "        prevCompList = np.array(list(accessionToLinks.get(curComp,set())))\n",
    "        for prevComp in prevCompList:\n",
    "            if (prevComp<curComp and prevComp<rightEnd or prevComp>rightEnd) and ((prevComp,curComp) not in associatedLinks):\n",
    "                if not ((prevComp==curComp-1 and compDir[prevComp]=='+' and compDir[curComp]=='+') or \\\n",
    "                         (prevComp==curComp+1 and compDir[prevComp]=='-' and compDir[curComp]=='-')):\n",
    "                    associatedLinks.append((prevComp,curComp))\n",
    "        \n",
    "        nextCompList = np.array(list(accessionLinks.get(curComp,set())))\n",
    "        distToNextComp = nextCompList-curComp\n",
    "        if len(nextCompList)==0:\n",
    "            break\n",
    "        if np.all(distToNextComp<=0):\n",
    "            isBackward = True\n",
    "            # add all backwards link jumping over the end to associated links\n",
    "            # This link is just a return from the block that started and ended beyond \n",
    "            # the right end of the genome and everything there is in reverse.\n",
    "            # That is why these links are listed and associated with this block \n",
    "            # beyond the right end.\n",
    "            associatedLinks.extend([(curComp,nextComp) for nextComp in nextCompList if not \\\n",
    "                                   (nextComp==curComp-1 and compDir[nextComp]=='-' and compDir[curComp]=='-')])\n",
    "            break\n",
    "        elif (np.all(nextCompList>fromComp) and (toComp<=fromComp)) or (np.all(nextCompList<=toComp) and (toComp>fromComp)):\n",
    "            extendedLinks = [(curComp,nextComp) for nextComp in nextCompList if not \\\n",
    "                                    ((nextComp==curComp+1 and compDir[nextComp]=='+' and compDir[curComp]=='+') or \\\n",
    "                                     (nextComp==curComp-1 and compDir[nextComp]=='-' and compDir[curComp]=='-'))]\n",
    "            associatedLinks.extend(extendedLinks)\n",
    "            newPositiveBlockStarts,newNegativeBlockStarts = addToNewBlockStarts(extendedLinks,compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "            break\n",
    "        elif np.any(distToNextComp<=0) or (np.any(nextCompList>fromComp) and toComp<=rightEnd) or (np.any(nextCompList<toComp) and (toComp>rightEnd)):\n",
    "            if np.any(distToNextComp<=0):\n",
    "                isBackward = True\n",
    "                \n",
    "            if (np.any(np.logical_and(nextCompList>toComp,nextCompList<=fromComp)) and toComp<=rightEnd) or \\\n",
    "                (np.any(nextCompList>toComp) and toComp>rightEnd):\n",
    "                linksToAssociate = []\n",
    "                for nextComp in nextCompList:\n",
    "                    if not ((curComp==nextComp-1 and compDir[curComp]=='+' and compDir[nextComp]=='+') or \\\n",
    "                         (curComp==nextComp+1 and compDir[curComp]=='-' and compDir[nextComp]=='-')) and \\\n",
    "                        ((curComp,nextComp) not in associatedLinks):\n",
    "                        if (((nextComp>=fromComp or nextComp<=toComp) and toComp<=rightEnd) or \\\n",
    "                            (toComp>rightEnd)):\n",
    "                            linksToAssociate.append((curComp,nextComp))\n",
    "                        else:\n",
    "                            extraLinks.append((curComp,nextComp))\n",
    "                        \n",
    "                # These auxiliary blocks should be associated only with the links that create this break \n",
    "                # (recorded in `linksToAssociate`), but not with the links which creates the main block \n",
    "                # (which recorded in `associatedLinks`).\n",
    "                if len(linksToAssociate)>0:\n",
    "                    newPositiveBlockStarts,newNegativeBlockStarts = addToNewBlockStarts(linksToAssociate,compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "                    blockList.append((accessionID,blockLength,tuple(linksToAssociate),tuple(deepcopy(block))))\n",
    "            else:\n",
    "                extendedLinks = [(curComp,nextComp) for nextComp in nextCompList if not \\\n",
    "                                    ((nextComp==curComp+1 and compDir[nextComp]=='+' and compDir[curComp]=='+') or \\\n",
    "                                     (nextComp==curComp-1 and compDir[nextComp]=='-' and compDir[curComp]=='-'))]\n",
    "                associatedLinks.extend(extendedLinks)\n",
    "                newPositiveBlockStarts,newNegativeBlockStarts = \\\n",
    "                    addToNewBlockStarts([link for link in extendedLinks if not (link[0]>=link[1] and link[1]<=rightEnd or link[0]<link[1] and link[1]>rightEnd)],\n",
    "                                        compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "                break\n",
    "        else:\n",
    "            for nextCompInd in np.where(distToNextComp>1)[0]:\n",
    "                nextComp = nextCompList[nextCompInd]\n",
    "                if nextComp>rightEnd and curComp<rightEnd:\n",
    "                    isBackward = True\n",
    "                    doBreak = True\n",
    "                    break\n",
    "                    \n",
    "                if nextComp<=fromComp:\n",
    "                    smallBlock = []\n",
    "                    smallAssociatedLinks = [(curComp,nextComp)]\n",
    "                    smallBlockSize = 0\n",
    "                    for compInd in range(curComp+1,nextComp):\n",
    "                        if accessionID in components[compInd-1]['occupants']:\n",
    "                            smallBlock.append(compInd)\n",
    "                            smallBlockSize += compLength(compInd,components)\n",
    "                    blockList.append((accessionID,smallBlockSize,tuple(smallAssociatedLinks),tuple(smallBlock)))\n",
    "#                 else:\n",
    "#                     associatedLinks.append((curComp,nextComp))\n",
    "            if doBreak:\n",
    "                break\n",
    "            \n",
    "        nextComp = nextCompList[np.argmin(np.where(distToNextComp>0,distToNextComp,np.max(distToNextComp)+np.abs(distToNextComp)+1))]\n",
    "        if ((nextComp-curComp>1 and compDir[nextComp]=='+' and compDir[curComp]=='+') or \\\n",
    "           (curComp-nextComp>1 and compDir[nextComp]=='-' and compDir[curComp]=='-')):\n",
    "            associatedLinks.append((curComp,nextComp))\n",
    "        if (curComp,nextComp) in extraLinks:\n",
    "            extraLinks.remove((curComp,nextComp))\n",
    "        newPositiveBlockStarts,newNegativeBlockStarts = \\\n",
    "            addToNewBlockStarts(extraLinks,compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "        associatedLinks.extend(extraLinks)\n",
    "        blockLength += compLength(nextComp,components)\n",
    "        block.append(nextComp)\n",
    "        curComp = nextComp\n",
    "    \n",
    "    blockList.append((accessionID,blockLength,tuple(associatedLinks+checkOvercoming(block,accessionLinks,accessionToLinks)),tuple(block)))\n",
    "    \n",
    "    if not isBackward and not isOverStart and not isOverEnd:\n",
    "\n",
    "        stopSearch = False\n",
    "\n",
    "        \n",
    "        for comp in range(toComp-1,0,-1):\n",
    "            compLinks = np.array(list(accessionLinks.get(comp,set())))\n",
    "            if len(accessionToLinks.get(comp,set()))==0 and accessionID in components[comp-1].get('starts',[]):\n",
    "                stopSearch = True\n",
    "\n",
    "            if len(compLinks)==0:\n",
    "                continue\n",
    "\n",
    "            distToNextComp = compLinks - comp\n",
    "\n",
    "            if np.all(distToNextComp==1):\n",
    "                break\n",
    "\n",
    "            for linkEnd in np.where(distToNextComp>1)[0]:\n",
    "                stopSearch = True\n",
    "                if not (comp<accEnds[accessionID] and (compLinks[linkEnd]>accEnds[accessionID])):\n",
    "                    blockList.append(processForwardLink(comp,compLinks[linkEnd],accessionLinks,accessionToLinks,accessionID,components))\n",
    "\n",
    "            if stopSearch:\n",
    "                break\n",
    "    \n",
    "    return blockList,newPositiveBlockStarts,newNegativeBlockStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be deleted\n",
    "def processForwardLink(fromComp,toComp,accessionLinks,accessionToLinks,accessionID,components):\n",
    "    \n",
    "    block = [toComp]\n",
    "    associatedLinks = [(fromComp,toComp)]\n",
    "    blockLength = compLength(toComp, components)\n",
    "    curComp = toComp\n",
    "    \n",
    "    stopSearch = False\n",
    "    \n",
    "    while True:\n",
    "        nextCompList = np.array(list(accessionLinks.get(curComp,set())))\n",
    "        \n",
    "        if len(nextCompList)==0 and accessionID in components[curComp-1].get('ends',[]):\n",
    "            stopSearch = True\n",
    "        \n",
    "        if np.any(nextCompList<toComp):\n",
    "            break\n",
    "        \n",
    "        distToNextComp = nextCompList-curComp\n",
    "        \n",
    "        if np.all(distToNextComp<=0):\n",
    "            break\n",
    "        \n",
    "        nextCompList = nextCompList[distToNextComp>0]\n",
    "        distToNextComp = distToNextComp[distToNextComp>0]\n",
    "        \n",
    "        nextComp = nextCompList[np.argmin(distToNextComp)]\n",
    "        if (nextComp-curComp>1):\n",
    "            associatedLinks.append((curComp,nextComp))\n",
    "        blockLength += compLength(nextComp,components)\n",
    "        block.append(nextComp)\n",
    "        curComp = nextComp\n",
    "        \n",
    "        if stopSearch:\n",
    "            break\n",
    "    \n",
    "    return (accessionID,blockLength,tuple(associatedLinks+checkOvercoming(block,accessionLinks,accessionToLinks)),tuple(block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be deleted\n",
    "def processNegativeLink(fromComp,toComp,accessionID,accStarts,accEnds,fromComponentLinksAcc,toComponentLinksAcc,accCompDir,components):\n",
    "    accessionFromLinks = fromComponentLinksAcc[accessionID]\n",
    "    accessionToLinks = toComponentLinksAcc[accessionID]\n",
    "    \n",
    "    compDir = accCompDir[accessionID]\n",
    "    \n",
    "    leftEnd = min(accStarts[accessionID],accEnds[accessionID])\n",
    "    rightEnd = min(accStarts[accessionID],accEnds[accessionID])\n",
    "    \n",
    "    if fromComp is not None:\n",
    "        isOverEnd = (fromComp<accEnds[accessionID] and toComp>accEnds[accessionID])\n",
    "        isOverStart = (fromComp>=accStarts[accessionID] and toComp<accStarts[accessionID])\n",
    "    else:\n",
    "        isOverStart = (accStarts[accessionID]<accEnds[accessionID])\n",
    "        isOverEnd = False\n",
    "    \n",
    "    isBackward = False\n",
    "    \n",
    "    # This list will include tuples in the following structure:\n",
    "    # (accessionID, blockLength, associatedLinks, includedComponents)\n",
    "    blockList = []\n",
    "    block = [toComp]\n",
    "    blockLength = compLength(toComp,components)\n",
    "    \n",
    "    newPositiveBlockStarts = set()\n",
    "    newNegativeBlockStarts = set()\n",
    "    \n",
    "    if fromComp is not None:\n",
    "        associatedLinks = [(fromComp,toComp)]\n",
    "        if fromComp<=toComp:\n",
    "            # If it is forward link, then we need to check whether there are any backward link\n",
    "            # coming to the same component and associate them with this block as well\n",
    "            for fc in accessionToLinks[toComp]:\n",
    "                if fc>=toComp:\n",
    "                    isBackward = True\n",
    "                    if (fc,toComp) not in associatedLinks:\n",
    "                        associatedLinks.append((fc,toComp))\n",
    "        fComp = fromComp\n",
    "    else:\n",
    "        associatedLinks = []\n",
    "        fComp = 0\n",
    "        # Not sure whether it is correct to do like this or it should be taken into account\n",
    "        # when the block ends and we hit another forward link. Possibly, it will be more universal solution.\n",
    "#         if toComp+1 in accessionFromLinks.get(fromComp+1,set()):\n",
    "#             associatedLinks.append((fromComp+1,toComp+1))\n",
    "    curComp = toComp\n",
    "    \n",
    "    doBreak = False\n",
    "#     pdb.set_trace()\n",
    "    while True:\n",
    "#         if curComp==2958 and accessionID==17:\n",
    "#             pdb.set_trace()\n",
    "        extraLinks = []\n",
    "        \n",
    "        nextCompList = np.array(list(accessionFromLinks.get(curComp,set())))\n",
    "        distToNextComp = nextCompList-curComp\n",
    "        if len(nextCompList)==0:\n",
    "            break\n",
    "        if np.all(distToNextComp>=0) or (np.any(np.logical_and(distToNextComp>0,nextCompList>toComp)) and (fComp>toComp)):\n",
    "            \n",
    "            # add all forward link jumping over the start to associated links\n",
    "            associatedLinks.extend([(curComp,nextComp) for nextComp in nextCompList if not \\\n",
    "                                    ((nextComp==curComp+1 and compDir[nextComp]=='+' and compDir[curComp]=='+'))])\n",
    "            break\n",
    "        elif np.all(nextCompList<fComp) and (fComp<toComp):\n",
    "            extendedLinks = [(curComp,nextComp) for nextComp in nextCompList if not \\\n",
    "                                    ((nextComp==curComp+1 and compDir[nextComp]=='+' and compDir[curComp]=='+') or \\\n",
    "                                     (nextComp==curComp-1 and compDir[nextComp]=='-' and compDir[curComp]=='-'))]\n",
    "            associatedLinks.extend(extendedLinks)\n",
    "            newPositiveBlockStarts,newNegativeBlockStarts = \\\n",
    "                    addToNewBlockStarts(extendedLinks,compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "            break\n",
    "        elif np.any(distToNextComp>=0) or np.any(nextCompList<fComp) and (fComp<toComp):\n",
    "            \n",
    "            if np.any(np.logical_and(nextCompList>=fComp,nextCompList<toComp)):\n",
    "                linksToAssociate = []\n",
    "                for nextComp in nextCompList:\n",
    "                    if not ((curComp==nextComp-1 and compDir[curComp]=='+' and compDir[nextComp]=='+') or \\\n",
    "                         (curComp==nextComp+1 and compDir[curComp]=='-' and compDir[nextComp]=='-')) and \\\n",
    "                        ((curComp,nextComp) not in associatedLinks):\n",
    "                            if (nextComp<=fComp or nextComp>toComp):\n",
    "                                linksToAssociate.append((curComp,nextComp))\n",
    "                            else:\n",
    "                                extraLinks.append((curComp,nextComp))\n",
    "                \n",
    "                # These auxiliary blocks should be associated only with the links that create this break \n",
    "                # (recorded in `linksToAssociate`), but not with the links which creates the main block \n",
    "                # (which recorded in `associatedLinks`).\n",
    "                if len(linksToAssociate)>0:\n",
    "                    blockList.append((accessionID,blockLength,tuple(linksToAssociate),tuple(deepcopy(block))))\n",
    "                    newPositiveBlockStarts,newNegativeBlockStarts = \\\n",
    "                        addToNewBlockStarts(linksToAssociate,compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "#                 else:\n",
    "#                     pdb.set_trace()\n",
    "            else:\n",
    "                extendedLinks = [(curComp,nextComp) for nextComp in nextCompList if not \\\n",
    "                                        ((nextComp==curComp+1 and compDir[nextComp]=='+' and compDir[curComp]=='+') or \\\n",
    "                                         (nextComp==curComp-1 and compDir[nextComp]=='-' and compDir[curComp]=='-'))]\n",
    "                associatedLinks.extend(extendedLinks)    \n",
    "                newPositiveBlockStarts,newNegativeBlockStarts = \\\n",
    "                    addToNewBlockStarts([link for link in extendedLinks if not (link[0]>=link[1] and link[1]<=leftEnd or link[0]<link[1] and link[1]>leftEnd)],\n",
    "                                        compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "                break\n",
    "        elif np.any(np.logical_and(distToNextComp>=0,nextCompList>toComp)) and (fComp>toComp):\n",
    "            \n",
    "            if np.any(np.logical_and(nextCompList<toComp)):\n",
    "                linksToAssociate = []\n",
    "                for nextComp in nextCompList:\n",
    "                    if (nextComp>toComp) and \\\n",
    "                    not ((curComp==nextComp-1 and compDir[curComp]=='+' and compDir[nextComp]=='+') or \\\n",
    "                         (curComp==nextComp+1 and compDir[curComp]=='-' and compDir[nextComp]=='-')) and \\\n",
    "                    ((curComp,nextComp) not in associatedLinks):\n",
    "                        linksToAssociate.append((curComp,nextComp))\n",
    "                \n",
    "                if len(linksToAsociate)>0:\n",
    "                    newPositiveBlockStarts,newNegativeBlockStarts = \\\n",
    "                        addToNewBlockStarts(linksToAssociate,compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "                blockList.append((accessionID,blockLength,tuple(associatedLinks+linksToAssociate),tuple(deepcopy(block))))\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            for nextCompInd in np.where(distToNextComp<-1)[0]:\n",
    "                nextComp = nextCompList[nextCompInd]\n",
    "                if nextComp<leftEnd and curComp>leftEnd:\n",
    "                    doBreak = True\n",
    "                    break\n",
    "                    \n",
    "                if nextComp>=toComp:\n",
    "                    smallBlock = []\n",
    "                    smallAssociatedLinks = [(curComp,nextComp)]\n",
    "                    smallBlockSize = 0\n",
    "                    for compInd in range(curComp+1,nextComp):\n",
    "                        if accessionID in components[compInd-1]['occupants']:\n",
    "                            smallBlock.append(compInd)\n",
    "                            smallBlockSize += compLength(compInd,components)\n",
    "                    blockList.append((accessionID,smallBlockSize,tuple(smallAssociatedLinks),tuple(smallBlock)))\n",
    "#                 else:\n",
    "#                     associatedLinks.append((curComp,nextComp))\n",
    "            if doBreak:\n",
    "                break\n",
    "            \n",
    "        nextComp = nextCompList[np.argmin(np.where(distToNextComp<0,distToNextComp,np.max(distToNextComp)+np.abs(distToNextComp)+1))]\n",
    "        if not ((nextComp-curComp==1 and compDir[nextComp]=='+' and compDir[curComp]=='+') or \\\n",
    "           (curComp-nextComp==1 and compDir[nextComp]=='-' and compDir[curComp]=='-')):\n",
    "            associatedLinks.append((curComp,nextComp))\n",
    "        if (curComp,nextComp) in extraLinks:\n",
    "            extraLinks.remove((curComp,nextComp))\n",
    "        newPositiveBlockStarts,newNegativeBlockStarts = \\\n",
    "            addToNewBlockStarts(extraLinks,compDir,accessionID,newPositiveBlockStarts,newNegativeBlockStarts)\n",
    "        associatedLinks.extend(extraLinks)\n",
    "        blockLength += compLength(nextComp,components)\n",
    "        block.append(nextComp)\n",
    "        curComp = nextComp\n",
    "    \n",
    "    leftmostBlockComp = min(block)\n",
    "    \n",
    "    \n",
    "    # If there was at least one link to the start of the block from the right (backward link),\n",
    "    # we should expect that there are links from the component just before \n",
    "    # (!!! is it just before or we should look further or hope that it will be picked up by other blocks?) \n",
    "    # the block going over it and all of them should also be associated with this block.\n",
    "    if (fComp>toComp or isBackward) and leftmostBlockComp>1:\n",
    "        for jumpToComp in accessionFromLinks.get(leftmostBlockComp-1,set()):\n",
    "            if jumpToComp>toComp:\n",
    "                associatedLinks.append((leftmostBlockComp-1,jumpToComp))\n",
    "    \n",
    "    blockList.append((accessionID,blockLength,tuple(associatedLinks),tuple(block)))\n",
    "    \n",
    "    # At the moment checkOvercoming was substituted by the routine just above, but there is a possibility that it may be needed.\n",
    "    # Double check!\n",
    "    #+checkOvercoming(block,accessionFromLinks,accessionToLinks)\n",
    "    \n",
    "    return blockList,newPositiveBlockStarts,newNegativeBlockStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be deleted\n",
    "def identifyCollapsibleBlocks(positiveBlockStarts,negativeBlockStarts,accStarts,accEnds,fromComponentLinksAcc,toComponentLinksAcc,accCompDir,components):\n",
    "    collapsibleBlocks = []\n",
    "    collectivePositiveBlockStarts = set(positiveBlockStarts)\n",
    "    collectiveNegativeBlockStarts = set(negativeBlockStarts)\n",
    "    _positiveBlockStarts = deepcopy(collectivePositiveBlockStarts)\n",
    "    _negativeBlockStarts = deepcopy(collectiveNegativeBlockStarts)\n",
    "    counter = 1\n",
    "    while len(_positiveBlockStarts)>0 or len(_negativeBlockStarts)>0:\n",
    "        print(f'Iteration {counter}, {len(_positiveBlockStarts)} positive starts, {len(_negativeBlockStarts)} negative starts')\n",
    "        counter += 1\n",
    "        for backLink in _positiveBlockStarts:\n",
    "            res,newPosBlockStarts,newNegBlockStarts = processBackwardLink(*backLink,accStarts,accEnds,fromComponentLinksAcc,toComponentLinksAcc,accCompDir,components)\n",
    "    #         print(f'Back Link {backLink[0]} -> {backLink[1]} for accession {backLink[2]} ({graph.accessions[backLink[2]]})')\n",
    "    #         print(res)\n",
    "            collapsibleBlocks.extend(res)\n",
    "        \n",
    "        _positiveBlockStarts = newPosBlockStarts.difference(collectivePositiveBlockStarts)\n",
    "        _negativeBlockStarts.update(newNegBlockStarts.difference(collectiveNegativeBlockStarts))\n",
    "        \n",
    "        collectivePositiveBlockStarts.update(_positiveBlockStarts)\n",
    "        collectiveNegativeBlockStarts.update(_negativeBlockStarts)\n",
    "        \n",
    "        for forwardLink in _negativeBlockStarts:\n",
    "            res,newPosBlockStarts,newNegBlockStarts = processNegativeLink(*forwardLink,accStarts,accEnds,fromComponentLinksAcc,toComponentLinksAcc,accCompDir,components)\n",
    "    #         print(f'Back Link {backLink[0]} -> {backLink[1]} for accession {backLink[2]} ({graph.accessions[backLink[2]]})')\n",
    "    #         print(res)\n",
    "            collapsibleBlocks.extend(res)\n",
    "            \n",
    "            \n",
    "        _positiveBlockStarts.update(newPosBlockStarts.difference(collectivePositiveBlockStarts))\n",
    "        _negativeBlockStarts = newNegBlockStarts.difference(collectiveNegativeBlockStarts)\n",
    "\n",
    "        collectivePositiveBlockStarts.update(_positiveBlockStarts)\n",
    "        collectiveNegativeBlockStarts.update(_negativeBlockStarts)\n",
    "    return collapsibleBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBackwardPositiveLinks(toComponentLinks,toComponentLinksAcc,accStarts,accEnds):\n",
    "    '''\n",
    "    Function gets toCOmponentLinks dict structure (output from `baseLayerZoom` (partially) and \n",
    "    `nodeToComponentLinks` (finalised) on base layer and by `nextLayerZoom` on every other zoom layer).\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    toComponentLinks: dict{int:dict{str:dict{int:dict{str:list[int]}}}}. This input is an hierarchical structure of dicts\n",
    "                    which holds all links between components on the current zoom layer. This structure is internal and \n",
    "                    produced by `baseLayerZoom` (partially) and `nodeToComponentLinks` (finalised) on base layer and \n",
    "                    by `nextLayerZoom` on every other zoom layer.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    compAccessionBackLinks: list[tuple(int)]. A list of tuples of component ids (1-based) (outgoing and incoming) and accessions \n",
    "                            where reversed (backward) links are coming.\n",
    "    \n",
    "    '''\n",
    "    allBlockStarts = []\n",
    "#     backLinksThroughStart = []\n",
    "#     forwardLinksThroughEnd = []\n",
    "    \n",
    "    for toComp,toCompDict in toComponentLinks.items():\n",
    "\n",
    "        # We are interested only in backward links coming to forward components (per accession, not overall)\n",
    "        for fromComp,fromCompDict in toCompDict.get('+',{}).items():\n",
    "            if fromComp>=toComp:\n",
    "                for accList in fromCompDict.values():\n",
    "                    for acc in accList:\n",
    "                        if fromComp>accEnds[acc] and toComp<=accEnds[acc] and not (fromComp>=accStarts[acc] and toComp<accStarts[acc]):\n",
    "                            if np.all(np.array(list(toComponentLinksAcc[acc][toComp]))>=toComp):\n",
    "                                continue\n",
    "                            \n",
    "                        if fromComp>=accStarts[acc] and toComp<accStarts[acc]:\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "                        else:\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "            else:\n",
    "                # Identify forward links through end\n",
    "                for accList in fromCompDict.values():\n",
    "                    for acc in accList:\n",
    "                        if fromComp<accEnds[acc] and toComp>accEnds[acc]:\n",
    "                            allBlockStarts.append((fromComp,toComp,acc))\n",
    "    \n",
    "    \n",
    "    return allBlockStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processBackwardLink(fromComp,toComp,accessionID,accStarts,accEnds,fromComponentLinksAcc,toComponentLinksAcc,components):\n",
    "    accessionLinks = fromComponentLinksAcc[accessionID]\n",
    "    accessionToLinks = toComponentLinksAcc[accessionID]\n",
    "    \n",
    "    isOverEnd = (fromComp<accEnds[accessionID] and toComp>accEnds[accessionID])\n",
    "    isOverStart = (fromComp>=accStarts[accessionID] and toComp<accStarts[accessionID])\n",
    "#     if fromComp==4 and toComp==2:\n",
    "#         pdb.set_trace()\n",
    "\n",
    "    # This list will include tuples in the following structure:\n",
    "    # (accessionID, blockLength, associatedLinks, includedComponents)\n",
    "    blockList = []\n",
    "    block = [toComp]\n",
    "    blockLength = compLength(toComp,components)\n",
    "    associatedLinks = [(fromComp,toComp)]\n",
    "    curComp = toComp\n",
    "    \n",
    "    isBackward = False\n",
    "    \n",
    "    while True:\n",
    "        nextCompList = np.array(list(accessionLinks.get(curComp,set())))\n",
    "        distToNextComp = nextCompList-curComp\n",
    "        if len(nextCompList)==0:\n",
    "            break\n",
    "        if np.any(distToNextComp<=0):\n",
    "            isBackward = True\n",
    "            # add all backwards link jumping over the end to associated links\n",
    "            for nextCompID in np.where(distToNextComp<=0)[0]:\n",
    "                nextComp = nextCompList[nextCompID]\n",
    "                if nextComp<=accEnds[accessionID] and curComp>accEnds[accessionID] and \\\n",
    "                   np.all(np.array(list(accessionToLinks[nextComp]))>=nextComp):\n",
    "                    associatedLinks.append((curComp,nextComp))\n",
    "            break\n",
    "        elif np.any(nextCompList>fromComp):\n",
    "            associatedLinks.extend([(curComp,nextComp) for nextComp in nextCompList if nextComp>curComp+1])\n",
    "            break\n",
    "        else:\n",
    "            \n",
    "            for nextCompInd in np.where(distToNextComp>1)[0]:\n",
    "                nextComp = nextCompList[nextCompInd]\n",
    "                if nextComp>accEnds[accessionID] and curComp<accEnds[accessionID]:\n",
    "                    isBackward = True\n",
    "                    break\n",
    "                    \n",
    "                if nextComp<=fromComp:\n",
    "                    smallBlock = []\n",
    "                    smallAssociatedLinks = [(curComp,nextComp)]\n",
    "                    smallBlockSize = 0\n",
    "                    for compInd in range(curComp+1,nextComp):\n",
    "                        if accessionID in components[compInd-1]['occupants']:\n",
    "                            smallBlock.append(compInd)\n",
    "                            smallBlockSize += compLength(compInd,components)\n",
    "                    blockList.append((accessionID,smallBlockSize,smallAssociatedLinks,smallBlock))\n",
    "#                 else:\n",
    "#                     associatedLinks.append((curComp,nextComp))\n",
    "            if isBackward:\n",
    "                break\n",
    "            \n",
    "            nextComp = nextCompList[np.argmin(distToNextComp)]\n",
    "            if (nextComp-curComp>1):\n",
    "                associatedLinks.append((curComp,nextComp))\n",
    "            blockLength += compLength(nextComp,components)\n",
    "            block.append(nextComp)\n",
    "            curComp = nextComp\n",
    "    \n",
    "    blockList.append((accessionID,blockLength,associatedLinks,block))\n",
    "    \n",
    "    if not isBackward and not isOverStart and not isOverEnd:\n",
    "\n",
    "        stopSearch = False\n",
    "\n",
    "        \n",
    "        for comp in range(toComp-1,0,-1):\n",
    "            compLinks = np.array(list(accessionLinks.get(comp,set())))\n",
    "            if len(accessionToLinks.get(comp,set()))==0 and accessionID in components[comp-1].get('starts',[]):\n",
    "                stopSearch = True\n",
    "\n",
    "            if len(compLinks)==0:\n",
    "                continue\n",
    "\n",
    "            distToNextComp = compLinks - comp\n",
    "\n",
    "            if np.all(distToNextComp==1):\n",
    "                break\n",
    "\n",
    "            for linkEnd in np.where(distToNextComp>1)[0]:\n",
    "                stopSearch = True\n",
    "                if not (comp<accEnds[accessionID] and (compLinks[linkEnd]>accEnds[accessionID])):\n",
    "                    blockList.append(processForwardLink(comp,compLinks[linkEnd],accessionLinks,accessionID,components))\n",
    "\n",
    "            if stopSearch:\n",
    "                break\n",
    "    \n",
    "    return blockList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processForwardLink(fromComp,toComp,accessionLinks,accessionID,components):\n",
    "    \n",
    "    block = [toComp]\n",
    "    associatedLinks = [(fromComp,toComp)]\n",
    "    blockLength = compLength(toComp, components)\n",
    "    curComp = toComp\n",
    "    \n",
    "    stopSearch = False\n",
    "    \n",
    "    while True:\n",
    "        nextCompList = np.array(list(accessionLinks.get(curComp,set())))\n",
    "        \n",
    "        if len(nextCompList)==0 and accessionID in components[curComp-1].get('ends',[]):\n",
    "            stopSearch = True\n",
    "        \n",
    "        if np.any(nextCompList<toComp):\n",
    "            break\n",
    "        \n",
    "        distToNextComp = nextCompList-curComp\n",
    "        \n",
    "        if np.all(distToNextComp<=0):\n",
    "            break\n",
    "        \n",
    "        nextCompList = nextCompList[distToNextComp>0]\n",
    "        distToNextComp = distToNextComp[distToNextComp>0]\n",
    "        \n",
    "        nextComp = nextCompList[np.argmin(distToNextComp)]\n",
    "        if (nextComp-curComp>1):\n",
    "            associatedLinks.append((curComp,nextComp))\n",
    "        blockLength += compLength(nextComp,components)\n",
    "        block.append(nextComp)\n",
    "        curComp = nextComp\n",
    "        \n",
    "        if stopSearch:\n",
    "            break\n",
    "    \n",
    "    return (accessionID,blockLength,associatedLinks,block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyCollapsibleBlocks(allBlockStarts,accStarts,accEnds,fromComponentLinksAcc,toComponentLinksAcc,components):\n",
    "    collapsibleBlocks = []\n",
    "    for backLink in allBlockStarts:\n",
    "        res = processBackwardLink(*backLink,accStarts,accEnds,fromComponentLinksAcc,toComponentLinksAcc,components)\n",
    "#         print(f'Back Link {backLink[0]} -> {backLink[1]} for accession {backLink[2]} ({graph.accessions[backLink[2]]})')\n",
    "#         print(res)\n",
    "        collapsibleBlocks.extend(res)\n",
    "    return collapsibleBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "def updateLinks(newToOldInd,oldToNewInd,\n",
    "                fromComponentLinks,toComponentLinks,\n",
    "                collapsibleBlocks,accStarts,accEnds,components,\n",
    "                newFromComponentLinks={},newToComponentLinks={}):\n",
    "    \n",
    "    for newComp,oldCompList in enumerate(newToOldInd):\n",
    "        leftOldCompId = oldCompList[0] + 1\n",
    "        rightOldCompId = oldCompList[-1] + 1\n",
    "        newCompId = newComp + 1\n",
    "        \n",
    "        # The next two if blocks set conditions for processing or not processing left and right of the current new component\n",
    "        # The side should not be processed if the end of the previous node is coming from the same component \n",
    "        # (on lower zoom level) as the begininng of the current component.\n",
    "        if newComp>0:\n",
    "            if oldCompList[0]==newToOldInd[newComp-1][-1]:\n",
    "                doLeft = False\n",
    "            else:\n",
    "                doLeft = True\n",
    "        else:\n",
    "            doLeft = True\n",
    "            \n",
    "        if newComp<len(newToOldInd)-1:\n",
    "            if oldCompList[-1]==newToOldInd[newComp+1][0]:\n",
    "                doRight = False\n",
    "            else:\n",
    "                doRight = True\n",
    "        else:\n",
    "            doRight = True\n",
    "\n",
    "        # Departure on the right (from positive block)\n",
    "        if doRight:\n",
    "            toCompDict = fromComponentLinks.get(rightOldCompId,{}).get('+',{})\n",
    "            for toOldComp,toOldCompDirDict in toCompDict.items():\n",
    "                # to positive strand\n",
    "                if '+' in toOldCompDirDict:\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][0]\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[toNewCompId][0]==toOldComp-1:\n",
    "                        addLink(newCompId,'+',toNewCompId+1,'+',toOldCompDirDict['+'],newFromComponentLinks,newToComponentLinks)\n",
    "                # to negative strand\n",
    "                if '-' in toOldCompDirDict:\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][-1]\n",
    "                    # Check whether the to comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[toNewCompId][-1]==toOldComp-1:\n",
    "                        addLink(newCompId,'+',toNewCompId+1,'-',toOldCompDirDict['-'],newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "        # Departure on the left (from negative block)\n",
    "        if doLeft:\n",
    "            toCompDict = fromComponentLinks.get(leftOldCompId,{}).get('-',{})\n",
    "            for toOldComp,toOldCompDirDict in toCompDict.items():\n",
    "                # to positive strand\n",
    "                if '+' in toOldCompDirDict:\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][0]\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[toNewCompId][0]==toOldComp-1:\n",
    "                        addLink(newCompId,'-',toNewCompId+1,'+',toOldCompDirDict['+'],newFromComponentLinks,newToComponentLinks)\n",
    "                # to negative strand\n",
    "                if '-' in toOldCompDirDict:\n",
    "                    # Getting to comp (new) id\n",
    "                    toNewCompId = oldToNewInd[toOldComp-1][-1]\n",
    "                    # Check whether the to comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[toNewCompId][-1]==toOldComp-1:\n",
    "                        addLink(newCompId,'-',toNewCompId+1,'-',toOldCompDirDict['-'],newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "\n",
    "        # Arrival on the left (to positive block)\n",
    "        if doLeft:\n",
    "            fromCompDict = toComponentLinks.get(leftOldCompId,{}).get('+',{})\n",
    "            for fromOldComp,fromOldCompDirDict in fromCompDict.items():\n",
    "                # from positive strand\n",
    "                if '+' in fromOldCompDirDict:\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][-1]\n",
    "                    # Check whether the from comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[fromNewCompId][-1]==fromOldComp-1:\n",
    "                        addLink(fromNewCompId+1,'+',newCompId,'+',fromOldCompDirDict['+'],newFromComponentLinks,newToComponentLinks)\n",
    "                # to negative strand\n",
    "                if '-' in fromOldCompDirDict:\n",
    "                    # Getting to comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][0]\n",
    "                    # Check whether the to comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[fromNewCompId][0]==fromOldComp-1:\n",
    "                        addLink(fromNewCompId+1,'-',newCompId,'+',fromOldCompDirDict['-'],newFromComponentLinks,newToComponentLinks)\n",
    "\n",
    "        if doRight:\n",
    "            # Arrival on the right (to negative block)\n",
    "            fromCompDict = toComponentLinks.get(rightOldCompId,{}).get('-',{})\n",
    "            for fromOldComp,fromOldCompDirDict in fromCompDict.items():\n",
    "                # from positive strand\n",
    "                if '+' in fromOldCompDirDict:\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][-1]\n",
    "                    # Check whether the from comp (old) is on the right of the new comp\n",
    "                    if newToOldInd[fromNewCompId][0]==fromOldComp-1:\n",
    "                        addLink(fromNewCompId+1,'+',newCompId,'-',fromOldCompDirDict['+'],newFromComponentLinks,newToComponentLinks)\n",
    "                # from negative strand\n",
    "                if '-' in fromOldCompDirDict:\n",
    "                    # Getting from comp (new) id\n",
    "                    fromNewCompId = oldToNewInd[fromOldComp-1][-1]\n",
    "                    # Check whether the from comp (old) is on the left of the new comp\n",
    "                    if newToOldInd[fromNewCompId][-1]==fromOldComp-1:\n",
    "                        addLink(fromNewCompId+1,'-',newCompId,'-',fromOldCompDirDict['-'],newFromComponentLinks,newToComponentLinks)\n",
    "    \n",
    "    for acc in accStarts.keys():\n",
    "        accStarts[acc] = oldToNewInd[accStarts[acc]-1][0]+1\n",
    "        accEnds[acc] = oldToNewInd[accEnds[acc]-1][0]+1\n",
    "        \n",
    "    for blockID,[accessionID,blockLength,associatedLinks,associatedComponents] in enumerate(collapsibleBlocks):\n",
    "        collapsibleBlocks[blockID] = (accessionID,blockLength,\n",
    "                                      [[oldToNewInd[link[0]-1][0]+1,oldToNewInd[link[1]-1][0]+1] for link in associatedLinks],\n",
    "                                      [compID+1 for comp in associatedComponents for compID in oldToNewInd[comp-1]])\n",
    "    \n",
    "    return newFromComponentLinks,newToComponentLinks,accStarts,accEnds,collapsibleBlocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-casino",
   "metadata": {},
   "source": [
    "### Old routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportToPantograph(graph=None, inputPath=None, GenomeGraphParams={}, outputPath=None, outputName=None, outputSuffix=None, isSeq=True,\n",
    "                       redisConn=None,\n",
    "                       listOfExports=['schematise', 'genomeToPangenome', 'annotationToGenome'],\n",
    "                       zoomLevels=[1], maxLengthComponent=100, maxLengthChunk=20, inversionThreshold=0.5,\n",
    "                       debug=False, returnDebugData=False):\n",
    "\n",
    "    if graph is None:\n",
    "        if inputPath is not None:\n",
    "            print('Loading Genome')\n",
    "            graph = GenomeGraph(gfaPath=inputPath, isGFASeq=isSeq, **GenomeGraphParams)\n",
    "        else:\n",
    "            raise ValueError(\"Either graph or inputpath to GFA file should be provided\")\n",
    "\n",
    "    if outputPath is None and outputName is None:\n",
    "        if inputPath is not None:\n",
    "            if outputSuffix is not None:\n",
    "                outputPath, outputName = pathConvert(inputPath, suffix = outputSuffix)\n",
    "            else:\n",
    "                outputPath, outputName = pathConvert(inputPath)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"If inputPath is not given, then outputPath and outputName should be provided.\")\n",
    "    else:\n",
    "        if outputSuffix is not None:\n",
    "            outputName = outputName + outputSuffix\n",
    "    print(f'Recording Pantograph data to {outputPath}{os.path.sep}{outputName}')\n",
    "    \n",
    "    if redisConn is not None:\n",
    "        redisConn.flushdb()\n",
    "    \n",
    "    numNodes = len(graph.nodes)\n",
    "    numNodesDigits = np.int(np.ceil(np.log10(numNodes)))\n",
    "    fromLinks = {}\n",
    "    toLinks = {}\n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    rootStruct = deepcopy(rootStructTemplate)\n",
    "    rootStruct[\"pathNames\"] = graph.accessions\n",
    "\n",
    "    if returnDebugData:\n",
    "        zoomComponentLengths = {}\n",
    "        zoomNodeToComponent = {}\n",
    "\n",
    "        zoomComponentToNodes = {}\n",
    "        zoomComponents = {}  # temporary structure for testing, later each zoomlevel should be just saved as soon as it is processed.\n",
    "        zoomCompNucleotides = {}\n",
    "\n",
    "    nodeLengths = calcNodeLengths(graph)\n",
    "\n",
    "    pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum = initialPathAnalysis(graph,nodeLengths)\n",
    "\n",
    "    for zoomLevel in zoomLevels:\n",
    "\n",
    "        zoomTime = time.time()\n",
    "\n",
    "        os.makedirs(f'{outputPath}{os.path.sep}{outputName}{os.path.sep}{zoomLevel}',exist_ok=True)\n",
    "\n",
    "        print('\\n===========================')\n",
    "        print(f'Zoom level {zoomLevel}')\n",
    "        print('===========================')\n",
    "        zoom_level_struct = {}\n",
    "        zoom_level_struct[\"files\"] = []\n",
    "\n",
    "        if returnDebugData:\n",
    "            nodeToComponent = zoomNodeToComponent.setdefault(zoomLevel,[])\n",
    "            componentToNode = zoomComponentToNodes.setdefault(zoomLevel,[])\n",
    "            componentLengths = zoomComponentLengths.setdefault(zoomLevel,[])\n",
    "            components = zoomComponents.setdefault(zoomLevel,[])\n",
    "            componentNucleotides = zoomCompNucleotides.setdefault(zoomLevel,[])\n",
    "        else:\n",
    "            nodeToComponent = []\n",
    "            componentToNode = []\n",
    "            componentLengths = []\n",
    "            components = []\n",
    "            componentNucleotides = []\n",
    "\n",
    "        component = deepcopy(componentTemplate)\n",
    "\n",
    "        occupants = set()\n",
    "        nucleotides = ''\n",
    "        matrix = {}\n",
    "\n",
    "        \n",
    "        nodeLinks = []\n",
    "\n",
    "        nBins = 0\n",
    "        previousInv = {}\n",
    "        nCols = 0\n",
    "        binLength = 0\n",
    "        occupancy = {}\n",
    "        inversion = {}\n",
    "        pos = {}\n",
    "        nodesInComp = set()\n",
    "        annotationNames = {}\n",
    "        breakComponentWhenBinEnds = False\n",
    "#         breakCompBeforeBin = False\n",
    "        binOpen = False\n",
    "        breakComponent = False\n",
    "        forceBreak = False\n",
    "\n",
    "        for nodeIdx in range(1,numNodes+1):\n",
    "            if debug:\n",
    "                print(f'Processing node {nodeIdx:0{numNodesDigits}}/{numNodes:0{numNodesDigits}}')\n",
    "            else:\n",
    "                print(f'\\nProcessing node {nodeIdx:0{numNodesDigits}}/{numNodes:0{numNodesDigits}}',end='')\n",
    "\n",
    "            # Find positions of the node in each path\n",
    "            nodePathsIdx, nodeSeqInPath = np.where(pathNodeArray == nodeIdx)\n",
    "            # Find node length\n",
    "            nodeLen = nodeLengths[nodeIdx-1]\n",
    "\n",
    "            # Find unique path IDs (numerical) and cound of given node in each path.\n",
    "            uniqueNodePathsIDx,pathNodeCount = np.unique(nodePathsIdx,return_counts=True)\n",
    "\n",
    "            ####################################\n",
    "            # Block to check whether the component\n",
    "            # should be broken before this node.\n",
    "            ####################################\n",
    "            # TO CHECK: Should it happen only if binOpen is False???\n",
    "\n",
    "            # Boolean indicator of far incoming link\n",
    "            # TO CHECK: Is it only incoming as incoming to the left\n",
    "            # or incoming to the left and outgoing from the left?\n",
    "            incomingFarLink = False\n",
    "\n",
    "            # Boolean if at least one path starts from this node\n",
    "            pathStart = False\n",
    "            # Boolean if at least one path ends on this node.\n",
    "            pathEnd = False\n",
    "            # TO CHECK: Does it take into account inverted nodes in\n",
    "            #           some accessions?\n",
    "\n",
    "            # Indicator whether inversion is changed from one side of\n",
    "            # `inversionThreshold` to the other.\n",
    "            isChangeInversion = False\n",
    "\n",
    "            # Check whether component should be broken before current node.\n",
    "            for j, pathID in enumerate(uniqueNodePathsIDx):\n",
    "                \n",
    "                # calculating occupancy for current node\n",
    "                # Do we need it?\n",
    "                pOcc = occupancy.setdefault(pathID, 0)\n",
    "                pOcc += pathNodeCount[j]*nodeLen\n",
    "                occupancy[pathID] = pOcc  # Occupancy\n",
    "\n",
    "                # Calculate inversion of current node\n",
    "                localInv = 0\n",
    "                for nodeNumInPath in nodeSeqInPath[np.where(nodePathsIdx==pathID)[0]]:\n",
    "                    localInv += int(pathDirArray[pathID,nodeNumInPath])\n",
    "\n",
    "                pInv = inversion.get(pathID,0)\n",
    "                # Do we need to multiply it by node length?\n",
    "                # Most probably it is needed for larger components\n",
    "                # Bigger question is why we add it to the pInv, not just assign?\n",
    "                pInv += localInv*nodeLen/pathNodeCount[j]\n",
    "                inversion[pathID] = pInv\n",
    "                \n",
    "                # Check whether inversion is switched from one side of `inversionThreshold` to the other side.\n",
    "                # Should not pInv be divided by node length to get actual inversion fraction? \n",
    "                # Does it ever work and whether it is repeated after previous node?\n",
    "                if (pInv/nodeLen-inversionThreshold)*(previousInv.setdefault(pathID, pInv)/nodeLen-inversionThreshold)<0:\n",
    "                    isChangeInversion = True\n",
    "                # Record current inversion for current pathID as previous (already been analysed).\n",
    "#                 previousInv[pathID] = pInv\n",
    "                \n",
    "                # Get indexes of positions of the node in the path\n",
    "                nodePositions = np.where(nodePathsIdx==pathID)[0]\n",
    "                # Get node inversion\n",
    "                # Is it necessary to divide by node length???\n",
    "                nodeInversionInPath = inversion[pathID]/nodeLengths[nodeIdx-1]\n",
    "                #np.sum([pathDirArray[pathID, nodeSeqInPath[nodePos]] for nodePos in nodePositions])/len(nodePositions)\n",
    "                # loop over node position sin path\n",
    "                for nodePos in nodePositions:\n",
    "                    # Get actual position in path of the node\n",
    "                    nodePositionInPath = nodeSeqInPath[nodePos]\n",
    "                    if debug:\n",
    "                        print(f'Node {nodeIdx}, Path {pathID} inversion {nodeInversionInPath}')\n",
    "                    if nodeInversionInPath<=inversionThreshold:\n",
    "                        # Not inverted node\n",
    "                        # For the node find the links goint to the left of the node\n",
    "                        if nodePositionInPath>0 and nodePositionInPath<pathLengths[pathID]-1:\n",
    "                            # node is not the first or last\n",
    "                            if debug:\n",
    "                                print(f\"IncomingLinks: {pathNodeArray[pathID,nodePositionInPath-1]} -> {pathNodeArray[pathID,nodePositionInPath]}\")\n",
    "                                print(f'Existing known links: {fromLinks.get(pathNodeArray[pathID,nodePositionInPath-1],{})}')\n",
    "    \n",
    "                            # Get previous and current nodes (IDs, 1 based) in the path\n",
    "                            previousNode = pathNodeArray[pathID,nodePositionInPath-1] # previous node\n",
    "                            nextNode = pathNodeArray[pathID,nodePositionInPath] # current node\n",
    "                            if previousNode+1!=nextNode:\n",
    "                                # Link in the path does not go between consecutive nodes (from previous to current)\n",
    "                                # This means that there is a links coming to the left of the node\n",
    "                                if (previousNode<nextNode and nextNode in fromLinks.get(previousNode,{})) or (previousNode>=nextNode):\n",
    "                                    # If we are not picking up passing through empty blocks as far link\n",
    "                                    # !!! Not sure why this condition is needed and what it excludes.\n",
    "                                    # Why tandems are excluded from here? \n",
    "                                    # They should be included as they also cause an arrow to the start of the node.\n",
    "                                    incomingFarLink = True\n",
    "                                    break\n",
    "                        elif nodePositionInPath==0:\n",
    "                            pathStart = True\n",
    "                    else:\n",
    "                        #Inverted node\n",
    "                        # For the node find the links goint from the left of the node\n",
    "                        if nodePositionInPath>0 and nodePositionInPath<pathLengths[pathID]-1:\n",
    "                            # node is not the first or last\n",
    "                            if debug:\n",
    "                                print(f\"IncomingLinks: {pathNodeArray[pathID,nodePositionInPath]} -> {pathNodeArray[pathID,nodePositionInPath+1]}\")\n",
    "                                print(f'Existing known links: {toLinks.get(pathNodeArray[pathID,nodePositionInPath+1],{})}')\n",
    "                            \n",
    "                            # Get previous and current nodes (IDs, 1 based) in the path\n",
    "                            previousNode = pathNodeArray[pathID,nodePositionInPath]\n",
    "                            nextNode = pathNodeArray[pathID,nodePositionInPath+1]\n",
    "                            \n",
    "                            if previousNode-1!=nextNode:\n",
    "                                # Link does not go between consecutive blocks (from this to previous one)\n",
    "                                if (previousNode>nextNode and previousNode in toLinks.get(nextNode,{})) or (previousNode<=nextNode):\n",
    "                                    # If we are not picking up passing through empty blocks as far link\n",
    "                                    # !!! Not sure why this condition is needed and what it excludes.\n",
    "                                    # Why tandems are excluded from here? \n",
    "                                    # They should be included as they also cause an arrow to the start of the node.\n",
    "                                    incomingFarLink = True\n",
    "                                    break\n",
    "                        elif nodePositionInPath==pathLengths[pathID]-1:\n",
    "                            # if last node, mark it as path end.\n",
    "                            pathEnd = True\n",
    "#                 if incomingFarLink or pathStart or pathEnd:\n",
    "#                     break\n",
    "            \n",
    "            #Assign current node inversion to previousInv\n",
    "            previousInv = inversion\n",
    "        \n",
    "            if nodeIdx>1 and (pathStart or pathEnd or incomingFarLink or isChangeInversion) and len(matrix)>0:\n",
    "                if debug:\n",
    "                    if incomingFarLink:\n",
    "                        print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to incoming far link.')\n",
    "                    else:\n",
    "                        print(f'Node {nodeIdx}: Component broken before node {nodeIdx} due to start or end of a path.')\n",
    "                component,components,componentNucleotides,matrix,occupants,nBins,nCols,nucleotides = \\\n",
    "                    finaliseComponent(component,components,componentNucleotides,matrix,occupants,nBins,nCols,componentLengths,nucleotides,\n",
    "                                      zoomLevel=zoomLevel,accessions=graph.accessions,redisConn=redisConn)\n",
    "                componentToNode.append(list(nodesInComp))\n",
    "                nodesInComp = set([nodeIdx])\n",
    "                breakComponent = False\n",
    "                forceBreak = False\n",
    "                isChangeInversion = False\n",
    "\n",
    "            occupants |= set(uniqueNodePathsIDx)\n",
    "\n",
    "            nodeToComponent.append([len(components)])\n",
    "            nodesInComp.add(nodeIdx)\n",
    "\n",
    "            if zoomLevel<nodeLen:\n",
    "                for posInd,i in enumerate(range(0,nodeLen,zoomLevel)):\n",
    "                    \n",
    "                    if isSeq:\n",
    "                        nucleotides += graph.nodesData[nodeIdx-1][i:i+zoomLevel]\n",
    "                    else:\n",
    "                        nucleotides += graph.nodes[nodeIdx-1][i:i+zoomLevel]\n",
    "\n",
    "                    if (i+zoomLevel>nodeLen):\n",
    "                        binLength = nodeLen-i\n",
    "                    else:\n",
    "                        binLength = zoomLevel\n",
    "\n",
    "                    for j,pathID in enumerate(uniqueNodePathsIDx):\n",
    "                        annotationNames.setdefault(graph.accessions[pathID],{}).\\\n",
    "                            update({k:None for k,v in graph.nodesAnnotation[nodeIdx-1][graph.accessions[pathID]].items() \\\n",
    "                                    for interval in v \\\n",
    "                                    if (interval[1]-i)*(i+zoomLevel-1-interval[0])>=0})\n",
    "                        posPath = pos.setdefault(pathID,[])\n",
    "                        for nodeNumInPath in nodeSeqInPath[np.where(nodePathsIdx==pathID)[0]]:\n",
    "                            offset = np.min([i+zoomLevel,nodeLen])\n",
    "                            nodeStart = pathNodeLengthsCum[pathID,nodeNumInPath]-nodeLen+1\n",
    "                            posPath.append([nodeStart+i,nodeStart+offset-1])\n",
    "                    \n",
    "                    matrix,pos,binLength,_,_,nBins,annotationNames,nCols,binOpen = \\\n",
    "                        finaliseBin(matrix,pos,binLength,\n",
    "                                    nodeLengths[nodeIdx-1],\n",
    "                                    occupancy,inversion,\n",
    "                                    nBins,nCols,posInd,\n",
    "                                    annotationNames,\n",
    "                                    graph.accessions)\n",
    "\n",
    "                    if nBins+1>maxLengthComponent and (i+zoomLevel<nodeLen) and len(matrix)>0:\n",
    "                        # Because this is intra-node break, all connectors will be handled by rdepartures without separating into inverted or non-inverted. \n",
    "                        # All inter-node links will be handled through links later when chunks are being recorded.\n",
    "                        \n",
    "                        forwardPaths = []\n",
    "                        invertedPaths = []\n",
    "                        for pathID in range(len(graph.paths)):\n",
    "                            if pathID in occupants:\n",
    "                                if matrix[pathID][1][0][1]>inversionThreshold:\n",
    "                                    invertedPaths.append(pathID)\n",
    "                                else:\n",
    "                                    forwardPaths.append(pathID)\n",
    "                            else:\n",
    "                                forwardPaths.append(pathID)\n",
    "                        \n",
    "                        if len(forwardPaths)>0:\n",
    "                            \n",
    "                            component[\"rdepartures\"].append({\n",
    "                                \"upstream\": component[\"first_bin\"]+nBins-1,\n",
    "                                \"downstream\": component[\"first_bin\"]+nBins,\n",
    "                                \"participants\": forwardPaths,\n",
    "                                'otherSideRight': False\n",
    "                            })\n",
    "                        if len(invertedPaths)>0:\n",
    "                            component[\"rarrivals\"].append({\n",
    "                                \"upstream\": component[\"first_bin\"]+nBins,\n",
    "                                \"downstream\": component[\"first_bin\"]+nBins-1,\n",
    "                                \"participants\": invertedPaths,\n",
    "                                'otherSideRight': False\n",
    "                            })\n",
    "\n",
    "                        if debug:\n",
    "                            print(f'Node {nodeIdx}: Component broken inside node {nodeIdx} due to max component length.')\n",
    "\n",
    "                        component,components,componentNucleotides,matrix,occupants,nBins,nCols,nucleotides = \\\n",
    "                            finaliseComponent(component,components,componentNucleotides,matrix,occupants,nBins,nCols,componentLengths,nucleotides,\n",
    "                                              zoomLevel=zoomLevel,accessions=graph.accessions,redisConn=redisConn)\n",
    "\n",
    "                        nodeToComponent[-1].append(len(components))\n",
    "                        componentToNode.append(list(nodesInComp))\n",
    "                        nodesInComp = set([nodeIdx])\n",
    "                        breakComponent = False\n",
    "                        forceBreak = False\n",
    "                binLength = 0\n",
    "                occupancy = {}\n",
    "                inversion = {}\n",
    "            else:\n",
    "                if nBins==0 and not binOpen:\n",
    "                    if debug:\n",
    "                        print(f'Before processing node {nodeIdx} the nodeLinks was cleared')\n",
    "                    nodeLinks = []\n",
    "                binOpen = True\n",
    "                binLength += nodeLen\n",
    "\n",
    "                for j,pathID in enumerate(uniqueNodePathsIDx):\n",
    "                    annotationNames.setdefault(graph.accessions[pathID],{}).\\\n",
    "                        update(graph.nodesAnnotation[nodeIdx-1][graph.accessions[pathID]])\n",
    "                        \n",
    "                    posPath = pos.setdefault(pathID,[])\n",
    "                    for nodeNumInPath in nodeSeqInPath[np.where(nodePathsIdx==pathID)[0]]:\n",
    "                        nodeStart = pathNodeLengthsCum[pathID,nodeNumInPath]-nodeLen+1\n",
    "                        posPath.append([nodeStart,nodeStart+nodeLen-1])\n",
    "            \n",
    "                if nodeIdx<len(graph.nodes):\n",
    "                    if binLength+nodeLengths[nodeIdx]>zoomLevel:\n",
    "                        matrix,pos,binLength,occupancy,inversion,nBins,annotationNames,nCols,binOpen = \\\n",
    "                        finaliseBin(matrix,pos,binLength,\n",
    "                                    binLength,\n",
    "                                    occupancy,inversion,\n",
    "                                    nBins,nCols,0,\n",
    "                                    annotationNames,\n",
    "                                    graph.accessions)\n",
    "                else:\n",
    "                    matrix,pos,binLength,occupancy,inversion,nBins,annotationNames,nCols,binOpen = \\\n",
    "                    finaliseBin(matrix,pos,binLength,\n",
    "                                binLength,\n",
    "                                occupancy,inversion,\n",
    "                                nBins,nCols,0,\n",
    "                                annotationNames,\n",
    "                                graph.accessions)\n",
    "\n",
    "            # marking path ends and breaking component if any exist\n",
    "            pathEnds = np.sort(np.unique([pathIdx for pathIdx,nodeInSeq in zip(nodePathsIdx,nodeSeqInPath) if pathLengths[pathIdx]==nodeInSeq+1]))\n",
    "            if len(pathEnds)>0:\n",
    "                if binOpen:\n",
    "                    component.setdefault(\"ends\",set()).update(pathEnds.tolist())\n",
    "                else:\n",
    "                    if nBins>0:\n",
    "\n",
    "                        component.setdefault(\"ends\",set()).update(pathEnds.tolist())\n",
    "\n",
    "                    else:\n",
    "                        components[-1].setdefault(\"ends\",set()).update(pathEnds.tolist())\n",
    "\n",
    "            pathEndsRelevant = np.sort(np.unique([pathIdx for pathIdx,nodeInSeq in zip(nodePathsIdx,nodeSeqInPath) if pathLengths[pathIdx]==nodeInSeq+1 and (not pathDirArray[pathIdx,nodeInSeq])]))\n",
    "            pathStartsRelevant = np.sort(np.unique([pathIdx for pathIdx,nodeInSeq in zip(nodePathsIdx,nodeSeqInPath) if nodeInSeq==0 and pathDirArray[pathIdx,nodeInSeq]]))\n",
    "            if len(pathEndsRelevant)>0 or len(pathStartsRelevant)>0:\n",
    "                if binOpen:\n",
    "                    if debug:\n",
    "                        print(f'Node {nodeIdx}: Component will be broken due to start or end of a path at node {nodeIdx} when bin is filled.')\n",
    "                    breakComponent = True\n",
    "                    forceBreak = True\n",
    "                elif nBins>0:\n",
    "                    if debug:\n",
    "                        print(f'Node {nodeIdx}: Component broken after node {nodeIdx} due to start or end of a path.')\n",
    "                    component,components,componentNucleotides,matrix,occupants,nBins,nCols,nucleotides = \\\n",
    "                        finaliseComponent(component,components,componentNucleotides,matrix,occupants,nBins,nCols,componentLengths,nucleotides,\n",
    "                                          zoomLevel=zoomLevel,accessions=graph.accessions,redisConn=redisConn)\n",
    "                    componentToNode.append(list(nodesInComp))\n",
    "\n",
    "                    nodesInComp = set()\n",
    "                    breakComponent = False\n",
    "                    forceBreak = False\n",
    "\n",
    "            if nodeIdx<len(graph.nodes) and nBins>0:\n",
    "                if nBins+nodeLengths[nodeIdx]/zoomLevel>maxLengthComponent:\n",
    "\n",
    "                    if debug:\n",
    "                        print(f'Node {nodeIdx}: Component broken after node {nodeIdx} because next component will not fit in this component.')\n",
    "                    component,components,componentNucleotides,matrix,occupants,nBins,nCols,nucleotides = \\\n",
    "                        finaliseComponent(component,components,componentNucleotides,matrix,occupants,nBins,nCols,componentLengths,nucleotides,\n",
    "                                          zoomLevel=zoomLevel,accessions=graph.accessions,redisConn=redisConn)\n",
    "                    componentToNode.append(list(nodesInComp))\n",
    "\n",
    "                    nodesInComp = set()\n",
    "                    breakComponent = False\n",
    "                    forceBreak = False\n",
    "            elif nBins>0:\n",
    "\n",
    "                if debug:\n",
    "                    print(f'Node {nodeIdx}: Last node in the last component.')\n",
    "                component,components,componentNucleotides,matrix,occupants,nBins,nCols,nucleotides = \\\n",
    "                    finaliseComponent(component,components,componentNucleotides,matrix,occupants,nBins,nCols,componentLengths,nucleotides,\n",
    "                                      zoomLevel=zoomLevel,accessions=graph.accessions,redisConn=redisConn)\n",
    "                componentToNode.append(list(nodesInComp))\n",
    "\n",
    "                nodesInComp = set()\n",
    "                breakComponent = False\n",
    "\n",
    "\n",
    "            nodeFromLink = fromLinks.setdefault(nodeIdx,{})\n",
    "\n",
    "            if zoomLevel==1:\n",
    "                for j,pathID in enumerate(uniqueNodePathsIDx):\n",
    "                    nodePositions = np.where(nodePathsIdx==pathID)[0]\n",
    "                    nodeInversionInPath = np.sum([pathDirArray[pathID,nodeSeqInPath[nodePos]] for nodePos in nodePositions])/len(nodePositions)\n",
    "                    for nodePos in nodePositions:\n",
    "                        nodePositionInPath = nodeSeqInPath[nodePos]\n",
    "                        if nodePositionInPath<(pathLengths[pathID]-1):\n",
    "                            nextNode = pathNodeArray[pathID,nodePositionInPath+1]\n",
    "                            nextNodePathsIdx,nextNodeSeqInPath = np.where(pathNodeArray==nextNode)\n",
    "                            nextNodePositions = np.where(nextNodePathsIdx==pathID)[0]\n",
    "                            nextNodeInversionInPath = np.sum([pathDirArray[pathID,nextNodeSeqInPath[nodePos]] for nodePos in nextNodePositions])/len(nextNodePositions)\n",
    "                            if debug:\n",
    "                                print(f'Node {nodeIdx}, next node {nextNode}, path {pathID}, number in path {nodePositionInPath}, length of path {pathLengths[pathID]}')\n",
    "                            \n",
    "                            if nodeInversionInPath>inversionThreshold and nextNodeInversionInPath>inversionThreshold:\n",
    "                                reverseCond  = (nodeIdx<=nextNode)\n",
    "                                step = -1\n",
    "                            else:\n",
    "                                reverseCond = (nodeIdx>=nextNode)\n",
    "                                step = 1\n",
    "\n",
    "                            if reverseCond:\n",
    "                                if debug:\n",
    "                                    print(f'Reverse link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "                                nodeFromLink.setdefault(nextNode,[]).append(pathID)\n",
    "                                toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "                                if (nBins>0 or binOpen) and (nodeInversionInPath<=inversionThreshold):\n",
    "\n",
    "                                    if debug:\n",
    "                                        print(f'Node {nodeIdx}: Component will be broken after node {nodeIdx} due to backward link to node {nextNode}.')\n",
    "                                    nodeLinks.append(nextNode)\n",
    "                                    breakComponent = True\n",
    "                                    forceBreak = True\n",
    "                            else:\n",
    "                                if np.any([node in pathNodeArray[pathID,:] for node in range(nodeIdx+1*step,nextNode,step)]):\n",
    "                                    if debug:\n",
    "                                        print(f'Jump link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "                                    nodeFromLink.setdefault(nextNode,[]).append(pathID)\n",
    "                                    toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "                                    if (nBins>0 or binOpen) and (nodeInversionInPath<=inversionThreshold): \n",
    "\n",
    "                                        if debug:\n",
    "                                            print(f'Node {nodeIdx}: Component will be broken after node {nodeIdx} due forward jumping link to node {nextNode}.')\n",
    "                                        nodeLinks.append(nextNode)\n",
    "                                        breakComponent = True\n",
    "                                else:\n",
    "\n",
    "\n",
    "                                    startNode = None\n",
    "                                    endNode = None\n",
    "                                    step = None\n",
    "\n",
    "                                    if nodeInversionInPath>inversionThreshold and nextNodeInversionInPath>inversionThreshold:\n",
    "                                        startNode = nodeIdx\n",
    "                                        endNode = nextNode\n",
    "                                        step = -1\n",
    "                                        if debug:\n",
    "                                            print(f'Intermediate nodes for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "                                    elif nodeInversionInPath<=inversionThreshold and nextNodeInversionInPath<=inversionThreshold:\n",
    "                                        startNode = nodeIdx\n",
    "                                        endNode = nextNode\n",
    "                                        step = 1\n",
    "                                        if debug:\n",
    "                                            print(f'Intermediate nodes for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "                                    else:\n",
    "                                        if debug:\n",
    "                                            print(f'Jump link for path {pathID} from node {nodeIdx} to node {nextNode}')\n",
    "\n",
    "                                        nodeFromLink.setdefault(nextNode,[]).append(pathID)\n",
    "                                        toLinks.setdefault(nextNode,{}).setdefault(nodeIdx,[]).append(pathID)\n",
    "                                        if nBins>0 or binOpen: \n",
    "\n",
    "                                            if debug:\n",
    "                                                print(f'Node {nodeIdx}: Component will be broken after node {nodeIdx} due forward jumping link to node {nextNode}.')\n",
    "                                            nodeLinks.append(nextNode)\n",
    "                                            breakComponent = True\n",
    "\n",
    "                                    if startNode is not None and endNode is not None and step is not None:\n",
    "                                        for intermediateNodeIdx in range(startNode,endNode,step):\n",
    "                                            if debug:\n",
    "                                                print(f'Adding link from node {intermediateNodeIdx} to node {intermediateNodeIdx+1*step} for path {pathID}')\n",
    "                                            fromLinks.setdefault(intermediateNodeIdx,{}).setdefault(intermediateNodeIdx+1*step,[]).append(pathID)\n",
    "                                            toLinks.setdefault(intermediateNodeIdx+1*step,{}).setdefault(intermediateNodeIdx,[]).append(pathID)\n",
    "                        else:\n",
    "                            if debug:\n",
    "                                print(\"Last node in path\")\n",
    "            else:#if not breakComponent:\n",
    "                if nBins>0 or binOpen:\n",
    "                    breakLink,nnodes = checkLinksForBreak(nodeIdx,nodeFromLink,toLinks.setdefault(nodeIdx,{}),matrix,inversion,binOpen,inversionThreshold,True)\n",
    "                    if breakLink==2 or (not binOpen and breakLink==1):\n",
    "                        if debug:\n",
    "                            print(f'Node {nodeIdx}: Component will be broken after node {nodeIdx} due a link from that node (res code {breakLink}) to nodes {nnodes}.')\n",
    "                        breakComponent = True\n",
    "                        nodeLinks.extend(nnodes)\n",
    "            \n",
    "            if breakComponent and not binOpen:\n",
    "                if np.any([node not in nodesInComp for node in nodeLinks]) or len(nodeLinks)==0 or forceBreak:\n",
    "                    \n",
    "                    if debug:\n",
    "                        print(f'Node {nodeIdx}: Component broken after node {nodeIdx} because of previously set flag.')\n",
    "                        print(f'Nodes in component: {nodesInComp}')\n",
    "                        print(f'Nodes linked from component: {nodeLinks}')\n",
    "                    component,components,componentNucleotides,matrix,occupants,nBins,nCols,nucleotides = \\\n",
    "                        finaliseComponent(component,components,componentNucleotides,matrix,occupants,nBins,nCols,componentLengths,nucleotides,\n",
    "                                          zoomLevel=zoomLevel,accessions=graph.accessions,redisConn=redisConn)\n",
    "                    componentToNode.append(list(nodesInComp))\n",
    "                    nodesInComp = set()\n",
    "                    breakComponent = False\n",
    "                    forceBreak = False\n",
    "                    nodeLinks = []\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print(f'Node {nodeIdx}: Component is not broken as all links are internal, flag reset.')\n",
    "                        print(f'Nodes in component: {nodesInComp}')\n",
    "                        print(f'Nodes linked from component: {nodeLinks}')\n",
    "                    breakComponent = False;\n",
    "\n",
    "        print('\\nNodes processed, recording component to files.')\n",
    "\n",
    "        if zoomLevel==1:\n",
    "            rootStruct[\"pangenome_length\"] = np.sum(componentLengths)\n",
    "\n",
    "        chunkList = rootStruct[\"zoom_levels\"].setdefault(zoomLevel,{\n",
    "            \"last_bin\": components[-1][\"last_bin\"],\n",
    "            \"files\":[]\n",
    "        })\n",
    "        # Recording data to files for zoom level\n",
    "\n",
    "    #     chunkTemplate = {\n",
    "    #     \"json_version\":17,\n",
    "    #     \"bin_width\":1,\n",
    "    #     \"first_bin\":1,\n",
    "    #     \"includes_connectors\": True,\n",
    "    #     \"components\": []\n",
    "    # }    \n",
    "        chunk = deepcopy(chunkTemplate)\n",
    "        chunkNum = 0\n",
    "        prevTotalCols = 0\n",
    "        curCompCols = 0\n",
    "        nucleotides = ''\n",
    "        nBins = 0\n",
    "        numComps = len(components)\n",
    "        numCompsDigits = np.int(np.ceil(np.log10(numComps)))\n",
    "        \n",
    "        for compNum in range(numComps):\n",
    "            if debug:    \n",
    "                print(f'Processing component {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}')\n",
    "            else:\n",
    "                print(f'\\nProcessing component {compNum+1:0{numCompsDigits}}/{numComps:0{numCompsDigits}}',end='')\n",
    "                \n",
    "            component = components[compNum]\n",
    "\n",
    "            nodeInComp = componentToNode[compNum]\n",
    "            nodeInComp.sort()\n",
    "\n",
    "            if len(nodeInComp)>1:\n",
    "                component = addLinksToComp(nodeInComp,nodeToComponent,toLinks,fromLinks,component,components)\n",
    "            elif len(nodeInComp)==1:\n",
    "\n",
    "                mainNode = nodeInComp[0]\n",
    "    #             compForNode = nodeToComponent[mainNode-1]\n",
    "                doLeft = False\n",
    "                if compNum==0:\n",
    "                    doLeft = True\n",
    "                elif componentToNode[compNum-1][-1]!=mainNode:\n",
    "                    doLeft = True\n",
    "\n",
    "                doRight = False # Check this conditions as they may be causing issue!\n",
    "                if compNum==(len(components)-1):\n",
    "                    doRight = True\n",
    "                elif componentToNode[compNum+1][0]!=mainNode:\n",
    "                    doRight = True\n",
    "\n",
    "                component = addLinksToComp(nodeInComp,nodeToComponent,toLinks,fromLinks,component,components,doLeft,doRight)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Component {compNum} does not have any associated nodes!\")\n",
    "            \n",
    "            nBins += component[\"last_bin\"]-component[\"first_bin\"]+1\n",
    "            if len(chunk['components'])>0:\n",
    "                if checkLinks(chunk[\"components\"][-1],component):\n",
    "                    \n",
    "                    newComp = joinComponents(chunk[\"components\"].pop(),component,maxLengthComponent,inversionThreshold)\n",
    "                    if isinstance(newComp,list):\n",
    "                        chunk[\"components\"].append(newComp[0])\n",
    "                        component = newComp[1]\n",
    "                    else:\n",
    "                        component = newComp\n",
    "            \n",
    "            nucleotides += componentNucleotides[compNum]\n",
    "            chunk[\"components\"].append(component)\n",
    "            \n",
    "\n",
    "            # End of chunk\n",
    "            if compNum<len(components)-1:\n",
    "\n",
    "                if len(chunk['components'])>=maxLengthChunk:\n",
    "                #nBins+components[compNum+1][\"last_bin\"]-components[compNum+1][\"first_bin\"]+1>maxLengthChunk:\n",
    "                    rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols,nucleotides = finaliseChunk(\n",
    "                                                                                              rootStruct,\n",
    "                                                                                              zoomLevel,\n",
    "                                                                                              chunk,\n",
    "                                                                                              nucleotides,\n",
    "                                                                                              nBins,\n",
    "                                                                                              chunkNum,\n",
    "                                                                                              curCompCols,\n",
    "                                                                                              prevTotalCols,\n",
    "                                                                                              outputPath,\n",
    "                                                                                              outputName)\n",
    "            else:\n",
    "                rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols,nucleotides = finaliseChunk(\n",
    "                                                                                          rootStruct,\n",
    "                                                                                          zoomLevel,\n",
    "                                                                                          chunk,\n",
    "                                                                                          nucleotides,\n",
    "                                                                                          nBins,\n",
    "                                                                                          chunkNum,\n",
    "                                                                                          curCompCols,\n",
    "                                                                                          prevTotalCols,\n",
    "                                                                                          outputPath,\n",
    "                                                                                          outputName)\n",
    "        if not debug:\n",
    "            print()\n",
    "        print(f'Recording finished. Zoom level time is {time.time() - zoomTime}. Time elapsed {time.time() - startTime}')\n",
    "\n",
    "    with open(f'{outputPath}{os.path.sep}{outputName}{os.path.sep}bin2file.json','w') as f:\n",
    "        json.dump(rootStruct,f,cls=NpEncoder)\n",
    "    \n",
    "    if returnDebugData:\n",
    "        return zoomComponentLengths,zoomNodeToComponent,zoomComponentToNodes,zoomComponents,zoomCompNucleotides,toLinks,fromLinks,graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLinks(leftComp,rightComp):\n",
    "    leftRdepCond = np.all([link['upstream']+1==link['downstream'] for link in leftComp['rdepartures']])\n",
    "    leftRarrCond = np.all([link['upstream']-1==link['downstream'] for link in leftComp['rarrivals']])\n",
    "\n",
    "    rightRdepCond = np.all([link['upstream']-1==link['downstream'] for link in rightComp['ldepartures']])\n",
    "    rightRarrCond = np.all([link['upstream']+1==link['downstream'] for link in rightComp['larrivals']])\n",
    "    \n",
    "    return leftRdepCond and leftRarrCond and rightRarrCond and rightRdepCond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatrixPathElement(matrix,pathID):\n",
    "    res = [el for el in matrix if el[0]==pathID]\n",
    "    if len(res)==1:\n",
    "        return res[0]\n",
    "    elif len(res)>0:\n",
    "        warnings.warn(f\"More than one element for path {pathID} is found!\")\n",
    "    \n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinComponents(leftComp,rightComp, maxLengthComponent, inversionThreshold=0.5):\n",
    "    '''\n",
    "    If the joining was successful, the function will return a joined component.\n",
    "    \n",
    "    If the joining was not successful and was aborted for one of the following reasons, it will return a list of original components. \n",
    "    The reasons for aborting the joining can be the following:\n",
    "    - In one of the paths the invertion is lower than threshold in one component and higher in the other.\n",
    "    - Left component contains at least one end\n",
    "    - Right component contains at least one start\n",
    "    \n",
    "    The function will not check links for coming or going on the right of the left component and left of the right component. \n",
    "    It will just get left links from left component and right links from right component and assign them to the new component.\n",
    "    '''\n",
    "    \n",
    "    if leftComp['last_bin']-leftComp['first_bin']+1 + rightComp['last_bin']-rightComp['first_bin']+1 > maxLengthComponent:\n",
    "        return [leftComp,rightComp]\n",
    "    \n",
    "    if leftComp.get('ends',False):\n",
    "        # End of a path\n",
    "        return [leftComp,rightComp]\n",
    "    \n",
    "    newComp = {}\n",
    "    newComp['first_bin'] = min(leftComp['first_bin'],rightComp['first_bin'])\n",
    "    newComp['last_bin'] = max(leftComp['last_bin'],rightComp['last_bin'])\n",
    "    newComp['firstCol'] = min(leftComp['firstCol'],rightComp['firstCol'])\n",
    "    newComp['lastCol'] = max(leftComp['lastCol'],rightComp['lastCol'])\n",
    "    \n",
    "    leftCompNumBins = leftComp['last_bin']-leftComp['first_bin']+1\n",
    "    \n",
    "    newComp['occupants'] = list(set(leftComp['occupants']).union(rightComp['occupants']))\n",
    "    \n",
    "    for pathID in newComp['occupants']:\n",
    "        leftPathElement = getMatrixPathElement(leftComp['matrix'],pathID)\n",
    "        rightPathElement = getMatrixPathElement(rightComp['matrix'],pathID)\n",
    "        if leftPathElement is None:\n",
    "            if len([el for el in rightPathElement[2][1] if el[2][0][0]==1 or el[2][-1][0]==1])>0:\n",
    "                # Start of a path\n",
    "                return [leftComp,rightComp]\n",
    "            rightPathElement[2][0] = [el+leftCompNumBins for el in rightPathElement[2][0]]\n",
    "            newComp.setdefault(\"matrix\",[]).append(rightPathElement)\n",
    "            continue\n",
    "        \n",
    "        if rightPathElement is None:\n",
    "            newComp.setdefault(\"matrix\",[]).append(leftPathElement)\n",
    "            continue\n",
    "        \n",
    "        if (leftPathElement[1]>inversionThreshold and rightPathElement[1]<=inversionThreshold) or \\\n",
    "           (leftPathElement[1]<=inversionThreshold and rightPathElement[1]>inversionThreshold):\n",
    "            return [leftComp,rightComp]\n",
    "        \n",
    "        newPathElement = []\n",
    "        newPathElement.append(pathID)\n",
    "        newPathElement.append(leftPathElement[1])\n",
    "        pathMatrix = []\n",
    "        pathMatrix.append(leftPathElement[2][0] + [el+leftCompNumBins for el in rightPathElement[2][0]])\n",
    "        pathMatrix.append(leftPathElement[2][1] + rightPathElement[2][1])\n",
    "        newPathElement.append(pathMatrix)\n",
    "        newComp.setdefault(\"matrix\",[]).append(newPathElement)\n",
    "        \n",
    "    newComp['larrivals'] = leftComp['larrivals']\n",
    "    newComp['ldepartures'] = leftComp['ldepartures']\n",
    "    newComp['rarrivals'] = rightComp['rarrivals']\n",
    "    newComp['rdepartures'] = rightComp['rdepartures']\n",
    "    ends = list(set(leftComp.get('ends',[])).union(rightComp.get('ends',[])))\n",
    "    if len(ends)>0:\n",
    "        newComp['ends'] = ends\n",
    "    \n",
    "    return newComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finaliseBin(matrix,pos,binLength,occInvAdj,occupancy,inversion,nBins,nCols,posInd,annotationNames,accessions):\n",
    "    for pathID in pos.keys():\n",
    "        matrixPath = matrix.setdefault(pathID,[[],[]])\n",
    "        posPath = pos.get(pathID)\n",
    "        posArray = np.array(posPath)\n",
    "#         print(f'[finaliseBin] original pos {posArray}')\n",
    "        posArray = posArray[np.argsort(posArray[:,0]),:]\n",
    "        posIntersect = (posArray[1:,1]-(posArray[:-1,0]-1))*\\\n",
    "                        (posArray[:-1,1]-(posArray[1:,0]-1))\n",
    "#         print(f'[finaliseBin] pos intersections {posIntersect}')\n",
    "        newPos = [[posArray[0,0]]]\n",
    "        candidates = [posArray[0,1]]\n",
    "        for jointNum in range(len(posIntersect)):\n",
    "            if posIntersect[jointNum]>=0:\n",
    "                candidates.extend(posArray[jointNum+1,:].tolist())\n",
    "            else:\n",
    "                newPos[-1].append(np.max(candidates))\n",
    "                newPos.append([posArray[jointNum+1,0]])\n",
    "                candidates = [posArray[jointNum+1,1]]\n",
    "            \n",
    "        newPos[-1].append(np.max(candidates))# !!!!        \n",
    "        \n",
    "#         posMapping = {int(overallNBins+1):(int(posStart),int(posEnd)) for posStart,posEnd in newPos}\n",
    "#         iset_add(redisConn, f'{zoomLevel}.{accessions[pathID]}.Pos',posMapping)\n",
    "        \n",
    "#         geneList = annotationNames[accessions[pathID]]\n",
    "#         if len(geneList)>0:\n",
    "#             geneMapping = {gene:int(overallNBins+1) for gene in geneList}\n",
    "#             redisConn.hmset( f'{zoomLevel}.{accessions[pathID]}.Gene',geneMapping)\n",
    "        \n",
    "        inversionRate = inversion[pathID]/occInvAdj\n",
    "#         pdb.set_trace()\n",
    "        matrixPathRecord = [occupancy[pathID]/occInvAdj, # occupancy\n",
    "                            inversionRate, # inversion\n",
    "                            newPos, # genomic positions\n",
    "                            list(annotationNames[accessions[pathID]].keys())] # annotation\n",
    "        matrixPath[0].append(nBins)\n",
    "#         matrixPathRecord[0] = occupancy[pathID]/occInvAdj # Occupancy\n",
    "#         matrixPathRecord[1] = inversionRate # Inversion rate\n",
    "#         matrixPathRecord[2] = newPos\n",
    "        if inversionRate>0.5:\n",
    "            matrixPath[1].insert(posInd,matrixPathRecord)\n",
    "        else:\n",
    "            matrixPath[1].append(matrixPathRecord)\n",
    "        \n",
    "    return matrix,{},0,{},{},nBins+1,{},nCols+binLength,False #matrix,pos,binLength,occupancy,inversion,nBins,annotationNames,nCols,overallNBins,binOpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustMatrixPathArray(matrixPathArray,isInverted,nBins):\n",
    "    if isInverted:\n",
    "        _tempArray = [nBins-binNum-1 for binNum in matrixPathArray[0]]\n",
    "        _tempArray.sort()\n",
    "        matrixPathArray[0] = _tempArray\n",
    "    return matrixPathArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finaliseComponent(component,\n",
    "                      components,componentNucleotides,\n",
    "                      matrix,occupants,nBins,nCols,componentLengths,nucleotides,zoomLevel,accessions,inversionThreshold=0.5,redisConn=None):\n",
    "    componentLengths.append(nBins)\n",
    "    component[\"matrix\"].extend([[pathID,\n",
    "                                 int(matrixPathArray[1][0][1]>inversionThreshold),\n",
    "                                 adjustMatrixPathArray(matrixPathArray,int(matrixPathArray[1][0][1]>inversionThreshold),nBins)] \\\n",
    "                                for pathID,matrixPathArray in matrix.items()])\n",
    "    \n",
    "    \n",
    "    component[\"occupants\"] = sorted(list(occupants))\n",
    "    component['last_bin'] = component['first_bin'] + nBins - 1\n",
    "    component['lastCol'] = component['firstCol'] + nCols - 1\n",
    "    componentNucleotides.append(nucleotides)\n",
    "    if redisConn is not None:\n",
    "        for pathID,matrixPathArray in matrix.items():\n",
    "            for binNum,binMatrix in zip(*matrixPathArray):\n",
    "                if binMatrix[1]>inversionThreshold:\n",
    "                    overallBin = component['last_bin']-binNum\n",
    "                else:\n",
    "                    overallBin = component['first_bin']+binNum\n",
    "                \n",
    "                posMapping = {int(overallBin):(int(posStart),int(posEnd)) for posStart,posEnd in binMatrix[2]}\n",
    "                iset_add(redisConn, f'{zoomLevel}.{accessions[pathID]}.Pos',posMapping)\n",
    "\n",
    "                geneList = binMatrix[3]\n",
    "                for gene in geneList:\n",
    "                    if not redisConn.hexists(f'{zoomLevel}.{accessions[pathID]}.Gene',gene):\n",
    "                        redisConn.hset( f'{zoomLevel}.{accessions[pathID]}.Gene',gene,overallBin)\n",
    "    \n",
    "    firstBin = component['last_bin'] + 1\n",
    "    firstCol = component['lastCol'] + 1\n",
    "    components.append(component)\n",
    "    component = deepcopy(componentTemplate)\n",
    "    component['first_bin'] = firstBin\n",
    "    component['firstCol'] = firstCol\n",
    "    return component,components,componentNucleotides,{},set(),0,0,''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLinksForBreak(nodeIdx,nodeFromLinks,nodeToLinks,matrix,inversion,binOpen,inversionThreshold,isCurrent):\n",
    "    res = 0\n",
    "    nodes = set()\n",
    "    if isCurrent:\n",
    "        for node,pathList in nodeFromLinks.items():\n",
    "            if nodeIdx==node:\n",
    "                res = max(1,res)\n",
    "                nodes.add(node)\n",
    "            else:\n",
    "                for pathID in pathList:\n",
    "                    if binOpen:\n",
    "                        invLevel = inversion.get(pathID)\n",
    "                    else:\n",
    "                        invLevel = matrix.get(pathID)\n",
    "                        if invLevel is not None:\n",
    "                            invLevel = invLevel[1][0][1]\n",
    "                    if invLevel is not None:\n",
    "                        if invLevel<=inversionThreshold:\n",
    "                            # Forward path\n",
    "                            if nodeIdx+1!=node:\n",
    "                                res = max(2,res)\n",
    "                                nodes.add(node)\n",
    "        for node,pathList in nodeToLinks.items():\n",
    "            if nodeIdx==node:\n",
    "                res = max(1,res)\n",
    "                nodes.add(node)\n",
    "            else:\n",
    "                for pathID in pathList:\n",
    "                    if binOpen:\n",
    "                        invLevel = inversion.get(pathID)\n",
    "                    else:\n",
    "                        invLevel = matrix.get(pathID)\n",
    "                        if invLevel is not None:\n",
    "                            invLevel = invLevel[1][0][1]\n",
    "                    if invLevel is not None:\n",
    "                        if invLevel>inversionThreshold:\n",
    "                            # Inverted path\n",
    "                            if nodeIdx+1!=node:\n",
    "                                res = max(2,res)\n",
    "                                nodes.add(node)\n",
    "            \n",
    "    else:\n",
    "        # Do not use isCurrent=False !!!\n",
    "        for node,pathList in nodeFromLinks.items():\n",
    "            if nodeIdx==node:\n",
    "                res = max(1,res)\n",
    "                nodes.add(node)\n",
    "            else:\n",
    "                for pathID in pathList:\n",
    "                    if binOpen:\n",
    "                        invLevel = inversion.get(pathID)\n",
    "                    else:\n",
    "                        invLevel = matrix.get(pathID)\n",
    "                        if invLevel is not None:\n",
    "                            invLevel = invLevel[1][0][1]\n",
    "                    if invLevel is not None:\n",
    "                        if invLevel>inversionThreshold:\n",
    "                            # Inverted path\n",
    "                            if nodeIdx-1!=node:\n",
    "                                res = max(2,res)\n",
    "                                nodes.add(node)\n",
    "        for node,pathList in nodeToLinks.items():\n",
    "            if nodeIdx==node:\n",
    "                res = max(1,res)\n",
    "                nodes.add(node)\n",
    "            else:\n",
    "                for pathID in pathList:\n",
    "                    if binOpen:\n",
    "                        invLevel = inversion.get(pathID)\n",
    "                    else:\n",
    "                        invLevel = matrix.get(pathID)\n",
    "                        if invLevel is not None:\n",
    "                            invLevel = invLevel[1][0][1]\n",
    "                    if invLevel is not None:\n",
    "                        if invLevel<=inversionThreshold:\n",
    "                            # Inverted path\n",
    "                            if nodeIdx+1!=node:\n",
    "                                res = max(2,res)\n",
    "                                nodes.add(node)\n",
    "        \n",
    "    return res,list(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finaliseChunk(rootStruct,zoomLevel,chunk,nucleotides,nBins,chunkNum,curCompCols,prevTotalCols,outputPath,outputName):\n",
    "    endChunkBin = chunk['components'][-1]['last_bin']\n",
    "    chunk['last_bin'] = endChunkBin\n",
    "    \n",
    "    localPath = f'{outputPath}{os.path.sep}{outputName}{os.path.sep}{zoomLevel}{os.path.sep}'\n",
    "    \n",
    "    fileName = f'chunk{chunkNum}_zoom{zoomLevel}.schematic.json'\n",
    "    \n",
    "    with open(f'{localPath}{fileName}','w') as f:\n",
    "        json.dump(chunk,f,cls=NpEncoder)\n",
    "    \n",
    "    rootStruct['zoom_levels'][zoomLevel]['files'].append({\n",
    "        'file': fileName,\n",
    "        'first_bin':chunk['first_bin'],\n",
    "        'last_bin':chunk['last_bin'],\n",
    "#         'x':prevTotalCols\n",
    "    })\n",
    "    \n",
    "    if zoomLevel==1:\n",
    "        fastaName = f'seq_chunk{chunkNum}_zoom{zoomLevel}.fa'\n",
    "        rootStruct['zoom_levels'][zoomLevel]['files'][-1]['fasta'] = fastaName\n",
    "        \n",
    "        with open(f'{localPath}{fastaName}','w') as f:\n",
    "            f.write(f'>first_bin:{chunk[\"first_bin\"]} last_bin:{chunk[\"last_bin\"]}\\n')\n",
    "            f.write(nucleotides)\n",
    "        \n",
    "    chunk = deepcopy(chunkTemplate)\n",
    "    chunk['first_bin'] = endChunkBin + 1\n",
    "    return rootStruct,chunk,0,chunkNum + 1,prevTotalCols+curCompCols,0,'' #rootStruct,chunk,nBins,chunkNum,prevTotalCols,curCompCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLinksToComp(nodeInComp,nodeToComponent,toLinks,fromLinks,component,components,doLeft=True,doRight=True):\n",
    "    compLinks = fillLinks(nodeInComp,nodeToComponent,toLinks,fromLinks,component,components,doLeft,doRight)\n",
    "    if \"lArrivals\" in compLinks:\n",
    "        for (upstream,downstream,otherSide),participants in compLinks[\"lArrivals\"].items():\n",
    "            if otherSide=='fr':\n",
    "                fromRight = True\n",
    "            else:\n",
    "                fromRight = False\n",
    "            component['larrivals'].append({\n",
    "                    'upstream': upstream,\n",
    "                    'downstream': downstream,\n",
    "                    'otherSideRight': fromRight,\n",
    "                    'participants': participants\n",
    "                })\n",
    "    \n",
    "    if 'rArrivals' in compLinks:\n",
    "        for (upstream,downstream,otherSide),participants in compLinks[\"rArrivals\"].items():\n",
    "            if otherSide == 'fr':\n",
    "                fromRight = True\n",
    "            else:\n",
    "                fromRight = False\n",
    "            component['rarrivals'].append({\n",
    "                    'upstream': upstream,\n",
    "                    'downstream': downstream,\n",
    "                    'otherSideRight': fromRight,\n",
    "                    'participants': participants\n",
    "                })\n",
    "            \n",
    "    if 'rDepartures' in compLinks:\n",
    "        for (upstream,downstream,otherSide),participants in compLinks[\"rDepartures\"].items():\n",
    "            if otherSide == 'tl':\n",
    "                toRight = False\n",
    "            else:\n",
    "                toRight = True\n",
    "            component['rdepartures'].append({\n",
    "                'upstream': upstream,\n",
    "                'downstream': downstream,\n",
    "                'otherSideRight': toRight,\n",
    "                'participants': participants\n",
    "            })\n",
    "    \n",
    "    if 'lDepartures' in compLinks:\n",
    "        for (upstream,downstream,otherSide),participants in compLinks[\"lDepartures\"].items():\n",
    "            if otherSide == 'tl':\n",
    "                toRight = False\n",
    "            else:\n",
    "                toRight = True\n",
    "            component['ldepartures'].append({\n",
    "                'upstream': upstream,\n",
    "                'downstream': downstream,\n",
    "                'otherSideRight': toRight,\n",
    "                'participants': participants\n",
    "            })\n",
    "        \n",
    "    return component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitforwardInversedNodeComp(pathList,component,isInverse):\n",
    "#     if component['firstCol']==460:\n",
    "#         pdb.set_trace()\n",
    "    \n",
    "    forward = []\n",
    "    inversed = []\n",
    "    \n",
    "    for pathID in pathList:\n",
    "            try:\n",
    "                if component[\"matrix\"][component[\"occupants\"].index(pathID)][1]>0:\n",
    "                    inversed.append(pathID)\n",
    "                else:\n",
    "                    forward.append(pathID)\n",
    "            except (IndexError,ValueError):\n",
    "                # If it is artificial pass link.\n",
    "                if isInverse:\n",
    "                    inversed.append(pathID)\n",
    "                else:\n",
    "                    forward.append(pathID)\n",
    "                \n",
    "    return forward,inversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillLinks(nodeInComp,nodeToComponent,toLinks,fromLinks,component,components,doLeft=True,doRight=True):\n",
    "    compLinks = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if component['first_bin']==2 and len(nodeInComp)==2:\n",
    "#         pdb.set_trace()\n",
    "    \n",
    "    for node in nodeInComp:\n",
    "        # Processing all external arrival links\n",
    "        nodeToLink = toLinks.get(node,{})\n",
    "        for fromNode in nodeToLink.keys():\n",
    "            intermediateCondition = (node<fromNode)\n",
    "            \n",
    "            la,ra = splitforwardInversedNodeComp(nodeToLink[fromNode],component,intermediateCondition)\n",
    "            \n",
    "            fromFirstComp = components[nodeToComponent[fromNode-1][0]]\n",
    "            fromLastComp = components[nodeToComponent[fromNode-1][-1]]\n",
    "            \n",
    "            #left arrivals\n",
    "            if len(la)>0 and doLeft:\n",
    "                frd,fld = splitforwardInversedNodeComp(la,fromFirstComp,intermediateCondition)\n",
    "                \n",
    "                complArrivals = compLinks.setdefault('lArrivals',{})\n",
    "                # from right departure\n",
    "                if len(frd)>0 and (fromNode not in nodeInComp) and (fromLastComp['last_bin']+1!=component['first_bin']):\n",
    "                    complArrivals.setdefault((fromLastComp['last_bin'],component['first_bin'],'fr'),set()).update(frd)\n",
    "                #from left departure\n",
    "                if len(fld)>0 and (fromNode not in nodeInComp):\n",
    "                    complArrivals.setdefault((fromFirstComp['first_bin'],component['first_bin'],'fl'),set()).update(fld)\n",
    "            \n",
    "            #right arrivals\n",
    "            if len(ra)>0 and doRight:\n",
    "                frd,fld = splitforwardInversedNodeComp(ra,fromFirstComp,intermediateCondition)\n",
    "                \n",
    "                comprArrivals = compLinks.setdefault('rArrivals',{})\n",
    "                #from right departures\n",
    "                if len(frd)>0 and (fromNode not in nodeInComp):\n",
    "                    comprArrivals.setdefault((fromLastComp['last_bin'],component['last_bin'],'fr'),set()).update(frd)\n",
    "                #from left departures\n",
    "                if len(fld)>0 and (fromNode not in nodeInComp):\n",
    "                    comprArrivals.setdefault((fromFirstComp['first_bin'],component['last_bin'],'fl'),set()).update(fld)\n",
    "            \n",
    "        # Processing all external departure links\n",
    "        nodeFromLink = fromLinks.get(node,{})\n",
    "        for toNode in nodeFromLink.keys():\n",
    "            intermediateCondition = (node>toNode)\n",
    "            \n",
    "            rd,ld = splitforwardInversedNodeComp(nodeFromLink[toNode],component,intermediateCondition)\n",
    "            \n",
    "            toFirstComp = components[nodeToComponent[toNode-1][0]]\n",
    "            toLastComp = components[nodeToComponent[toNode-1][-1]]\n",
    "            \n",
    "            #right departures\n",
    "            if len(rd)>0 and doRight: # Check if doRight is set incorrectly for our case (121->122 at level 4)\n",
    "                tla,tra = splitforwardInversedNodeComp(rd,toFirstComp,intermediateCondition)\n",
    "                \n",
    "                comprDepartures = compLinks.setdefault('rDepartures',{})\n",
    "                #to left arrivals\n",
    "                if len(tla)>0:\n",
    "                    if toNode not in nodeInComp:\n",
    "                         comprDepartures.setdefault((component['last_bin'],toFirstComp['first_bin'],'tl'),set()).update(tla)\n",
    "                    elif node==nodeInComp[-1] and toNode==nodeInComp[0]:\n",
    "                        # Check that repeated element is actually contiguous inside otherwise it is not a loop and should not be visible.\n",
    "                        tla_update = list(set(tla).intersection(*[set(fromLinks.get(nodeInComp[i],{}).get(nodeInComp[i+1],[])) for i in range(len(nodeInComp)-1)]))\n",
    "                        \n",
    "                        if len(tla_update)>0:\n",
    "                            #Loop link, can only happen when with left arrival and right departure (or vice versa).\n",
    "                            complArrivals = compLinks.setdefault('lArrivals',{})\n",
    "\n",
    "                            complArrivals.setdefault((component['last_bin'],component['first_bin'],'fr'),set()).update(tla)\n",
    "                            comprDepartures.setdefault((component['last_bin'],component['first_bin'],'tl'),set()).update(tla)\n",
    "                \n",
    "                #to right arrivals\n",
    "                if len(tra)>0: # Most probably the problem is here! Check it!\n",
    "                    if toNode not in nodeInComp:\n",
    "                        comprDepartures.setdefault((component['last_bin'],toLastComp['last_bin'],'tr'),set()).update(tra)\n",
    "            \n",
    "            #left departures\n",
    "            if len(ld)>0 and doLeft:\n",
    "                tla,tra = splitforwardInversedNodeComp(ld,toFirstComp,intermediateCondition)\n",
    "                \n",
    "                complDepartures = compLinks.setdefault('lDepartures',{})\n",
    "                #to left arrivals\n",
    "                if len(tla)>0:\n",
    "                    if toNode not in nodeInComp:\n",
    "                        complDepartures.setdefault((component['first_bin'],toFirstComp['first_bin'],'tl'),set()).update(tla)\n",
    "                \n",
    "                if len(tra)>0:\n",
    "                    if toNode not in nodeInComp:\n",
    "                        if component['first_bin']-1!=toFirstComp['last_bin']:\n",
    "                            complDepartures.setdefault((component['first_bin'],toLastComp['last_bin'],'tr'),set()).update(tra)\n",
    "                    elif node==nodeInComp[0] and toNode==nodeInComp[-1]:\n",
    "                        # Check that repeated element is actually contiguous inside otherwise it is not a loop and should not be visible.\n",
    "                        tla_update = list(set(tra).intersection(*[set(fromLinks.get(nodeInComp[i],{}).get(nodeInComp[i-1],[])) for i in range(len(nodeInComp)-1,0,-1)]))\n",
    "                        \n",
    "                        if len(tla_update)>0:\n",
    "                            #Loop link, can only happen when with right arrival and left departure (or vice versa).\n",
    "                            comprArrivals = compLinks.setdefault('rArrivals',{})\n",
    "\n",
    "                            comprArrivals.setdefault((component['first_bin'],component['last_bin'],'fl'),set()).update(tra)\n",
    "                            complDepartures.setdefault((component['first_bin'],component['last_bin'],'tr'),set()).update(tra)\n",
    "                        \n",
    "    return compLinks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

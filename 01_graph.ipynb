{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph module\n",
    "\n",
    "> Provides main class and helpers classes and functions to handle pangenome graph and related data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_init.ipynb.\n",
      "Converted 01_graph.ipynb.\n",
      "Converted 02_tree.ipynb.\n",
      "Converted 03_synteny.ipynb.\n",
      "Converted 04_utils.ipynb.\n",
      "Converted 05_export.ipynb.\n",
      "Converted deBruijnGraphProcessing.ipynb.\n",
      "No export destination, ignored:\n",
      "#exporti\n",
      "\n",
      "import os\n",
      "import glob\n",
      "# import json\n",
      "# import time\n",
      "# import itertools\n",
      "import warnings\n",
      "\n",
      "# from collections.abc import Iterable\n",
      "\n",
      "import pdb\n",
      "\n",
      "# from copy import deepcopy\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "# from sortedcontainers import SortedSet\n",
      "# from multiprocessing import Process, Manager, cpu_count\n",
      "\n",
      "# from redis import ResponseError\n",
      "\n",
      "# from pangraph_constructor.utils import pathConvert,NpEncoder,adjustZoomLevels\n",
      "# from pangraph_constructor.utils import iset_add,getDBID,resetDB\n",
      "from pangraph_constructor.graph import GenomeGraph,initialPathAnalysis,calcNodeLengths,getPathNodeInversionRate\n",
      "from pangraph_constructor.utils import pathFileToPathDict\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Converted dev.ipynb.\n",
      "Converted graphTesting.ipynb.\n",
      "Converted index (2).ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import itertools\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skbio.io import read as skbio_read\n",
    "from skbio.metadata import IntervalMetadata\n",
    "from skbio.sequence import DNA\n",
    "\n",
    "from dnasim.IO import writeFASTA\n",
    "from dnasim.simulation import inverseSequence\n",
    "\n",
    "from pangraph_constructor.synteny import processAccession,generatePathsLinks\n",
    "from pangraph_constructor.utils import bidict,NpEncoder,pathFileToPathDict\n",
    "from pangraph_constructor.tree import TremauxTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calcNodeLengths(graph):\n",
    "    print('Calculating nodes length...')\n",
    "    \n",
    "    numNodes = len(graph.nodes)\n",
    "    numNodesDigits = np.int(np.ceil(np.log10(numNodes)))\n",
    "    nodeLengths = [0]*numNodes\n",
    "    \n",
    "    for nodeIdx in range(numNodes):\n",
    "        print(f'\\nProcessing node {nodeIdx+1:0{numNodesDigits}}/{numNodes:0{numNodesDigits}}',end='')\n",
    "        if graph.nodesData[nodeIdx]=='':\n",
    "            nodeLengths[nodeIdx] = len(graph.nodes[nodeIdx])\n",
    "        else:\n",
    "            nodeLengths[nodeIdx] = len(graph.nodesData[nodeIdx])\n",
    "    \n",
    "    print('\\nFinished calculating nodes lengths')\n",
    "    return nodeLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def initialPathAnalysis(graph,nodeLengths):\n",
    "    '''\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    `pathLengths`: TBD\n",
    "\n",
    "    `pathNodeArray`: numpy.array[int]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing sequence of nodes in the order as they are passed by the given \n",
    "                    path. If the length of the path is less than the number of columns of the\n",
    "                    array, then the unused columns are padded with zeros (node numbers are 1-based).\n",
    "    \n",
    "    `pathNodeLengths`: TBD\n",
    "    \n",
    "    `pathDirArray`: numpy.array[bool]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing direction (normal or inversed) in which the given path passes each node. \n",
    "                    `False` means normal direction, `True` means inverted. If the length of the path \n",
    "                    is less than the number of columns of the array, then the unused columns \n",
    "                    are padded with `False`.\n",
    "    \n",
    "    `pathNodeLengthsCum`: TBD\n",
    "    \n",
    "    \n",
    "    Example\n",
    "    =======\n",
    "    \n",
    "    The following paths are present in the graph (containing 5 nodes):\n",
    "    seq1: 1+, 2+, 3+, 4+, 5+ \n",
    "    ... # seq2 - seq6 are the same as seq1 as inversion is relative to consensus\n",
    "    seq7: 1+, 4-, 3-, 2-, 5+\n",
    "    seq8: 1+, 4-, 3-, 2-, 4-, 3-, 2-, 5+\n",
    "    seq9: 1+, 4-, 3+, 2-, 5+\n",
    "    seq10: 1+, 4-, 3+, 2-, 4-, 3+, 2-, 5+\n",
    "    \n",
    "    The result is:\n",
    "    `pathLengths`: TBD\n",
    "    \n",
    "    `pathNodeArray`:\n",
    "    array([[1, 2, 3, 4, 5, 0, 0, 0],\n",
    "           ...\n",
    "           [1, 4, 3, 2, 5, 0, 0, 0],\n",
    "           [1, 4, 3, 2, 4, 3, 2, 5],\n",
    "           [1, 4, 3, 2, 5, 0, 0, 0],\n",
    "           [1, 4, 3, 2, 4, 3, 2, 5]]),\n",
    "    \n",
    "    `pathNodeLengths`: TBD\n",
    "    \n",
    "    `pathDirArray`:\n",
    "    array([[False, False, False, False, False, False, False, False],\n",
    "           ...\n",
    "           [False,  True,  True,  True, False, False, False, False],\n",
    "           [False,  True,  True,  True,  True,  True,  True, False],\n",
    "           [False,  True, False,  True, False, False, False, False],\n",
    "           [False,  True, False,  True,  True, False,  True, False]]))\n",
    "    \n",
    "    `pathNodeLengthsCum`: TBD\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    print('Preprocessing paths...')\n",
    "    \n",
    "    numPaths = len(graph.paths)\n",
    "    numPathsZeros = np.int(np.ceil(np.log10(numPaths)))\n",
    "    \n",
    "    maxLengthPath = len(max(graph.paths,key=lambda arr: len(arr)))\n",
    "\n",
    "    pathLengths = []\n",
    "    pathNodeArray = np.zeros((len(graph.paths),maxLengthPath),dtype = np.int)\n",
    "    pathNodeLengths = np.zeros((len(graph.paths),maxLengthPath),dtype = np.int)\n",
    "    pathDirArray = np.zeros((len(graph.paths),maxLengthPath),dtype = np.bool) # True - \"+\", False - \"-\" or padding for shorter paths.\n",
    "\n",
    "    for i,path in enumerate(graph.paths):\n",
    "        print(f'\\nProcessing path {i+1:0{numPathsZeros}}/{numPaths:0{numPathsZeros}}',end='')\n",
    "        pathLengths.append(len(path))\n",
    "\n",
    "        pathNodeArray[i,:pathLengths[-1]] = [int(node[:-1]) for node in path]\n",
    "        pathDirArray[i,:pathLengths[-1]] = [node[-1]=='-' for node in path]\n",
    "        pathNodeLengths[i,:pathLengths[-1]] = [nodeLengths[node-1] for node in pathNodeArray[i,:pathLengths[-1]]]\n",
    "\n",
    "    pathNodeLengthsCum = np.cumsum(pathNodeLengths,axis=1)\n",
    "    print('\\nFinished preprocessing paths')\n",
    "    return pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getPathNodeInversionRate(pathNodeArray,pathDirArray,pathLengths,inversionThreshold=0.5):\n",
    "    '''\n",
    "    Generate a dict of dicts which stores information about inversion rate of each node for each path.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    `pathLengths`: TBD (generated by `initialPathAnalysis`)\n",
    "\n",
    "    `pathNodeArray`: numpy.array[int]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing sequence of nodes in the order as they are passed by the given \n",
    "                    path. If the length of the path is less than the number of columns of the\n",
    "                    array, then the unused columns are padded with zeros (node numbers are 1-based). \n",
    "                    Generated by `initialPathAnalysis`.\n",
    "    \n",
    "    `pathDirArray`: numpy.array[bool]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing direction (normal or inversed) in which the given path passes each node. \n",
    "                    `False` means normal direction, `True` means inverted. If the length of the path \n",
    "                    is less than the number of columns of the array, then the unused columns \n",
    "                    are padded with `False`.\n",
    "                    Generated by `initialPathAnalysis`.\n",
    "    \n",
    "    `inversionThreshold`: float (default: 0.5). A float from the range [0,1], which defines whether an inversion rate\n",
    "                        is considered as normal or inverted in binary inversion. It is needed for link directions\n",
    "                        and visualisation of the nodes. It is a dictionary with pathIDs as keys and dictionaries as values.\n",
    "                        The dictionaries as values have nodeID as keys and boolean indicating whether this node for this path\n",
    "                        is inverted (True) or not (False).\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pathNodeInversionRate = {}\n",
    "    for pathID in range(pathNodeArray.shape[0]):\n",
    "        nodeInversionRate = pathNodeInversionRate.setdefault(pathID,{})\n",
    "        pathNodes = pathNodeArray[pathID,:pathLengths[pathID]]\n",
    "        uniqueNodes = np.unique(pathNodes)\n",
    "        for node in uniqueNodes:\n",
    "            nodeInversionRate[node] = np.mean(pathDirArray[pathID,np.where(pathNodes==node)[0]])>inversionThreshold\n",
    "    \n",
    "    return pathNodeInversionRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinkGetter:\n",
    "    def __init__(self,nodes,links):\n",
    "        self.links = links\n",
    "        self.nodes = nodes\n",
    "    \n",
    "    def __getitem__(self,nodeID):\n",
    "        try:\n",
    "            node = self.links[nodeID]\n",
    "            childrenList = list(itertools.chain(*list(node.values())))\n",
    "            return list(set([el[0] for el in childrenList]))\n",
    "        except KeyError:\n",
    "            if nodeID>0 and nodeID<=len(self.nodes):\n",
    "                return []\n",
    "            else:\n",
    "                raise KeyError(f'There is no node with ID {nodeID}')\n",
    "    def __call__(self):\n",
    "        allLinks = []\n",
    "        for node in range(1,len(self.nodes)+1):\n",
    "            res = self[node]\n",
    "            if res is not None:\n",
    "                allLinks.extend([(node,el) for el in res])\n",
    "        return allLinks\n",
    "#         return list(self)\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.nodes)):\n",
    "            res = self[i+1]\n",
    "            if res is not None:\n",
    "                yield (i+1,res)\n",
    "            else:\n",
    "                yield (i+1,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GenomeGraph:\n",
    "    def __init__(self,gfaPath=None,doOverlapCleaning=True,\n",
    "                 paths=None,\n",
    "                 nodes=None,nodesData=None,links=None,\n",
    "                 pathsDict=None,\n",
    "                 sequenceFiles=None,annotationFiles=None,\n",
    "                 doBack=False,**kwargs):\n",
    "        \n",
    "        '''\n",
    "        Priority 1: If you pass gfaPath as actual path to gfa file, then it will be loaded ignoring other options\n",
    "        accessionsToRemove: list or None (default). If not None, a list of strings, if any of the string contains \n",
    "        in pathname, the path will be ignored.\n",
    "        In this case, the following options are available:\n",
    "            `isGFASeq`: boolean (default: True). Whether the graph should be considered as sequence graph (True)\n",
    "                        or as gene/block graph (False).\n",
    "        \n",
    "        Priority 4: If annotationFiles is not None, but is a list of paths to annotation (gff3) files, \n",
    "        then the following extra options are available:\n",
    "            `fileOrder`: list or None (default) Order in which each accession should be loaded into the \n",
    "                         graph (and order in which paths will be represented)\n",
    "            `doUS`: boolean (default: False) Add unrelated sequence blocks between annotated genes/blocks.\n",
    "            `refAnnotationFile`: str. If given, it has to be a path to gff3 file with reference annotation \n",
    "                                 with AT notation for gene names. For this, `transMap` has to be provided.\n",
    "            `refSequenceFile`: str or None (default). If provided with path, then it will be used to obtain \n",
    "                               sequences of each block/gene.\n",
    "            `transMap`: a bidict object (`util` module) or None (default). A dictionary ontaining bidirectional \n",
    "                        relation between OG notation of genes and AT notation of genes. \n",
    "                        It is required if refAnnotationFile is provided.\n",
    "            `seqSuffix`: str or None (default). Which sequence suffix within each annotation to use. \n",
    "                         If None, it will run all sequences in each annotation in lexicographic order\n",
    "                         and join them together (e.g. end of chr1 will be joined to start of chr2).\n",
    "            `refAccession`: str or None (default). Optional accession ID for reference annotation (if not the same as the file name).\n",
    "        \n",
    "        '''\n",
    "        self.nodes = []\n",
    "        self.nodesData = []\n",
    "        self.nodesAnnotation = []\n",
    "        self.nodesChr = []\n",
    "        self.forwardLinks = {}\n",
    "        self.overlaps = {}\n",
    "        self.paths = []\n",
    "        self.accessions = []\n",
    "        self._nxGraph = None\n",
    "        self.tremauxTree = None\n",
    "        \n",
    "        self.isBack = doBack\n",
    "        \n",
    "        if gfaPath is not None:\n",
    "            self._loadGFA(gfaPath,isGFASeq=kwargs.get('isGFASeq',True),accessionsToRemove=kwargs.get('accessionsToRemove',None))\n",
    "        elif nodes is not None and links is not None and paths is not None:\n",
    "            self.nodes = nodes\n",
    "            if nodesData is not None:\n",
    "                self.nodesData = nodesData\n",
    "            else:\n",
    "                self.nodesData = ['']*len(self.nodes)\n",
    "            self.forwardLinks = links\n",
    "            self.paths = paths\n",
    "        elif pathsDict is not None:\n",
    "            self._graphFromPaths(pathsDict,**kwargs) # sequenceFiles can be None\n",
    "        elif annotationFiles is not None:\n",
    "            self._graphFromAnnotation(annotationFiles,sequenceFiles,**kwargs)\n",
    "        \n",
    "        self.order = list(range(1,len(self.nodes)+1))\n",
    "        \n",
    "        self.pureForwardlinks = LinkGetter(self.nodes,self.forwardLinks)\n",
    "\n",
    "        self._pathCount()\n",
    "        self.invertNodes()\n",
    "        \n",
    "        if doBack:\n",
    "            self.backLinks = self._revertLinks()\n",
    "            self.pureBackLinks = LinkGetter(self.nodes,self.backLinks)\n",
    "        \n",
    "        if len(self.overlaps)>0 and doOverlapCleaning:\n",
    "            self.treeSort()\n",
    "            pdb.set_trace()\n",
    "            self.removeOverlaps()\n",
    "            \n",
    "    # check edgePaths calculation. Incorrectly calculates the numbers \n",
    "    # (one too many in one of group of incoming edges to each node)\n",
    "    def _pathCount(self):\n",
    "        # self.inPath = []\n",
    "        # self.outPath = []\n",
    "        self.nodePass = [0]*len(self.nodes)\n",
    "        \n",
    "        self.nodeStrandPaths = [[0,0] for _ in range(len(self.nodes))]\n",
    "        self.pathStarts = [0]*len(self.nodes)\n",
    "        self.inPath = [0]*len(self.nodes)\n",
    "        self.outPath = [0]*len(self.nodes)\n",
    "        self.edgePaths = {}\n",
    "        \n",
    "        self.nodePassUnique = {}\n",
    "        self.inPathUnique = {}\n",
    "        self.outPathUnique = {}\n",
    "        self.edgePathsUnique = {}\n",
    "        \n",
    "        for pathID,path in enumerate(self.paths):\n",
    "            \n",
    "            previousNode = None\n",
    "            for nodeStrand in path:\n",
    "                pathNode = int(nodeStrand[:-1])-1\n",
    "                pathStrand = int(nodeStrand[-1]=='-') # 0 if \"+\", 1 if \"-\"\n",
    "                self.nodePass[pathNode] += 1\n",
    "                self.nodePassUnique.setdefault(pathNode,set()).add(pathID)\n",
    "                self.nodeStrandPaths[pathNode][pathStrand] += 1\n",
    "                self.outPath[pathNode] += 1\n",
    "                self.outPathUnique.setdefault(pathNode,set()).add(pathID)\n",
    "                self.inPath[pathNode] += 1\n",
    "                self.inPathUnique.setdefault(pathNode,set()).add(pathID)\n",
    "                if previousNode is not None:\n",
    "                    self.edgePaths.setdefault((previousNode+1,pathNode+1),0)\n",
    "                    self.edgePaths[(previousNode+1,pathNode+1)] += 1\n",
    "                    \n",
    "                    self.edgePathsUnique.setdefault((previousNode+1,pathNode+1),set())\\\n",
    "                                            .add(pathID)\n",
    "                else:\n",
    "                    self.pathStarts[pathNode] += 1\n",
    "                    self.inPath[pathNode] -= 1\n",
    "                previousNode = pathNode\n",
    "            self.outPath[previousNode] -= 1\n",
    "        \n",
    "        # We are not interested in pathIDs in *Unique blocks, so, \n",
    "        # converting them back to standard format.\n",
    "        self.nodePassUnique = [len(self.nodePassUnique.get(key,[])) for key in range(len(self.nodes))]\n",
    "        self.inPathUnique = [len(self.inPathUnique.get(key,[])) for key in range(len(self.nodes))]\n",
    "        self.outPathUnique = [len(self.outPathUnique.get(key,[])) for key in range(len(self.nodes))]\n",
    "        self.edgePathsUnique = {key:len(value) for key,value in self.edgePathsUnique.items()}\n",
    "    \n",
    "    def _revertLinks(self):\n",
    "        backLinks = {}\n",
    "        for fromNode,links in self.forwardLinks.items():\n",
    "            for fromStrand,strandLinks in links.items():\n",
    "                for item in strandLinks:\n",
    "#                     if item[0] not in backLinks.keys():\n",
    "#                         backLinks[item[0]] = {}\n",
    "#                         backLinks[item[0]][item[1]] = []\n",
    "\n",
    "#                     elif item[1] not in forwardLinks[item[0]].keys():\n",
    "#                         backLinks[item[0]][item[1]] = []\n",
    "\n",
    "                    backLinks.setdefault(item[0],{}).setdefault(item[1],[]).append((fromNode,fromStrand))\n",
    "        return backLinks\n",
    "    \n",
    "    def _loadGFA(self, gfaFile, isGFASeq=True, accessionsToRemove=None):\n",
    "        baseName = os.path.splitext(os.path.basename(gfaFile))[0]\n",
    "        dirPath = os.path.dirname(gfaFile)\n",
    "        jsonFile = f'{dirPath}{os.path.sep}nodeNames_{baseName}.json'\n",
    "        annotationFile = f'{dirPath}{os.path.sep}annotation_{baseName}.dat'\n",
    "        \n",
    "        print(f'Loading graph from {gfaFile}')\n",
    "        \n",
    "        if os.path.exists(jsonFile):\n",
    "            print(f'Found nodeNames file {jsonFile}, loading names.')\n",
    "            nodeNames = json.load(open(jsonFile,mode='r'))\n",
    "        else:\n",
    "            nodeNames = None\n",
    "        \n",
    "        loadAnnotation = False\n",
    "        \n",
    "        if os.path.exists(annotationFile):\n",
    "            print(f'Found node annotation file {annotationFile}, loading associations.')\n",
    "            self.nodesAnnotation = joblib.load(annotationFile)\n",
    "            emptyAnnotation = False\n",
    "        else:\n",
    "            emptyAnnotation = True\n",
    "        \n",
    "        prevPathSegment = None\n",
    "        \n",
    "        gfaList = open(gfaFile,mode='r').readlines()\n",
    "        \n",
    "        if gfaList[0][7:-1] == '2.0':\n",
    "            raise NotImplementedError('At the moment only GFA v1 is supported')\n",
    "        elif gfaList[0][7:-1] != '1.0':\n",
    "            warnings.warn('Cannot identify version of GFA. Assuming it is GFA v1. If it is not, expect unpredictable results.',category=ResourceWarning)\n",
    "       \n",
    "        segmentList = [el for el in gfaList if el.lower().startswith('s')]\n",
    "        linkList = [el for el in gfaList if el.lower().startswith('l')]\n",
    "        pathStringsList = [el for el in gfaList if el.lower().startswith('p')]\n",
    "\n",
    "        self.nodeNameToID = {}\n",
    "        \n",
    "        numSegments = len(segmentList)\n",
    "        if numSegments>0:\n",
    "            numSegmentDigits = int(np.ceil(np.log10(numSegments)))\n",
    "        else:\n",
    "            raise ValueError('Incorrect GFA file format. No segments were found')\n",
    "        \n",
    "        for nodeID,node in enumerate(segmentList):\n",
    "            print(f'\\nLoading segment {nodeID+1:0{numSegmentDigits}}/{numSegments:0{numSegmentDigits}}',end='')\n",
    "            segmentArray = node.rstrip().split(sep='\\t')\n",
    "            segID,segGFAData = segmentArray[1:3]\n",
    "            if isGFASeq:\n",
    "                segSeq = segGFAData\n",
    "            else:\n",
    "                segSeq = ''\n",
    "            \n",
    "            if nodeNames is not None:\n",
    "                segName = nodeNames[int(segID)-1]\n",
    "            elif isGFASeq:\n",
    "                segName = str(segID)\n",
    "            else:\n",
    "                segName = segGFAData\n",
    "            \n",
    "            self.nodeNameToID[segID] = len(self.nodes)+1\n",
    "            \n",
    "            self.nodes.append(segName)\n",
    "            self.nodesData.append(segSeq)\n",
    "        \n",
    "        if emptyAnnotation:\n",
    "            self.nodesAnnotation = [{}]*len(self.nodes)\n",
    "            \n",
    "        print('\\nLoading segments finished.')\n",
    "            \n",
    "        numLinks = len(linkList)\n",
    "        if numLinks>0:\n",
    "            numLinkDigits = int(np.ceil(np.log10(numLinks)))\n",
    "        else:\n",
    "            numLinkDigits = 1\n",
    "        \n",
    "        for linkID,link in enumerate(linkList):\n",
    "            print(f'\\nLoading link {linkID+1:0{numLinkDigits}}/{numLinks:0{numLinkDigits}}',end='')\n",
    "            linkArray = link.rstrip().split(sep='\\t')\n",
    "            fromNodeID,fromStrand,toNodeID,toStrand = linkArray[1:5]\n",
    "            overlap = linkArray[5]\n",
    "            fromNode = self.nodeNameToID[fromNodeID]\n",
    "            toNode = self.nodeNameToID[toNodeID]\n",
    "            if overlap[:-1].isnumeric() and overlap[-1]=='M':\n",
    "                self.overlaps[(fromNode,fromStrand)] = int(overlap[:-1])\n",
    "                \n",
    "            curLink = self.forwardLinks.setdefault(fromNode,{})\n",
    "            curStrand = curLink.setdefault(fromStrand,[])\n",
    "            if (toNode,toStrand) not in curStrand:\n",
    "                curStrand.append((toNode,toStrand))\n",
    "        print('\\nLoading links finished')\n",
    "        \n",
    "        numPaths = len(pathStringsList)\n",
    "        if numPaths>0:\n",
    "            numPathDigits = int(np.ceil(np.log10(numPaths)))\n",
    "        else:\n",
    "            raise ValueError('Incorrect GFA file format. No paths were found')\n",
    "        \n",
    "        addedPaths = 0\n",
    "        ignoredPaths = 0\n",
    "        for pathID,pathString in enumerate(pathStringsList):\n",
    "            print(f'\\nLoading path {pathID+1:0{numPathDigits}}/{numPaths:0{numPathDigits}}',end='')\n",
    "            pathArray = pathString.rstrip().split(sep='\\t')\n",
    "            seqID,path = pathArray[1:3]\n",
    "            useAccession = True\n",
    "            if isinstance(accessionsToRemove,list):\n",
    "                for accessionTemplate in accessionsToRemove:\n",
    "                    if seqID.find(accessionTemplate)!=-1:\n",
    "                        ignoredPaths += 1\n",
    "                        useAccession = False\n",
    "                        break\n",
    "            if useAccession:\n",
    "                self.paths.append([f'{self.nodeNameToID.get(ns[:-1],ns[:-1])}{ns[-1]}' for ns in path.split(',')])\n",
    "                self.accessions.append(seqID)\n",
    "                addedPaths += 1\n",
    "        print(f'\\nLoading paths finished. {addedPaths} paths added, {ignoredPaths} paths ignored.')\n",
    "    \n",
    "    def loadAnnotations(self, annotationPath,seqSuffix):\n",
    "        if len(self.nodesData[0])==0:\n",
    "            warnings.warn('Annotation can be applied only to sequence graph, but no sequence associated with nodes was found. Aborted.')\n",
    "            return\n",
    "        \n",
    "        for accID,path in zip(self.accessions,self.paths):\n",
    "            absPosStart = 0\n",
    "            annotation = skbio_read(f'{annotationPath}{os.path.sep}{accID}.gff',format='gff3',into=IntervalMetadata,seq_id=f'{accID}{seqSuffix}')\n",
    "            for nodestrand in path:\n",
    "                nodeNum = int(nodesstrand[:-1])\n",
    "                nodeDict = self.nodeAnnotation[nodeNum-1].setdefault(accID,{})\n",
    "                nodeLen = len(self.nodesData[nodeNum-1])\n",
    "                nodeAnnotationGen = annotation.query((absPosStart+1,absPosStart+nodeLen))\n",
    "                for na in nodeAnnotationGen:\n",
    "                    if na.bounds[0]<absPosStart+1:\n",
    "                        leftNodeBound = 1\n",
    "                    else:\n",
    "                        leftNodeBound = na.bound[0] - absPosStart\n",
    "\n",
    "                    if na.bound[1]<absPosStart+nodeLen:\n",
    "                        rightNodeBound = na.bound[1] - absPosStart\n",
    "                    else:\n",
    "                        rightNodeBound = nodeLen\n",
    "                        \n",
    "                    ogName = na.metadata['OG']\n",
    "                    atNamesStr = na.metadata.get('AT')\n",
    "                    \n",
    "                    nodeDict.setdefault(ogName,[]).append((leftNodeBound,rightNodeBound))\n",
    "                    \n",
    "                    if atNamesStr is not None:\n",
    "                        atNameList = atNameStr.split(',')\n",
    "                        for atName in atNameList:\n",
    "                            nodeDict.setdefault(atName,[]).append((leftNodeBound,rightNodeBound))\n",
    "    \n",
    "    def updateAnnotationFromNodes(self,isSeq=True):\n",
    "        '''\n",
    "        This function is used only for primitive block graphs (e.g. gene and chain graphs)\n",
    "        if there is no proper annotation available (e.g. graph was created from paths and \n",
    "        some extra information about nodes is needed).\n",
    "\n",
    "        It takes \"name\" of each node either from `graph.nodes` (if `isSeq` is False) or\n",
    "        from `graph.nodesData` (if `isSeq` is True).\n",
    "\n",
    "        Parameters\n",
    "        ##########\n",
    "\n",
    "        `isSeq`: Whether it contains names as names or as seq.\n",
    "        '''\n",
    "        offset = 0\n",
    "        for annID in range(len(self.nodesAnnotation)):\n",
    "            if isSeq:\n",
    "                nodeSeq = self.nodesData[annID]\n",
    "            else:\n",
    "                nodeSeq = self.nodes[annID]\n",
    "            annEl = self.nodesAnnotation[annID]\n",
    "            updatedAnnEl = {}\n",
    "            for pathName in annEl:\n",
    "                updatedAnnEl[pathName] = {nodeSeq:[(0,len(nodeSeq)-1)]}\n",
    "            self.nodesAnnotation[annID] = updatedAnnEl\n",
    "    \n",
    "    def _graphFromNodesLinks(self,nodes,links):\n",
    "        raise NotImplementedError('Generating graph from nodes and links is not yet implemented.')\n",
    "    \n",
    "    def _getNodeID(self,node,maxNodeNameLength,pathID):\n",
    "        _node = node.zfill(maxNodeNameLength)\n",
    "        try:\n",
    "            nodeID = self.nodes.index(_node)+1\n",
    "            self.nodesAnnotation[nodeID-1].setdefault(pathID,{}).setdefault(_node,[]).append((0,len(_node)-1))\n",
    "        except ValueError:\n",
    "            self.nodes.append(_node)\n",
    "            self.nodesAnnotation.append({pathID:{_node:[(0,len(_node)-1)]}})\n",
    "            nodeID = len(self.nodes)\n",
    "            self.nodeNameToID[str(nodeID)] = nodeID\n",
    "            \n",
    "        return nodeID\n",
    "    \n",
    "    def _graphFromPaths(self,paths,sequenceFiles=None,nodeNameLength=None):\n",
    "        if sequenceFiles is not None:\n",
    "            warnings.warn(\"sequenceFiles reading with path is not yet implemented.\")\n",
    "        \n",
    "        if not isinstance(paths,dict):\n",
    "            raise ValueError(f\"paths should be dict but {type(paths)} was given.\")\n",
    "        \n",
    "#         if sequenceFiles is None:\n",
    "        if nodeNameLength is None:\n",
    "            maxNodeNameLength = len(max([max(path,key=lambda a: len(a)) for path in paths.values()],key=lambda a: len(a))) - 1\n",
    "        else:\n",
    "            maxNodeNameLength = nodeNameLength\n",
    "        \n",
    "        self.nodeNameToID = {}\n",
    "        self.nodes = []\n",
    "        self.paths = []\n",
    "        self.accessions = []\n",
    "        links = {}\n",
    "        \n",
    "        self.nodeNameToID = {}\n",
    "        \n",
    "        for pathID,path in paths.items():\n",
    "            self.accessions.append(pathID)\n",
    "            prevNode = path[0][:-1]\n",
    "            prevDirection = path[0][-1]\n",
    "            prevNodeID = self._getNodeID(prevNode,maxNodeNameLength,pathID)\n",
    "            newPath = [f'{prevNodeID}{prevDirection}']\n",
    "            for nodeDir in path[1:]:\n",
    "                \n",
    "                node = nodeDir[:-1]\n",
    "                direction = nodeDir[-1]\n",
    "                \n",
    "                nodeID = self._getNodeID(node,maxNodeNameLength,pathID)\n",
    "                newPath.append(f'{nodeID}{direction}')\n",
    "                links.setdefault(prevNodeID,{}).setdefault(prevDirection,set()).add((nodeID,direction))\n",
    "                \n",
    "                prevNode = node\n",
    "                prevDirection = direction\n",
    "                prevNodeID = nodeID\n",
    "            self.paths.append(newPath)\n",
    "        \n",
    "        \n",
    "        self.forwardLinks = dict([(fromNode,dict([(fromStrand,list(toSet)) for fromStrand,toSet in strandDict.items()])) for fromNode,strandDict in links.items()])\n",
    "        self.nodesData = ['']*len(self.nodes)\n",
    "    \n",
    "    def _processAnnotation(self, annotationFile, links, ATmap=None, seqFile=None, seqSuffix=None, doUS=False, isRef=False, accID=None):\n",
    "        accessionID, genes, sequences = \\\n",
    "            processAccession(annotationFile,\n",
    "                             seqFile,\n",
    "                             ATmap=ATmap,\n",
    "                             isRef=isRef,\n",
    "                             accID=accID)\n",
    "        if seqSuffix is None:\n",
    "            seqList = genes.sequenceID.unique().tolist()\n",
    "            seqList.sort()\n",
    "        else:\n",
    "            seqList = [f'{accessionID}{seqSuffix}']\n",
    "\n",
    "        path = []\n",
    "        for seqID in seqList:\n",
    "\n",
    "            p, cigar, usCounter = generatePathsLinks(genes.loc[genes.sequenceID == seqID], seqID, accessionID, sequences, self.OGList,\n",
    "                                                     self.nodes, self.nodesAnnotation, self.nodesChr, self.nodeNameToID, links,\n",
    "                                                     self.usCounter, doUS=doUS, segmentData=self.nodesData)\n",
    "            path = path + p\n",
    "        if isRef:\n",
    "            self.paths.insert(0,path)\n",
    "            self.accessions.insert(0,accessionID)\n",
    "        else:\n",
    "            self.paths.append(path)\n",
    "            self.accessions.append(accessionID)\n",
    "\n",
    "        return links\n",
    "    \n",
    "    def _graphFromAnnotation(self,annotationFiles,sequenceFiles=None,**kwargs):\n",
    "        self.nodeNameToID = {}\n",
    "\n",
    "        fileOrder = kwargs.get('fileOrder',list(range(len(annotationFiles))))\n",
    "        \n",
    "        doUS = kwargs.get('doUS',False)\n",
    "        self.usCounter = 0\n",
    "        self.OGList = []\n",
    "        links = self._linksDictToSet(self.forwardLinks)\n",
    "\n",
    "        if 'refAnnotationFile' in kwargs:\n",
    "            links = self._processAnnotation(kwargs['refAnnotationFile'], links,\n",
    "                                            ATmap=kwargs.get('transMap', None),\n",
    "                                            seqFile=kwargs.get('refSequenceFile',None),\n",
    "                                            seqSuffix=kwargs.get('seqSuffix', None),\n",
    "                                            doUS=doUS,\n",
    "                                            isRef=True,\n",
    "                                            accID=kwargs.get('refAccession',None))\n",
    "        \n",
    "        for fileNum in fileOrder:\n",
    "            if sequenceFiles is not None:\n",
    "                seqFile = sequenceFiles[fileNum]\n",
    "            else:\n",
    "                seqFile = None\n",
    "             # annotationFile\n",
    "             # transMap\n",
    "            links = self._processAnnotation(annotationFiles[fileNum], links,\n",
    "                                            ATmap=kwargs.get('transMap', None),\n",
    "                                            seqFile=seqFile,\n",
    "                                            seqSuffix=kwargs.get('seqSuffix', None),\n",
    "                                            doUS=doUS)\n",
    "        \n",
    "\n",
    "        self.forwardLinks = self._linksSetToDict(links)\n",
    "    \n",
    "    def _linksDictToSet(self,dictLinks):\n",
    "        setLinks = {}\n",
    "        for fromNode,strandLinks in dictLinks.items():\n",
    "            for fromStrand,linkList in strandLinks.items():\n",
    "                for toNode,toStrand in linkList:\n",
    "                    fromNodeStrand = f'{fromNode}{fromStrand}'\n",
    "                    toNodeStrand = f'{toNode}{toStrand}'\n",
    "                    if fromNodeStrand not in setLinks.keys():\n",
    "                        setLinks[fromNodeStrand] = set()\n",
    "                    setLinks[fromNodeStrand].add(toNodeStrand)\n",
    "        return setLinks\n",
    "    \n",
    "    def _linksSetToDict(self,setLinks):\n",
    "        dictLinks = {}\n",
    "        for fromNodeStrand,links in setLinks.items():\n",
    "            fromNode = int(fromNodeStrand[:-2])\n",
    "            fromStrand = fromNodeStrand[-1]\n",
    "            for toNodeStrand in links:\n",
    "                toNode = int(toNodeStrand[:-2])\n",
    "                toStrand = toNodeStrand[-1]\n",
    "                \n",
    "                if fromNode not in dictLinks.keys():\n",
    "                    dictLinks[fromNode] = {}\n",
    "                    dictLinks[fromNode][fromStrand] = []\n",
    "\n",
    "                elif fromStrand not in dictLinks[fromNode].keys():\n",
    "                    dictLinks[fromNode][fromStrand] = []\n",
    "\n",
    "                dictLinks[fromNode][fromStrand].append((toNode,toStrand))\n",
    "        return dictLinks\n",
    "    \n",
    "    def generateTremauxTree(self,byPath=True):\n",
    "        _nxGraph = nx.DiGraph()\n",
    "        \n",
    "        for nodeID,toList in self.pureForwardlinks:\n",
    "            if toList is not None:\n",
    "                edgeList = [(nodeID,toItem) for toItem in toList]\n",
    "                _nxGraph.add_edges_from(edgeList)\n",
    "            \n",
    "        self.tremauxTree = TremauxTree(_nxGraph,self,byPath)\n",
    "        \n",
    "    def addAccessionAnnotation(self,annotationFile,sequenceFile=None):\n",
    "        '''\n",
    "        Ideally, a function should be able to add one accesstion to existing graph. \n",
    "        When implemented, `_graphFromAnnotation` should be using this function.\n",
    "        \n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def addLink(self,fromNode,fromStrand,toNode,toStrand):\n",
    "        # Need testing\n",
    "        if fromNode not in self.nodes:\n",
    "            raise IndexError(f'Node {fromNode} is not in nodes list')\n",
    "        if toNode not in self.nodes:\n",
    "            raise IndexError(f'Node {toNode} is not in nodes list')\n",
    "        \n",
    "        if fromNode not in self.forwardLinks.keys():\n",
    "            self.forwardLinks[fromNode] = {}\n",
    "            self.forwardLinks[fromNode][fromStrand] = []\n",
    "            \n",
    "        elif fromStrand not in self.forwardLinks[fromNode].keys():\n",
    "            self.forwardLinks[fromNode][fromStrand] = []\n",
    "\n",
    "        self.forwardLinks[fromNode][fromStrand].append([toNode,toStrand])\n",
    "\n",
    "        if self.isBack:\n",
    "            if toNode not in self.backLinks.keys():\n",
    "                self.backLinks[toNode] = {}\n",
    "                self.backLinks[toNode][toStrand] = []\n",
    "\n",
    "            elif toStrand not in self.backLinks[toNode].keys():\n",
    "                self.backLinks[toNode][toStrand] = []\n",
    "\n",
    "            self.backLinks[toNode][toStrand].append([fromNode,fromStrand])\n",
    "    \n",
    "    def addNode(self,nodeID,data=None):\n",
    "        # Need testing\n",
    "        if nodeID not in self.nodes:\n",
    "            self.nodes.append(nodeID)\n",
    "            self.nodesData[nodeID] = data\n",
    "        else:\n",
    "            warnings.warn(f'You attempted to add node with {nodeID}, but it already exists in the graph. The addition was ignored.')\n",
    "        pass\n",
    "    \n",
    "    def _getStartNode(self,bubbleNode):\n",
    "#         allPaths = list(nx.shortest_path(self.tremauxTree,None,bubbleNode).values())\n",
    "#         startList = []\n",
    "#         for path in allPaths:\n",
    "#             if len(startList)>0:\n",
    "#                 for node in startList.copy():\n",
    "#                     if nx.has_path(self.tremauxTree,node,path[0]):\n",
    "#                         continue\n",
    "#                     if nx.has_path(self.tremauxTree,path[0],node):\n",
    "#                         startList.remove(node)\n",
    "\n",
    "#             startList.append(path[0])\n",
    "\n",
    "#         return startList\n",
    "        rootNodes = self.tremauxTree.getRootNodes()\n",
    "        \n",
    "        for root in rootNodes:\n",
    "            if nx.has_path(self.tremauxTree,root,bubbleNode):\n",
    "                return root\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    def _getEdgeValue(self,start,end,unique=False):\n",
    "        \n",
    "        if start is None:\n",
    "            endInPathRatio = (self.nodePass[end-1]-self.inPath[end-1])/self.nodePass[end-1]\n",
    "            if unique:\n",
    "                return self.nodePassUnique[end-1]*endInPathRatio\n",
    "            else:\n",
    "                return self.nodePass[end-1]*endInPathRatio\n",
    "        else:\n",
    "            startOutPathRatio = self.edgePaths.get((start,end),0)/self.outPath[start-1]\n",
    "            endInPathRatio = self.edgePaths.get((start,end),0)/self.inPath[end-1]\n",
    "            if unique:\n",
    "                return self.edgePathsUnique.get((start,end),0)*startOutPathRatio*endInPathRatio\n",
    "            else:\n",
    "                return self.edgePaths.get((start,end),0)*startOutPathRatio*endInPathRatio\n",
    "    \n",
    "    def treeSort(self,byPath=True,bubblePriorityThreshold=0.5):\n",
    "        \n",
    "        print('Constructing Tremaux tree')\n",
    "        self.generateTremauxTree(byPath)\n",
    "        print('Done!')\n",
    "        queue = []\n",
    "        stopNodes = set()\n",
    "        stopNodesOrigin = {}\n",
    "        processed = []\n",
    "        self.order = []\n",
    "\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        print('Getting root nodes')\n",
    "        rootNodes = self.tremauxTree.getRootNodes()\n",
    "#         self.order.append(rootNode)\n",
    "        \n",
    "        # The first root node won't be added to the order automatically,\n",
    "        # but will be processed as all other nodes.\n",
    "        startNode = rootNodes.pop()\n",
    "#         self.order.append(startNode)\n",
    "#         descendantsToAdd = list(self.tremauxTree.edges(startNode))\n",
    "#         descendantsToAdd.sort(key=lambda edge: self.edgePathsUnique.get(edge,0))\n",
    "#         queue.extend(descendantsToAdd)\n",
    "        queue.append((None,startNode))\n",
    "        \n",
    "        print('Start Loop...')\n",
    "        while len(queue)>0 or len(rootNodes)>0:\n",
    "            if len(queue)==0:\n",
    "                try:\n",
    "                    while len(queue)==0:\n",
    "                        startNode = rootNodes.pop()\n",
    "#                         descendantsToAdd = list(self.tremauxTree.edges(startNode))\n",
    "#                         if len(descendantsToAdd)>0:\n",
    "#                             descendantsToAdd.sort(key=lambda edge: self.edgePathsUnique.get(edge,0))\n",
    "#                             queue.extend([edge for edge in descendantsToAdd if edge not in processed])\n",
    "#                         if startNode not in self.order:\n",
    "#                             self.order.append(startNode)\n",
    "                        queue.append((None,startNode))\n",
    "                except IndexError:\n",
    "                    break\n",
    "            \n",
    "            startNode,endNode = queue.pop()\n",
    "            \n",
    "#             if endNode==840:\n",
    "#                 pdb.set_trace()\n",
    "            \n",
    "#             print(f'Queue: {len(queue)} - Processed: {len(processed)} - Order: {len(self.order)} - Start: {startNode} - End: {endNode}')\n",
    "            print(f'\\nNodes in order: {len(self.order)}/{len(self.nodes)}',end='')\n",
    "    \n",
    "            if (startNode,endNode) in processed:\n",
    "                continue\n",
    "            if (startNode in self.order and endNode in self.order):\n",
    "                if not ((startNode,endNode) in processed):\n",
    "                    processed.append((startNode,endNode))\n",
    "                continue\n",
    "            \n",
    "            endNodeAdded = False\n",
    "            \n",
    "            bubblePriorityQueue = []\n",
    "            bubbleEdges = self.tremauxTree.bubbleEdges.inverse.get(endNode,[])+[startNode]\n",
    "            if len(bubbleEdges)>0:\n",
    "                if byPath:\n",
    "                    bubbleEdgesOrder = np.argsort([self._getEdgeValue(edge,endNode) for edge in bubbleEdges])\n",
    "                else:\n",
    "                    bubbleEdgesOrder = list(range(len(bubbleEdges)))\n",
    "                # Chech that bubble node is not in order already\n",
    "                # Check edgePaths for all outgoing links (including non-bubbles but not loops), use this bubble \n",
    "                # only if the bubble edge has maximum number of paths.\n",
    "                # if this bubble should be used compare edgePaths for bubble edge and for normal edge to \n",
    "                # current node. If normal edge is larger, then add current node to order and node past LCA \n",
    "                # on alternative path(s) to the queue (to be processed next) and after them the descendandts of \n",
    "                # current node. Otherwise, do not add current node to order, but add nodes past LCA and then (to processed later) current node to queue.\n",
    "                \n",
    "                for bEdge in bubbleEdgesOrder:\n",
    "                    bubbleNode = bubbleEdges[bEdge]\n",
    "                    if bubbleNode in self.order and bubbleNode!=startNode:\n",
    "                        continue\n",
    "                    if byPath:\n",
    "                        curBubbleEdgePaths = self._getEdgeValue(bubbleNode,endNode)\n",
    "                        if bubbleNode is not None:\n",
    "                            bubbleNodeOutEdges = list(self.tremauxTree.out_edges(bubbleNode)) + \\\n",
    "                                                [(bubbleNode,node) for node in self.tremauxTree.bubbleEdges.get(bubbleNode,[])]\n",
    "                            bubbleNodeOutEdgesValue = [self._getEdgeValue(*edge) for edge in bubbleNodeOutEdges]\n",
    "                        else:\n",
    "                            bubbleNodeOutEdgesValue = [self._getEdgeValue(bubbleNode,endNode)]\n",
    "                        \n",
    "                        if max(bubbleNodeOutEdgesValue)>curBubbleEdgePaths:\n",
    "                            continue\n",
    "                        \n",
    "#                         if bubbleNode is not None:\n",
    "#                             if self._getEdgeValue(bubbleNode,endNode,unique=False)/self.inPath[endNode-1]>bubblePriorityThreshold or \\\n",
    "#                             self._getEdgeValue(bubbleNode,endNode,unique=False)/self.outPath[bubbleNode-1]>bubblePriorityThreshold:\n",
    "#                                 bubblePriority = True\n",
    "#                             else:\n",
    "#                                 bubblePriority = False\n",
    "#                         else:\n",
    "#                             bubblePriority = True\n",
    "                        bubblePriority = True\n",
    "    \n",
    "                    if bubbleNode!=startNode:\n",
    "                        # We are not on the main (original) edge\n",
    "                        lca = nx.lowest_common_ancestor(self.tremauxTree,endNode,bubbleNode)\n",
    "                        if byPath:\n",
    "                            if lca is None:\n",
    "                                _lca = self._getStartNode(bubbleNode)\n",
    "    #                             startBubbleNodes.sort(key=lambda node: self.nodePassUnique[node-1])\n",
    "    #                             lcaDescendantsToProcess = []\n",
    "    #                             for startBubbleNode in startBubbleNodes: \n",
    "    #                                 snDescendantsToProcess = [(startBubbleNode,node) for node in list(self.tremauxTree[startBubbleNode])\\\n",
    "    #                                                           if node not in self.order and nx.has_path(self.tremauxTree,node,bubbleNode)]\n",
    "    #                                 snDescendantsToProcess.sort(key=lambda node: self.edgePathsUnique.get((startBubbleNode,node),0))\n",
    "    #                                 lcaDescendantsToProcess.extend(snDescendantsToProcess)\n",
    "\n",
    "                            else: \n",
    "                                _lca = lca\n",
    "                #                             lcaDescendantsToProcess = [(lca,node) for node in list(self.tremauxTree[lca]) \\\n",
    "    #                                                        if node not in self.order and nx.has_path(self.tremauxTree,node,bubbleNode)]\n",
    "    #                             lcaDescendantsToProcess.sort(key=lambda node: self.edgePathsUnique.get((lca,node),0))\n",
    "                            if _lca==bubbleNode:\n",
    "                                # BubbleNode is the top of another tree\n",
    "                                lcaDescendantsToProcess = [(None,bubbleNode)]\n",
    "                            else:\n",
    "                                lcaDescendantsToProcess = [(_lca,node) for node in list(self.tremauxTree[_lca])\\\n",
    "                                                                  if node not in self.order and nx.has_path(self.tremauxTree,node,bubbleNode)]\n",
    "                                lcaDescendantsToProcess.sort(key=lambda edge: self.edgePathsUnique.get(edge,0))\n",
    "\n",
    "                            for edge in lcaDescendantsToProcess:\n",
    "                                if edge in queue:\n",
    "                                    queue.remove(edge)\n",
    "                            if len(lcaDescendantsToProcess)>0:\n",
    "                                if bubblePriority:\n",
    "                                    bubblePriorityQueue.append((bubbleNode,[edge for edge in lcaDescendantsToProcess if edge not in processed]))\n",
    "                                else:\n",
    "                                    queue.extend([edge for edge in lcaDescendantsToProcess if edge not in processed and edge[0] is not None])\n",
    "                        else:\n",
    "                            # TODO!!!\n",
    "                            # rewrite pure graph sorting to process alternative branches by adding the top nodes \n",
    "                            # of each branch to the queue for immediate processing.\n",
    "                            pathToAdd = nx.shortest_path(self.tremauxTree,lca,bubbleNode)\n",
    "                            if lca is None:\n",
    "                                allPaths = list(pathToAdd.values())\n",
    "                                allPaths.sort(key=len)\n",
    "                                pathToAdd = allPaths[-1]\n",
    "                            else:\n",
    "                                if endNode not in self.order and byPath:\n",
    "                                    self.order.append(endNode)\n",
    "                                    endNodeAdded = True\n",
    "                            # WRONG!\n",
    "                            self.order.extend([node for node in pathToAdd if node not in self.order])\n",
    "                    else:\n",
    "                        # We consider startNode as bubble\n",
    "                        if byPath:\n",
    "                            if bubblePriority:\n",
    "                                bubblePriorityQueue.append((bubbleNode,(startNode,endNode)))\n",
    "                            else:\n",
    "                                # Do we need to add the current edge back to queue???\n",
    "                                pass\n",
    "                            \n",
    "                            \n",
    "            bubblePriorityQueue.sort(key=lambda b: self._getEdgeValue(b[0],endNode))\n",
    "            if len(bubblePriorityQueue)>=1:\n",
    "#             or \\\n",
    "#                 (len(bubblePriorityQueue)==1 and bubblePriorityQueue[-1][1]!=(startNode,endNode)):\n",
    "#                 queue.append((startNode,endNode))#Why would I add the processed block again? Should I add descendant edges of the end node here? \n",
    "                # It should save a lot of wasted time and speed up the process.\n",
    "                queueLen = len(queue)\n",
    "                curEdgePassed = False\n",
    "                while len(bubblePriorityQueue)>0:\n",
    "                    bNode,bToAdd = bubblePriorityQueue.pop()\n",
    "                    \n",
    "                    if bNode!=startNode:\n",
    "                        queue.extend(bToAdd)\n",
    "                        stopNodes.add(bNode)\n",
    "                        stopNodesOrigin[bNode] = endNode\n",
    "                    else:\n",
    "                        if len(bubblePriorityQueue)==0:\n",
    "                            endNodeAdded = self._addNextEdgesToQueue(startNode,endNode,\n",
    "                                                    processed,queue,stopNodes,stopNodesOrigin)\n",
    "                            curEdgePassed = True\n",
    "                        else:\n",
    "                            queue.append((startNode,endNode))\n",
    "                if not curEdgePassed:\n",
    "                    queue[queueLen:queueLen] = [(startNode,endNode)]\n",
    "            else:\n",
    "                endNodeAdded = self._addNextEdgesToQueue(startNode,endNode,\n",
    "                                                    processed,queue,stopNodes,stopNodesOrigin)\n",
    "        print()\n",
    "    \n",
    "    def _addNextEdgesToQueue(self,startNode,endNode,processed,queue,stopNodes,stopNodesOrigin):\n",
    "        endNodeAdded = False\n",
    "        processed.append((startNode,endNode))\n",
    "        # Should we add start or end???\n",
    "        if endNode not in self.order:\n",
    "            self.order.append(endNode)\n",
    "            endNodeAdded = True\n",
    "\n",
    "        edgesToAdd = [edge for edge in list(self.tremauxTree.edges(endNode)) if edge not in processed and edge not in queue]\n",
    "\n",
    "        edgesToAdd.sort(key=lambda edge: self._getEdgeValue(*edge))\n",
    "        if endNode in stopNodes and len(edgesToAdd)>0:\n",
    "            bubbleEnd = stopNodesOrigin[endNode]\n",
    "            bubbleEndEdge = list(self.tremauxTree.in_edges(bubbleEnd))[0]\n",
    "            try: \n",
    "                bubbleEndEdgeInd = queue.index(bubbleEndEdge)\n",
    "            except ValueError:\n",
    "                bubbleEndEdgeInd = len(queue)\n",
    "            \n",
    "            queue[bubbleEndEdgeInd:bubbleEndEdgeInd] = edgesToAdd\n",
    "#             queue.append(bubbleEndEdge)\n",
    "            stopNodes.remove(endNode)\n",
    "            del stopNodesOrigin[endNode]\n",
    "        else:\n",
    "            queue.extend(edgesToAdd)\n",
    "        \n",
    "        return endNodeAdded\n",
    "    \n",
    "    def toGFA(self,gfaFile,doSeq=True):\n",
    "        '''\n",
    "            Recording existing graph structures to GFA v1 file.\n",
    "        '''\n",
    "        baseName = os.path.splitext(os.path.basename(gfaFile))[0]\n",
    "        dirPath = os.path.dirname(gfaFile)\n",
    "        jsonFile = f'{dirPath}{os.path.sep}nodeNames_{baseName}.json'\n",
    "        annotationFile = f'{dirPath}{os.path.sep}annotation_{baseName}.dat'\n",
    "        \n",
    "        gfaWriter = open(gfaFile,mode='w')\n",
    "        \n",
    "        gfaWriter.write('H\\tVN:Z:1.0\\n')\n",
    "        \n",
    "        translator = {}\n",
    "        nodeNameList = []\n",
    "        nodesAnnotation = []\n",
    "        \n",
    "        for i,nodeID in enumerate(self.order):\n",
    "            nodeSeq = self.nodesData[nodeID-1]\n",
    "            nodeName = self.nodes[nodeID-1]\n",
    "            nodesAnnotation.append(self.nodesAnnotation[nodeID-1])\n",
    "            if doSeq and len(nodeSeq)>0:\n",
    "                gfaWriter.write(f'S\\t{i+1}\\t{nodeSeq}\\n')\n",
    "                nodeNameList.append(nodeName)\n",
    "            else:\n",
    "                gfaWriter.write(f'S\\t{i+1}\\t{nodeName}\\n')\n",
    "            \n",
    "            translator[nodeID] = i+1\n",
    "        \n",
    "#         isInversionDict = self._generateIsInversionDict()\n",
    "#         strandInversionDict = {'+':'-','-':'+'}\n",
    "        \n",
    "        for fromNode,strandLinks in self.forwardLinks.items():\n",
    "            for fromStrand,toLinkStrands in strandLinks.items():\n",
    "                for toNode,toStrand in toLinkStrands:\n",
    "                    \n",
    "#                     if isInversionDict.get(fromNode,False):\n",
    "#                         _fromStrand = strandInversionDict[fromStrand]\n",
    "#                     else:\n",
    "#                         _fromStrand = fromStrand\n",
    "\n",
    "#                     if isInversionDict.get(toNode,False):\n",
    "#                         _toStrand = strandInversionDict[toStrand]\n",
    "#                     else:\n",
    "#                         _toStrand = toStrand\n",
    "                    gfaWriter.write(f'L\\t{translator[fromNode]}\\t{fromStrand}\\t{translator[toNode]}\\t{toStrand}\\t*\\n')\n",
    "        \n",
    "        for path,accessionID in zip(self.paths,self.accessions):\n",
    "            newPath = []\n",
    "            for nodeStrand in path:\n",
    "                node = int(nodeStrand[:-1])#self.nodeNameToID.get(nodeStrand[:-1],nodeStrand[:-1])\n",
    "#                 if isInversionDict.get(node,False):\n",
    "#                     strand = strandInversionDict[nodeStrand[-1]]\n",
    "#                 else:\n",
    "                strand = nodeStrand[-1]\n",
    "                newPath.append(f'{translator[node]}{strand}')\n",
    "            gfaWriter.write(f'P\\t{accessionID}\\t{\",\".join(newPath)}\\t*\\n')\n",
    "                \n",
    "        gfaWriter.write('\\n')\n",
    "        gfaWriter.close()\n",
    "        \n",
    "        if len(nodeNameList)==len(self.nodes):\n",
    "            with open(jsonFile,'w') as jsf:\n",
    "                json.dump(nodeNameList,jsf)\n",
    "                \n",
    "        if len(nodesAnnotation)==len(self.nodes):\n",
    "            joblib.dump(nodesAnnotation,annotationFile)\n",
    "    \n",
    "    # Node inversion functionality\n",
    "    def invertNodes(self):\n",
    "        nodeLengths = calcNodeLengths(self)\n",
    "        pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum = initialPathAnalysis(self,nodeLengths)\n",
    "\n",
    "        for nodeID in range(len(self.nodes)):\n",
    "            if self.nodeStrandPaths[nodeID][1]>self.nodeStrandPaths[nodeID][0]:\n",
    "                print(f'\\nNode {nodeID+1} inverted',end='')\n",
    "                self._invertNode(nodeID,pathNodeArray)\n",
    "\n",
    "        self._pathCount()\n",
    "        print()\n",
    "\n",
    "    def _invertNode(self,nodeID,pathNodeArray):\n",
    "        \n",
    "        self.nodesData[nodeID] = inverseSequence(self.nodesData[nodeID])\n",
    "        \n",
    "        pathIDs,positions = np.where(pathNodeArray==nodeID+1)\n",
    "        strandreversal = {'+':'-','-':'+'}\n",
    "        for pathID,pos in zip(pathIDs,positions):\n",
    "            nodeStrand = self.paths[pathID][pos]\n",
    "            self.paths[pathID][pos] = nodeStrand[:-1]+strandreversal[nodeStrand[-1]]\n",
    "\n",
    "        nodeFromLink = self.forwardLinks.get(nodeID+1,{})\n",
    "        positiveStrand = nodeFromLink.get('+',[])\n",
    "        negativeStrand = nodeFromLink.get('-',[])\n",
    "\n",
    "        if len(positiveStrand)>0:\n",
    "            self.forwardLinks[nodeID+1]['-'] = positiveStrand\n",
    "        else:\n",
    "            if len(negativeStrand)>0:\n",
    "                del self.forwardLinks[nodeID+1]['-']\n",
    "\n",
    "        if len(negativeStrand)>0:\n",
    "            self.forwardLinks[nodeID+1]['+'] = negativeStrand\n",
    "        else:\n",
    "            if len(positiveStrand)>0:\n",
    "                del self.forwardLinks[nodeID+1]['+']\n",
    "\n",
    "        revertLinks = self._revertLinks()        \n",
    "        nodeToLink = revertLinks.get(nodeID+1,{})\n",
    "        positiveStrand = nodeToLink.get('+',[])\n",
    "        negativeStrand = nodeToLink.get('-',[])\n",
    "\n",
    "        for fromNode,fromStrand in positiveStrand:\n",
    "            self.forwardLinks[fromNode][fromStrand].remove((nodeID+1,'+'))\n",
    "            self.forwardLinks[fromNode][fromStrand].append((nodeID+1,'-'))\n",
    "\n",
    "        for fromNode,fromStrand in negativeStrand:\n",
    "            self.forwardLinks[fromNode][fromStrand].remove((nodeID+1,'-'))\n",
    "            self.forwardLinks[fromNode][fromStrand].append((nodeID+1,'+'))\n",
    "            \n",
    "        positiveOverlap = self.overlaps.pop((nodeID+1,'+'),0)\n",
    "        negativeOverlap = self.overlaps.pop((nodeID+1,'-'),0)\n",
    "        if positiveOverlap>0:\n",
    "            self.overlaps[(nodeID+1,'-')] = positiveOverlap\n",
    "        if negativeOverlap>0:\n",
    "            self.overlaps[(nodeID+1,'+')] = negativeOverlap\n",
    "    \n",
    "    # End of node inversion functionality\n",
    "    \n",
    "    # node removal functionality\n",
    "    def _removePositionsFromPaths(self,pathIDs,positions):\n",
    "        print('Removing empty nodes from paths')\n",
    "        print('paths')\n",
    "        print(self.paths)\n",
    "        for pathID in np.unique(pathIDs):\n",
    "            offset = 0\n",
    "            posArray  = np.sort(np.array(positions)[np.array(pathIDs)==pathID])\n",
    "            for pos in posArray:\n",
    "                print(f'{pathID} - {pos}')\n",
    "                del self.paths[pathID][pos-offset]\n",
    "                offset += 1\n",
    "    \n",
    "    def _updateLinkList(self,strandList,offsetDict):\n",
    "        newStrand = []\n",
    "        for toNode,toStrand in strandList:\n",
    "            newStrand.append((offsetDict[toNode-1]+1,toStrand))\n",
    "        return newStrand\n",
    "    \n",
    "    def _clearNodes(self,nodeIDs):\n",
    "        print('nodeIDs')\n",
    "        print(nodeIDs)\n",
    "        print('paths')\n",
    "        print(self.paths)\n",
    "        offsetDict = {node:node for node in range(len(self.nodes))}\n",
    "        for nodeID in nodeIDs:\n",
    "            print(f'Removing node {nodeID+1}')\n",
    "            updatedNodeID = offsetDict[nodeID]\n",
    "            nodeName = self.nodes[updatedNodeID]\n",
    "            del self.nodeNameToID[nodeName]\n",
    "            del self.nodes[updatedNodeID]\n",
    "            del self.nodesData[updatedNodeID]\n",
    "            self.order.remove(nodeID+1)\n",
    "            del offsetDict[nodeID]\n",
    "            offsetDict.update({k:v-1 for k,v in offsetDict.items() if k>nodeID})\n",
    "            \n",
    "        \n",
    "        self.order = [offsetDict[el-1]+1 for el in self.order]\n",
    "        self.nodeNameToID.update({k:offsetDict[v-1]+1 for k,v in self.nodeNameToID.items()})\n",
    "        \n",
    "        for pathID in range(len(self.paths)):\n",
    "            self.paths[pathID] = [f'{offsetDict[int(el[:-1])-1]+1}{el[-1]}' for el in self.paths[pathID]]\n",
    "        \n",
    "        print('paths')\n",
    "        print(self.paths)\n",
    "        print('offsetDict')\n",
    "        print(offsetDict)\n",
    "        \n",
    "        nodesInForwardLinks = list(self.forwardLinks.keys())\n",
    "        for node in sorted(nodesInForwardLinks):\n",
    "            nodeDict = self.forwardLinks[node]\n",
    "            newNode = offsetDict[node-1]+1\n",
    "            if node!=newNode:\n",
    "                del self.forwardLinks[node]\n",
    "            forwardStrand = self._updateLinkList(nodeDict.get('+',[]),offsetDict)\n",
    "            inverseStrand = self._updateLinkList(nodeDict.get('-',[]),offsetDict)\n",
    "\n",
    "            if len(forwardStrand)>0:\n",
    "                self.forwardLinks.setdefault(newNode,{})['+'] = forwardStrand\n",
    "            if len(inverseStrand)>0:\n",
    "                self.forwardLinks.setdefault(newNode,{})['-'] = inverseStrand\n",
    "    \n",
    "    def _removeNode(self,nodeID,revertLinks,pathNodeArray):\n",
    "        pathIDs,positions = np.where(pathNodeArray==nodeID+1)\n",
    "\n",
    "        excludeTuples = [(nodeID+1,'+'),(nodeID+1,'-')]\n",
    "\n",
    "        nodeToLink = revertLinks.get(nodeID+1,{})\n",
    "        toPositiveStrand = nodeToLink.get('+',[])\n",
    "        toNegativeStrand = nodeToLink.get('-',[])\n",
    "\n",
    "        nodeFromLink = self.forwardLinks.get(nodeID+1,{})\n",
    "        fromPositiveStrand = nodeFromLink.get('+',[])\n",
    "        fromNegativeStrand = nodeFromLink.get('-',[])\n",
    "\n",
    "        for fromNode,fromStrand in toPositiveStrand:\n",
    "            # Amending forwardLinks for positive strand of current node\n",
    "            forwardNodeStrand = self.forwardLinks.get(fromNode,{}).get(fromStrand,[])\n",
    "            forwardNodeStrand = list(set(forwardNodeStrand).union(fromPositiveStrand).difference(excludeTuples))\n",
    "            self.forwardLinks[fromNode][fromStrand] = forwardNodeStrand\n",
    "\n",
    "        for fromNode,fromStrand in toNegativeStrand:\n",
    "            # Amend forwardLinks for negative strand of current node\n",
    "            forwardNodeStrand = self.forwardLinks.get(fromNode,{}).get(fromStrand,[])\n",
    "            forwardNodeStrand = list(set(forwardNodeStrand).union(fromNegativeStrand).difference(excludeTuples))\n",
    "            self.forwardLinks[fromNode][fromStrand] = forwardNodeStrand\n",
    "\n",
    "        for toNode,toStrand in fromPositiveStrand:\n",
    "            # Amending revertLinks for positive strand of current node\n",
    "            revertNodeStrand = revertLinks.get(toNode,{}).get(toStrand,[])\n",
    "            revertNodeStrand = list(set(revertNodeStrand).union(toPositiveStrand).difference(excludeTuples))\n",
    "            revertLinks[toNode][toStrand] = revertNodeStrand\n",
    "\n",
    "        for toNode,toStrand in fromNegativeStrand:\n",
    "            # Amend revertLinks for negative strand of current node\n",
    "            revertNodeStrand = revertLinks.get(toNode,{}).get(toStrand,[])\n",
    "            revertNodeStrand = list(set(revertNodeStrand).union(toNegativeStrand).difference(excludeTuples))\n",
    "            revertLinks[toNode][toStrand] = revertNodeStrand\n",
    "\n",
    "        del revertLinks[nodeID+1]\n",
    "        del self.forwardLinks[nodeID+1]\n",
    "\n",
    "        return pathIDs,positions\n",
    "    \n",
    "    def removeNodes(self,nodeIDsToRemove):\n",
    "        revertLinks = self._revertLinks()\n",
    "        nodeLengths = calcNodeLengths(self)\n",
    "        _,pathNodeArray,_,_,_ = initialPathAnalysis(self,nodeLengths)\n",
    "\n",
    "        pathIDs = []\n",
    "        positions = []\n",
    "        for nodeID in nodeIDsToRemove:\n",
    "            pID,pos = self._removeNode(nodeID,revertLinks,pathNodeArray)\n",
    "            pathIDs.extend(pID)\n",
    "            positions.extend(pos)\n",
    "\n",
    "        self._removePositionsFromPaths(pathIDs,positions)\n",
    "        self._clearNodes(nodeIDsToRemove)\n",
    "\n",
    "        self._pathCount()\n",
    "    \n",
    "    #end of node removal functionality\n",
    "    \n",
    "    # Node substitution functionality\n",
    "\n",
    "    # End of node substitution functionality\n",
    "    \n",
    "    # Overlap removal functionality\n",
    "    def _linkBounce(self,fromNodeStart,fromStrandStart,revertLinks,nodeLengths,kmerOverlap,cutOffsetRight,leftCut,rightCut):\n",
    "        cutOffsetLeft = 0\n",
    "        leftToCut = [(fromNodeStart,fromStrandStart)]\n",
    "        rightToCut = []\n",
    "        leftToProcess = [(fromNodeStart,fromStrandStart)]\n",
    "        rightToProcess = []\n",
    "    #     pdb.set_trace()\n",
    "        while (len(leftToProcess)>0 or len(rightToProcess)>0):\n",
    "            for node,strand in leftToProcess:\n",
    "                rightSide = self.forwardLinks.get(node,{}).get(strand,[])\n",
    "                for toNode,toStrand in rightSide:\n",
    "                    if toStrand=='+':\n",
    "                        cutOffsetLeft = max(leftCut.get(toNode,0),cutOffsetLeft)\n",
    "                    else:\n",
    "                        cutOffsetLeft = max(rightCut.get(toNode,0),cutOffsetLeft)\n",
    "\n",
    "                    if cutOffsetLeft<kmerOverlap-cutOffsetRight and (toNode,toStrand) not in rightToCut:# and nodeLengths[toNode-1]>0:\n",
    "                        rightToCut.append((toNode,toStrand))\n",
    "                        rightToProcess.append((toNode,toStrand))\n",
    "            leftToProcess = []\n",
    "\n",
    "            for node,strand in rightToProcess:\n",
    "                leftSide = revertLinks.get(node,{}).get(strand,[])\n",
    "                for fromNode,fromStrand in leftSide:\n",
    "                    if fromStrand=='+':\n",
    "                        cutOffsetRight = max(rightCut.get(fromNode,0),cutOffsetRight)\n",
    "                    else:\n",
    "                        cutOffsetRight = max(leftCut.get(fromNode,0),cutOffsetRight)\n",
    "\n",
    "                    if cutOffsetRight<kmerOverlap-cutOffsetLeft and (fromNode,fromStrand) not in leftToCut:# and nodeLengths[fromNode-1]>0:\n",
    "                        leftToCut.append((fromNode,fromStrand))\n",
    "                        leftToProcess.append((fromNode,fromStrand))\n",
    "            rightToProcess = []\n",
    "\n",
    "        return leftToCut,rightToCut,cutOffsetLeft,cutOffsetRight\n",
    "    \n",
    "    def _processBouncedLink(self,leftToCut,rightToCut,kmerOverlap,cutOffsetLeft,cutOffsetRight,nodeLengths,leftCut,rightCut,leftForbidden,rightForbidden):\n",
    "        toCut = kmerOverlap - cutOffsetLeft - cutOffsetRight\n",
    "        minLengthRight = min([nodeLengths[node-1] for node,strand in rightToCut])\n",
    "        minLengthLeft = min([nodeLengths[node-1] for node,strand in leftToCut])\n",
    "        isRightForbidden = np.any([ns in rightForbidden for ns in rightToCut ])\n",
    "        isLeftForbidden = np.any([ns in leftForbidden for ns in leftToCut ])\n",
    "        \n",
    "        if isRightForbidden and isLeftForbidden:\n",
    "            return\n",
    "        \n",
    "        if (minLengthRight<minLengthLeft and not isRightForbidden) or isLeftForbidden:\n",
    "            sideToCut = rightToCut\n",
    "            sideToKeep = leftToCut\n",
    "            globalPositiveSide = leftCut\n",
    "            globalNegativeSide = rightCut\n",
    "            side = 'right'\n",
    "        else:\n",
    "            sideToCut = leftToCut\n",
    "            sideToKeep = rightToCut\n",
    "            globalPositiveSide = rightCut\n",
    "            globalNegativeSide = leftCut\n",
    "            side = 'left'\n",
    "\n",
    "        maxCutAdjustment = max([max(toCut - nodeLengths[node-1],0) for node,strand in sideToCut])\n",
    "        if toCut>maxCutAdjustment:\n",
    "            for node,strand in sideToCut:\n",
    "                if strand=='+':\n",
    "                    if side =='right':\n",
    "                        self.nodesData[node-1] = self.nodesData[node-1][toCut-maxCutAdjustment:]\n",
    "                    else:\n",
    "                        self.nodesData[node-1] = self.nodesData[node-1][:-(toCut-maxCutAdjustment)]\n",
    "                    globalPositiveSide[node] = globalPositiveSide.get(node,0) + toCut - maxCutAdjustment\n",
    "                else:\n",
    "                    if side =='left':\n",
    "                        self.nodesData[node-1] = self.nodesData[node-1][toCut-maxCutAdjustment:]\n",
    "                    else:\n",
    "                        self.nodesData[node-1] = self.nodesData[node-1][:-(toCut-maxCutAdjustment)]\n",
    "                    globalNegativeSide[node] = globalNegativeSide.get(node,0) + toCut - maxCutAdjustment\n",
    "                nodeLengths[node-1] -= toCut - maxCutAdjustment\n",
    "\n",
    "        if maxCutAdjustment>0:\n",
    "            # adjust the other side as well.\n",
    "            for node,strand in sideToKeep:\n",
    "                if strand=='+':\n",
    "                    if side =='right':\n",
    "                        self.nodesData[node-1] = self.nodesData[node-1][:-(maxCutAdjustment)]\n",
    "                    else:\n",
    "                        self.nodesData[node-1] = self.nodesData[node-1][maxCutAdjustment:]\n",
    "                    globalNegativeSide[node] = globalNegativeSide.get(node,0) + maxCutAdjustment\n",
    "                else:\n",
    "                    if side =='left':\n",
    "                        self.nodesData[node-1] = self.nodesData[node-1][:-(maxCutAdjustment)]\n",
    "                    else:\n",
    "                        self.nodesData[node-1] = self.nodesData[node-1][maxCutAdjustment:]\n",
    "                    globalPositiveSide[node] = globalPositiveSide.get(node,0) + maxCutAdjustment\n",
    "                nodeLengths[node-1] -= maxCutAdjustment\n",
    "        for nodeStrand in leftToCut:\n",
    "            del self.overlaps[nodeStrand]\n",
    "\n",
    "    def removeOverlaps(self):\n",
    "        nodeIDsToRemove = []\n",
    "        leftCut = {}\n",
    "        rightCut = {}\n",
    "\n",
    "        leftForbidden = list(set([(int(path[-1][:-1]),path[-1][-1]) for path in self.paths])) # Nodes which should not be cut on the left side of link\n",
    "        rightForbidden = list(set([(int(path[0][:-1]),path[-1][-1]) for path in self.paths])) # Nodes which should not be cut on the right side of link\n",
    "\n",
    "        revertLinks = self._revertLinks()\n",
    "        nodeLengths = calcNodeLengths(self)\n",
    "        print('nodeLengths')\n",
    "        print(nodeLengths)\n",
    "\n",
    "        for fromNode in self.order:\n",
    "            print('-----------')\n",
    "            print(f'Processing node {fromNode}')\n",
    "            if (fromNode,'+') in self.overlaps:\n",
    "                print(f'Working on forward strand')\n",
    "                kmerOverlap = self.overlaps[(fromNode,'+')]\n",
    "                cutOffsetRight = rightCut.get(fromNode,0)\n",
    "                print(f'Initial overlap={kmerOverlap}')\n",
    "                print(f'Initial cutOffsetRight={cutOffsetRight}')\n",
    "                if cutOffsetRight<kmerOverlap and nodeLengths[fromNode-1]>0:\n",
    "                    leftToCut,rightToCut,cutOffsetLeft,cutOffsetRight = self._linkBounce(fromNode,'+',\n",
    "                                                                                         revertLinks,\n",
    "                                                                                         nodeLengths,\n",
    "                                                                                         kmerOverlap,\n",
    "                                                                                         cutOffsetRight,\n",
    "                                                                                         leftCut,\n",
    "                                                                                         rightCut)\n",
    "                    print('leftToCut')\n",
    "                    print(leftToCut)\n",
    "                    print('rightToCut')\n",
    "                    print(rightToCut)\n",
    "                    print(f'cutOffsetLeft={cutOffsetLeft}; cutOffsetRight={cutOffsetRight}')\n",
    "                    # process only if both leftToCut and rightToCut have some elements\n",
    "                    if len(leftToCut)>0 and len(rightToCut)>0:\n",
    "                        self._processBouncedLink(leftToCut,\n",
    "                                                 rightToCut,\n",
    "                                                 kmerOverlap,\n",
    "                                                 cutOffsetLeft,\n",
    "                                                 cutOffsetRight,\n",
    "                                                 nodeLengths,\n",
    "                                                 leftCut,\n",
    "                                                 rightCut,\n",
    "                                                 leftForbidden,\n",
    "                                                 rightForbidden)\n",
    "                    print('leftCut')\n",
    "                    print(leftCut)\n",
    "                    print('rightCut')\n",
    "                    print(rightCut)\n",
    "                    print('nodeLengths')\n",
    "                    print(nodeLengths)\n",
    "\n",
    "            if (fromNode,'-') in self.overlaps:\n",
    "                print(f'Working on inverse strand')\n",
    "                kmerOverlap = self.overlaps[(fromNode,'-')]\n",
    "                cutOffsetRight = leftCut.get(fromNode,0)\n",
    "                print(f'Initial overlap={kmerOverlap}')\n",
    "                print(f'Initial cutOffsetRight={cutOffsetRight}')\n",
    "                if cutOffsetRight<kmerOverlap and nodeLengths[fromNode-1]>0:\n",
    "                    leftToCut,rightToCut,cutOffsetLeft,cutOffsetRight = self._linkBounce(fromNode,'-',\n",
    "                                                                                         revertLinks,\n",
    "                                                                                         nodeLengths,\n",
    "                                                                                         kmerOverlap,\n",
    "                                                                                         cutOffsetRight,\n",
    "                                                                                         leftCut,\n",
    "                                                                                         rightCut)\n",
    "                    print('leftToCut')\n",
    "                    print(leftToCut)\n",
    "                    print('rightToCut')\n",
    "                    print(rightToCut)\n",
    "                    print(f'cutOffsetLeft={cutOffsetLeft}; cutOffsetRight={cutOffsetRight}')\n",
    "                    if len(leftToCut)>0 and len(rightToCut)>0:\n",
    "                        self._processBouncedLink(leftToCut,\n",
    "                                                 rightToCut,\n",
    "                                                 kmerOverlap,\n",
    "                                                 cutOffsetLeft,\n",
    "                                                 cutOffsetRight,\n",
    "                                                 nodeLengths,\n",
    "                                                 leftCut,\n",
    "                                                 rightCut,\n",
    "                                                 leftForbidden,\n",
    "                                                 rightForbidden)\n",
    "                    print('leftCut')\n",
    "                    print(leftCut)\n",
    "                    print('rightCut')\n",
    "                    print(rightCut)\n",
    "                    print('nodeLengths')\n",
    "                    print(nodeLengths)\n",
    "        nodeIDsToRemove = [i for i,l in enumerate(nodeLengths) if l==0]\n",
    "        if len(nodeIDsToRemove)>0:\n",
    "            self.removeNodes(nodeIDsToRemove)\n",
    "    # End of overlap removal functionality\n",
    "    \n",
    "    def __iter__(self,forward=True):\n",
    "        print(forward)\n",
    "        for i in range(len(self.nodes)):\n",
    "            yield i+1,self.forwardLinks[i+1]\n",
    "    \n",
    "    def __getitem__(self,ind):\n",
    "        if isinstance(ind,tuple):\n",
    "            nodeID = ind[0]\n",
    "            forward = ind[1]\n",
    "        else:\n",
    "            nodeID = ind\n",
    "            forward = True\n",
    "            \n",
    "        if nodeID>len(self.nodes):\n",
    "            raise IndexError('The nodeID index {nodeID} is out of range')\n",
    "            \n",
    "        if not forward and self.isBack:\n",
    "            try:\n",
    "                return self.backLinks[nodeID]\n",
    "            except KeyError:\n",
    "                return None\n",
    "        else:\n",
    "            try:\n",
    "                return self.forwardLinks[nodeID]\n",
    "            except KeyError:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Provides main class and helpers classes and functions to handle pangenome\n",
    "  graph and related data structures\n",
    "output-file: graph.html\n",
    "title: Graph module\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skbio.io import read as skbio_read\n",
    "from skbio.metadata import IntervalMetadata\n",
    "from skbio.sequence import DNA\n",
    "\n",
    "from pygengraph.synteny import processAccessions,generatePathsLinks,readTransMap\n",
    "from pygengraph.utils import bidict,pathFileToPathDict,inverseSequence\n",
    "from pygengraph.tree import TremauxTree\n",
    "\n",
    "from fastcore.all import patch_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path conversion utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are utility, but because they are directly related to graph structures, they are places in this module and not in `Util` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calcNodeLengths(graph):\n",
    "    '''\n",
    "    Simple function that calculates node lengths (in visual columns).\n",
    "    \n",
    "    If it is nucleotide graph, it will actually calculate a number of nucleotides in each node,\n",
    "    but if it is non-nucleotide graph, then it will return 1 for each node.\n",
    "    '''\n",
    "    \n",
    "    print('Calculating nodes length...')\n",
    "    \n",
    "    numNodes = len(graph.nodes)\n",
    "    numNodesDigits = np.int(np.ceil(np.log10(numNodes)))\n",
    "    nodeLengths = [0]*numNodes\n",
    "    \n",
    "    for nodeIdx in range(numNodes):\n",
    "        print(f'\\rProcessing node {nodeIdx+1:0{numNodesDigits}}/{numNodes:0{numNodesDigits}}',end='')\n",
    "        if graph.nodesData[nodeIdx]=='':\n",
    "            nodeLengths[nodeIdx] = 1#len(graph.nodes[nodeIdx])\n",
    "        else:\n",
    "            nodeLengths[nodeIdx] = len(graph.nodesData[nodeIdx])\n",
    "    \n",
    "    print('\\nFinished calculating nodes lengths')\n",
    "    return nodeLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def initialPathAnalysis(graph,nodeLengths):\n",
    "    '''\n",
    "    \n",
    "    This function creates auxiliary data structures to make it easier to work with paths and their relationships with nodes.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    `pathLengths`: a list of number of nodes in each path\n",
    "\n",
    "    `pathNodeArray`: numpy.array[int]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing sequence of nodes in the order as they are passed by the given \n",
    "                    path. If the length of the path is less than the number of columns of the\n",
    "                    array, then the unused columns are padded with zeros (node numbers are 1-based).\n",
    "    \n",
    "    `pathNodeLengths`: length of each node in each path\n",
    "    \n",
    "    `pathDirArray`: numpy.array[bool]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing direction (normal or inversed) in which the given path passes each node. \n",
    "                    `False` means normal direction, `True` means inverted. If the length of the path \n",
    "                    is less than the number of columns of the array, then the unused columns \n",
    "                    are padded with `False`.\n",
    "    \n",
    "    `pathNodeLengthsCum`: Cumulative length of each paths (in terms of node lengths).\n",
    "    \n",
    "    \n",
    "    Example\n",
    "    =======\n",
    "    \n",
    "    The following paths are present in the graph (containing 5 nodes):\n",
    "    seq1: 1+, 2+, 3+, 4+, 5+ \n",
    "    ... # seq2 - seq6 are the same as seq1 as inversion is relative to consensus\n",
    "    seq7: 1+, 4-, 3-, 2-, 5+\n",
    "    seq8: 1+, 4-, 3-, 2-, 4-, 3-, 2-, 5+\n",
    "    seq9: 1+, 4-, 3+, 2-, 5+\n",
    "    seq10: 1+, 4-, 3+, 2-, 4-, 3+, 2-, 5+\n",
    "    \n",
    "    The result is:\n",
    "    `pathLengths`: [5, 5, 5, 5, 5, 5, 5, 8, 5, 8]\n",
    "    \n",
    "    `pathNodeArray`:\n",
    "    array([[1, 2, 3, 4, 5, 0, 0, 0],\n",
    "           ...\n",
    "           [1, 4, 3, 2, 5, 0, 0, 0],\n",
    "           [1, 4, 3, 2, 4, 3, 2, 5],\n",
    "           [1, 4, 3, 2, 5, 0, 0, 0],\n",
    "           [1, 4, 3, 2, 4, 3, 2, 5]]),\n",
    "    \n",
    "    `pathNodeLengths`: Cannot be defined without node lengths.\n",
    "    \n",
    "    `pathDirArray`:\n",
    "    array([[False, False, False, False, False, False, False, False],\n",
    "           ...\n",
    "           [False,  True,  True,  True, False, False, False, False],\n",
    "           [False,  True,  True,  True,  True,  True,  True, False],\n",
    "           [False,  True, False,  True, False, False, False, False],\n",
    "           [False,  True, False,  True,  True, False,  True, False]]))\n",
    "    \n",
    "    `pathNodeLengthsCum`: Cannot be defined without node lengths.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    print('Preprocessing paths...')\n",
    "    \n",
    "    numPaths = len(graph.paths)\n",
    "    numPathsZeros = np.int(np.ceil(np.log10(numPaths)))\n",
    "    \n",
    "    maxLengthPath = len(max(graph.paths,key=lambda arr: len(arr)))\n",
    "\n",
    "    pathLengths = []\n",
    "    pathNodeArray = np.zeros((len(graph.paths),maxLengthPath),dtype = np.int)\n",
    "    pathNodeLengths = np.zeros((len(graph.paths),maxLengthPath),dtype = np.int)\n",
    "    pathDirArray = np.zeros((len(graph.paths),maxLengthPath),dtype = np.bool) # True - \"+\", False - \"-\" or padding for shorter paths.\n",
    "\n",
    "    for i,path in enumerate(graph.paths):\n",
    "        print(f'\\rProcessing path {i+1:0{numPathsZeros}}/{numPaths:0{numPathsZeros}}',end='')\n",
    "        pathLengths.append(len(path))\n",
    "\n",
    "        pathNodeArray[i,:pathLengths[-1]] = [int(node[:-1]) for node in path]\n",
    "        pathDirArray[i,:pathLengths[-1]] = [node[-1]=='-' for node in path]\n",
    "        pathNodeLengths[i,:pathLengths[-1]] = [nodeLengths[node-1] for node in pathNodeArray[i,:pathLengths[-1]]]\n",
    "\n",
    "    pathNodeLengthsCum = np.cumsum(pathNodeLengths,axis=1)\n",
    "    print('\\nFinished preprocessing paths')\n",
    "    return pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getNodesStructurePathNodeInversionRate(pathNodeArray,pathDirArray,pathLengths,inversionThreshold=0.5):\n",
    "    '''\n",
    "    Generate a dict of dicts which stores information about inversion rate of each node for each path.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    `pathLengths`: TBD (generated by `initialPathAnalysis`)\n",
    "\n",
    "    `pathNodeArray`: numpy.array[int]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing sequence of nodes in the order as they are passed by the given \n",
    "                    path. If the length of the path is less than the number of columns of the\n",
    "                    array, then the unused columns are padded with zeros (node numbers are 1-based). \n",
    "                    Generated by `initialPathAnalysis`.\n",
    "    \n",
    "    `pathDirArray`: numpy.array[bool]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing direction (normal or inversed) in which the given path passes each node. \n",
    "                    `False` means normal direction, `True` means inverted. If the length of the path \n",
    "                    is less than the number of columns of the array, then the unused columns \n",
    "                    are padded with `False`.\n",
    "                    Generated by `initialPathAnalysis`.\n",
    "    \n",
    "    `inversionThreshold`: float (default: 0.5). A float from the range [0,1], which defines whether an inversion rate\n",
    "                        is considered as normal or inverted in binary inversion. It is needed for link directions\n",
    "                        and visualisation of the nodes. It is a dictionary with pathIDs as keys and dictionaries as values.\n",
    "                        The dictionaries as values have nodeID as keys and boolean indicating whether this node for this path\n",
    "                        is inverted (True) or not (False).\n",
    "    \n",
    "    '''\n",
    "    nodesStruct = {}\n",
    "    pathNodeInversionRate = {}\n",
    "    combinedNodeDirArray = []\n",
    "    \n",
    "    nodeNum = np.max(pathNodeArray)\n",
    "    for pathID in range(pathNodeArray.shape[0]):\n",
    "        nodeInversionRate = pathNodeInversionRate.setdefault(pathID,{})\n",
    "\n",
    "        pathNodes = pathNodeArray[pathID,:pathLengths[pathID]]\n",
    "        uniqueNodes = np.unique(pathNodes,return_counts=True)\n",
    "        countNodes = np.flip(uniqueNodes[1]).tolist()\n",
    "        uniqueNodes = np.flip(uniqueNodes[0]).tolist()\n",
    "        for node in range(1,nodeNum+1):\n",
    "            if len(uniqueNodes)>0 and uniqueNodes[-1]==node:\n",
    "                uniqueNodes.pop()\n",
    "                occNode = countNodes.pop()\n",
    "                invNode = np.mean(pathDirArray[pathID,np.where(pathNodes==node)[0]])>inversionThreshold\n",
    "                nodeInversionRate[node] = invNode\n",
    "            else:\n",
    "                occNode = nodesStruct.get(node-1,[(1,0)])[-1][0]\n",
    "                invNode = False\n",
    "            nodesStruct.setdefault(node,[]).append((occNode,invNode))\n",
    "        combinedNodeDirArray.append([node*(-1 if nodeInversionRate[node] else 1) if node>0 else 0 for node in pathNodeArray[pathID,:]])\n",
    "    return pathNodeInversionRate,[nodesStruct[key] for key in sorted(nodesStruct.keys())],np.array(combinedNodeDirArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convertPathsToGraph(fullPath,doSorting=False,v2=False):\n",
    "    '''\n",
    "    Parameters\n",
    "    ==========\n",
    "    `doSorting`: False or str. If False, nodes will appear in the sequence as they appear in the paths (starting from first path)\n",
    "                 if \"nodesort\", then it is assumed that nodes are the sequence numbers of the nodes in which they should be \n",
    "                 ordered (1-based numbering), if \"treesort\", then standard TreeSort algorithm is used for sorting the graph.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    paths = pathFileToPathDict(fullPath,True,True,v2)\n",
    "    coregraph = GenomeGraph(pathsDict=paths)\n",
    "\n",
    "    if doSorting:\n",
    "        if doSorting=='treesort':\n",
    "            coregraph.treeSort()\n",
    "            assert len(coregraph.nodes)==len(coregraph.order),\\\n",
    "                f'Graph sorting failed, not all nodes appear in graph order: Number of nodes {len(coregraph.nodes)}, \\\n",
    "                number in sorted order {len(coregraph.order)}'\n",
    "        elif doSorting=='nodesort':\n",
    "            for i,node in enumerate(coregraph.nodes):\n",
    "                coregraph.order[int(node)-1] = i+1\n",
    "    \n",
    "    coreGFApath = f'{os.path.splitext(fullPath)[0]}.gfa'\n",
    "    coregraph.toGFA(coreGFApath,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getPathNodeInversionRate(pathNodeArray,pathDirArray,pathLengths,inversionThreshold=0.5):\n",
    "    '''\n",
    "    deprecated\n",
    "    Generate a dict of dicts which stores information about inversion rate of each node for each path.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    `pathLengths`: TBD (generated by `initialPathAnalysis`)\n",
    "\n",
    "    `pathNodeArray`: numpy.array[int]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing sequence of nodes in the order as they are passed by the given \n",
    "                    path. If the length of the path is less than the number of columns of the\n",
    "                    array, then the unused columns are padded with zeros (node numbers are 1-based). \n",
    "                    Generated by `initialPathAnalysis`.\n",
    "    \n",
    "    `pathDirArray`: numpy.array[bool]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing direction (normal or inversed) in which the given path passes each node. \n",
    "                    `False` means normal direction, `True` means inverted. If the length of the path \n",
    "                    is less than the number of columns of the array, then the unused columns \n",
    "                    are padded with `False`.\n",
    "                    Generated by `initialPathAnalysis`.\n",
    "    \n",
    "    `inversionThreshold`: float (default: 0.5). A float from the range [0,1], which defines whether an inversion rate\n",
    "                        is considered as normal or inverted in binary inversion. It is needed for link directions\n",
    "                        and visualisation of the nodes. It is a dictionary with pathIDs as keys and dictionaries as values.\n",
    "                        The dictionaries as values have nodeID as keys and boolean indicating whether this node for this path\n",
    "                        is inverted (True) or not (False).\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    pathNodeInversionRate = {}\n",
    "    for pathID in range(pathNodeArray.shape[0]):\n",
    "        nodeInversionRate = pathNodeInversionRate.setdefault(pathID,{})\n",
    "        pathNodes = pathNodeArray[pathID,:pathLengths[pathID]]\n",
    "        uniqueNodes = np.unique(pathNodes)\n",
    "        for node in uniqueNodes:\n",
    "            nodeInversionRate[node] = np.mean(pathDirArray[pathID,np.where(pathNodes==node)[0]])>inversionThreshold\n",
    "    \n",
    "    return pathNodeInversionRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pathNodeDirToCombinedArray(pathNodeArray,pathDirArray):\n",
    "    '''\n",
    "    Combines path node and direction arrays (provided by `graph.initialPathAnalysis` function \n",
    "    as `pathNodeArray` and `pathDirArray` (output indices `1` and `3`)).\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    `pathNodeArray`: numpy.array[int]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing sequence of nodes in the order as they are passed by the given \n",
    "                    path. If the length of the path is less than the number of columns of the\n",
    "                    array, then the unused columns are padded with zeros (node numbers are 1-based).\n",
    "    `pathDirArray`: numpy.array[bool]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing direction (normal or inversed) in which the given path passes each node. \n",
    "                    `False` means normal direction, `True` means inverted. If the length of the path \n",
    "                    is less than the number of columns of the array, then the unused columns \n",
    "                    are padded with `False`.\n",
    "    \n",
    "    Return\n",
    "    ======\n",
    "    \n",
    "    `combinedNodeDirArray`: numpy.array[int]. An array of the size number_of_paths x max_length_of_path, \n",
    "                    containing sequence of nodes and their direction (for given path) in the order as \n",
    "                    they are passed by the given path. Nodes that are passed in the normal direction are \n",
    "                    shown using positive integer id of the node. The nodes that are passed in the inverted \n",
    "                    direction are presented as negative of the integer id of the node.\n",
    "                    If the length of the path is less than the number of columns of the array, then the \n",
    "                    unused columns are padded with zeros (node numbers are 1-based).\n",
    "\n",
    "    Notes\n",
    "    =====\n",
    "    1. The dimensions of `pathNodeArray` and `pathDirArray` should be identical \n",
    "        (as provided by `graph.initialPathAnalysis` function). AT THE MOMENT IT IS NOT CHECKED EXPLICITLY!\n",
    "    \n",
    "    \n",
    "    Example\n",
    "    =======\n",
    "    The following paths are present in the graph (containing 5 nodes):\n",
    "    seq1: 1+, 2+, 3+, 4+, 5+\n",
    "    ... # seq2 - seq6 are the same as seq1 as inversion is relative to consensus\n",
    "    seq7: 1+, 4-, 3-, 2-, 5+\n",
    "    seq8: 1+, 4-, 3-, 2-, 4-, 3-, 2-, 5+\n",
    "    seq9: 1+, 4-, 3+, 2-, 5+\n",
    "    seq10: 1+, 4-, 3+, 2-, 4-, 3+, 2-, 5+\n",
    "    \n",
    "    `pathNodeArray`:\n",
    "    array([[1, 2, 3, 4, 5, 0, 0, 0],\n",
    "           ...\n",
    "           [1, 4, 3, 2, 5, 0, 0, 0],\n",
    "           [1, 4, 3, 2, 4, 3, 2, 5],\n",
    "           [1, 4, 3, 2, 5, 0, 0, 0],\n",
    "           [1, 4, 3, 2, 4, 3, 2, 5]]),\n",
    "    `pathDirArray`:\n",
    "    array([[False, False, False, False, False, False, False, False],\n",
    "           ...\n",
    "           [False,  True,  True,  True, False, False, False, False],\n",
    "           [False,  True,  True,  True,  True,  True,  True, False],\n",
    "           [False,  True, False,  True, False, False, False, False],\n",
    "           [False,  True, False,  True,  True, False,  True, False]]))\n",
    "           \n",
    "    The result `combinedNodeDirArray`:\n",
    "    array([[ 1,  2,  3,  4,  5,  0,  0,  0],\n",
    "           ...\n",
    "           [ 1, -4, -3, -2,  5,  0,  0,  0],\n",
    "           [ 1, -4, -3, -2, -4, -3, -2,  5],\n",
    "           [ 1, -4,  3, -2,  5,  0,  0,  0],\n",
    "           [ 1, -4,  3, -2, -4,  3, -2,  5]])\n",
    "    '''\n",
    "    \n",
    "    intDirArray = -1*pathDirArray.astype(int)\n",
    "    intDirArray[intDirArray==0] = 1\n",
    "\n",
    "    return intDirArray*pathNodeArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def getNextNodePath(pathNodeArray,pathLengths):\n",
    "    '''\n",
    "    \n",
    "    When following path to find next in graph order, it will not necessarily be  ð‘˜+1 , it can be  ð‘˜+ð‘  if  ð‘˜+1,...,ð‘˜+ð‘âˆ’1  are not passed by the path.\n",
    "\n",
    "    Create a list of all unique node numbers in each path by\n",
    "    - Either set(path)\n",
    "    - *** or np.unique(path) Preferable option would be selected according to the selection of the options for next step\n",
    "    \n",
    "    And then do one of the following\n",
    "    - Just leave the list as it is and in a loop check if  ð‘˜+ð‘  (with  ð‘=1,... ) is in the path (k+p in pathUnique) Probably slow\n",
    "    - Sort the list pathUnique and for every node where we need to find next in order just find its index and take \n",
    "        the next one pathUnique[pathUnique.index(k)+1]\n",
    "    - Create a dict for each node (except the last one) with key as  ð‘˜  and value as  ð‘˜+ð‘ . On break in path at position  ð‘˜  we get the next as dict[k]\n",
    "    - *** Do np.diff(np.sort(pathUnique)) and create a dict for each node after which diff!=1 with key as  ð‘˜  and value as  ð‘˜+ð‘ . \n",
    "        Then when we get to the break in path at position k. We check k in dict and if True, then the next is dict[k], otherwise it is k+1\n",
    "    \n",
    "    This function implements generating the dict as described in *** (triple starred) options, which are currently used options.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    nextNodeDict = {}\n",
    "    \n",
    "    for pathID,nodeArray in enumerate(pathNodeArray):\n",
    "        uniqueNodes = np.sort(np.unique(nodeArray[:pathLengths[pathID]]))\n",
    "        breaks = np.where(np.diff(uniqueNodes)>1)[0]\n",
    "        nextNodeDict[pathID] = bidict({uniqueNodes[gap]:uniqueNodes[gap+1] for gap in breaks})\n",
    "    \n",
    "    return nextNodeDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant class implementing link getting mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LinkGetter:\n",
    "    '''\n",
    "    This auxiliary class allows creating virtual subscribable structure inside the main `GenomeGraph` class\n",
    "    to access links as Iterable and Subscribable object. Full links (with directionality) are available in the main class.\n",
    "    This class provides simplified view on the links without directionality (the fact that a link goes from node A to node B).\n",
    "    '''\n",
    "    def __init__(self,nodes,links):\n",
    "        self.links = links\n",
    "        self.nodes = nodes\n",
    "    \n",
    "    def __getitem__(self,nodeID):\n",
    "        try:\n",
    "            node = self.links[nodeID]\n",
    "            childrenList = list(itertools.chain(*list(node.values())))\n",
    "            return list(set([el[0] for el in childrenList]))\n",
    "        except KeyError:\n",
    "            if nodeID>0 and nodeID<=len(self.nodes):\n",
    "                return []\n",
    "            else:\n",
    "                raise KeyError(f'There is no node with ID {nodeID}')\n",
    "    def __call__(self):\n",
    "        allLinks = []\n",
    "        for node in range(1,len(self.nodes)+1):\n",
    "            res = self[node]\n",
    "            if res is not None:\n",
    "                allLinks.extend([(node,el) for el in res])\n",
    "        return allLinks\n",
    "#         return list(self)\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.nodes)):\n",
    "            res = self[i+1]\n",
    "            if res is not None:\n",
    "                yield (i+1,res)\n",
    "            else:\n",
    "                yield (i+1,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main class holding all data and main methods operating the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph definition, constructor and some utils for constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GenomeGraph:\n",
    "    def __init__(self,gfaPath=None,doOverlapCleaning=True,\n",
    "                 paths=None,\n",
    "                 nodes=None,nodesData=None,links=None,\n",
    "                 pathsDict=None,\n",
    "                 sequenceFilesDict=None,annotationFiles=None,pangenomeFiles=None,\n",
    "                 doBack=False, verbose = True,**kwargs):\n",
    "\n",
    "        '''\n",
    "        This is a constructor of a class `GenomeGraph`. This class allows to hold not only vanila genome graph, but\n",
    "        also a lot of extra information and also manipulate graphs in multiple ways, including sorting graphs, adding\n",
    "        and deleting nodes and links, and manipulating metadata etc.\n",
    "        \n",
    "        At the moment, there are four ways an instance can be created. It depends on what parameters are passed to the \n",
    "        constructor. If parameters for more than 1 option is passed, there is a priority queue which constructor follows.\n",
    "        Each option and its priorities are provided below.\n",
    "        \n",
    "        - Priority 1: If you pass gfaPath as actual path to gfa file, then it will be loaded as is. In this case, the \n",
    "        following options are available: \n",
    "            \n",
    "            `accessionsToRemove`: list or None (default). If not None, a list of strings, if any of the string contains \n",
    "                                  in pathname, the path will be ignored while loading.\n",
    "            \n",
    "            `isGFASeq`: boolean (default: True). Whether the graph should be considered as sequence graph (True)\n",
    "                        or as gene/block graph (False).\n",
    "        \n",
    "        - Priority 2: If nodes, links and paths are provided (not None), they should be as following:\n",
    "            \n",
    "            `nodes`: list[str]: a list of strings with node IDs (unique)\n",
    "            \n",
    "            `links`: dict{int:dict{str:list[tuple(int,str)]}}: a dict with keys integers with 1-basednode numbers \n",
    "            (in the order as in self.nodes) from which the link starts. Value is a dict with key of directionality of\n",
    "            the from node ('+' for normal direction or '-' for inverse). Value is a list of tuples with two values:\n",
    "            first integer is 1-based node number of node to which the link is going and second string is '+' or '-'\n",
    "            representing the directionality in which this node is represented in this link.\n",
    "            \n",
    "            'paths': list[list[str]]: List, which contains a list for each accession/path, which is represented by\n",
    "            a list of strings, each of which has a format '{1-based node number}{directionality}', where \n",
    "            {1-based node number} is an integer 1-based number of node using the order as in `nodes`, \n",
    "            {directionality} is either '+' for normal direction, or '-' for inverted.\n",
    "            \n",
    "        - Priority 3: if pathsDict is provided then the graph is created from the paths for multiple accessions.\n",
    "            `pathsDict` is a dict{int:list[str]}; keys are names of accessions, and values are lists of strings\n",
    "            of the following format '{node name}{directionality}', where {node name} is identifiable unique name\n",
    "            which identifies the node, {directionality} is either '+' for normal direction, or '-' for inverted.\n",
    "            Note, that this can create no-sequence graph only (e.g. gene graph). Sequences can be added later on\n",
    "            through adding sequences to GenomeGraph.nodesData list.\n",
    "            \n",
    "            An extra optional parameter is:\n",
    "            \n",
    "            `nodeNameLengths`: list[int] or None, a list of alternative node lengths. By default, each node will be \n",
    "                               represented as a single cell/column, but if provided, variable length can be provided.\n",
    "        \n",
    "        - Priority 4: If annotationFiles is not None, but is a list of paths to annotation (gff3) files, \n",
    "        then the following extra options are available:\n",
    "            \n",
    "            'sequenceFilesDict': a dict{str:str}, where keys are IDs of accessions used in annotation files and value\n",
    "                                is a path to FASTA file (relative to gff files). Assumption is that FASTA sequence names\n",
    "                                are the same as GFF3 sequence names.\n",
    "            \n",
    "            `pangenomeFiles`: a list[str], a list of GFF3 files for the same intervals as in `annotationFiles`, \n",
    "                            ID fields in GFF2 metadata should be the same.\n",
    "            \n",
    "            `accOrder`: list or None (default), Order of accessions in the graph. If None, accessions will be sorted in \n",
    "                        alphabetical order.\n",
    "            \n",
    "            `chromosome`: str or None, if None, create one graph for all chromosomes (not fully implemented, see manual), \n",
    "                        otherwise, create only one graph for given chromosome.\n",
    "            \n",
    "            `doUS`: boolean (default: False) Add unrelated sequence blocks between annotated genes/blocks.\n",
    "            \n",
    "            `refAnnotationFile`: str. If given, it has to be a path to gff3 file with reference annotation \n",
    "                                 with reference notation for gene names. In main annotations reference gene names should be identified \n",
    "                                 either in \"gene\" records under \"AT\" key (prioritised), \n",
    "                                 or in \"mRNA\" records under \"Name\" key (fallback). If ATMap is provided, then \n",
    "            \n",
    "            `refSequenceFile`: str or None (default). If provided with path, then it will be used to obtain \n",
    "                               sequences of each block/gene.\n",
    "            \n",
    "            `transmapFile`: a tab delimited file with column \"Orthogroup\", which contains similarity ID for genes and a column with name\n",
    "                            given by `transmapFileRefCol` which contains reference annotation gene names.\n",
    "            \n",
    "            `transmapFileRefCol`: str or None, a name of column for reference gene names in `transmapFile`\n",
    "            \n",
    "            `refAccession`: str or None (default). Accession ID for reference annotation (should be provided if `refAnnotationFile`\n",
    "                            if provided).\n",
    "\n",
    "        '''\n",
    "        self.nodes = []\n",
    "        self.nodesData = []\n",
    "        self.chromosomes = set()\n",
    "        self.nodesMetadata = []\n",
    "        self.hasPangenome = False\n",
    "        self.quiet = not verbose\n",
    "        \n",
    "        self.forwardLinks = {}\n",
    "        self.overlaps = {}\n",
    "        self.paths = []\n",
    "        self.accessions = []\n",
    "        self._nxGraph = None\n",
    "        self.tremauxTree = None\n",
    "\n",
    "        self.isBack = doBack\n",
    "\n",
    "        if gfaPath is not None:\n",
    "            self._loadGFA(gfaPath,isGFASeq=kwargs.get('isGFASeq',True),accessionsToRemove=kwargs.get('accessionsToRemove',None))\n",
    "        elif nodes is not None and links is not None and paths is not None:\n",
    "            self.nodes = nodes\n",
    "            if nodesData is not None:\n",
    "                self.nodesData = nodesData\n",
    "            else:\n",
    "                self.nodesData = ['']*len(self.nodes)\n",
    "            self.forwardLinks = links\n",
    "            self.paths = paths\n",
    "        elif pathsDict is not None:\n",
    "            self._graphFromPaths(pathsDict,**kwargs) # sequenceFiles can be None\n",
    "        elif annotationFiles is not None:\n",
    "            self._graphFromAnnotation(annotationFiles,pangenomeFiles,sequenceFilesDict,**kwargs)\n",
    "\n",
    "        self.order = list(range(1,len(self.nodes)+1))\n",
    "\n",
    "        self.pureForwardlinks = LinkGetter(self.nodes,self.forwardLinks)\n",
    "\n",
    "        self._pathCount()\n",
    "        self.invertNodes()\n",
    "\n",
    "        if doBack:\n",
    "            self.backLinks = self._revertLinks()\n",
    "            self.pureBackLinks = LinkGetter(self.nodes,self.backLinks)\n",
    "\n",
    "        if len(self.overlaps)>0 and doOverlapCleaning:\n",
    "            self.treeSort()\n",
    "            self.removeOverlaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch_to(GenomeGraph)\n",
    "def _revertLinks(self):\n",
    "    '''\n",
    "    Function creates backlinks if necessary:\n",
    "    By default, the links stored and can be accessed in forward direction (by starts).\n",
    "    In some situations, one need to access links by ends. This function creates a separate structure to search links\n",
    "    in backward direction. This structure is stored in attribute `backlinks` and `pureBackLinks`.\n",
    "    '''\n",
    "    backLinks = {}\n",
    "    for fromNode,links in self.forwardLinks.items():\n",
    "        for fromStrand,strandLinks in links.items():\n",
    "            for item in strandLinks:\n",
    "#                     if item[0] not in backLinks.keys():\n",
    "#                         backLinks[item[0]] = {}\n",
    "#                         backLinks[item[0]][item[1]] = []\n",
    "\n",
    "#                     elif item[1] not in forwardLinks[item[0]].keys():\n",
    "#                         backLinks[item[0]][item[1]] = []\n",
    "\n",
    "                backLinks.setdefault(item[0],{}).setdefault(item[1],[]).append((fromNode,fromStrand))\n",
    "    return backLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# check edgePaths calculation. Incorrectly calculates the numbers \n",
    "# (one too many in one of group of incoming edges to each node)\n",
    "@patch_to(GenomeGraph)\n",
    "def _pathCount(self):\n",
    "    '''\n",
    "    Function calculates relationships between paths and nodes, e.g. how many paths pass each node in specific direction\n",
    "    and how many times.\n",
    "    '''\n",
    "    \n",
    "    self.nodePass = [0]*len(self.nodes)\n",
    "\n",
    "    self.nodeStrandPaths = [[0,0] for _ in range(len(self.nodes))]\n",
    "    self.pathStarts = [0]*len(self.nodes)\n",
    "    self.inPath = [0]*len(self.nodes)\n",
    "    self.outPath = [0]*len(self.nodes)\n",
    "    self.edgePaths = {}\n",
    "\n",
    "    self.nodePassUnique = {}\n",
    "    self.inPathUnique = {}\n",
    "    self.outPathUnique = {}\n",
    "    self.edgePathsUnique = {}\n",
    "\n",
    "    for pathID,path in enumerate(self.paths):\n",
    "\n",
    "        previousNode = None\n",
    "        for nodeStrand in path:\n",
    "            pathNode = int(nodeStrand[:-1])-1\n",
    "            pathStrand = int(nodeStrand[-1]=='-') # 0 if \"+\", 1 if \"-\"\n",
    "            self.nodePass[pathNode] += 1\n",
    "            self.nodePassUnique.setdefault(pathNode,set()).add(pathID)\n",
    "            self.nodeStrandPaths[pathNode][pathStrand] += 1\n",
    "            self.outPath[pathNode] += 1\n",
    "            self.outPathUnique.setdefault(pathNode,set()).add(pathID)\n",
    "            self.inPath[pathNode] += 1\n",
    "            self.inPathUnique.setdefault(pathNode,set()).add(pathID)\n",
    "            if previousNode is not None:\n",
    "                self.edgePaths.setdefault((previousNode+1,pathNode+1),0)\n",
    "                self.edgePaths[(previousNode+1,pathNode+1)] += 1\n",
    "\n",
    "                self.edgePathsUnique.setdefault((previousNode+1,pathNode+1),set())\\\n",
    "                                        .add(pathID)\n",
    "            else:\n",
    "                self.pathStarts[pathNode] += 1\n",
    "                self.inPath[pathNode] -= 1\n",
    "            previousNode = pathNode\n",
    "        self.outPath[previousNode] -= 1\n",
    "\n",
    "    # We are not interested in pathIDs in *Unique blocks, so, \n",
    "    # converting them back to standard format.\n",
    "    self.nodePassUnique = [len(self.nodePassUnique.get(key,[])) for key in range(len(self.nodes))]\n",
    "    self.inPathUnique = [len(self.inPathUnique.get(key,[])) for key in range(len(self.nodes))]\n",
    "    self.outPathUnique = [len(self.outPathUnique.get(key,[])) for key in range(len(self.nodes))]\n",
    "    self.edgePathsUnique = {key:len(value) for key,value in self.edgePathsUnique.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import graph from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From GFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch_to(GenomeGraph)\n",
    "def _loadGFA(self, gfaFile, isGFASeq=True, accessionsToRemove=None):\n",
    "    '''\n",
    "    Loading GFA file and instantiating the object from it.\n",
    "    \n",
    "    At the moment only GFA v1 is supported.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    baseName = os.path.splitext(os.path.basename(gfaFile))[0]\n",
    "    dirPath = os.path.dirname(gfaFile)\n",
    "    jsonFile = f'{dirPath}{os.path.sep}nodeNames_{baseName}.json'\n",
    "    annotationFile = f'{dirPath}{os.path.sep}annotation_{baseName}.dat'\n",
    "\n",
    "    print(f'Loading graph from {gfaFile}')\n",
    "\n",
    "    if os.path.exists(jsonFile):\n",
    "        print(f'Found nodeNames file {jsonFile}, loading names.')\n",
    "        nodeNames = json.load(open(jsonFile,mode='r'))\n",
    "    else:\n",
    "        nodeNames = None\n",
    "\n",
    "    loadAnnotation = False\n",
    "\n",
    "    if os.path.exists(annotationFile):\n",
    "        print(f'Found node annotation file {annotationFile}, loading associations.')\n",
    "        self.nodesMetadata = joblib.load(annotationFile)\n",
    "        emptyAnnotation = False\n",
    "    else:\n",
    "        emptyAnnotation = True\n",
    "\n",
    "    prevPathSegment = None\n",
    "\n",
    "    gfaList = open(gfaFile,mode='r').readlines()\n",
    "\n",
    "    if gfaList[0][7:-1] == '2.0':\n",
    "        raise NotImplementedError('At the moment only GFA v1 is supported')\n",
    "    elif gfaList[0][7:-1] != '1.0':\n",
    "        warnings.warn('Cannot identify version of GFA. Assuming it is GFA v1. If it is not, expect unpredictable results.',category=ResourceWarning)\n",
    "\n",
    "    segmentList = [el for el in gfaList if el.lower().startswith('s')]\n",
    "    linkList = [el for el in gfaList if el.lower().startswith('l')]\n",
    "    pathStringsList = [el for el in gfaList if el.lower().startswith('p')]\n",
    "\n",
    "    self.nodeNameToID = {}\n",
    "\n",
    "    numSegments = len(segmentList)\n",
    "    if numSegments>0:\n",
    "        numSegmentDigits = int(np.ceil(np.log10(numSegments)))\n",
    "    else:\n",
    "        raise ValueError('Incorrect GFA file format. No segments were found')\n",
    "\n",
    "    for nodeID,node in enumerate(segmentList):\n",
    "        if not self.quiet:\n",
    "            print(f'\\rLoading segment {nodeID+1:0{numSegmentDigits}}/{numSegments:0{numSegmentDigits}}',end='')\n",
    "        segmentArray = node.rstrip().split(sep='\\t')\n",
    "        segID,segGFAData = segmentArray[1:3]\n",
    "        if isGFASeq:\n",
    "            segSeq = segGFAData\n",
    "        else:\n",
    "            segSeq = ''\n",
    "\n",
    "        if nodeNames is not None:\n",
    "            segName = nodeNames[int(segID)-1]\n",
    "        elif isGFASeq:\n",
    "            segName = str(segID)\n",
    "        else:\n",
    "            segName = segGFAData\n",
    "\n",
    "        self.nodeNameToID[segID] = len(self.nodes)+1\n",
    "\n",
    "        self.nodes.append(segName)\n",
    "        self.nodesData.append(segSeq)\n",
    "\n",
    "    if emptyAnnotation:\n",
    "        self.nodesMetadata = [{}]*len(self.nodes)\n",
    "\n",
    "    print('\\nLoading segments finished.')\n",
    "\n",
    "    numLinks = len(linkList)\n",
    "    if numLinks>0:\n",
    "        numLinkDigits = int(np.ceil(np.log10(numLinks)))\n",
    "    else:\n",
    "        numLinkDigits = 1\n",
    "\n",
    "    for linkID,link in enumerate(linkList):\n",
    "        if not self.quiet:\n",
    "            print(f'\\rLoading link {linkID+1:0{numLinkDigits}}/{numLinks:0{numLinkDigits}}',end='')\n",
    "        linkArray = link.rstrip().split(sep='\\t')\n",
    "        fromNodeID,fromStrand,toNodeID,toStrand = linkArray[1:5]\n",
    "        overlap = linkArray[5]\n",
    "        fromNode = self.nodeNameToID[fromNodeID]\n",
    "        toNode = self.nodeNameToID[toNodeID]\n",
    "        if overlap[:-1].isnumeric() and overlap[-1]=='M':\n",
    "            self.overlaps[(fromNode,fromStrand)] = int(overlap[:-1])\n",
    "\n",
    "        curLink = self.forwardLinks.setdefault(fromNode,{})\n",
    "        curStrand = curLink.setdefault(fromStrand,[])\n",
    "        if (toNode,toStrand) not in curStrand:\n",
    "            curStrand.append((toNode,toStrand))\n",
    "    print('\\nLoading links finished')\n",
    "\n",
    "    numPaths = len(pathStringsList)\n",
    "    if numPaths>0:\n",
    "        numPathDigits = int(np.ceil(np.log10(numPaths)))\n",
    "    else:\n",
    "        raise ValueError('Incorrect GFA file format. No paths were found')\n",
    "\n",
    "    addedPaths = 0\n",
    "    ignoredPaths = 0\n",
    "    for pathID,pathString in enumerate(pathStringsList):\n",
    "        if not self.quiet:\n",
    "            print(f'\\rLoading path {pathID+1:0{numPathDigits}}/{numPaths:0{numPathDigits}}',end='')\n",
    "        pathArray = pathString.rstrip().split(sep='\\t')\n",
    "        seqID,path = pathArray[1:3]\n",
    "        useAccession = True\n",
    "        if isinstance(accessionsToRemove,list):\n",
    "            for accessionTemplate in accessionsToRemove:\n",
    "                if seqID.find(accessionTemplate)!=-1:\n",
    "                    ignoredPaths += 1\n",
    "                    useAccession = False\n",
    "                    break\n",
    "        if useAccession:\n",
    "            self.paths.append([f'{self.nodeNameToID.get(ns[:-1],ns[:-1])}{ns[-1]}' for ns in path.split(',')])\n",
    "            self.accessions.append(seqID)\n",
    "            addedPaths += 1\n",
    "    print(f'\\nLoading paths finished. {addedPaths} paths added, {ignoredPaths} paths ignored.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _getNodeID(self,node,pathID,nodeNameLengths=None):\n",
    "    '''\n",
    "    Function to either find already created node or create a new one and return its ID.\n",
    "    \n",
    "    '''\n",
    "    try:\n",
    "        nodeID = self.nodes.index(node)+1\n",
    "        if nodeNameLengths is not None:\n",
    "            nodeLength = nodeNameLengths[nodeID]\n",
    "        else:\n",
    "            nodeLength = 1\n",
    "        self.nodesMetadata[nodeID-1].setdefault(pathID, {}).setdefault('annotation',{}).setdefault(node, []).append((0, nodeLength - 1))\n",
    "    except ValueError:\n",
    "        self.nodes.append(node)\n",
    "        nodeID = len(self.nodes)\n",
    "        if nodeNameLengths is not None:\n",
    "            nodeLength = nodeNameLengths[nodeID]\n",
    "        else:\n",
    "            nodeLength = 1\n",
    "        self.nodesMetadata.append({pathID:{'annotation':{node:[(0,nodeLength - 1)]}}})\n",
    "\n",
    "        self.nodeNameToID[str(nodeID)] = nodeID\n",
    "\n",
    "    return nodeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _graphFromPaths(self,paths,sequenceFiles=None,nodeNameLengths=None):\n",
    "    '''\n",
    "    This function creates a graph from a set of paths (non-nucleotide graphs) and instantiate an object.\n",
    "    '''\n",
    "    \n",
    "    if sequenceFiles is not None:\n",
    "        warnings.warn(\"sequenceFiles reading with path is not yet implemented.\")\n",
    "\n",
    "    if not isinstance(paths,dict):\n",
    "        raise ValueError(f\"paths should be dict but {type(paths)} was given.\")\n",
    "\n",
    "#         if sequenceFiles is None:\n",
    "    # if nodeNameLength is None:\n",
    "    #     maxNodeNameLength = len(max([max(path,key=lambda a: len(a)) for path in paths.values()],key=lambda a: len(a))) - 1\n",
    "    # else:\n",
    "    #     maxNodeNameLength = nodeNameLength\n",
    "\n",
    "    self.nodeNameToID = {}\n",
    "    self.nodes = []\n",
    "    self.paths = []\n",
    "    self.accessions = []\n",
    "    links = {}\n",
    "\n",
    "    self.nodeNameToID = {}\n",
    "\n",
    "    for pathID,path in paths.items():\n",
    "        self.accessions.append(pathID)\n",
    "        prevNode = path[0][:-1]\n",
    "        prevDirection = path[0][-1]\n",
    "        prevNodeID = self._getNodeID(prevNode,pathID,nodeNameLengths)\n",
    "        newPath = [f'{prevNodeID}{prevDirection}']\n",
    "        for nodeDir in path[1:]:\n",
    "\n",
    "            node = nodeDir[:-1]\n",
    "            direction = nodeDir[-1]\n",
    "\n",
    "            nodeID = self._getNodeID(node,pathID,nodeNameLengths)\n",
    "            newPath.append(f'{nodeID}{direction}')\n",
    "            links.setdefault(prevNodeID,{}).setdefault(prevDirection,set()).add((nodeID,direction))\n",
    "\n",
    "            prevNode = node\n",
    "            prevDirection = direction\n",
    "            prevNodeID = nodeID\n",
    "        self.paths.append(newPath)\n",
    "\n",
    "\n",
    "    self.forwardLinks = dict([(fromNode,dict([(fromStrand,list(toSet)) for fromStrand,toSet in strandDict.items()])) for fromNode,strandDict in links.items()])\n",
    "    self.nodesData = ['']*len(self.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _processAnnotations(self, annotationFiles, links, \n",
    "                        annotationType='standard', \n",
    "                        pangenomeFiles = None, seqFilesDict = None, ATmap = None,\n",
    "                        chromosome = None, doUS = False,\n",
    "                        accOrder  = None):\n",
    "    '''\n",
    "    Processing all annotations (normally non-reference ones). It assumes that these annotations refer to gene IDs in reference annotation.\n",
    "    '''\n",
    "    if annotationType=='standard':\n",
    "        simID = 'OG'\n",
    "        simAssignment = 'gene'\n",
    "    elif annotationType=='pangenome':\n",
    "        simID = 'simgr'\n",
    "        simAssignment = 'mrna'\n",
    "    else:\n",
    "        raise ValueError(f'`annotationType` can be either \"standard\" or \"pangenome\", but {annotationType} was given.')\n",
    "    \n",
    "    if ATmap is None:\n",
    "        genes, chromosomes, ATmap, pangenomeDict, sequences = \\\n",
    "            processAccessions(annotationFiles, \n",
    "                              similarityIDKey = simID, \n",
    "                              similarityIDAssignment = simAssignment, \n",
    "                              pangenomeFiles = pangenomeFiles, \n",
    "                              sequenceFilesDict = seqFilesDict, \n",
    "                              seqidJoinSym = '_', ATsplitSym = ',')\n",
    "    else:\n",
    "        genes, chromosomes, pangenomeDict, sequences = \\\n",
    "            processAccessions(annotationFiles, \n",
    "                              similarityIDKey = simID, \n",
    "                              ATMap = ATmap,\n",
    "                              similarityIDAssignment = simAssignment, \n",
    "                              pangenomeFiles = pangenomeFiles, \n",
    "                              sequenceFilesDict = seqFilesDict, \n",
    "                              seqidJoinSym = '_', ATsplitSym = ',')\n",
    "    \n",
    "    if chromosome is None:\n",
    "        seqList = list(chromosomes)\n",
    "        seqList.sort()\n",
    "    else:\n",
    "        seqList = [chromosome]\n",
    "    \n",
    "    accessions = list(genes.keys())\n",
    "    \n",
    "    if accOrder is None:\n",
    "        accessionOrder = sorted(accessions)\n",
    "    else:\n",
    "        accessionOrder = [accessions[ind] for ind in accOrder]\n",
    "    \n",
    "    path = []\n",
    "    for accessionID in accessionOrder:\n",
    "        geneAcc = genes[accessionID]\n",
    "        for seqID in seqList:\n",
    "\n",
    "            p, cigar, usCounter = generatePathsLinks(geneAcc, ATmap, accessionID, sequences, self.OGList,\n",
    "                                                     self.nodes, self.nodesMetadata, self.nodeNameToID, links,\n",
    "                                                     self.usCounter, chromosomeID = seqID, doUS=doUS, segmentData=self.nodesData)\n",
    "            \n",
    "            path = path + p + [',<sep>,']\n",
    "\n",
    "        path.pop()\n",
    "        \n",
    "        self.paths.append(path)\n",
    "        self.accessions.append(accessionID)\n",
    "    \n",
    "    self.chromosomes.update(seqList)\n",
    "\n",
    "    return links, ATmap, pangenomeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch_to(GenomeGraph)\n",
    "def _processRefAnnotation(self, annotationFile, links, ATmap, pangenomeDict, accID, \n",
    "                        seqFile = None, \n",
    "                        chromosome = None, doUS = False):\n",
    "    '''\n",
    "    Processing reference annotation.\n",
    "    '''\n",
    "    if seqFile is not None:\n",
    "        seqFilesDict = {accID: seqFile}\n",
    "    else:\n",
    "        seqFilesDict = None\n",
    "    \n",
    "    genes, chromosomes, _, sequences = \\\n",
    "        processAccessions([annotationFile], \n",
    "                          ATmap = ATmap,\n",
    "                          pangenomeDict = pangenomeDict,\n",
    "                          sequenceFilesDict = seqFilesDict, \n",
    "                          seqidJoinSym = '_', ATsplitSym = ',')\n",
    "    \n",
    "    if chromosome is None:\n",
    "        seqList = list(chromosomes)\n",
    "        seqList.sort()\n",
    "    else:\n",
    "        seqList = [chromosome]\n",
    "    \n",
    "    if accID not in genes:\n",
    "        raise ValueError(f'Accession {accID} not found in provided annotation file')\n",
    "    \n",
    "    path = []\n",
    "    for seqID in seqList:\n",
    "\n",
    "        p, cigar, usCounter = generatePathsLinks(genes[accID], ATmap, accID, sequences, self.OGList,\n",
    "                                                     self.nodes, self.nodesMetadata, self.nodeNameToID, links,\n",
    "                                                     self.usCounter, chromosomeID = seqID, doUS=doUS, segmentData=self.nodesData)\n",
    "        path = path + p\n",
    "        \n",
    "    self.paths.insert(0,path)\n",
    "    self.accessions.insert(0,accID)\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _graphFromAnnotation(self,annotationFiles,pangenomeFiles=None, sequenceFilesDict=None,**kwargs):\n",
    "    '''\n",
    "    This function creates a gene/annotation graph (non-nucleotide) from a set of annotations for multiple accessions\n",
    "    and instantiate an object.\n",
    "    \n",
    "    It allows FASTA files and provide nucleotide sequences to each node, but will take nucleotide sequence from the first\n",
    "    accession where this gene (of the given similarity ID) is encountered. So, if similarity is not defined as 100% identical sequence\n",
    "    (not possible), then it will give invalid results. Not recommended to use.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    self.nodeNameToID = {}\n",
    "    \n",
    "    if pangenomeFiles is not None:\n",
    "        annotationType = 'pangenome'\n",
    "        self.hasPangenome = True\n",
    "    else:\n",
    "        annotationType = 'standard'    \n",
    "    \n",
    "    ATMapfile = kwargs.get('transMapFile',None)\n",
    "    ATMapSimGrColName = kwargs.get('transmapFileRefCol',None)\n",
    "    \n",
    "    if ATMapfile is not None and ATMapSimGrColName is not None:\n",
    "        ATmap = readTransMap(ATMapfile,ATMapSimGrColName)\n",
    "    else:\n",
    "        ATmap = None\n",
    "    \n",
    "    doUS = kwargs.get('doUS',False)\n",
    "    self.usCounter = 0\n",
    "    self.OGList = []\n",
    "    links = self._linksDictToSet(self.forwardLinks)\n",
    "\n",
    "    links,ATmap,pangenomeDict = self._processAnnotations(annotationFiles, links, \n",
    "                                      annotationType = annotationType, \n",
    "                                      pangenomeFiles = pangenomeFiles, \n",
    "                                      seqFilesDict = sequenceFilesDict,\n",
    "                                      ATmap = ATmap,\n",
    "                                      chromosome = kwargs.get('chromosome', None),\n",
    "                                      accOrder = kwargs.get('accessionOrder',None),\n",
    "                                      doUS = doUS)\n",
    "    \n",
    "    if 'refAnnotationFile' in kwargs:\n",
    "        links = self._processRefAnnotation(kwargs['refAnnotationFile'], links,\n",
    "                                        ATmap=ATmap,pangenomeDict=pangenomeDict,\n",
    "                                        seqFile = kwargs.get('refSequenceFile',None), \n",
    "                                        chromosome = kwargs.get('chromosome', None), doUS = doUS,\n",
    "                                        accID = kwargs.get('refAccession',None))\n",
    "\n",
    "    self.forwardLinks = self._linksSetToDict(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import or create annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def loadAnnotations(self, annotationPath,seqSuffix):\n",
    "    '''\n",
    "    This function should allow adding interval metadata (annotations) to sequence (nucleotide) graph. It has never been properly tested.\n",
    "    '''\n",
    "    if len(self.nodesData[0])==0:\n",
    "        warnings.warn('Annotation can be applied only to sequence graph, but no sequence associated with nodes was found. Aborted.')\n",
    "        return\n",
    "\n",
    "    for accID,path in zip(self.accessions,self.paths):\n",
    "        absPosStart = 0\n",
    "        annotation = skbio_read(f'{annotationPath}{os.path.sep}{accID}.gff',format='gff3',into=IntervalMetadata,seq_id=f'{accID}{seqSuffix}')\n",
    "        for nodestrand in path:\n",
    "            nodeNum = int(nodesstrand[:-1])\n",
    "            nodeDict = self.nodeAnnotation[nodeNum-1].setdefault(accID,{})\n",
    "            nodeLen = len(self.nodesData[nodeNum-1])\n",
    "            nodeAnnotationGen = annotation.query((absPosStart+1,absPosStart+nodeLen))\n",
    "            for na in nodeAnnotationGen:\n",
    "                if na.bounds[0]<absPosStart+1:\n",
    "                    leftNodeBound = 1\n",
    "                else:\n",
    "                    leftNodeBound = na.bound[0] - absPosStart\n",
    "\n",
    "                if na.bound[1]<absPosStart+nodeLen:\n",
    "                    rightNodeBound = na.bound[1] - absPosStart\n",
    "                else:\n",
    "                    rightNodeBound = nodeLen\n",
    "\n",
    "                ogName = na.metadata['OG']\n",
    "                atNamesStr = na.metadata.get('AT')\n",
    "\n",
    "                nodeDict.setdefault(ogName,[]).append((leftNodeBound,rightNodeBound))\n",
    "\n",
    "                if atNamesStr is not None:\n",
    "                    atNameList = atNameStr.split(',')\n",
    "                    for atName in atNameList:\n",
    "                        nodeDict.setdefault(atName,[]).append((leftNodeBound,rightNodeBound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create annotation from nodes (artificial annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def updateAnnotationFromNodes(self,isSeq=True):\n",
    "    '''\n",
    "    This function is used only for primitive block graphs (e.g. gene and chain graphs)\n",
    "    if there is no proper annotation available (e.g. graph was created from paths and \n",
    "    some extra information about nodes is needed).\n",
    "\n",
    "    It takes \"name\" of each node either from `graph.nodes` (if `isSeq` is False) or\n",
    "    from `graph.nodesData` (if `isSeq` is True).\n",
    "\n",
    "    Parameters\n",
    "    ##########\n",
    "\n",
    "    `isSeq`: Whether it contains names as names or as seq.\n",
    "    '''\n",
    "    offset = 0\n",
    "    for annID in range(len(self.nodesMetadata)):\n",
    "        if isSeq:\n",
    "            nodeSeq = self.nodesData[annID]\n",
    "        else:\n",
    "            nodeSeq = self.nodes[annID]\n",
    "        annEl = self.nodesMetadata[annID]\n",
    "        updatedAnnEl = {}\n",
    "        for pathName in annEl:\n",
    "            updatedAnnEl[pathName] = {'annotation':{nodeSeq:[(0,len(nodeSeq)-1)]}}\n",
    "        self.nodesMetadata[annID] = updatedAnnEl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def generateTremauxTree(self,byPath=True):\n",
    "    '''\n",
    "    This function generates Tremaux tree for our graph. It is not a simple Tremaux tree and requires an adjustment process, which happens inside\n",
    "    the `TremauxTree` class constructor.\n",
    "    '''\n",
    "    \n",
    "    _nxGraph = nx.DiGraph()\n",
    "\n",
    "    for nodeID,toList in self.pureForwardlinks:\n",
    "        if toList is not None:\n",
    "            edgeList = [(nodeID,toItem) for toItem in toList]\n",
    "            _nxGraph.add_edges_from(edgeList)\n",
    "\n",
    "    self.tremauxTree = TremauxTree(_nxGraph,self,byPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _getStartNode(self,bubbleNode):\n",
    "\n",
    "    rootNodes = self.tremauxTree.getRootNodes()\n",
    "\n",
    "    for root in rootNodes:\n",
    "        if nx.has_path(self.tremauxTree,root,bubbleNode):\n",
    "            return root\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _getEdgeValue(self,start,end,unique=False):\n",
    "    '''\n",
    "    A function for calculating the value of an edge in the graph. This value is used in `treeSort`\n",
    "    and plays crucial role.\n",
    "\n",
    "    Originally, simply a number of paths (unique or not-unique) passing through given egde was used, but\n",
    "    that allowed a lot of Mobile Blocks to get into the main fabric as it had one strong edge with a given node.\n",
    "    Now the number of paths (unqiue) are weighted (multiplied) by ratio of paths (non-unique) of this edge \n",
    "    to number of paths outgoing from out node and incoming to in node.\n",
    "\n",
    "    It makes priority calculation much more \"fair\".\n",
    "    '''\n",
    "    if start is None:\n",
    "        endInPathRatio = (self.nodePass[end-1]-self.inPath[end-1])/self.nodePass[end-1]\n",
    "        if unique:\n",
    "            return self.nodePassUnique[end-1]*endInPathRatio\n",
    "        else:\n",
    "            return self.nodePass[end-1]*endInPathRatio\n",
    "    else:\n",
    "        startOutPathRatio = self.edgePaths.get((start,end),0)/self.outPath[start-1]\n",
    "        endInPathRatio = self.edgePaths.get((start,end),0)/self.inPath[end-1]\n",
    "        if unique:\n",
    "            return self.edgePathsUnique.get((start,end),0)*startOutPathRatio*endInPathRatio\n",
    "        else:\n",
    "            return self.edgePaths.get((start,end),0)*startOutPathRatio*endInPathRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def treeSort(self,byPath=True,bubblePriorityThreshold=0.5):\n",
    "    '''\n",
    "    This is the main function for sorting graph. It requires some further work, but works relatively well as is.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    `byPath`: bool. If False, then simple topological sort will be done. This needs further testing as after implementation a lot\n",
    "                    of things changed!\n",
    "                    If True, then more complex Consensus sort is used which tries to preserve consensus \"linearity\" amonth paths.\n",
    "    '''\n",
    "    print('Constructing Tremaux tree')\n",
    "    self.generateTremauxTree(byPath)\n",
    "    print('Done!')\n",
    "    queue = []\n",
    "    stopNodes = set()\n",
    "    stopNodesOrigin = {}\n",
    "    processed = []\n",
    "    self.order = []\n",
    "\n",
    "    print('Getting root nodes')\n",
    "    rootNodes = self.tremauxTree.getRootNodes()\n",
    "\n",
    "    # The first root node won't be added to the order automatically,\n",
    "    # but will be processed as all other nodes.\n",
    "    startNode = rootNodes.pop()\n",
    "    queue.append((None,startNode))\n",
    "\n",
    "    if self.quiet:\n",
    "        p1num = int(len(self.nodes)//100)\n",
    "    \n",
    "    print('Start Loop...')\n",
    "    while len(queue)>0 or len(rootNodes)>0:\n",
    "        if len(queue)==0:\n",
    "            try:\n",
    "                while len(queue)==0:\n",
    "                    startNode = rootNodes.pop()\n",
    "                    queue.append((None,startNode))\n",
    "            except IndexError:\n",
    "                break\n",
    "\n",
    "        startNode,endNode = queue.pop()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f'\\rNodes in order: {len(self.order)}/{len(self.nodes)}',end='')\n",
    "        else:\n",
    "            if len(self.order) % p1num == 0:\n",
    "                print(f'\\rNodes in order: {len(self.order)}/{len(self.nodes)}',end='')\n",
    "\n",
    "        if (startNode,endNode) in processed:\n",
    "            continue\n",
    "        if (startNode in self.order and endNode in self.order):\n",
    "            if not ((startNode,endNode) in processed):\n",
    "                processed.append((startNode,endNode))\n",
    "            continue\n",
    "\n",
    "        endNodeAdded = False\n",
    "\n",
    "        bubblePriorityQueue = []\n",
    "        bubbleEdges = self.tremauxTree.bubbleEdges.inverse.get(endNode,[])+[startNode]\n",
    "        if len(bubbleEdges)>0:\n",
    "            if byPath:\n",
    "                bubbleEdgesOrder = np.argsort([self._getEdgeValue(edge,endNode) for edge in bubbleEdges])\n",
    "            else:\n",
    "                bubbleEdgesOrder = list(range(len(bubbleEdges)))\n",
    "            # Chech that bubble node is not in order already\n",
    "            # Check edgePaths for all outgoing links (including non-bubbles but not loops), use this bubble \n",
    "            # only if the bubble edge has maximum number of paths.\n",
    "            # if this bubble should be used compare edgePaths for bubble edge and for normal edge to \n",
    "            # current node. If normal edge is larger, then add current node to order and node past LCA \n",
    "            # on alternative path(s) to the queue (to be processed next) and after them the descendandts of \n",
    "            # current node. Otherwise, do not add current node to order, but add nodes past LCA and then (to processed later) current node to queue.\n",
    "\n",
    "            for bEdge in bubbleEdgesOrder:\n",
    "                bubbleNode = bubbleEdges[bEdge]\n",
    "                if bubbleNode in self.order and bubbleNode!=startNode:\n",
    "                    continue\n",
    "                if byPath:\n",
    "                    curBubbleEdgePaths = self._getEdgeValue(bubbleNode,endNode)\n",
    "                    if bubbleNode is not None:\n",
    "                        bubbleNodeOutEdges = list(self.tremauxTree.out_edges(bubbleNode)) + \\\n",
    "                                            [(bubbleNode,node) for node in self.tremauxTree.bubbleEdges.get(bubbleNode,[])]\n",
    "                        bubbleNodeOutEdgesValue = [self._getEdgeValue(*edge) for edge in bubbleNodeOutEdges]\n",
    "                    else:\n",
    "                        bubbleNodeOutEdgesValue = [self._getEdgeValue(bubbleNode,endNode)]\n",
    "\n",
    "                    if max(bubbleNodeOutEdgesValue)>curBubbleEdgePaths:\n",
    "                        continue\n",
    "\n",
    "                    if bubbleNode is not None:\n",
    "                        if self._getEdgeValue(bubbleNode,endNode,unique=False)/self.inPath[endNode-1]<bubblePriorityThreshold or \\\n",
    "                        self._getEdgeValue(bubbleNode,endNode,unique=False)/self.outPath[bubbleNode-1]<bubblePriorityThreshold:\n",
    "                            bubblePriority = False\n",
    "                        else:\n",
    "                            bubblePriority = True\n",
    "                    else:\n",
    "                        bubblePriority = True\n",
    "\n",
    "                if bubbleNode!=startNode:\n",
    "                    # We are not on the main (original) edge\n",
    "                    lca = nx.lowest_common_ancestor(self.tremauxTree,endNode,bubbleNode)\n",
    "                    if byPath:\n",
    "                        if lca is None:\n",
    "                            _lca = self._getStartNode(bubbleNode)\n",
    "\n",
    "                        else: \n",
    "                            _lca = lca\n",
    "                        if _lca==bubbleNode:\n",
    "                            # BubbleNode is the top of another tree\n",
    "                            lcaDescendantsToProcess = [(None,bubbleNode)]\n",
    "                        else:\n",
    "                            lcaDescendantsToProcess = [(_lca,node) for node in list(self.tremauxTree[_lca])\\\n",
    "                                                              if node not in self.order and nx.has_path(self.tremauxTree,node,bubbleNode)]\n",
    "                            lcaDescendantsToProcess.sort(key=lambda edge: self.edgePathsUnique.get(edge,0))\n",
    "\n",
    "                        for edge in lcaDescendantsToProcess:\n",
    "                            if edge in queue:\n",
    "                                queue.remove(edge)\n",
    "                        if len(lcaDescendantsToProcess)>0:\n",
    "                            if bubblePriority:\n",
    "                                bubblePriorityQueue.append((bubbleNode,[edge for edge in lcaDescendantsToProcess if edge not in processed]))\n",
    "                            else:\n",
    "                                queue[0:0] = [edge for edge in lcaDescendantsToProcess if edge not in processed and edge[0] is not None]\n",
    "                    else:\n",
    "                        # TODO!!!\n",
    "                        # rewrite pure graph sorting to process alternative branches by adding the top nodes \n",
    "                        # of each branch to the queue for immediate processing.\n",
    "                        pathToAdd = nx.shortest_path(self.tremauxTree,lca,bubbleNode)\n",
    "                        if lca is None:\n",
    "                            allPaths = list(pathToAdd.values())\n",
    "                            allPaths.sort(key=len)\n",
    "                            pathToAdd = allPaths[-1]\n",
    "                        else:\n",
    "                            if endNode not in self.order and byPath:\n",
    "                                self.order.append(endNode)\n",
    "                                endNodeAdded = True\n",
    "                        # WRONG!\n",
    "                        self.order.extend([node for node in pathToAdd if node not in self.order])\n",
    "                else:\n",
    "                    # We consider startNode as bubble\n",
    "                    if byPath:\n",
    "                        if bubblePriority:\n",
    "                            bubblePriorityQueue.append((bubbleNode,(startNode,endNode)))\n",
    "                        else:\n",
    "                            # Do we need to add the current edge back to queue???\n",
    "                            pass\n",
    "\n",
    "\n",
    "        bubblePriorityQueue.sort(key=lambda b: self._getEdgeValue(b[0],endNode))\n",
    "        if len(bubblePriorityQueue)>=1:\n",
    "            # It should save a lot of wasted time and speed up the process.\n",
    "            queueLen = len(queue)\n",
    "            curEdgePassed = False\n",
    "            while len(bubblePriorityQueue)>0:\n",
    "                bNode,bToAdd = bubblePriorityQueue.pop()\n",
    "\n",
    "                if bNode!=startNode:\n",
    "                    queue.extend(bToAdd)\n",
    "                    stopNodes.add(bNode)\n",
    "                    stopNodesOrigin[bNode] = endNode\n",
    "                else:\n",
    "                    if len(bubblePriorityQueue)==0:\n",
    "                        endNodeAdded = self._addNextEdgesToQueue(startNode,endNode,\n",
    "                                                processed,queue,stopNodes,stopNodesOrigin)\n",
    "                        curEdgePassed = True\n",
    "                    else:\n",
    "                        queue.append((startNode,endNode))\n",
    "            if not curEdgePassed:\n",
    "                queue[queueLen:queueLen] = [(startNode,endNode)]\n",
    "        else:\n",
    "            endNodeAdded = self._addNextEdgesToQueue(startNode,endNode,\n",
    "                                                processed,queue,stopNodes,stopNodesOrigin)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _addNextEdgesToQueue(self,startNode,endNode,processed,queue,stopNodes,stopNodesOrigin):\n",
    "    endNodeAdded = False\n",
    "    processed.append((startNode,endNode))\n",
    "    # Should we add start or end???\n",
    "    if endNode not in self.order:\n",
    "        self.order.append(endNode)\n",
    "        endNodeAdded = True\n",
    "\n",
    "    edgesToAdd = [edge for edge in list(self.tremauxTree.edges(endNode)) if edge not in processed and edge not in queue]\n",
    "\n",
    "    edgesToAdd.sort(key=lambda edge: self._getEdgeValue(*edge))\n",
    "    if endNode in stopNodes and len(edgesToAdd)>0:\n",
    "        bubbleEnd = stopNodesOrigin[endNode]\n",
    "        bubbleEndEdge = list(self.tremauxTree.in_edges(bubbleEnd))[0]\n",
    "        try: \n",
    "            bubbleEndEdgeInd = queue.index(bubbleEndEdge)\n",
    "        except ValueError:\n",
    "            bubbleEndEdgeInd = len(queue)\n",
    "\n",
    "        queue[bubbleEndEdgeInd:bubbleEndEdgeInd] = edgesToAdd\n",
    "        stopNodes.remove(endNode)\n",
    "        del stopNodesOrigin[endNode]\n",
    "    else:\n",
    "        queue.extend(edgesToAdd)\n",
    "\n",
    "    return endNodeAdded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export/Save (to GFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def toGFA(self,gfaFile,doSeq=True):\n",
    "    '''\n",
    "        Recording existing graph structures to GFA v1 file + some json and joblib files to preserve extra metadata.\n",
    "    '''\n",
    "    baseName = os.path.splitext(os.path.basename(gfaFile))[0]\n",
    "    dirPath = os.path.dirname(gfaFile)\n",
    "    jsonFile = f'{dirPath}{os.path.sep}nodeNames_{baseName}.json'\n",
    "    annotationFile = f'{dirPath}{os.path.sep}annotation_{baseName}.dat'\n",
    "\n",
    "    gfaWriter = open(gfaFile,mode='w')\n",
    "\n",
    "    gfaWriter.write('H\\tVN:Z:1.0\\n')\n",
    "\n",
    "    translator = {}\n",
    "    nodeNameList = []\n",
    "    nodesMetadata = []\n",
    "\n",
    "    for i,nodeID in enumerate(self.order):\n",
    "        nodeSeq = self.nodesData[nodeID-1]\n",
    "        nodeName = self.nodes[nodeID-1]\n",
    "        nodesMetadata.append(self.nodesMetadata[nodeID-1])\n",
    "        if doSeq and len(nodeSeq)>0:\n",
    "            gfaWriter.write(f'S\\t{i+1}\\t{nodeSeq}\\n')\n",
    "            nodeNameList.append(nodeName)\n",
    "        else:\n",
    "            gfaWriter.write(f'S\\t{i+1}\\t{nodeName}\\n')\n",
    "\n",
    "        translator[nodeID] = i+1\n",
    "\n",
    "    for fromNode,strandLinks in self.forwardLinks.items():\n",
    "        for fromStrand,toLinkStrands in strandLinks.items():\n",
    "            for toNode,toStrand in toLinkStrands:\n",
    "\n",
    "                gfaWriter.write(f'L\\t{translator[fromNode]}\\t{fromStrand}\\t{translator[toNode]}\\t{toStrand}\\t*\\n')\n",
    "\n",
    "    for path,accessionID in zip(self.paths,self.accessions):\n",
    "        newPath = []\n",
    "        for nodeStrand in path:\n",
    "            node = int(nodeStrand[:-1])\n",
    "            strand = nodeStrand[-1]\n",
    "            newPath.append(f'{translator[node]}{strand}')\n",
    "        gfaWriter.write(f'P\\t{accessionID}\\t{\",\".join(newPath)}\\t*\\n')\n",
    "\n",
    "    gfaWriter.write('\\n')\n",
    "    gfaWriter.close()\n",
    "\n",
    "    if len(nodeNameList)==len(self.nodes):\n",
    "        with open(jsonFile,'w') as jsf:\n",
    "            json.dump(nodeNameList,jsf)\n",
    "\n",
    "    if len(nodesMetadata)==len(self.nodes):\n",
    "        joblib.dump(nodesMetadata,annotationFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elements operations (for nodes, links, annotations, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add node, link and accession (not properly implemented or not tested)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here another function is needed to add accession with relevant provate nodes and links. Then possibly the functions below will be used\n",
    "but as private function, not external API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export        \n",
    "@patch_to(GenomeGraph)\n",
    "def addAccessionAnnotation(self,annotationFile,sequenceFile=None):\n",
    "    '''\n",
    "    Ideally, a function should be able to add one accesstion to existing graph. \n",
    "    When implemented, `_graphFromAnnotation` should be using this function.\n",
    "\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def addLink(self,fromNode,fromStrand,toNode,toStrand):\n",
    "    '''\n",
    "    Need testing. Not sure if it actually makes sense as links not present in any of the paths does not play any role.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if fromNode not in self.nodes:\n",
    "        raise IndexError(f'Node {fromNode} is not in nodes list')\n",
    "    if toNode not in self.nodes:\n",
    "        raise IndexError(f'Node {toNode} is not in nodes list')\n",
    "\n",
    "    if fromNode not in self.forwardLinks.keys():\n",
    "        self.forwardLinks[fromNode] = {}\n",
    "        self.forwardLinks[fromNode][fromStrand] = []\n",
    "\n",
    "    elif fromStrand not in self.forwardLinks[fromNode].keys():\n",
    "        self.forwardLinks[fromNode][fromStrand] = []\n",
    "\n",
    "    self.forwardLinks[fromNode][fromStrand].append([toNode,toStrand])\n",
    "\n",
    "    if self.isBack:\n",
    "        if toNode not in self.backLinks.keys():\n",
    "            self.backLinks[toNode] = {}\n",
    "            self.backLinks[toNode][toStrand] = []\n",
    "\n",
    "        elif toStrand not in self.backLinks[toNode].keys():\n",
    "            self.backLinks[toNode][toStrand] = []\n",
    "\n",
    "        self.backLinks[toNode][toStrand].append([fromNode,fromStrand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def addNode(self,nodeID,data=None):\n",
    "    '''\n",
    "    Need testing. Again, there is no point of adding a node to a graph if this node will not be present in any of the paths.\n",
    "    '''\n",
    "    \n",
    "    if nodeID not in self.nodes:\n",
    "        self.nodes.append(nodeID)\n",
    "        self.nodesData[nodeID] = data\n",
    "    else:\n",
    "        warnings.warn(f'You attempted to add node with {nodeID}, but it already exists in the graph. The addition was ignored.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "# Node inversion functionality\n",
    "@patch_to(GenomeGraph)\n",
    "def invertNodes(self):\n",
    "    '''\n",
    "    This function look at inversion/strand of each node in each path. If more than half of paths passing node in \"inverted\"\n",
    "    direction, then inverstion should be switched over (currently inverted passes should become normal and normal passes should become inverted.) \n",
    "    It is done every time a graph is loaded. Possibly, it should be possible to not doing it as it will take a lot of time for larger graphs.\n",
    "    '''\n",
    "    \n",
    "    nodeLengths = calcNodeLengths(self)\n",
    "    pathLengths,pathNodeArray,pathNodeLengths,pathDirArray,pathNodeLengthsCum = initialPathAnalysis(self,nodeLengths)\n",
    "\n",
    "    p1num = int(len(self.nodes) // 100)\n",
    "    \n",
    "    for nodeID in range(len(self.nodes)):\n",
    "        if self.nodeStrandPaths[nodeID][1]>self.nodeStrandPaths[nodeID][0]:\n",
    "            if not self.quiet:\n",
    "                print(f'\\rNode {nodeID+1} inverted',end='')\n",
    "            else:\n",
    "                if (nodeID % p1num == 0):\n",
    "                    print(f'\\rNode {nodeID+1}/{len(self.nodes)} processed for inversion', end='')\n",
    "            self._invertNode(nodeID,pathNodeArray)\n",
    "\n",
    "    self._pathCount()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch_to(GenomeGraph)\n",
    "def _invertNode(self,nodeID,pathNodeArray):\n",
    "\n",
    "    self.nodesData[nodeID] = inverseSequence(self.nodesData[nodeID])\n",
    "\n",
    "    pathIDs,positions = np.where(pathNodeArray==nodeID+1)\n",
    "    strandreversal = {'+':'-','-':'+'}\n",
    "    for pathID,pos in zip(pathIDs,positions):\n",
    "        nodeStrand = self.paths[pathID][pos]\n",
    "        self.paths[pathID][pos] = nodeStrand[:-1]+strandreversal[nodeStrand[-1]]\n",
    "\n",
    "    nodeFromLink = self.forwardLinks.get(nodeID+1,{})\n",
    "    positiveStrand = nodeFromLink.get('+',[])\n",
    "    negativeStrand = nodeFromLink.get('-',[])\n",
    "\n",
    "    if len(positiveStrand)>0:\n",
    "        self.forwardLinks[nodeID+1]['-'] = positiveStrand\n",
    "    else:\n",
    "        if len(negativeStrand)>0:\n",
    "            del self.forwardLinks[nodeID+1]['-']\n",
    "\n",
    "    if len(negativeStrand)>0:\n",
    "        self.forwardLinks[nodeID+1]['+'] = negativeStrand\n",
    "    else:\n",
    "        if len(positiveStrand)>0:\n",
    "            del self.forwardLinks[nodeID+1]['+']\n",
    "\n",
    "    revertLinks = self._revertLinks()        \n",
    "    nodeToLink = revertLinks.get(nodeID+1,{})\n",
    "    positiveStrand = nodeToLink.get('+',[])\n",
    "    negativeStrand = nodeToLink.get('-',[])\n",
    "\n",
    "    for fromNode,fromStrand in positiveStrand:\n",
    "        self.forwardLinks[fromNode][fromStrand].remove((nodeID+1,'+'))\n",
    "        self.forwardLinks[fromNode][fromStrand].append((nodeID+1,'-'))\n",
    "\n",
    "    for fromNode,fromStrand in negativeStrand:\n",
    "        self.forwardLinks[fromNode][fromStrand].remove((nodeID+1,'-'))\n",
    "        self.forwardLinks[fromNode][fromStrand].append((nodeID+1,'+'))\n",
    "\n",
    "    positiveOverlap = self.overlaps.pop((nodeID+1,'+'),0)\n",
    "    negativeOverlap = self.overlaps.pop((nodeID+1,'-'),0)\n",
    "    if positiveOverlap>0:\n",
    "        self.overlaps[(nodeID+1,'-')] = positiveOverlap\n",
    "    if negativeOverlap>0:\n",
    "        self.overlaps[(nodeID+1,'+')] = negativeOverlap\n",
    "\n",
    "# End of node inversion functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node removal methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "# node removal functionality\n",
    "@patch_to(GenomeGraph)\n",
    "def _removePositionsFromPaths(self,pathIDs,positions):\n",
    "    print('Removing empty nodes from paths')\n",
    "    print('paths')\n",
    "    print(self.paths)\n",
    "    for pathID in np.unique(pathIDs):\n",
    "        offset = 0\n",
    "        posArray  = np.sort(np.array(positions)[np.array(pathIDs)==pathID])\n",
    "        for pos in posArray:\n",
    "            print(f'{pathID} - {pos}')\n",
    "            del self.paths[pathID][pos-offset]\n",
    "            offset += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _updateLinkList(self,strandList,offsetDict):\n",
    "    newStrand = []\n",
    "    for toNode,toStrand in strandList:\n",
    "        newStrand.append((offsetDict[toNode-1]+1,toStrand))\n",
    "    return newStrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _clearNodes(self,nodeIDs):\n",
    "    print('nodeIDs')\n",
    "    print(nodeIDs)\n",
    "    print('paths')\n",
    "    print(self.paths)\n",
    "    offsetDict = {node:node for node in range(len(self.nodes))}\n",
    "    for nodeID in nodeIDs:\n",
    "        print(f'Removing node {nodeID+1}')\n",
    "        updatedNodeID = offsetDict[nodeID]\n",
    "        nodeName = self.nodes[updatedNodeID]\n",
    "        del self.nodeNameToID[nodeName]\n",
    "        del self.nodes[updatedNodeID]\n",
    "        del self.nodesData[updatedNodeID]\n",
    "        self.order.remove(nodeID+1)\n",
    "        del offsetDict[nodeID]\n",
    "        offsetDict.update({k:v-1 for k,v in offsetDict.items() if k>nodeID})\n",
    "\n",
    "\n",
    "    self.order = [offsetDict[el-1]+1 for el in self.order]\n",
    "    self.nodeNameToID.update({k:offsetDict[v-1]+1 for k,v in self.nodeNameToID.items()})\n",
    "\n",
    "    for pathID in range(len(self.paths)):\n",
    "        self.paths[pathID] = [f'{offsetDict[int(el[:-1])-1]+1}{el[-1]}' for el in self.paths[pathID]]\n",
    "\n",
    "    print('paths')\n",
    "    print(self.paths)\n",
    "    print('offsetDict')\n",
    "    print(offsetDict)\n",
    "\n",
    "    nodesInForwardLinks = list(self.forwardLinks.keys())\n",
    "    for node in sorted(nodesInForwardLinks):\n",
    "        nodeDict = self.forwardLinks[node]\n",
    "        newNode = offsetDict[node-1]+1\n",
    "        if node!=newNode:\n",
    "            del self.forwardLinks[node]\n",
    "        forwardStrand = self._updateLinkList(nodeDict.get('+',[]),offsetDict)\n",
    "        inverseStrand = self._updateLinkList(nodeDict.get('-',[]),offsetDict)\n",
    "\n",
    "        if len(forwardStrand)>0:\n",
    "            self.forwardLinks.setdefault(newNode,{})['+'] = forwardStrand\n",
    "        if len(inverseStrand)>0:\n",
    "            self.forwardLinks.setdefault(newNode,{})['-'] = inverseStrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _removeNode(self,nodeID,revertLinks,pathNodeArray):\n",
    "    pathIDs,positions = np.where(pathNodeArray==nodeID+1)\n",
    "\n",
    "    excludeTuples = [(nodeID+1,'+'),(nodeID+1,'-')]\n",
    "\n",
    "    nodeToLink = revertLinks.get(nodeID+1,{})\n",
    "    toPositiveStrand = nodeToLink.get('+',[])\n",
    "    toNegativeStrand = nodeToLink.get('-',[])\n",
    "\n",
    "    nodeFromLink = self.forwardLinks.get(nodeID+1,{})\n",
    "    fromPositiveStrand = nodeFromLink.get('+',[])\n",
    "    fromNegativeStrand = nodeFromLink.get('-',[])\n",
    "\n",
    "    for fromNode,fromStrand in toPositiveStrand:\n",
    "        # Amending forwardLinks for positive strand of current node\n",
    "        forwardNodeStrand = self.forwardLinks.get(fromNode,{}).get(fromStrand,[])\n",
    "        forwardNodeStrand = list(set(forwardNodeStrand).union(fromPositiveStrand).difference(excludeTuples))\n",
    "        self.forwardLinks[fromNode][fromStrand] = forwardNodeStrand\n",
    "\n",
    "    for fromNode,fromStrand in toNegativeStrand:\n",
    "        # Amend forwardLinks for negative strand of current node\n",
    "        forwardNodeStrand = self.forwardLinks.get(fromNode,{}).get(fromStrand,[])\n",
    "        forwardNodeStrand = list(set(forwardNodeStrand).union(fromNegativeStrand).difference(excludeTuples))\n",
    "        self.forwardLinks[fromNode][fromStrand] = forwardNodeStrand\n",
    "\n",
    "    for toNode,toStrand in fromPositiveStrand:\n",
    "        # Amending revertLinks for positive strand of current node\n",
    "        revertNodeStrand = revertLinks.get(toNode,{}).get(toStrand,[])\n",
    "        revertNodeStrand = list(set(revertNodeStrand).union(toPositiveStrand).difference(excludeTuples))\n",
    "        revertLinks[toNode][toStrand] = revertNodeStrand\n",
    "\n",
    "    for toNode,toStrand in fromNegativeStrand:\n",
    "        # Amend revertLinks for negative strand of current node\n",
    "        revertNodeStrand = revertLinks.get(toNode,{}).get(toStrand,[])\n",
    "        revertNodeStrand = list(set(revertNodeStrand).union(toNegativeStrand).difference(excludeTuples))\n",
    "        revertLinks[toNode][toStrand] = revertNodeStrand\n",
    "\n",
    "    del revertLinks[nodeID+1]\n",
    "    del self.forwardLinks[nodeID+1]\n",
    "\n",
    "    return pathIDs,positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def removeNodes(self,nodeIDsToRemove):\n",
    "    '''\n",
    "    This (and related to it) function allows removal of a node from a graph. In normal situation, it should not be done to a graph\n",
    "    as it will make it invalid in most cases, it is very important functionality for removal of overlaps (see below).\n",
    "    '''\n",
    "    revertLinks = self._revertLinks()\n",
    "    nodeLengths = calcNodeLengths(self)\n",
    "    _,pathNodeArray,_,_,_ = initialPathAnalysis(self,nodeLengths)\n",
    "\n",
    "    pathIDs = []\n",
    "    positions = []\n",
    "    for nodeID in nodeIDsToRemove:\n",
    "        pID,pos = self._removeNode(nodeID,revertLinks,pathNodeArray)\n",
    "        pathIDs.extend(pID)\n",
    "        positions.extend(pos)\n",
    "\n",
    "    self._removePositionsFromPaths(pathIDs,positions)\n",
    "    self._clearNodes(nodeIDsToRemove)\n",
    "\n",
    "    self._pathCount()\n",
    "\n",
    "#end of node removal functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node Substitution (not implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "# Node substitution functionality\n",
    "\n",
    "# End of node substitution functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node overlap removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "# Overlap removal functionality\n",
    "@patch_to(GenomeGraph)\n",
    "def _linkBounce(self,fromNodeStart,fromStrandStart,revertLinks,nodeLengths,kmerOverlap,cutOffsetRight,leftCut,rightCut):\n",
    "    cutOffsetLeft = 0\n",
    "    leftToCut = [(fromNodeStart,fromStrandStart)]\n",
    "    rightToCut = []\n",
    "    leftToProcess = [(fromNodeStart,fromStrandStart)]\n",
    "    rightToProcess = []\n",
    "    while (len(leftToProcess)>0 or len(rightToProcess)>0):\n",
    "        for node,strand in leftToProcess:\n",
    "            rightSide = self.forwardLinks.get(node,{}).get(strand,[])\n",
    "            for toNode,toStrand in rightSide:\n",
    "                if toStrand=='+':\n",
    "                    cutOffsetLeft = max(leftCut.get(toNode,0),cutOffsetLeft)\n",
    "                else:\n",
    "                    cutOffsetLeft = max(rightCut.get(toNode,0),cutOffsetLeft)\n",
    "\n",
    "                if cutOffsetLeft<kmerOverlap-cutOffsetRight and (toNode,toStrand) not in rightToCut:# and nodeLengths[toNode-1]>0:\n",
    "                    rightToCut.append((toNode,toStrand))\n",
    "                    rightToProcess.append((toNode,toStrand))\n",
    "        leftToProcess = []\n",
    "\n",
    "        for node,strand in rightToProcess:\n",
    "            leftSide = revertLinks.get(node,{}).get(strand,[])\n",
    "            for fromNode,fromStrand in leftSide:\n",
    "                if fromStrand=='+':\n",
    "                    cutOffsetRight = max(rightCut.get(fromNode,0),cutOffsetRight)\n",
    "                else:\n",
    "                    cutOffsetRight = max(leftCut.get(fromNode,0),cutOffsetRight)\n",
    "\n",
    "                if cutOffsetRight<kmerOverlap-cutOffsetLeft and (fromNode,fromStrand) not in leftToCut:# and nodeLengths[fromNode-1]>0:\n",
    "                    leftToCut.append((fromNode,fromStrand))\n",
    "                    leftToProcess.append((fromNode,fromStrand))\n",
    "        rightToProcess = []\n",
    "\n",
    "    return leftToCut,rightToCut,cutOffsetLeft,cutOffsetRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _processBouncedLink(self,leftToCut,rightToCut,kmerOverlap,cutOffsetLeft,cutOffsetRight,nodeLengths,leftCut,rightCut,leftForbidden,rightForbidden):\n",
    "    toCut = kmerOverlap - cutOffsetLeft - cutOffsetRight\n",
    "    minLengthRight = min([nodeLengths[node-1] for node,strand in rightToCut])\n",
    "    minLengthLeft = min([nodeLengths[node-1] for node,strand in leftToCut])\n",
    "    isRightForbidden = np.any([ns in rightForbidden for ns in rightToCut ])\n",
    "    isLeftForbidden = np.any([ns in leftForbidden for ns in leftToCut ])\n",
    "\n",
    "    if isRightForbidden and isLeftForbidden:\n",
    "        return\n",
    "\n",
    "    if (minLengthRight<minLengthLeft and not isRightForbidden) or isLeftForbidden:\n",
    "        sideToCut = rightToCut\n",
    "        sideToKeep = leftToCut\n",
    "        globalPositiveSide = leftCut\n",
    "        globalNegativeSide = rightCut\n",
    "        side = 'right'\n",
    "    else:\n",
    "        sideToCut = leftToCut\n",
    "        sideToKeep = rightToCut\n",
    "        globalPositiveSide = rightCut\n",
    "        globalNegativeSide = leftCut\n",
    "        side = 'left'\n",
    "\n",
    "    maxCutAdjustment = max([max(toCut - nodeLengths[node-1],0) for node,strand in sideToCut])\n",
    "    if toCut>maxCutAdjustment:\n",
    "        for node,strand in sideToCut:\n",
    "            if strand=='+':\n",
    "                if side =='right':\n",
    "                    self.nodesData[node-1] = self.nodesData[node-1][toCut-maxCutAdjustment:]\n",
    "                else:\n",
    "                    self.nodesData[node-1] = self.nodesData[node-1][:-(toCut-maxCutAdjustment)]\n",
    "                globalPositiveSide[node] = globalPositiveSide.get(node,0) + toCut - maxCutAdjustment\n",
    "            else:\n",
    "                if side =='left':\n",
    "                    self.nodesData[node-1] = self.nodesData[node-1][toCut-maxCutAdjustment:]\n",
    "                else:\n",
    "                    self.nodesData[node-1] = self.nodesData[node-1][:-(toCut-maxCutAdjustment)]\n",
    "                globalNegativeSide[node] = globalNegativeSide.get(node,0) + toCut - maxCutAdjustment\n",
    "            nodeLengths[node-1] -= toCut - maxCutAdjustment\n",
    "\n",
    "    if maxCutAdjustment>0:\n",
    "        # adjust the other side as well.\n",
    "        for node,strand in sideToKeep:\n",
    "            if strand=='+':\n",
    "                if side =='right':\n",
    "                    self.nodesData[node-1] = self.nodesData[node-1][:-(maxCutAdjustment)]\n",
    "                else:\n",
    "                    self.nodesData[node-1] = self.nodesData[node-1][maxCutAdjustment:]\n",
    "                globalNegativeSide[node] = globalNegativeSide.get(node,0) + maxCutAdjustment\n",
    "            else:\n",
    "                if side =='left':\n",
    "                    self.nodesData[node-1] = self.nodesData[node-1][:-(maxCutAdjustment)]\n",
    "                else:\n",
    "                    self.nodesData[node-1] = self.nodesData[node-1][maxCutAdjustment:]\n",
    "                globalPositiveSide[node] = globalPositiveSide.get(node,0) + maxCutAdjustment\n",
    "            nodeLengths[node-1] -= maxCutAdjustment\n",
    "    for nodeStrand in leftToCut:\n",
    "        del self.overlaps[nodeStrand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch_to(GenomeGraph)\n",
    "def removeOverlaps(self):\n",
    "    '''\n",
    "    When the graph (nucleotide only) is loaded, overlaps are allowed and can be provided using CIGAR strings (it will not be checked).\n",
    "    Such overlaps can appear for instance when a compacted de bruijn graph is used (e.g. generated by CUTTLEFISH). They should be removed \n",
    "    in order to make the graph not artificially overcomplicated.\n",
    "    \n",
    "    Unfortunately, this current implementation is not working properly and needs to be looked at in details. It is most probably\n",
    "    overcomplicated and overthought. It should be relatively easy to do.\n",
    "    '''\n",
    "    nodeIDsToRemove = []\n",
    "    leftCut = {}\n",
    "    rightCut = {}\n",
    "\n",
    "    leftForbidden = list(set([(int(path[-1][:-1]),path[-1][-1]) for path in self.paths])) # Nodes which should not be cut on the left side of link\n",
    "    rightForbidden = list(set([(int(path[0][:-1]),path[-1][-1]) for path in self.paths])) # Nodes which should not be cut on the right side of link\n",
    "\n",
    "    revertLinks = self._revertLinks()\n",
    "    nodeLengths = calcNodeLengths(self)\n",
    "    print('nodeLengths')\n",
    "    print(nodeLengths)\n",
    "\n",
    "    for fromNode in self.order:\n",
    "        print('-----------')\n",
    "        print(f'Processing node {fromNode}')\n",
    "        if (fromNode,'+') in self.overlaps:\n",
    "            print(f'Working on forward strand')\n",
    "            kmerOverlap = self.overlaps[(fromNode,'+')]\n",
    "            cutOffsetRight = rightCut.get(fromNode,0)\n",
    "            print(f'Initial overlap={kmerOverlap}')\n",
    "            print(f'Initial cutOffsetRight={cutOffsetRight}')\n",
    "            if cutOffsetRight<kmerOverlap and nodeLengths[fromNode-1]>0:\n",
    "                leftToCut,rightToCut,cutOffsetLeft,cutOffsetRight = self._linkBounce(fromNode,'+',\n",
    "                                                                                     revertLinks,\n",
    "                                                                                     nodeLengths,\n",
    "                                                                                     kmerOverlap,\n",
    "                                                                                     cutOffsetRight,\n",
    "                                                                                     leftCut,\n",
    "                                                                                     rightCut)\n",
    "                print('leftToCut')\n",
    "                print(leftToCut)\n",
    "                print('rightToCut')\n",
    "                print(rightToCut)\n",
    "                print(f'cutOffsetLeft={cutOffsetLeft}; cutOffsetRight={cutOffsetRight}')\n",
    "                # process only if both leftToCut and rightToCut have some elements\n",
    "                if len(leftToCut)>0 and len(rightToCut)>0:\n",
    "                    self._processBouncedLink(leftToCut,\n",
    "                                             rightToCut,\n",
    "                                             kmerOverlap,\n",
    "                                             cutOffsetLeft,\n",
    "                                             cutOffsetRight,\n",
    "                                             nodeLengths,\n",
    "                                             leftCut,\n",
    "                                             rightCut,\n",
    "                                             leftForbidden,\n",
    "                                             rightForbidden)\n",
    "                print('leftCut')\n",
    "                print(leftCut)\n",
    "                print('rightCut')\n",
    "                print(rightCut)\n",
    "                print('nodeLengths')\n",
    "                print(nodeLengths)\n",
    "\n",
    "        if (fromNode,'-') in self.overlaps:\n",
    "            print(f'Working on inverse strand')\n",
    "            kmerOverlap = self.overlaps[(fromNode,'-')]\n",
    "            cutOffsetRight = leftCut.get(fromNode,0)\n",
    "            print(f'Initial overlap={kmerOverlap}')\n",
    "            print(f'Initial cutOffsetRight={cutOffsetRight}')\n",
    "            if cutOffsetRight<kmerOverlap and nodeLengths[fromNode-1]>0:\n",
    "                leftToCut,rightToCut,cutOffsetLeft,cutOffsetRight = self._linkBounce(fromNode,'-',\n",
    "                                                                                     revertLinks,\n",
    "                                                                                     nodeLengths,\n",
    "                                                                                     kmerOverlap,\n",
    "                                                                                     cutOffsetRight,\n",
    "                                                                                     leftCut,\n",
    "                                                                                     rightCut)\n",
    "                print('leftToCut')\n",
    "                print(leftToCut)\n",
    "                print('rightToCut')\n",
    "                print(rightToCut)\n",
    "                print(f'cutOffsetLeft={cutOffsetLeft}; cutOffsetRight={cutOffsetRight}')\n",
    "                if len(leftToCut)>0 and len(rightToCut)>0:\n",
    "                    self._processBouncedLink(leftToCut,\n",
    "                                             rightToCut,\n",
    "                                             kmerOverlap,\n",
    "                                             cutOffsetLeft,\n",
    "                                             cutOffsetRight,\n",
    "                                             nodeLengths,\n",
    "                                             leftCut,\n",
    "                                             rightCut,\n",
    "                                             leftForbidden,\n",
    "                                             rightForbidden)\n",
    "                print('leftCut')\n",
    "                print(leftCut)\n",
    "                print('rightCut')\n",
    "                print(rightCut)\n",
    "                print('nodeLengths')\n",
    "                print(nodeLengths)\n",
    "    nodeIDsToRemove = [i for i,l in enumerate(nodeLengths) if l==0]\n",
    "    if len(nodeIDsToRemove)>0:\n",
    "        self.removeNodes(nodeIDsToRemove)\n",
    "# End of overlap removal functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link conversion methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two different types of data sructure for links: based on sets and dicts. Normally, dict type is used, but for some specific operation\n",
    "sets type is needed. The following two function does the convertion between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _linksDictToSet(self,dictLinks):\n",
    "    setLinks = {}\n",
    "    for fromNode,strandLinks in dictLinks.items():\n",
    "        for fromStrand,linkList in strandLinks.items():\n",
    "            for toNode,toStrand in linkList:\n",
    "                fromNodeStrand = f'{fromNode}{fromStrand}'\n",
    "                toNodeStrand = f'{toNode}{toStrand}'\n",
    "                if fromNodeStrand not in setLinks.keys():\n",
    "                    setLinks[fromNodeStrand] = set()\n",
    "                setLinks[fromNodeStrand].add(toNodeStrand)\n",
    "    return setLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def _linksSetToDict(self,setLinks):\n",
    "    dictLinks = {}\n",
    "    for fromNodeStrand,links in setLinks.items():\n",
    "        fromNode = int(fromNodeStrand[:-2])\n",
    "        fromStrand = fromNodeStrand[-1]\n",
    "        for toNodeStrand in links:\n",
    "            toNode = int(toNodeStrand[:-2])\n",
    "            toStrand = toNodeStrand[-1]\n",
    "\n",
    "            if fromNode not in dictLinks.keys():\n",
    "                dictLinks[fromNode] = {}\n",
    "                dictLinks[fromNode][fromStrand] = []\n",
    "\n",
    "            elif fromStrand not in dictLinks[fromNode].keys():\n",
    "                dictLinks[fromNode][fromStrand] = []\n",
    "\n",
    "            dictLinks[fromNode][fromStrand].append((toNode,toStrand))\n",
    "    return dictLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class enumerator (nodes) and subscription (links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def __iter__(self,forward=True):\n",
    "    for i in range(len(self.nodes)):\n",
    "        yield i+1,self.forwardLinks.get(i+1,{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "@patch_to(GenomeGraph)\n",
    "def __getitem__(self,ind):\n",
    "    if isinstance(ind,tuple):\n",
    "        nodeID = ind[0]\n",
    "        forward = ind[1]\n",
    "    else:\n",
    "        nodeID = ind\n",
    "        forward = True\n",
    "\n",
    "    if nodeID>len(self.nodes):\n",
    "        raise IndexError('The nodeID index {nodeID} is out of range')\n",
    "\n",
    "    if not forward and self.isBack:\n",
    "        return self.backLinks.get(nodeID,{})\n",
    "    else:\n",
    "        return self.forwardLinks.get(nodeID,{})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
